%YAML 1.1
%TAG !u! tag:unity3d.com,2011:
--- !u!114 &11400000
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 0}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: ffdd4f9587b2d8846a37ba5240ae14b2, type: 3}
  m_Name: Sigma
  m_EditorClassIdentifier: 
  version: 34
  assetCreated: 1
  serializedModules:
  - name: Dense
    dense:
      bias: 1
      weights:
        data:
        - 0.06647226
        - -0.06815179
        - 0.13048412
        - -0.03583467
        - -0.33388188
        - -0.5396112
        - -0.20588098
        - 0.21888787
        - -0.4547791
        - 0.09269016
        - 0.21612257
        - -0.6056907
        - -0.15109667
        - 0.50143635
        - 0.2945824
        - -0.4622491
        - -0.014914271
        - -0.7015994
        - 0.038760316
        - 0.2259247
        - -0.11880048
        - 0.7272186
        - -0.16338757
        - -0.5662491
        - 0.11037679
        - -0.22917703
        - -0.16707468
        - -0.70625436
        - -0.2835698
        - 0.019949902
        - -0.47695935
        - 0.5338138
        - 0.6278743
        - -0.7267651
        - -0.7866493
        - 0.5711787
        - 0.65021205
        - -0.07076683
        - -0.3295074
        - 0.30837956
        - -0.19405784
        - 0.15076166
        - -0.39397871
        - 0.54216367
        - 0.43419996
        - 0.18799894
        - -0.5377027
        - -0.24168801
        - 0.94510084
        - -0.5289105
        - -0.06470366
        - 0.29474512
        - -0.52013916
        - -0.47626242
        - 1.014832
        - -0.25966296
        - 0.28513294
        - 0.6772213
        - -0.084366806
        - -0.1761779
        - -0.24939525
        - 0.15286425
        - 0.24191657
        - 0.23636302
        - 0.34007284
        - -0.57108396
        - -0.75956607
        - 0.2517199
        - -0.026555672
        - 0.015003452
        - -1.3226322
        - 0.607603
        - -0.10989022
        - -0.62261206
        - -0.3787496
        - -0.07547304
        - 0.3068929
        - 0.3151229
        - 0.48714083
        - 0.47847432
        - -0.7147715
        - 0.5645757
        - -0.31757692
        - 0.086830266
        - -0.6750091
        - -0.102435715
        - 0.05839897
        - 0.65046996
        - 0.0647085
        - -0.115604006
        - -0.25142255
        - 0.0052805804
        - -1.0376985
        - -0.59049875
        - -1.0142329
        - 0.30855283
        - -0.3921619
        - -0.4604108
        - 0.4148013
        - 0.36260504
        - 0.24736503
        - 0.7814552
        - -0.13941613
        - -0.6777852
        - 0.61906433
        - -0.49659184
        - 0.047227807
        - -0.124805294
        - -0.71001583
        - 0.17116226
        - 0.11603793
        - 0.080231816
        - 0.6790268
        - -0.0025328759
        - 0.023417665
        - -0.788189
        - 0.5354123
        - 0.05780731
        - -0.7217634
        - 0.6743097
        - 0.8062094
        - 0.42704335
        - -0.5438609
        - 0.3755815
        - 0.55179274
        - 0.62370676
        - -0.6216296
        - 0.4270476
        - -0.77575237
        - 0.5582012
        - -1.1551317
        - -0.057166953
        - 0.25676423
        - -0.8106554
        - -0.67986554
        - 0.578088
        - 0.263717
        - 0.07561147
        - 0.29289433
        - 0.621653
        - 0.8740876
        - -0.55773866
        - 0.78869087
        - -0.7415871
        - 0.4785756
        - 0.29420432
        - -0.6770875
        - -0.04947206
        - -0.3476433
        - -0.6206807
        - 1.0242002
        - 0.39905274
        - 0.7910505
        - 0.6741605
        - 0.6353744
        - 0.47939306
        - 0.40317753
        - -0.21857381
        - -0.08786143
        - 0.028046161
        - 0.54727966
        - -0.7218584
        - -0.61054707
        - 0.3150627
        - -0.28286678
        - -0.053151023
        - -0.1772648
        - 0.4237124
        - 0.5259668
        - -0.07444433
        - 0.91992736
        - 0.58006734
        - 0.44307864
        - 0.2332174
        - 0.2277437
        - 0.2042794
        - -0.99832505
        - 0.6989816
        - -0.5427814
        - -0.67548823
        - -0.57806665
        - -0.08782163
        - -0.14097339
        - 0.6490619
        - -0.31979224
        - -0.57436347
        - 0.024037186
        - -0.5075703
        - -0.432161
        - 0.35976896
        - 0.81885654
        - -0.18511243
        - -0.1507169
        - 0.13334125
        - -0.49821058
        - -0.03161374
        - -0.60354567
        - 0.2735275
        - 0.68312424
        - 0.6441185
        - -0.27265307
        - 0.65992785
        - -0.4167028
        - -0.079684824
        - -0.6762637
        - 0.44901308
        - -0.74266016
        - 0.14228623
        - 0.24675703
        - 0.10072658
        - 0.72964
        - -0.7164143
        - 0.14267507
        - 0.3525831
        - 0.8726063
        - -0.6573481
        - 0.4439909
        - -0.34718928
        - -0.8716527
        - 0.060487032
        - -0.29924822
        - -0.15103494
        - -0.5008145
        - 0.024929766
        - 0.090002224
        - -0.14138891
        - 0.55098814
        - -0.2146847
        - -0.2984333
        - 0.028165007
        - 0.6485639
        - 0.4315009
        - 0.91862035
        - 0.12786302
        - 0.23623618
        - 0.4369623
        - 0.41336346
        - 0.8732599
        - 0.8293235
        - -0.1940844
        - -0.6303084
        - 0.5731455
        - -0.3283486
        - -0.2859145
        - 0.28915846
        - 0.26880926
        - 0.31337246
        - -0.7644306
        - -0.5320936
        - 0.6951562
        - -0.0139621645
        - 0.66289985
        - -0.89084405
        - -0.25460112
        - 0.14401197
        - -0.24395922
        - -0.9028483
        - 0.0075428383
        - -0.12613118
        - -0.111132756
        - -0.11807309
        - -0.4520513
        - -0.49847314
        - -0.32656583
        - -0.697697
        - -0.15854974
        - -0.03650166
        - -0.713306
        - -0.17953074
        - 0.6773419
        - 0.26360622
        - 0.56299883
        - -0.4197537
        - 0.04160169
        - 0.1300139
        - 0.46594864
        - -0.06994323
        - 0.8431383
        - -0.3680263
        - -0.7222019
        - 0.7828621
        - 0.51069266
        - -0.7069936
        - 0.59840006
        - -0.8103736
        - 0.60993403
        - -0.5788004
        - 0.12011929
        - -0.048110798
        - 0.13624576
        - -0.47663245
        - -0.63152313
        - 0.014228499
        - 0.33825752
        - -0.64451796
        - -0.14284801
        - 0.021871652
        - 0.2819227
        - 0.24921621
        - -0.4691274
        - -1.2958363
        - 0.31359205
        - 0.33511573
        - 0.1967726
        - -0.6846978
        - 0.3720112
        - 0.75449294
        - -0.076151505
        - -0.308485
        - -0.8256058
        - -0.027632242
        - 0.4152834
        - -0.45892546
        - 0.5171866
        - 0.5969952
        - -0.29107565
        - 0.3862982
        - 0.11889106
        - -0.03438102
        - 0.531154
        shape: 200000000a000000
      biases:
        data:
        - -0.030443382
        - 0.07736758
        - -0.0029665749
        - 0.0879171
        - 0.19620833
        - -0.028620396
        - 0.047567442
        - 0.07365788
        - 0.07692792
        - 0.017193126
        - 0.01393759
        - -0.022146799
        - 0.0038416332
        - 0.070523344
        - 0.19717544
        - 0.067507036
        - 0.03305037
        - 0.09568436
        - -0.10766737
        - 0.063203946
        - -0.029547507
        - -0.047094442
        - -0.046848197
        - 0.09870786
        - -0.037463285
        - 0.00095930934
        - 0.0330377
        - 0.1411861
        - 0.13184999
        - 0.09600834
        - 0.3281192
        - 0.014139035
        shape: 20000000
    densegpu:
      bias: 1
      weights:
        serialized_data: []
        shape: 
      biases:
        serialized_data: []
        shape: 
    rnncell:
      nonlinearity: 0
      onReturn: 0
      weights:
        data: []
        shape: 
      biases:
        data: []
        shape: 
      r_weights:
        data: []
        shape: 
      r_biases:
        data: []
        shape: 
    groupedqueryattention:
      W_QKV:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      W_O:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      q_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      k_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      drop:
        inPlace: 0
        dropout: 0
      softmax:
        is_safe: 0
        temperature: 0
    layernorm:
      affine: 1
      bias: 1
      epsilon: 0.00001
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    rmsnorm:
      epsilon: 0.000001
      affine: 1
      gamma:
        data: []
        shape: 
      gammaGrad:
        data: []
        shape: 
    batchnorm:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    gatedlinearunit:
      activation: swish
      up_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      gate_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      down_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
    lazyconv2d:
      Conv2D:
        bias: 1
        kernels:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazydense:
      Dense:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm1d:
      BatchNorm1D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm2d:
      BatchNorm2D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    dropout:
      inPlace: 0
      dropout: 0
    flatten:
      startAxis: -3
      endAxis: -1
    reshape:
      inputShape: 
      outputShape: 
    residualconnectionfork:
      residualConnectionHash: 1908730750
    residualconnectionjoin:
      residualConnectionHash: 1908730750
    squeeze:
      axis: 0
    unsqueeze:
      axis: 0
    permute:
      axes: 
    batchnorm2d:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    conv2d:
      bias: 1
      kernels:
        data: []
        shape: 
      biases:
        data: []
        shape: 
    avgpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    maxpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    zeropad2d:
      hPadding: 0
      wPadding: 0
    mirrorpad2d:
      padding: 0
    dropout2d:
      inPlace: 0
      dropout: 0
    zeropad1d:
      padding: 0
    mirrorpad1d:
      padding: 0
    relu:
      inPlace: 0
    tanh:
      inPlace: 0
    softmax:
      is_safe: 0
      temperature: 0
    leakyrelu:
      inPlace: 0
      alpha: 0
    sigmoid:
      inPlace: 0
    softplus:
      beta: 0
      psi:
        data: []
        shape: 
      scaleTrainable: 0
      inPlace: 0
    elu:
      alpha: 0
    threshold:
      threshold: 0
      value: 0
    hardtanh:
      min_value: -1
      max_value: 1
    gelu:
      inPlace: 0
    prelu:
      inPlace: 0
      alpha:
        data: []
        shape: 
    rrelu:
      lower: 0
      upper: 0
    silu:
      inPlace: 0
    relu6:
      inPlace: 0
    rish:
      inPlace: 0
  - name: Silu
    dense:
      bias: 1
      weights:
        data: []
        shape: 
      biases:
        data: []
        shape: 
    densegpu:
      bias: 1
      weights:
        serialized_data: []
        shape: 
      biases:
        serialized_data: []
        shape: 
    rnncell:
      nonlinearity: 0
      onReturn: 0
      weights:
        data: []
        shape: 
      biases:
        data: []
        shape: 
      r_weights:
        data: []
        shape: 
      r_biases:
        data: []
        shape: 
    groupedqueryattention:
      W_QKV:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      W_O:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      q_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      k_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      drop:
        inPlace: 0
        dropout: 0
      softmax:
        is_safe: 0
        temperature: 0
    layernorm:
      affine: 1
      bias: 1
      epsilon: 0.00001
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    rmsnorm:
      epsilon: 0.000001
      affine: 1
      gamma:
        data: []
        shape: 
      gammaGrad:
        data: []
        shape: 
    batchnorm:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    gatedlinearunit:
      activation: swish
      up_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      gate_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      down_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
    lazyconv2d:
      Conv2D:
        bias: 1
        kernels:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazydense:
      Dense:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm1d:
      BatchNorm1D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm2d:
      BatchNorm2D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    dropout:
      inPlace: 0
      dropout: 0
    flatten:
      startAxis: -3
      endAxis: -1
    reshape:
      inputShape: 
      outputShape: 
    residualconnectionfork:
      residualConnectionHash: -950134194
    residualconnectionjoin:
      residualConnectionHash: -950134194
    squeeze:
      axis: 0
    unsqueeze:
      axis: 0
    permute:
      axes: 
    batchnorm2d:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    conv2d:
      bias: 1
      kernels:
        data: []
        shape: 
      biases:
        data: []
        shape: 
    avgpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    maxpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    zeropad2d:
      hPadding: 0
      wPadding: 0
    mirrorpad2d:
      padding: 0
    dropout2d:
      inPlace: 0
      dropout: 0
    zeropad1d:
      padding: 0
    mirrorpad1d:
      padding: 0
    relu:
      inPlace: 0
    tanh:
      inPlace: 0
    softmax:
      is_safe: 0
      temperature: 0
    leakyrelu:
      inPlace: 0
      alpha: 0
    sigmoid:
      inPlace: 0
    softplus:
      beta: 0
      psi:
        data: []
        shape: 
      scaleTrainable: 0
      inPlace: 0
    elu:
      alpha: 0
    threshold:
      threshold: 0
      value: 0
    hardtanh:
      min_value: -1
      max_value: 1
    gelu:
      inPlace: 0
    prelu:
      inPlace: 0
      alpha:
        data: []
        shape: 
    rrelu:
      lower: 0
      upper: 0
    silu:
      inPlace: 1
    relu6:
      inPlace: 0
    rish:
      inPlace: 0
  - name: Dense
    dense:
      bias: 1
      weights:
        data:
        - 0.40714717
        - -0.32445678
        - -0.35195842
        - -0.4243734
        - -0.13866548
        - -0.18561712
        - 0.0005367775
        - -0.25082493
        - 0.10228065
        - 0.361287
        - -0.16787994
        - 0.40093312
        - 0.36246902
        - -0.43728387
        - 0.37171143
        - -0.056655362
        - -0.09677074
        - 0.053084403
        - 0.22699097
        - -0.42877805
        - 0.28250664
        - 0.27369106
        - -0.27522293
        - -0.35734034
        - 0.1970932
        - -0.39210153
        - 0.035133783
        - 0.28423482
        - -0.31279764
        - -0.16485752
        - 0.04175837
        - 0.124339566
        - 0.037969075
        - -0.15195008
        - -0.36576605
        - -0.2283194
        - 0.08998402
        - 0.0029187403
        - 0.3586187
        - 0.22677533
        - 0.27846265
        - -0.5173766
        - 0.45323244
        - -0.26136735
        - 0.2726093
        - -0.14659008
        - 0.19739348
        - 0.43930274
        - 0.2779653
        - -0.29436114
        - -0.0037607828
        - -0.46823508
        - 0.28643116
        - -0.41489485
        - -0.23757537
        - -0.33475962
        - -0.026927069
        - 0.44682992
        - -0.47827423
        - 0.36833802
        - 0.16004813
        - -0.32172397
        - -0.20035774
        - -0.2766728
        - -0.4581912
        - -0.19261314
        - 0.3719625
        - 0.5673011
        - 0.20302907
        - -0.29522616
        - -0.10215137
        - 0.45163867
        - 0.09444717
        - -0.17673194
        - -0.34598428
        - -0.03293898
        - -0.00037379185
        - 0.5500436
        - -0.5881354
        - 0.04094226
        - -0.10428214
        - -0.47766915
        - -0.13897496
        - -0.3226919
        - -0.13067564
        - 0.32214767
        - -0.2023159
        - -0.19893791
        - 0.3581814
        - -0.63185525
        - 0.006983161
        - -0.10693034
        - -0.098650336
        - 0.21907482
        - -0.172264
        - 0.108916394
        - 0.35231686
        - 0.004370759
        - -0.03344364
        - 0.07244001
        - -0.13016292
        - 0.27859232
        - 0.053261764
        - 0.02375957
        - -0.029952994
        - -0.15373807
        - -0.15305993
        - 0.10955997
        - -0.3356868
        - -0.08443872
        - 0.10237938
        - 0.39952412
        - 0.27670583
        - 0.08520251
        - 0.35763636
        - -0.3537059
        - 0.07128663
        - 0.018706052
        - 0.38167042
        - 0.37719855
        - 0.036618814
        - 0.047265857
        - -0.12427405
        - 0.59046537
        - -0.34434795
        - 0.28801566
        - 0.2947169
        - -0.16567664
        - -0.21073233
        - 0.19170468
        - -0.014042171
        - -0.6693499
        - 0.13157526
        - 0.059102874
        - -0.18993816
        - -0.16910602
        - 0.086874
        - -0.20496376
        - -0.06770821
        - 0.3513309
        - -0.49678412
        - -0.115826055
        - 0.2871514
        - 0.12196461
        - 0.24839464
        - -0.2808531
        - -0.48294756
        - 0.100800745
        - -0.14236157
        - -0.27824375
        - -0.009704915
        - -0.07105464
        - -0.23404804
        - 0.59423524
        - -0.39765605
        - -0.10280539
        - -0.042869058
        - -0.38622555
        - -0.6285473
        - -0.06806892
        - 0.49247783
        - 0.26161134
        - 0.32928523
        - -0.23315863
        - -0.38418338
        - 0.06812656
        - -0.19782728
        - -0.007882838
        - -0.27273187
        - -0.02911602
        - 0.21131082
        - -0.21287696
        - -0.085475214
        - 0.08488463
        - 0.1456038
        - 0.107898474
        - 0.12644133
        - 0.1381698
        - -0.20361991
        - -0.110773556
        - -0.37363786
        - -0.30883917
        - 0.3724524
        - -0.37699288
        - 0.47489768
        - -0.26840475
        - -0.034988925
        - 0.21820463
        - -0.20043406
        - -0.36364403
        - 0.35456
        - 0.21587026
        - -0.10806781
        - -0.16123162
        - -0.2143019
        - -0.3452516
        - 0.34212306
        - 0.41941267
        - 0.23579276
        - -0.031293776
        - 0.12121752
        - 0.23247616
        - -0.110534124
        - 0.40717283
        - -0.48513466
        - -0.33266684
        - 0.35976312
        - 0.10586221
        - -0.045199156
        - -0.38452408
        - -0.1618343
        - 0.48468444
        - 0.1282798
        - 0.20173898
        - -0.17648704
        - -0.33416748
        - -0.32331577
        - -0.14063348
        - -0.42902362
        - 0.120658964
        - -0.17713696
        - -0.31394932
        - -0.20469217
        - 0.2847463
        - -0.29658023
        - 0.007389739
        - 0.1270283
        - -0.36087587
        - -0.3369243
        - -0.10192395
        - 0.07272989
        - 0.44674143
        - 0.18902728
        - 0.09667332
        - 0.05672456
        - -0.2626558
        - 0.30189437
        - 0.115843415
        - -0.026350917
        - 0.44853246
        - 0.17638956
        - 0.40077427
        - 0.38294464
        - -0.09730998
        - -0.36767542
        - -0.021699574
        - 0.31473163
        - 0.44453946
        - 0.11693319
        - -0.26976648
        - 0.16962482
        - -0.1311256
        - -0.4111397
        - -0.10637378
        - -0.4880041
        - 0.16108045
        - -0.26185045
        - -0.03401705
        - -0.0006035473
        - 0.45550895
        - 0.36238876
        - -0.14695182
        - -0.14011447
        - 0.20970164
        - 0.2572133
        - 0.43660963
        - 0.27648672
        - 0.2287505
        - 0.32662496
        - 0.17129572
        - -0.06578004
        - 0.14980471
        - -0.27209175
        - -0.23413742
        - 0.19128318
        - -0.03997278
        - -0.13146046
        - 0.24106577
        - -0.08491353
        - -0.034507208
        - 0.361424
        - 0.36708134
        - 0.16081516
        - 0.19356132
        - 0.46437234
        - -0.1905393
        - 0.48568523
        - 0.22841834
        - -0.41663384
        - -0.08273192
        - -0.35084066
        - 0.56683207
        - -0.09784891
        - 0.35246235
        - -0.02742111
        - -0.1580405
        - -0.2141466
        - 0.07007038
        - 0.2905492
        - 0.050714053
        - 0.13160206
        - 0.4062139
        - 0.009142663
        - -0.3649301
        - -0.57643306
        - -0.51423323
        - 0.38409805
        - -0.5329857
        - -0.4726887
        - -0.16512083
        - 0.19417371
        - 0.5337439
        - 0.10646935
        - 0.060244337
        - 0.036789693
        - -0.45024806
        - -0.5978598
        - 0.20885843
        - -0.1243591
        - -0.10564072
        - 0.24059822
        - 0.19408402
        - -0.30528173
        - -0.3144939
        - 0.38423288
        - -0.336071
        - 0.1765232
        - 0.36361048
        - -0.0031845924
        - 0.5604905
        - -0.4646905
        - -0.3443292
        - -0.48176342
        - -0.2946037
        - -0.3715803
        - -0.41125813
        - 0.23377533
        - 0.18335044
        - -0.4774375
        - 0.44512329
        - 0.04012675
        - 0.33264554
        - -0.23438545
        - 0.19064386
        - 0.1789028
        - 0.3674314
        - 0.30153516
        - 0.2766554
        - 0.6027831
        - 0.12010682
        - 0.07106891
        - -0.50646734
        - -0.17462781
        - -0.055651452
        - 0.121747255
        - -0.3071658
        - 0.21863474
        - -0.21132305
        - -0.4443032
        - -0.20318806
        - 0.6998729
        - 0.49284318
        - -0.45518076
        - 0.04592461
        - 0.22737025
        - -0.17369303
        - 0.27938855
        - 0.28367034
        - 0.29644418
        - -0.2199244
        - -0.22794579
        - -0.2887256
        - 0.45398432
        - -0.043391235
        - -0.13099407
        - 0.1309915
        - -0.23044384
        - -0.24577558
        - 0.19600241
        - 0.27497226
        - 0.32913762
        - 0.24106424
        - -0.19479325
        - 0.24766551
        - -0.399796
        - 0.255583
        - 0.18779804
        - 0.040899344
        - 0.55115825
        - 0.13286644
        - 0.29624525
        - 0.15253773
        - -0.6094893
        - 0.22996631
        - -0.3489327
        - 0.32210043
        - -0.06237998
        - -0.028525803
        - -0.1535857
        - -0.19486743
        - 0.009960244
        - -0.03872578
        - -0.2919265
        - 0.3543154
        - 0.3970815
        - 0.21282339
        - 0.14144544
        - -0.1974277
        - 0.18567538
        - 0.15457302
        - -0.23805156
        - -0.32944888
        - 0.3548183
        - -0.52449304
        - -0.60288626
        - 0.27335122
        - -0.4124301
        - 0.07579311
        - 0.47618145
        - 0.026714578
        - 0.34926444
        - -0.21262644
        - 0.41502577
        - 0.14485201
        - -0.45179105
        - -0.2724853
        - 0.2241821
        - 0.052707445
        - -0.05786258
        - -0.3482511
        - 0.47530222
        - -0.18749082
        - 0.013185127
        - -0.27789938
        - 0.28195578
        - 0.3484547
        - -0.3491448
        - -0.31100792
        - 0.11214982
        - 0.3565343
        - 0.11750958
        - 0.059776917
        - -0.23066583
        - 0.37696663
        - -0.17841865
        - -0.54052967
        - -0.10765816
        - -0.06636805
        - -0.12424228
        - -0.43285072
        - -0.3557459
        - -0.36441967
        - 0.0059621315
        - 0.259094
        - 0.09424878
        - -0.22962761
        - 0.06556306
        - 0.067230895
        - -0.009190747
        - 0.36479855
        - -0.26282507
        - 0.2367648
        - 0.10053624
        - 0.2103188
        - -0.46106544
        - 0.40065372
        - -0.43923753
        - -0.3329474
        - 0.079743765
        - 0.2971418
        - 0.070292585
        - 0.52802134
        - 0.1709848
        - -0.3534541
        - -0.24896815
        - -0.14019743
        - -0.45952314
        - -0.16863121
        - -0.4380454
        - 0.0230961
        - 0.23530939
        - 0.49286664
        - -0.5413425
        - -0.22703099
        - -0.09629756
        - -0.06515748
        - -0.23919322
        - -0.34285796
        - -0.10179804
        - -0.2666496
        - 0.20050278
        - -0.23600496
        - -0.20302199
        - -0.25261626
        - 0.42649552
        - 0.2495241
        - 0.44181186
        - 0.46821007
        - -0.110314496
        - 0.27296314
        - -0.036429856
        - 0.1478551
        - 0.08489847
        - -0.28515768
        - -0.01638146
        - 0.3177984
        - 0.58627266
        - -0.26561636
        - 0.32250497
        - -0.029988049
        - -0.21772966
        - 0.13250457
        - 0.26892754
        - 0.01985342
        - -0.050855864
        - -0.7082836
        - 0.15856583
        - 0.19257447
        - -0.18000948
        - -0.0202347
        - -0.40683872
        - -0.18887147
        - 0.32265124
        - -0.28140548
        - -0.14945343
        - -0.09207986
        - 0.020612866
        - 0.3243959
        - 0.35217455
        - -0.45807323
        - 0.09466242
        - -0.063649766
        - 0.11335121
        - 0.30036163
        - 0.26791677
        - 0.35179573
        - -0.30742222
        - 0.4206134
        - 0.074936144
        - -0.35094684
        - 0.30298164
        - 0.42107418
        - 0.31146324
        - -0.2884626
        - -0.06839453
        - 0.2423505
        - 0.16265188
        - 0.16487998
        - 0.22975937
        - 0.37862498
        - 0.06802881
        - 0.020624623
        - -0.29007307
        - -0.12022756
        - 0.20959046
        - 0.079354584
        - -0.018014135
        - 0.35824892
        - -0.10403496
        - 0.029048229
        - -0.16046529
        - 0.4147998
        - -0.24858136
        - 0.13687722
        - 0.142361
        - -0.46532336
        - -0.369063
        - -0.2743561
        - 0.039899707
        - -0.17100272
        - 0.14575748
        - -0.45450023
        - 0.47406504
        - -0.15652977
        - -0.58360213
        - 0.18576837
        - -0.14036559
        - -0.100728035
        - -0.05401536
        - 0.20584369
        - -0.30748498
        - -0.21732573
        - -0.14994991
        - 0.32217652
        - 0.18854178
        - 0.18188289
        - 0.35799187
        - 0.23659551
        - -0.27955833
        - -0.13721053
        - 0.11432866
        - 0.4712308
        - -0.11338752
        - 0.4132928
        - 0.37989235
        - 0.45324707
        - -0.46136075
        - -0.4260997
        - 0.30617356
        - 0.17556377
        - 0.30055025
        - -0.16052587
        - 0.133983
        - 0.40143487
        - -0.23384918
        - 0.068272896
        - -0.45059213
        - 0.07055373
        - 0.1473231
        - -0.30831796
        - 0.16302133
        - 0.35803854
        - -0.30128673
        - 0.30107316
        - 0.23458047
        - 0.07719525
        - 0.41262153
        - -0.22941884
        - 0.25112954
        - 0.39002416
        - -0.19416793
        - -0.29345375
        - -0.18889278
        - -0.1679076
        - 0.31597278
        - 0.51677835
        - -0.28107786
        - 0.06978592
        - -0.29236445
        - 0.41280004
        - 0.32394525
        - -0.3228908
        - 0.27320865
        - 0.2545255
        - 0.0999129
        - 0.29274067
        - -0.34065926
        - -0.17963827
        - 0.104553625
        - 0.11040064
        - 0.28787297
        - -0.023438383
        - 0.44214413
        - -0.015654685
        - -0.14956063
        - 0.2302942
        - 0.43054858
        - 0.33684018
        - -0.14987431
        - 0.21346664
        - -0.21106093
        - -0.11782949
        - -0.32936293
        - 0.0487217
        - 0.44825011
        - -0.03959531
        - -0.20991848
        - -0.017755222
        - 0.28960222
        - 0.29423374
        - 0.40424505
        - 0.12584732
        - -0.44410828
        - -0.20919153
        - -0.10146047
        - 0.35243022
        - 0.15981199
        - -0.43717745
        - 0.3238365
        - -0.33057955
        - -0.100789994
        - -0.23206505
        - 0.13359259
        - 0.38274243
        - 0.033375066
        - 0.24687009
        - 0.036862295
        - -0.14436719
        - -0.06638075
        - 0.22954893
        - 0.5091223
        - 0.45196843
        - 0.14501922
        - 0.062537596
        - -0.35011044
        - 0.31141034
        - -0.5271428
        - -0.3056201
        - -0.32037947
        - -0.26047635
        - -0.2498713
        - 0.35533527
        - -0.15815665
        - -0.039549112
        - 0.038215134
        - -0.15857686
        - -0.38023877
        - -0.16089652
        - 0.32969272
        - -0.09088942
        - 0.43408343
        - -0.23037484
        - -0.08206788
        - -0.09365532
        - 0.37355912
        - -0.18384051
        - -0.10335654
        - -0.22035511
        - 0.39366204
        - 0.11420309
        - 0.4991339
        - 0.06417519
        - 0.27680936
        - -0.26991197
        - 0.4572395
        - 0.1382615
        - 0.062160946
        - -0.14648403
        - 0.34615788
        - 0.31969145
        - -0.04601039
        - 0.19032866
        - -0.48473963
        - 0.31508365
        - -0.1487562
        - -0.38350487
        - -0.40331557
        - 0.54872674
        - -0.15602963
        - 0.21140037
        - -0.38313034
        - 0.10400236
        - -0.1887642
        - -0.36140266
        - -0.50052357
        - 0.071811296
        - -0.21084893
        - 0.017741483
        - -0.4579572
        - -0.36220098
        - -0.40605265
        - -0.050292943
        - -0.1023937
        - 0.30194438
        - -0.17015952
        - 0.15048875
        - 0.34377736
        - -0.15426233
        - 0.4573023
        - -0.29976094
        - 0.08852759
        - 0.28276014
        - -0.19209717
        - -0.39213565
        - -0.06052722
        - -0.20258912
        - -0.37140164
        - -0.1256994
        - -0.26514223
        - -0.12523797
        - 0.34006658
        - 0.05323121
        - 0.10735735
        - 0.2939912
        - -0.07938699
        - -0.077554315
        - 0.4607647
        - -0.09305889
        - 0.013761998
        - -0.59635466
        - 0.17916921
        - 0.39709863
        - -0.51892984
        - -0.06872685
        - -0.41422573
        - 0.21622606
        - -0.04044691
        - 0.14888486
        - -0.006567874
        - -0.16789828
        - -0.01977299
        - 0.28676763
        - -0.85959846
        - -0.13122912
        - -0.21582916
        - -0.84254664
        - -0.5253525
        - 0.20257555
        - 0.06307381
        - -0.2524197
        - -0.24902199
        - 0.085366346
        - -0.33683035
        - -0.55918354
        - -0.17708875
        - -0.09761959
        - -0.6705705
        - 0.22538629
        - 0.4979934
        - -0.23681131
        - -0.01044564
        - 0.24687569
        - -0.1863155
        - -0.27877894
        - -0.3309049
        - -0.17734723
        - 0.19449873
        - -0.028894173
        - -0.35679233
        - 0.25529093
        - -0.17692204
        - 0.32174468
        - 0.09372766
        - -0.060285024
        - -0.19347788
        - -0.14773719
        - -0.38381648
        - -0.17967941
        - 0.34508955
        - -0.32396
        - 0.19250208
        - -0.39323443
        - -0.20930184
        - 0.30264172
        - -0.16158797
        - -0.29078433
        - -0.43754113
        - -0.071415484
        - 0.254066
        - -0.6687553
        - -0.14023292
        - 0.38339958
        - -0.23874508
        - -0.14652957
        - 0.19685687
        - -0.51669836
        - 0.13554074
        - -0.14603476
        - -0.2225314
        - 0.23036714
        - 0.2233311
        - -0.056403708
        - -0.17920996
        - 0.061103035
        - 0.2134615
        - -0.5018482
        - -0.26395413
        - 0.07450745
        - 0.44903004
        - 0.20224035
        - 0.11553457
        - -0.21753605
        - -0.31317565
        - 0.0057062567
        - 0.3376251
        - 0.12281629
        - -0.49751356
        - -0.03608419
        - -0.2500498
        - -0.26966304
        - -0.022287292
        - -0.16177642
        - 0.15437084
        - 0.30974123
        - -0.4067807
        - -0.10663691
        - -0.25312746
        - 0.46348557
        - -0.17047049
        - 0.032920357
        - -0.063889116
        - 0.43606293
        - 0.311265
        - -0.33661473
        - 0.225138
        - -0.42578262
        - -0.040749114
        - 0.024507353
        - -0.115144186
        - -0.13454774
        - 0.313917
        - 0.28576022
        - -0.2390061
        - 0.12989084
        - 0.41924435
        - 0.0033986997
        - -0.3358675
        - -0.073123045
        - 0.034175534
        - -0.04957228
        - 0.013350226
        - 0.35559025
        - -0.42428696
        - 0.007760729
        - 0.26532286
        - -0.092981346
        - -0.45473978
        - 0.19423147
        - 0.3478674
        - -0.07670942
        - -0.42336372
        - -0.4515535
        - 0.09632514
        - -0.34503677
        - 0.3109796
        - 0.22133483
        - -0.02558928
        - -0.41134924
        - 0.007657471
        - 0.04005113
        - -0.43084064
        - 0.1736579
        - 0.2945945
        - 0.042928323
        - -0.17976765
        - 0.07533996
        - -0.39030376
        - 0.19411309
        - 0.15007406
        - -0.018695159
        - -0.20957062
        - -0.012025128
        - -0.39069173
        - -0.4527939
        - 0.04963476
        - 0.30657357
        - 0.31845906
        - 0.20507514
        - 0.08340606
        - -0.07003729
        - 0.353984
        - -0.083110675
        - 0.11887372
        - -0.22451787
        - -0.053163234
        - -0.16444288
        - -0.4919743
        - 0.41485235
        - 0.009103461
        - -0.20430797
        - 0.20050888
        - 0.18080096
        - 0.5178492
        - -0.013731532
        - 0.19161181
        - -0.42673975
        - -0.16327661
        - 0.039487332
        - 0.26091436
        - 0.016796034
        - -0.19444886
        - -0.18918318
        - -0.101389356
        - 0.059572864
        - -0.09371787
        - 0.33637568
        - 0.1575076
        - -0.094244055
        - -0.43482387
        - -0.22109993
        - -0.274382
        - 0.021557624
        - -0.2672618
        - 0.5390733
        - -0.23947908
        - 0.15445925
        - 0.34517556
        - -0.20558894
        - 0.1606563
        - 0.5154944
        - 0.036147986
        - -0.21241392
        - -0.15947604
        - 0.091923736
        - -0.10104823
        - 0.18732175
        - -0.350536
        - -0.10003459
        - -0.28361863
        - 0.032837853
        - 0.43161947
        - 0.33528936
        - 0.44119543
        - 0.02851612
        - -0.04478596
        - 0.009910843
        - 0.013904019
        - -0.38699478
        - 0.23305535
        - 0.12059083
        - 0.581242
        - 0.083512016
        - -0.09517144
        - -0.24022187
        - 0.29069236
        - 0.2712124
        - -0.008813093
        - 0.40471172
        - 0.21552281
        - 0.089850925
        - 0.41846904
        - 0.16940428
        - 0.38384947
        - 0.36482424
        - 0.376071
        - 0.31793648
        - 0.03696659
        - 0.124195285
        - -0.091649584
        - -0.47639135
        - 0.12969163
        - 0.22256158
        - -0.0885461
        - -0.15310635
        - 0.28029183
        - -0.047429223
        - 0.22185732
        - -0.2379419
        - -0.38936216
        - -0.20129031
        - -0.17137863
        - -0.047364924
        - 0.03213195
        - 0.42621306
        shape: 2000000020000000
      biases:
        data:
        - -0.009147698
        - 0.041760277
        - 0.10494176
        - 0.005916346
        - 0.16693945
        - -0.0023868114
        - 0.063609615
        - 0.0207063
        - -0.013390347
        - 0.040236257
        - 0.06013004
        - 0.07922338
        - 0.034539223
        - 0.09075813
        - 0.066228226
        - -0.10832329
        - 0.014306434
        - 0.007847149
        - -0.028521638
        - 0.008316555
        - 0.016005952
        - -0.005985372
        - 0.08217212
        - -0.056527596
        - 0.08730321
        - 0.036798973
        - -0.025240244
        - 0.030632056
        - -0.011090901
        - 0.07302405
        - 0.038036227
        - 0.016177002
        shape: 20000000
    densegpu:
      bias: 1
      weights:
        serialized_data: []
        shape: 
      biases:
        serialized_data: []
        shape: 
    rnncell:
      nonlinearity: 0
      onReturn: 0
      weights:
        data: []
        shape: 
      biases:
        data: []
        shape: 
      r_weights:
        data: []
        shape: 
      r_biases:
        data: []
        shape: 
    groupedqueryattention:
      W_QKV:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      W_O:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      q_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      k_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      drop:
        inPlace: 0
        dropout: 0
      softmax:
        is_safe: 0
        temperature: 0
    layernorm:
      affine: 1
      bias: 1
      epsilon: 0.00001
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    rmsnorm:
      epsilon: 0.000001
      affine: 1
      gamma:
        data: []
        shape: 
      gammaGrad:
        data: []
        shape: 
    batchnorm:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    gatedlinearunit:
      activation: swish
      up_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      gate_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      down_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
    lazyconv2d:
      Conv2D:
        bias: 1
        kernels:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazydense:
      Dense:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm1d:
      BatchNorm1D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm2d:
      BatchNorm2D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    dropout:
      inPlace: 0
      dropout: 0
    flatten:
      startAxis: -3
      endAxis: -1
    reshape:
      inputShape: 
      outputShape: 
    residualconnectionfork:
      residualConnectionHash: -1302489902
    residualconnectionjoin:
      residualConnectionHash: -1302489902
    squeeze:
      axis: 0
    unsqueeze:
      axis: 0
    permute:
      axes: 
    batchnorm2d:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    conv2d:
      bias: 1
      kernels:
        data: []
        shape: 
      biases:
        data: []
        shape: 
    avgpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    maxpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    zeropad2d:
      hPadding: 0
      wPadding: 0
    mirrorpad2d:
      padding: 0
    dropout2d:
      inPlace: 0
      dropout: 0
    zeropad1d:
      padding: 0
    mirrorpad1d:
      padding: 0
    relu:
      inPlace: 0
    tanh:
      inPlace: 0
    softmax:
      is_safe: 0
      temperature: 0
    leakyrelu:
      inPlace: 0
      alpha: 0
    sigmoid:
      inPlace: 0
    softplus:
      beta: 0
      psi:
        data: []
        shape: 
      scaleTrainable: 0
      inPlace: 0
    elu:
      alpha: 0
    threshold:
      threshold: 0
      value: 0
    hardtanh:
      min_value: -1
      max_value: 1
    gelu:
      inPlace: 0
    prelu:
      inPlace: 0
      alpha:
        data: []
        shape: 
    rrelu:
      lower: 0
      upper: 0
    silu:
      inPlace: 0
    relu6:
      inPlace: 0
    rish:
      inPlace: 0
  - name: Silu
    dense:
      bias: 1
      weights:
        data: []
        shape: 
      biases:
        data: []
        shape: 
    densegpu:
      bias: 1
      weights:
        serialized_data: []
        shape: 
      biases:
        serialized_data: []
        shape: 
    rnncell:
      nonlinearity: 0
      onReturn: 0
      weights:
        data: []
        shape: 
      biases:
        data: []
        shape: 
      r_weights:
        data: []
        shape: 
      r_biases:
        data: []
        shape: 
    groupedqueryattention:
      W_QKV:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      W_O:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      q_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      k_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      drop:
        inPlace: 0
        dropout: 0
      softmax:
        is_safe: 0
        temperature: 0
    layernorm:
      affine: 1
      bias: 1
      epsilon: 0.00001
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    rmsnorm:
      epsilon: 0.000001
      affine: 1
      gamma:
        data: []
        shape: 
      gammaGrad:
        data: []
        shape: 
    batchnorm:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    gatedlinearunit:
      activation: swish
      up_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      gate_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      down_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
    lazyconv2d:
      Conv2D:
        bias: 1
        kernels:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazydense:
      Dense:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm1d:
      BatchNorm1D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm2d:
      BatchNorm2D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    dropout:
      inPlace: 0
      dropout: 0
    flatten:
      startAxis: -3
      endAxis: -1
    reshape:
      inputShape: 
      outputShape: 
    residualconnectionfork:
      residualConnectionHash: 133612450
    residualconnectionjoin:
      residualConnectionHash: 133612450
    squeeze:
      axis: 0
    unsqueeze:
      axis: 0
    permute:
      axes: 
    batchnorm2d:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    conv2d:
      bias: 1
      kernels:
        data: []
        shape: 
      biases:
        data: []
        shape: 
    avgpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    maxpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    zeropad2d:
      hPadding: 0
      wPadding: 0
    mirrorpad2d:
      padding: 0
    dropout2d:
      inPlace: 0
      dropout: 0
    zeropad1d:
      padding: 0
    mirrorpad1d:
      padding: 0
    relu:
      inPlace: 0
    tanh:
      inPlace: 0
    softmax:
      is_safe: 0
      temperature: 0
    leakyrelu:
      inPlace: 0
      alpha: 0
    sigmoid:
      inPlace: 0
    softplus:
      beta: 0
      psi:
        data: []
        shape: 
      scaleTrainable: 0
      inPlace: 0
    elu:
      alpha: 0
    threshold:
      threshold: 0
      value: 0
    hardtanh:
      min_value: -1
      max_value: 1
    gelu:
      inPlace: 0
    prelu:
      inPlace: 0
      alpha:
        data: []
        shape: 
    rrelu:
      lower: 0
      upper: 0
    silu:
      inPlace: 1
    relu6:
      inPlace: 0
    rish:
      inPlace: 0
  - name: Dense
    dense:
      bias: 1
      weights:
        data:
        - 0.15355289
        - 0.33756283
        - -0.35968286
        - -0.118407466
        - 0.2315634
        - 0.029686017
        - 0.12670296
        - 0.4036533
        - -0.15069696
        - -0.07493092
        - -0.35356715
        - -0.5321367
        - 0.138967
        - 0.4745733
        - 0.42697144
        - -0.35293067
        - -0.07397569
        - 0.4417149
        - 0.20061393
        - -0.011640392
        - 0.096183605
        - -0.37301502
        - 0.47106138
        - -0.38426918
        - -0.15870482
        - 0.3841022
        - -0.06134036
        - -0.24773718
        - -0.22393736
        - 0.07692678
        - -0.4465905
        - 0.14162183
        - 0.31842503
        - 0.19483475
        - 0.39247528
        - 0.44988415
        - -0.39643615
        - 0.1956954
        - -0.4816618
        - 0.33262947
        - -0.046814978
        - 0.5818645
        - -0.54486173
        - -0.41070113
        - -0.14054176
        - 0.10457261
        - 0.29756945
        - 0.16976033
        - -0.4089601
        - -0.38462752
        - 0.016342161
        - 0.43372995
        - -0.20110816
        - 0.11268153
        - 0.19087581
        - -0.0069677043
        - 0.27458817
        - 0.1176013
        - -0.12291335
        - 0.5430956
        - -0.031091817
        - -0.16674407
        - -0.0040337597
        - 0.39991397
        shape: 0200000020000000
      biases:
        data:
        - 0.031177783
        - -0.0041360427
        shape: 02000000
    densegpu:
      bias: 1
      weights:
        serialized_data: []
        shape: 
      biases:
        serialized_data: []
        shape: 
    rnncell:
      nonlinearity: 0
      onReturn: 0
      weights:
        data: []
        shape: 
      biases:
        data: []
        shape: 
      r_weights:
        data: []
        shape: 
      r_biases:
        data: []
        shape: 
    groupedqueryattention:
      W_QKV:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      W_O:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      q_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      k_rmsn:
        epsilon: 0.000001
        affine: 1
        gamma:
          data: []
          shape: 
        gammaGrad:
          data: []
          shape: 
      drop:
        inPlace: 0
        dropout: 0
      softmax:
        is_safe: 0
        temperature: 0
    layernorm:
      affine: 1
      bias: 1
      epsilon: 0.00001
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    rmsnorm:
      epsilon: 0.000001
      affine: 1
      gamma:
        data: []
        shape: 
      gammaGrad:
        data: []
        shape: 
    batchnorm:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    gatedlinearunit:
      activation: swish
      up_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      gate_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      down_proj:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
    lazyconv2d:
      Conv2D:
        bias: 1
        kernels:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazydense:
      Dense:
        bias: 1
        weights:
          data: []
          shape: 
        biases:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm1d:
      BatchNorm1D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    lazybatchnorm2d:
      BatchNorm2D:
        affine: 1
        num_features: 0
        momentum: 0
        epsilon: 0
        runningMean:
          data: []
          shape: 
        runningVar:
          data: []
          shape: 
        gamma:
          data: []
          shape: 
        beta:
          data: []
          shape: 
      initialized: 0
    dropout:
      inPlace: 0
      dropout: 0
    flatten:
      startAxis: -3
      endAxis: -1
    reshape:
      inputShape: 
      outputShape: 
    residualconnectionfork:
      residualConnectionHash: 1569714802
    residualconnectionjoin:
      residualConnectionHash: 1569714802
    squeeze:
      axis: 0
    unsqueeze:
      axis: 0
    permute:
      axes: 
    batchnorm2d:
      affine: 1
      num_features: 0
      momentum: 0
      epsilon: 0
      runningMean:
        data: []
        shape: 
      runningVar:
        data: []
        shape: 
      gamma:
        data: []
        shape: 
      beta:
        data: []
        shape: 
    conv2d:
      bias: 1
      kernels:
        data: []
        shape: 
      biases:
        data: []
        shape: 
    avgpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    maxpool2d:
      kernel_size: 0
      padding: 0
      padding_mode: 0
    zeropad2d:
      hPadding: 0
      wPadding: 0
    mirrorpad2d:
      padding: 0
    dropout2d:
      inPlace: 0
      dropout: 0
    zeropad1d:
      padding: 0
    mirrorpad1d:
      padding: 0
    relu:
      inPlace: 0
    tanh:
      inPlace: 0
    softmax:
      is_safe: 0
      temperature: 0
    leakyrelu:
      inPlace: 0
      alpha: 0
    sigmoid:
      inPlace: 0
    softplus:
      beta: 0
      psi:
        data: []
        shape: 
      scaleTrainable: 0
      inPlace: 0
    elu:
      alpha: 0
    threshold:
      threshold: 0
      value: 0
    hardtanh:
      min_value: -1
      max_value: 1
    gelu:
      inPlace: 0
    prelu:
      inPlace: 0
      alpha:
        data: []
        shape: 
    rrelu:
      lower: 0
      upper: 0
    silu:
      inPlace: 0
    relu6:
      inPlace: 0
    rish:
      inPlace: 0
