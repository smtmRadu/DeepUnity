{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 8,
  "global_step": 155,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03292181069958848,
      "grad_norm": 19.444623947143555,
      "learning_rate": 0.0,
      "loss": 4.5109,
      "step": 1
    },
    {
      "epoch": 0.06584362139917696,
      "grad_norm": 19.8987979888916,
      "learning_rate": 3.75e-05,
      "loss": 4.5123,
      "step": 2
    },
    {
      "epoch": 0.09876543209876543,
      "grad_norm": 12.7373685836792,
      "learning_rate": 7.5e-05,
      "loss": 4.1845,
      "step": 3
    },
    {
      "epoch": 0.13168724279835392,
      "grad_norm": 9.241140365600586,
      "learning_rate": 0.0001125,
      "loss": 3.88,
      "step": 4
    },
    {
      "epoch": 0.1646090534979424,
      "grad_norm": 5.101895332336426,
      "learning_rate": 0.00015,
      "loss": 3.5604,
      "step": 5
    },
    {
      "epoch": 0.19753086419753085,
      "grad_norm": 5.227546215057373,
      "learning_rate": 0.00018749999999999998,
      "loss": 3.4895,
      "step": 6
    },
    {
      "epoch": 0.23045267489711935,
      "grad_norm": 4.702144622802734,
      "learning_rate": 0.000225,
      "loss": 3.3993,
      "step": 7
    },
    {
      "epoch": 0.26337448559670784,
      "grad_norm": 3.135899543762207,
      "learning_rate": 0.0002625,
      "loss": 3.2677,
      "step": 8
    },
    {
      "epoch": 0.26337448559670784,
      "eval_loss": 3.0965709686279297,
      "eval_runtime": 16.6403,
      "eval_samples_per_second": 7.692,
      "eval_steps_per_second": 7.692,
      "step": 8
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 2.208514928817749,
      "learning_rate": 0.0003,
      "loss": 3.0348,
      "step": 9
    },
    {
      "epoch": 0.3292181069958848,
      "grad_norm": 2.1275627613067627,
      "learning_rate": 0.00029996917150534153,
      "loss": 2.9778,
      "step": 10
    },
    {
      "epoch": 0.36213991769547327,
      "grad_norm": 2.096630334854126,
      "learning_rate": 0.0002998767001013082,
      "loss": 3.0123,
      "step": 11
    },
    {
      "epoch": 0.3950617283950617,
      "grad_norm": 1.4466255903244019,
      "learning_rate": 0.0002997226280212954,
      "loss": 2.8454,
      "step": 12
    },
    {
      "epoch": 0.4279835390946502,
      "grad_norm": 1.4463156461715698,
      "learning_rate": 0.00029950702563286293,
      "loss": 2.8714,
      "step": 13
    },
    {
      "epoch": 0.4609053497942387,
      "grad_norm": 1.2666268348693848,
      "learning_rate": 0.0002992299914055972,
      "loss": 2.7359,
      "step": 14
    },
    {
      "epoch": 0.49382716049382713,
      "grad_norm": 1.1022770404815674,
      "learning_rate": 0.0002988916518661382,
      "loss": 2.744,
      "step": 15
    },
    {
      "epoch": 0.5267489711934157,
      "grad_norm": 1.1640962362289429,
      "learning_rate": 0.0002984921615403923,
      "loss": 2.6491,
      "step": 16
    },
    {
      "epoch": 0.5267489711934157,
      "eval_loss": 2.617769718170166,
      "eval_runtime": 14.0255,
      "eval_samples_per_second": 9.126,
      "eval_steps_per_second": 9.126,
      "step": 16
    },
    {
      "epoch": 0.5596707818930041,
      "grad_norm": 0.9351508021354675,
      "learning_rate": 0.0002980317028829577,
      "loss": 2.6579,
      "step": 17
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 1.168617844581604,
      "learning_rate": 0.0002975104861937938,
      "loss": 2.5711,
      "step": 18
    },
    {
      "epoch": 0.6255144032921811,
      "grad_norm": 1.033125877380371,
      "learning_rate": 0.0002969287495221734,
      "loss": 2.5432,
      "step": 19
    },
    {
      "epoch": 0.6584362139917695,
      "grad_norm": 1.0121159553527832,
      "learning_rate": 0.0002962867585579614,
      "loss": 2.5305,
      "step": 20
    },
    {
      "epoch": 0.691358024691358,
      "grad_norm": 0.9711318612098694,
      "learning_rate": 0.00029558480651026894,
      "loss": 2.5241,
      "step": 21
    },
    {
      "epoch": 0.7242798353909465,
      "grad_norm": 0.9742908477783203,
      "learning_rate": 0.0002948232139735399,
      "loss": 2.503,
      "step": 22
    },
    {
      "epoch": 0.757201646090535,
      "grad_norm": 1.0163264274597168,
      "learning_rate": 0.00029400232878112897,
      "loss": 2.4203,
      "step": 23
    },
    {
      "epoch": 0.7901234567901234,
      "grad_norm": 0.9239991903305054,
      "learning_rate": 0.0002931225258464402,
      "loss": 2.4897,
      "step": 24
    },
    {
      "epoch": 0.7901234567901234,
      "eval_loss": 2.432379722595215,
      "eval_runtime": 14.0936,
      "eval_samples_per_second": 9.082,
      "eval_steps_per_second": 9.082,
      "step": 24
    },
    {
      "epoch": 0.823045267489712,
      "grad_norm": 0.9946935772895813,
      "learning_rate": 0.00029218420699169697,
      "loss": 2.4542,
      "step": 25
    },
    {
      "epoch": 0.8559670781893004,
      "grad_norm": 0.872767984867096,
      "learning_rate": 0.00029118780076442215,
      "loss": 2.439,
      "step": 26
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.9428943395614624,
      "learning_rate": 0.00029013376224171287,
      "loss": 2.388,
      "step": 27
    },
    {
      "epoch": 0.9218106995884774,
      "grad_norm": 0.9203556180000305,
      "learning_rate": 0.00028902257282239835,
      "loss": 2.4215,
      "step": 28
    },
    {
      "epoch": 0.9547325102880658,
      "grad_norm": 0.852854311466217,
      "learning_rate": 0.00028785474000717596,
      "loss": 2.3808,
      "step": 29
    },
    {
      "epoch": 0.9876543209876543,
      "grad_norm": 0.9065694808959961,
      "learning_rate": 0.00028663079716682654,
      "loss": 2.3854,
      "step": 30
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.189981460571289,
      "learning_rate": 0.0002853513032986141,
      "loss": 2.3899,
      "step": 31
    },
    {
      "epoch": 1.0329218106995885,
      "grad_norm": 0.9977288842201233,
      "learning_rate": 0.0002840168427709812,
      "loss": 2.3167,
      "step": 32
    },
    {
      "epoch": 1.0329218106995885,
      "eval_loss": 2.330458402633667,
      "eval_runtime": 14.398,
      "eval_samples_per_second": 8.89,
      "eval_steps_per_second": 8.89,
      "step": 32
    },
    {
      "epoch": 1.0658436213991769,
      "grad_norm": 0.8617135286331177,
      "learning_rate": 0.00028262802505665753,
      "loss": 2.2945,
      "step": 33
    },
    {
      "epoch": 1.0987654320987654,
      "grad_norm": 0.9954286217689514,
      "learning_rate": 0.0002811854844543022,
      "loss": 2.3669,
      "step": 34
    },
    {
      "epoch": 1.131687242798354,
      "grad_norm": 0.852787971496582,
      "learning_rate": 0.00027968987979880777,
      "loss": 2.319,
      "step": 35
    },
    {
      "epoch": 1.1646090534979423,
      "grad_norm": 1.0924346446990967,
      "learning_rate": 0.0002781418941603984,
      "loss": 2.1959,
      "step": 36
    },
    {
      "epoch": 1.1975308641975309,
      "grad_norm": 0.8996383547782898,
      "learning_rate": 0.0002765422345326593,
      "loss": 2.2194,
      "step": 37
    },
    {
      "epoch": 1.2304526748971194,
      "grad_norm": 0.9200879335403442,
      "learning_rate": 0.00027489163150963894,
      "loss": 2.2081,
      "step": 38
    },
    {
      "epoch": 1.263374485596708,
      "grad_norm": 0.90887051820755,
      "learning_rate": 0.00027319083895217415,
      "loss": 2.2553,
      "step": 39
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 0.8749346137046814,
      "learning_rate": 0.00027144063364358743,
      "loss": 2.2107,
      "step": 40
    },
    {
      "epoch": 1.2962962962962963,
      "eval_loss": 2.2638750076293945,
      "eval_runtime": 17.0105,
      "eval_samples_per_second": 7.525,
      "eval_steps_per_second": 7.525,
      "step": 40
    },
    {
      "epoch": 1.3292181069958848,
      "grad_norm": 0.9383775591850281,
      "learning_rate": 0.000269641814934916,
      "loss": 2.2785,
      "step": 41
    },
    {
      "epoch": 1.3621399176954734,
      "grad_norm": 0.9058841466903687,
      "learning_rate": 0.00026779520437983313,
      "loss": 2.2447,
      "step": 42
    },
    {
      "epoch": 1.3950617283950617,
      "grad_norm": 0.8748311996459961,
      "learning_rate": 0.0002659016453594297,
      "loss": 2.2114,
      "step": 43
    },
    {
      "epoch": 1.4279835390946503,
      "grad_norm": 1.0029792785644531,
      "learning_rate": 0.00026396200269702654,
      "loss": 2.2034,
      "step": 44
    },
    {
      "epoch": 1.4609053497942388,
      "grad_norm": 0.9311568737030029,
      "learning_rate": 0.0002619771622631932,
      "loss": 2.1872,
      "step": 45
    },
    {
      "epoch": 1.4938271604938271,
      "grad_norm": 1.0115119218826294,
      "learning_rate": 0.0002599480305711551,
      "loss": 2.1851,
      "step": 46
    },
    {
      "epoch": 1.5267489711934157,
      "grad_norm": 1.1298191547393799,
      "learning_rate": 0.000257875534362772,
      "loss": 2.2117,
      "step": 47
    },
    {
      "epoch": 1.5596707818930042,
      "grad_norm": 1.3467780351638794,
      "learning_rate": 0.00025576062018527776,
      "loss": 2.2206,
      "step": 48
    },
    {
      "epoch": 1.5596707818930042,
      "eval_loss": 2.232579469680786,
      "eval_runtime": 13.6562,
      "eval_samples_per_second": 9.373,
      "eval_steps_per_second": 9.373,
      "step": 48
    },
    {
      "epoch": 1.5925925925925926,
      "grad_norm": 1.116822361946106,
      "learning_rate": 0.00025360425395897494,
      "loss": 2.1929,
      "step": 49
    },
    {
      "epoch": 1.625514403292181,
      "grad_norm": 1.3861572742462158,
      "learning_rate": 0.0002514074205360812,
      "loss": 2.1663,
      "step": 50
    },
    {
      "epoch": 1.6584362139917697,
      "grad_norm": 1.1630632877349854,
      "learning_rate": 0.000249171123250929,
      "loss": 2.1818,
      "step": 51
    },
    {
      "epoch": 1.691358024691358,
      "grad_norm": 0.9691023826599121,
      "learning_rate": 0.0002468963834617244,
      "loss": 2.1562,
      "step": 52
    },
    {
      "epoch": 1.7242798353909465,
      "grad_norm": 1.101449966430664,
      "learning_rate": 0.00024458424008407404,
      "loss": 2.1752,
      "step": 53
    },
    {
      "epoch": 1.757201646090535,
      "grad_norm": 1.1093902587890625,
      "learning_rate": 0.0002422357491164929,
      "loss": 2.1854,
      "step": 54
    },
    {
      "epoch": 1.7901234567901234,
      "grad_norm": 1.1301074028015137,
      "learning_rate": 0.00023985198315811058,
      "loss": 2.1825,
      "step": 55
    },
    {
      "epoch": 1.823045267489712,
      "grad_norm": 0.9889260530471802,
      "learning_rate": 0.00023743403091879545,
      "loss": 2.1872,
      "step": 56
    },
    {
      "epoch": 1.823045267489712,
      "eval_loss": 2.1958999633789062,
      "eval_runtime": 17.6218,
      "eval_samples_per_second": 7.264,
      "eval_steps_per_second": 7.264,
      "step": 56
    },
    {
      "epoch": 1.8559670781893005,
      "grad_norm": 1.0872260332107544,
      "learning_rate": 0.00023498299672192088,
      "loss": 2.1502,
      "step": 57
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.9121906161308289,
      "learning_rate": 0.00023249999999999999,
      "loss": 2.2063,
      "step": 58
    },
    {
      "epoch": 1.9218106995884774,
      "grad_norm": 1.0648350715637207,
      "learning_rate": 0.0002299861747834207,
      "loss": 2.144,
      "step": 59
    },
    {
      "epoch": 1.954732510288066,
      "grad_norm": 1.074836015701294,
      "learning_rate": 0.00022744266918251277,
      "loss": 2.1503,
      "step": 60
    },
    {
      "epoch": 1.9876543209876543,
      "grad_norm": 1.2095295190811157,
      "learning_rate": 0.00022487064486318478,
      "loss": 2.1508,
      "step": 61
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.360923409461975,
      "learning_rate": 0.00022227127651636998,
      "loss": 2.0605,
      "step": 62
    },
    {
      "epoch": 2.0329218106995883,
      "grad_norm": 0.965499758720398,
      "learning_rate": 0.00021964575132152315,
      "loss": 2.0601,
      "step": 63
    },
    {
      "epoch": 2.065843621399177,
      "grad_norm": 1.2421027421951294,
      "learning_rate": 0.00021699526840441373,
      "loss": 2.0597,
      "step": 64
    },
    {
      "epoch": 2.065843621399177,
      "eval_loss": 2.163787364959717,
      "eval_runtime": 13.8331,
      "eval_samples_per_second": 9.253,
      "eval_steps_per_second": 9.253,
      "step": 64
    },
    {
      "epoch": 2.0987654320987654,
      "grad_norm": 1.0813676118850708,
      "learning_rate": 0.00021432103828946333,
      "loss": 2.1093,
      "step": 65
    },
    {
      "epoch": 2.1316872427983538,
      "grad_norm": 0.9704092741012573,
      "learning_rate": 0.0002116242823468765,
      "loss": 2.042,
      "step": 66
    },
    {
      "epoch": 2.1646090534979425,
      "grad_norm": 1.1207152605056763,
      "learning_rate": 0.00020890623223481883,
      "loss": 2.0634,
      "step": 67
    },
    {
      "epoch": 2.197530864197531,
      "grad_norm": 1.2291386127471924,
      "learning_rate": 0.00020616812933689567,
      "loss": 2.0901,
      "step": 68
    },
    {
      "epoch": 2.230452674897119,
      "grad_norm": 1.1444990634918213,
      "learning_rate": 0.00020341122419518934,
      "loss": 2.0745,
      "step": 69
    },
    {
      "epoch": 2.263374485596708,
      "grad_norm": 1.1684656143188477,
      "learning_rate": 0.0002006367759391138,
      "loss": 2.0551,
      "step": 70
    },
    {
      "epoch": 2.2962962962962963,
      "grad_norm": 1.0230896472930908,
      "learning_rate": 0.00019784605171034665,
      "loss": 2.0303,
      "step": 71
    },
    {
      "epoch": 2.3292181069958846,
      "grad_norm": 1.0579434633255005,
      "learning_rate": 0.0001950403260841024,
      "loss": 1.9961,
      "step": 72
    },
    {
      "epoch": 2.3292181069958846,
      "eval_loss": 2.1529293060302734,
      "eval_runtime": 13.5493,
      "eval_samples_per_second": 9.447,
      "eval_steps_per_second": 9.447,
      "step": 72
    },
    {
      "epoch": 2.3621399176954734,
      "grad_norm": 1.095413327217102,
      "learning_rate": 0.00019222088048701048,
      "loss": 2.0855,
      "step": 73
    },
    {
      "epoch": 2.3950617283950617,
      "grad_norm": 1.0608543157577515,
      "learning_rate": 0.00018938900261186384,
      "loss": 2.1071,
      "step": 74
    },
    {
      "epoch": 2.42798353909465,
      "grad_norm": 1.2393498420715332,
      "learning_rate": 0.00018654598582950617,
      "loss": 2.0164,
      "step": 75
    },
    {
      "epoch": 2.460905349794239,
      "grad_norm": 1.1920408010482788,
      "learning_rate": 0.00018369312859812547,
      "loss": 2.0697,
      "step": 76
    },
    {
      "epoch": 2.493827160493827,
      "grad_norm": 0.9994681477546692,
      "learning_rate": 0.00018083173387022425,
      "loss": 2.0321,
      "step": 77
    },
    {
      "epoch": 2.526748971193416,
      "grad_norm": 1.0177323818206787,
      "learning_rate": 0.00017796310849753702,
      "loss": 2.0837,
      "step": 78
    },
    {
      "epoch": 2.5596707818930042,
      "grad_norm": 1.0888227224349976,
      "learning_rate": 0.00017508856263416726,
      "loss": 2.0951,
      "step": 79
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 0.9454302787780762,
      "learning_rate": 0.0001722094091382156,
      "loss": 2.0582,
      "step": 80
    },
    {
      "epoch": 2.5925925925925926,
      "eval_loss": 2.1284713745117188,
      "eval_runtime": 13.5393,
      "eval_samples_per_second": 9.454,
      "eval_steps_per_second": 9.454,
      "step": 80
    },
    {
      "epoch": 2.625514403292181,
      "grad_norm": 1.0650994777679443,
      "learning_rate": 0.00016932696297217346,
      "loss": 2.0176,
      "step": 81
    },
    {
      "epoch": 2.6584362139917697,
      "grad_norm": 1.2036724090576172,
      "learning_rate": 0.0001664425406023554,
      "loss": 1.9737,
      "step": 82
    },
    {
      "epoch": 2.691358024691358,
      "grad_norm": 0.9809815883636475,
      "learning_rate": 0.00016355745939764462,
      "loss": 2.0397,
      "step": 83
    },
    {
      "epoch": 2.7242798353909468,
      "grad_norm": 1.1513863801956177,
      "learning_rate": 0.00016067303702782654,
      "loss": 2.0415,
      "step": 84
    },
    {
      "epoch": 2.757201646090535,
      "grad_norm": 1.1442590951919556,
      "learning_rate": 0.0001577905908617844,
      "loss": 2.0032,
      "step": 85
    },
    {
      "epoch": 2.7901234567901234,
      "grad_norm": 1.1175826787948608,
      "learning_rate": 0.0001549114373658327,
      "loss": 2.0753,
      "step": 86
    },
    {
      "epoch": 2.8230452674897117,
      "grad_norm": 1.1398845911026,
      "learning_rate": 0.00015203689150246295,
      "loss": 2.0372,
      "step": 87
    },
    {
      "epoch": 2.8559670781893005,
      "grad_norm": 1.3201537132263184,
      "learning_rate": 0.00014916826612977575,
      "loss": 2.0113,
      "step": 88
    },
    {
      "epoch": 2.8559670781893005,
      "eval_loss": 2.1187825202941895,
      "eval_runtime": 13.6814,
      "eval_samples_per_second": 9.356,
      "eval_steps_per_second": 9.356,
      "step": 88
    },
    {
      "epoch": 2.888888888888889,
      "grad_norm": 0.9422940015792847,
      "learning_rate": 0.00014630687140187445,
      "loss": 2.0509,
      "step": 89
    },
    {
      "epoch": 2.9218106995884776,
      "grad_norm": 1.0092536211013794,
      "learning_rate": 0.00014345401417049382,
      "loss": 1.9801,
      "step": 90
    },
    {
      "epoch": 2.954732510288066,
      "grad_norm": 1.0345008373260498,
      "learning_rate": 0.00014061099738813616,
      "loss": 2.0094,
      "step": 91
    },
    {
      "epoch": 2.9876543209876543,
      "grad_norm": 1.1539114713668823,
      "learning_rate": 0.00013777911951298952,
      "loss": 2.0363,
      "step": 92
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.5084457397460938,
      "learning_rate": 0.00013495967391589757,
      "loss": 2.0817,
      "step": 93
    },
    {
      "epoch": 3.0329218106995883,
      "grad_norm": 1.1628353595733643,
      "learning_rate": 0.00013215394828965335,
      "loss": 2.0228,
      "step": 94
    },
    {
      "epoch": 3.065843621399177,
      "grad_norm": 1.0650699138641357,
      "learning_rate": 0.00012936322406088615,
      "loss": 1.9716,
      "step": 95
    },
    {
      "epoch": 3.0987654320987654,
      "grad_norm": 1.0516769886016846,
      "learning_rate": 0.00012658877580481063,
      "loss": 1.9887,
      "step": 96
    },
    {
      "epoch": 3.0987654320987654,
      "eval_loss": 2.113863468170166,
      "eval_runtime": 17.4147,
      "eval_samples_per_second": 7.35,
      "eval_steps_per_second": 7.35,
      "step": 96
    },
    {
      "epoch": 3.1316872427983538,
      "grad_norm": 1.0510048866271973,
      "learning_rate": 0.00012383187066310433,
      "loss": 1.9643,
      "step": 97
    },
    {
      "epoch": 3.1646090534979425,
      "grad_norm": 0.9710578322410583,
      "learning_rate": 0.00012109376776518116,
      "loss": 1.9096,
      "step": 98
    },
    {
      "epoch": 3.197530864197531,
      "grad_norm": 1.1053240299224854,
      "learning_rate": 0.00011837571765312347,
      "loss": 2.0031,
      "step": 99
    },
    {
      "epoch": 3.230452674897119,
      "grad_norm": 0.974757730960846,
      "learning_rate": 0.00011567896171053667,
      "loss": 1.9847,
      "step": 100
    },
    {
      "epoch": 3.263374485596708,
      "grad_norm": 1.0823160409927368,
      "learning_rate": 0.00011300473159558624,
      "loss": 1.9714,
      "step": 101
    },
    {
      "epoch": 3.2962962962962963,
      "grad_norm": 0.9394290447235107,
      "learning_rate": 0.00011035424867847683,
      "loss": 2.0324,
      "step": 102
    },
    {
      "epoch": 3.3292181069958846,
      "grad_norm": 1.0366342067718506,
      "learning_rate": 0.00010772872348362991,
      "loss": 1.9764,
      "step": 103
    },
    {
      "epoch": 3.3621399176954734,
      "grad_norm": 0.98586505651474,
      "learning_rate": 0.00010512935513681518,
      "loss": 1.9073,
      "step": 104
    },
    {
      "epoch": 3.3621399176954734,
      "eval_loss": 2.105607748031616,
      "eval_runtime": 16.6146,
      "eval_samples_per_second": 7.704,
      "eval_steps_per_second": 7.704,
      "step": 104
    },
    {
      "epoch": 3.3950617283950617,
      "grad_norm": 1.1639808416366577,
      "learning_rate": 0.00010255733081748727,
      "loss": 1.9737,
      "step": 105
    },
    {
      "epoch": 3.42798353909465,
      "grad_norm": 1.0575989484786987,
      "learning_rate": 0.00010001382521657936,
      "loss": 1.9719,
      "step": 106
    },
    {
      "epoch": 3.460905349794239,
      "grad_norm": 1.0155096054077148,
      "learning_rate": 9.750000000000003e-05,
      "loss": 1.9721,
      "step": 107
    },
    {
      "epoch": 3.493827160493827,
      "grad_norm": 1.0797837972640991,
      "learning_rate": 9.50170032780791e-05,
      "loss": 1.928,
      "step": 108
    },
    {
      "epoch": 3.526748971193416,
      "grad_norm": 1.258399248123169,
      "learning_rate": 9.25659690812045e-05,
      "loss": 1.9122,
      "step": 109
    },
    {
      "epoch": 3.5596707818930042,
      "grad_norm": 1.046035885810852,
      "learning_rate": 9.01480168418894e-05,
      "loss": 1.9912,
      "step": 110
    },
    {
      "epoch": 3.5925925925925926,
      "grad_norm": 1.1371641159057617,
      "learning_rate": 8.776425088350712e-05,
      "loss": 1.9102,
      "step": 111
    },
    {
      "epoch": 3.625514403292181,
      "grad_norm": 1.2750909328460693,
      "learning_rate": 8.541575991592593e-05,
      "loss": 1.9856,
      "step": 112
    },
    {
      "epoch": 3.625514403292181,
      "eval_loss": 2.1129703521728516,
      "eval_runtime": 16.1039,
      "eval_samples_per_second": 7.948,
      "eval_steps_per_second": 7.948,
      "step": 112
    },
    {
      "epoch": 3.6584362139917697,
      "grad_norm": 1.1444056034088135,
      "learning_rate": 8.310361653827552e-05,
      "loss": 1.9608,
      "step": 113
    },
    {
      "epoch": 3.691358024691358,
      "grad_norm": 1.2343782186508179,
      "learning_rate": 8.082887674907099e-05,
      "loss": 1.9555,
      "step": 114
    },
    {
      "epoch": 3.7242798353909468,
      "grad_norm": 1.0039732456207275,
      "learning_rate": 7.859257946391877e-05,
      "loss": 1.9302,
      "step": 115
    },
    {
      "epoch": 3.757201646090535,
      "grad_norm": 1.0222059488296509,
      "learning_rate": 7.639574604102505e-05,
      "loss": 2.0191,
      "step": 116
    },
    {
      "epoch": 3.7901234567901234,
      "grad_norm": 1.1105767488479614,
      "learning_rate": 7.423937981472221e-05,
      "loss": 1.9242,
      "step": 117
    },
    {
      "epoch": 3.8230452674897117,
      "grad_norm": 1.1001155376434326,
      "learning_rate": 7.212446563722798e-05,
      "loss": 1.937,
      "step": 118
    },
    {
      "epoch": 3.8559670781893005,
      "grad_norm": 0.9873670935630798,
      "learning_rate": 7.005196942884484e-05,
      "loss": 2.0259,
      "step": 119
    },
    {
      "epoch": 3.888888888888889,
      "grad_norm": 1.217698335647583,
      "learning_rate": 6.802283773680678e-05,
      "loss": 1.8954,
      "step": 120
    },
    {
      "epoch": 3.888888888888889,
      "eval_loss": 2.096020460128784,
      "eval_runtime": 15.65,
      "eval_samples_per_second": 8.179,
      "eval_steps_per_second": 8.179,
      "step": 120
    },
    {
      "epoch": 3.9218106995884776,
      "grad_norm": 1.0736429691314697,
      "learning_rate": 6.603799730297347e-05,
      "loss": 1.9687,
      "step": 121
    },
    {
      "epoch": 3.954732510288066,
      "grad_norm": 1.0001243352890015,
      "learning_rate": 6.409835464057024e-05,
      "loss": 1.907,
      "step": 122
    },
    {
      "epoch": 3.9876543209876543,
      "grad_norm": 1.0564206838607788,
      "learning_rate": 6.220479562016685e-05,
      "loss": 1.9505,
      "step": 123
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.5941741466522217,
      "learning_rate": 6.035818506508402e-05,
      "loss": 1.994,
      "step": 124
    },
    {
      "epoch": 4.032921810699588,
      "grad_norm": 1.129037857055664,
      "learning_rate": 5.8559366356412546e-05,
      "loss": 1.9396,
      "step": 125
    },
    {
      "epoch": 4.065843621399177,
      "grad_norm": 1.154053807258606,
      "learning_rate": 5.680916104782587e-05,
      "loss": 1.8889,
      "step": 126
    },
    {
      "epoch": 4.098765432098766,
      "grad_norm": 1.0264942646026611,
      "learning_rate": 5.510836849036104e-05,
      "loss": 1.9248,
      "step": 127
    },
    {
      "epoch": 4.131687242798354,
      "grad_norm": 1.0345796346664429,
      "learning_rate": 5.345776546734071e-05,
      "loss": 1.9061,
      "step": 128
    },
    {
      "epoch": 4.131687242798354,
      "eval_loss": 2.095348358154297,
      "eval_runtime": 13.5766,
      "eval_samples_per_second": 9.428,
      "eval_steps_per_second": 9.428,
      "step": 128
    },
    {
      "epoch": 4.1646090534979425,
      "grad_norm": 1.1268070936203003,
      "learning_rate": 5.185810583960152e-05,
      "loss": 1.9221,
      "step": 129
    },
    {
      "epoch": 4.197530864197531,
      "grad_norm": 1.1032994985580444,
      "learning_rate": 5.031012020119222e-05,
      "loss": 1.9198,
      "step": 130
    },
    {
      "epoch": 4.230452674897119,
      "grad_norm": 1.1186856031417847,
      "learning_rate": 4.8814515545697804e-05,
      "loss": 1.9083,
      "step": 131
    },
    {
      "epoch": 4.2633744855967075,
      "grad_norm": 0.9443172812461853,
      "learning_rate": 4.737197494334243e-05,
      "loss": 1.9248,
      "step": 132
    },
    {
      "epoch": 4.296296296296296,
      "grad_norm": 1.0120322704315186,
      "learning_rate": 4.5983157229018776e-05,
      "loss": 1.8826,
      "step": 133
    },
    {
      "epoch": 4.329218106995885,
      "grad_norm": 1.0023010969161987,
      "learning_rate": 4.464869670138592e-05,
      "loss": 1.894,
      "step": 134
    },
    {
      "epoch": 4.362139917695473,
      "grad_norm": 0.9592952132225037,
      "learning_rate": 4.336920283317343e-05,
      "loss": 1.9836,
      "step": 135
    },
    {
      "epoch": 4.395061728395062,
      "grad_norm": 1.109610676765442,
      "learning_rate": 4.214525999282402e-05,
      "loss": 1.9,
      "step": 136
    },
    {
      "epoch": 4.395061728395062,
      "eval_loss": 2.094088554382324,
      "eval_runtime": 13.7608,
      "eval_samples_per_second": 9.302,
      "eval_steps_per_second": 9.302,
      "step": 136
    },
    {
      "epoch": 4.42798353909465,
      "grad_norm": 0.9753338694572449,
      "learning_rate": 4.097742717760162e-05,
      "loss": 2.0177,
      "step": 137
    },
    {
      "epoch": 4.460905349794238,
      "grad_norm": 0.9892321228981018,
      "learning_rate": 3.986623775828708e-05,
      "loss": 1.9613,
      "step": 138
    },
    {
      "epoch": 4.493827160493828,
      "grad_norm": 1.0024096965789795,
      "learning_rate": 3.881219923557781e-05,
      "loss": 1.8913,
      "step": 139
    },
    {
      "epoch": 4.526748971193416,
      "grad_norm": 0.9965609908103943,
      "learning_rate": 3.7815793008302995e-05,
      "loss": 1.9076,
      "step": 140
    },
    {
      "epoch": 4.559670781893004,
      "grad_norm": 1.0618939399719238,
      "learning_rate": 3.687747415355973e-05,
      "loss": 1.9115,
      "step": 141
    },
    {
      "epoch": 4.592592592592593,
      "grad_norm": 1.0438735485076904,
      "learning_rate": 3.599767121887099e-05,
      "loss": 1.9004,
      "step": 142
    },
    {
      "epoch": 4.625514403292181,
      "grad_norm": 1.0044203996658325,
      "learning_rate": 3.517678602646011e-05,
      "loss": 1.9004,
      "step": 143
    },
    {
      "epoch": 4.658436213991769,
      "grad_norm": 1.0234990119934082,
      "learning_rate": 3.441519348973103e-05,
      "loss": 1.9088,
      "step": 144
    },
    {
      "epoch": 4.658436213991769,
      "eval_loss": 2.097151279449463,
      "eval_runtime": 13.6777,
      "eval_samples_per_second": 9.358,
      "eval_steps_per_second": 9.358,
      "step": 144
    },
    {
      "epoch": 4.6913580246913575,
      "grad_norm": 1.4477194547653198,
      "learning_rate": 3.3713241442038604e-05,
      "loss": 1.9099,
      "step": 145
    },
    {
      "epoch": 4.724279835390947,
      "grad_norm": 1.064429521560669,
      "learning_rate": 3.307125047782656e-05,
      "loss": 1.8826,
      "step": 146
    },
    {
      "epoch": 4.757201646090535,
      "grad_norm": 1.0766072273254395,
      "learning_rate": 3.2489513806206166e-05,
      "loss": 1.9293,
      "step": 147
    },
    {
      "epoch": 4.790123456790123,
      "grad_norm": 1.0254855155944824,
      "learning_rate": 3.1968297117042256e-05,
      "loss": 1.9121,
      "step": 148
    },
    {
      "epoch": 4.823045267489712,
      "grad_norm": 1.0165835618972778,
      "learning_rate": 3.150783845960765e-05,
      "loss": 1.8939,
      "step": 149
    },
    {
      "epoch": 4.8559670781893,
      "grad_norm": 1.0315486192703247,
      "learning_rate": 3.110834813386178e-05,
      "loss": 1.8833,
      "step": 150
    },
    {
      "epoch": 4.888888888888889,
      "grad_norm": 0.9967024922370911,
      "learning_rate": 3.077000859440277e-05,
      "loss": 1.9226,
      "step": 151
    },
    {
      "epoch": 4.921810699588478,
      "grad_norm": 0.9889740347862244,
      "learning_rate": 3.0492974367137066e-05,
      "loss": 1.8581,
      "step": 152
    },
    {
      "epoch": 4.921810699588478,
      "eval_loss": 2.092933416366577,
      "eval_runtime": 14.8642,
      "eval_samples_per_second": 8.611,
      "eval_steps_per_second": 8.611,
      "step": 152
    },
    {
      "epoch": 4.954732510288066,
      "grad_norm": 1.037131428718567,
      "learning_rate": 3.0277371978704595e-05,
      "loss": 1.8946,
      "step": 153
    },
    {
      "epoch": 4.987654320987654,
      "grad_norm": 1.046742558479309,
      "learning_rate": 3.0123299898691732e-05,
      "loss": 2.0051,
      "step": 154
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.5472654104232788,
      "learning_rate": 3.0030828494658433e-05,
      "loss": 1.9767,
      "step": 155
    }
  ],
  "logging_steps": 1,
  "max_steps": 155,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 16,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2508748250400000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
