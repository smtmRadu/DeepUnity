{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177eaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/MobileLLM-125M were not used when initializing MobileLLMForCausalLM: ['lm_head.weight']\n",
      "- This IS expected if you are initializing MobileLLMForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileLLMForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           0.3
          ],
          "y": [
           0.5,
           1
          ]
         },
         "hole": 0.3,
         "hovertemplate": "<b>%{hovertext}</b><extra></extra>",
         "hovertext": [
          "<b>Trainable</b><br>124,635,456<br>100.0%"
         ],
         "labels": [
          "Trainable"
         ],
         "marker": {
          "colors": [
           "#2ecc71"
          ]
         },
         "name": "Trainable Status",
         "pull": [
          0.02
         ],
         "text": [
          "Trainable<br>100.0%"
         ],
         "textfont": {
          "color": "white",
          "size": 11
         },
         "textinfo": "text",
         "textposition": "auto",
         "type": "pie",
         "values": [
          100
         ]
        },
        {
         "domain": {
          "x": [
           0.35,
           0.6499999999999999
          ],
          "y": [
           0.5,
           1
          ]
         },
         "hole": 0.3,
         "hovertemplate": "<b>%{hovertext}</b><extra></extra>",
         "hovertext": [
          "<b>float32</b><br>124,635,456<br>100.0%"
         ],
         "labels": [
          "float32"
         ],
         "marker": {
          "colors": [
           "#9b59b6"
          ]
         },
         "name": "Data Types",
         "pull": [
          0.02
         ],
         "text": [
          "float32<br>100.0%"
         ],
         "textfont": {
          "color": "white",
          "size": 11
         },
         "textinfo": "text",
         "textposition": "auto",
         "type": "pie",
         "values": [
          100
         ]
        },
        {
         "domain": {
          "x": [
           0.7,
           1
          ],
          "y": [
           0.5,
           1
          ]
         },
         "hole": 0.3,
         "hovertemplate": "<b>%{hovertext}</b><extra></extra>",
         "hovertext": [
          "<b>cpu</b><br>475.45 MB<br>100.0%"
         ],
         "labels": [
          "cpu"
         ],
         "marker": {
          "colors": [
           "#f39c12"
          ]
         },
         "name": "Devices",
         "pull": [
          0.02
         ],
         "text": [
          "cpu<br>100.0%"
         ],
         "textfont": {
          "color": "white",
          "size": 11
         },
         "textinfo": "text",
         "textposition": "auto",
         "type": "pie",
         "values": [
          100
         ]
        },
        {
         "cells": {
          "align": "left",
          "fill": {
           "color": "#2d2d2d"
          },
          "font": {
           "color": "white",
           "size": 10
          },
          "height": 32,
          "line": {
           "width": 0
          },
          "values": [
           [
            "MobileLLMForCausalLM",
            "model",
            "model.embed_tokens",
            "model.layers",
            "model.layers.0",
            "model.layers.0.self_attn",
            "model.layers.0.self_attn.q_proj",
            "model.layers.0.self_attn.k_proj",
            "model.layers.0.self_attn.v_proj",
            "model.layers.0.self_attn.o_proj",
            "model.layers.0.self_attn.rotary_emb",
            "model.layers.0.mlp",
            "model.layers.0.mlp.gate_proj",
            "model.layers.0.mlp.up_proj",
            "model.layers.0.mlp.down_proj",
            "model.layers.0.mlp.act_fn",
            "model.layers.0.input_layernorm",
            "model.layers.0.post_attention_layernorm",
            "model.layers.1",
            "model.layers.1.self_attn",
            "model.layers.1.self_attn.q_proj",
            "model.layers.1.self_attn.k_proj",
            "model.layers.1.self_attn.v_proj",
            "model.layers.1.self_attn.o_proj",
            "model.layers.1.self_attn.rotary_emb",
            "model.layers.1.mlp",
            "model.layers.1.mlp.gate_proj",
            "model.layers.1.mlp.up_proj",
            "model.layers.1.mlp.down_proj",
            "model.layers.1.mlp.act_fn",
            "model.layers.1.input_layernorm",
            "model.layers.1.post_attention_layernorm",
            "model.layers.2",
            "model.layers.2.self_attn",
            "model.layers.2.self_attn.q_proj",
            "model.layers.2.self_attn.k_proj",
            "model.layers.2.self_attn.v_proj",
            "model.layers.2.self_attn.o_proj",
            "model.layers.2.self_attn.rotary_emb",
            "model.layers.2.mlp",
            "model.layers.2.mlp.gate_proj",
            "model.layers.2.mlp.up_proj",
            "model.layers.2.mlp.down_proj",
            "model.layers.2.mlp.act_fn",
            "model.layers.2.input_layernorm",
            "model.layers.2.post_attention_layernorm",
            "model.layers.3",
            "model.layers.3.self_attn",
            "model.layers.3.self_attn.q_proj",
            "model.layers.3.self_attn.k_proj",
            "model.layers.3.self_attn.v_proj",
            "model.layers.3.self_attn.o_proj",
            "model.layers.3.self_attn.rotary_emb",
            "model.layers.3.mlp",
            "model.layers.3.mlp.gate_proj",
            "model.layers.3.mlp.up_proj",
            "model.layers.3.mlp.down_proj",
            "model.layers.3.mlp.act_fn",
            "model.layers.3.input_layernorm",
            "model.layers.3.post_attention_layernorm",
            "model.layers.4",
            "model.layers.4.self_attn",
            "model.layers.4.self_attn.q_proj",
            "model.layers.4.self_attn.k_proj",
            "model.layers.4.self_attn.v_proj",
            "model.layers.4.self_attn.o_proj",
            "model.layers.4.self_attn.rotary_emb",
            "model.layers.4.mlp",
            "model.layers.4.mlp.gate_proj",
            "model.layers.4.mlp.up_proj",
            "model.layers.4.mlp.down_proj",
            "model.layers.4.mlp.act_fn",
            "model.layers.4.input_layernorm",
            "model.layers.4.post_attention_layernorm",
            "model.layers.5",
            "model.layers.5.self_attn",
            "model.layers.5.self_attn.q_proj",
            "model.layers.5.self_attn.k_proj",
            "model.layers.5.self_attn.v_proj",
            "model.layers.5.self_attn.o_proj",
            "model.layers.5.self_attn.rotary_emb",
            "model.layers.5.mlp",
            "model.layers.5.mlp.gate_proj",
            "model.layers.5.mlp.up_proj",
            "model.layers.5.mlp.down_proj",
            "model.layers.5.mlp.act_fn",
            "model.layers.5.input_layernorm",
            "model.layers.5.post_attention_layernorm",
            "model.layers.6",
            "model.layers.6.self_attn",
            "model.layers.6.self_attn.q_proj",
            "model.layers.6.self_attn.k_proj",
            "model.layers.6.self_attn.v_proj",
            "model.layers.6.self_attn.o_proj",
            "model.layers.6.self_attn.rotary_emb",
            "model.layers.6.mlp",
            "model.layers.6.mlp.gate_proj",
            "model.layers.6.mlp.up_proj",
            "model.layers.6.mlp.down_proj",
            "model.layers.6.mlp.act_fn",
            "model.layers.6.input_layernorm",
            "model.layers.6.post_attention_layernorm",
            "model.layers.7",
            "model.layers.7.self_attn",
            "model.layers.7.self_attn.q_proj",
            "model.layers.7.self_attn.k_proj",
            "model.layers.7.self_attn.v_proj",
            "model.layers.7.self_attn.o_proj",
            "model.layers.7.self_attn.rotary_emb",
            "model.layers.7.mlp",
            "model.layers.7.mlp.gate_proj",
            "model.layers.7.mlp.up_proj",
            "model.layers.7.mlp.down_proj",
            "model.layers.7.mlp.act_fn",
            "model.layers.7.input_layernorm",
            "model.layers.7.post_attention_layernorm",
            "model.layers.8",
            "model.layers.8.self_attn",
            "model.layers.8.self_attn.q_proj",
            "model.layers.8.self_attn.k_proj",
            "model.layers.8.self_attn.v_proj",
            "model.layers.8.self_attn.o_proj",
            "model.layers.8.self_attn.rotary_emb",
            "model.layers.8.mlp",
            "model.layers.8.mlp.gate_proj",
            "model.layers.8.mlp.up_proj",
            "model.layers.8.mlp.down_proj",
            "model.layers.8.mlp.act_fn",
            "model.layers.8.input_layernorm",
            "model.layers.8.post_attention_layernorm",
            "model.layers.9",
            "model.layers.9.self_attn",
            "model.layers.9.self_attn.q_proj",
            "model.layers.9.self_attn.k_proj",
            "model.layers.9.self_attn.v_proj",
            "model.layers.9.self_attn.o_proj",
            "model.layers.9.self_attn.rotary_emb",
            "model.layers.9.mlp",
            "model.layers.9.mlp.gate_proj",
            "model.layers.9.mlp.up_proj",
            "model.layers.9.mlp.down_proj",
            "model.layers.9.mlp.act_fn",
            "model.layers.9.input_layernorm",
            "model.layers.9.post_attention_layernorm",
            "model.layers.10",
            "model.layers.10.self_attn",
            "model.layers.10.self_attn.q_proj",
            "model.layers.10.self_attn.k_proj",
            "model.layers.10.self_attn.v_proj",
            "model.layers.10.self_attn.o_proj",
            "model.layers.10.self_attn.rotary_emb",
            "model.layers.10.mlp",
            "model.layers.10.mlp.gate_proj",
            "model.layers.10.mlp.up_proj",
            "model.layers.10.mlp.down_proj",
            "model.layers.10.mlp.act_fn",
            "model.layers.10.input_layernorm",
            "model.layers.10.post_attention_layernorm",
            "model.layers.11",
            "model.layers.11.self_attn",
            "model.layers.11.self_attn.q_proj",
            "model.layers.11.self_attn.k_proj",
            "model.layers.11.self_attn.v_proj",
            "model.layers.11.self_attn.o_proj",
            "model.layers.11.self_attn.rotary_emb",
            "model.layers.11.mlp",
            "model.layers.11.mlp.gate_proj",
            "model.layers.11.mlp.up_proj",
            "model.layers.11.mlp.down_proj",
            "model.layers.11.mlp.act_fn",
            "model.layers.11.input_layernorm",
            "model.layers.11.post_attention_layernorm",
            "model.layers.12",
            "model.layers.12.self_attn",
            "model.layers.12.self_attn.q_proj",
            "model.layers.12.self_attn.k_proj",
            "model.layers.12.self_attn.v_proj",
            "model.layers.12.self_attn.o_proj",
            "model.layers.12.self_attn.rotary_emb",
            "model.layers.12.mlp",
            "model.layers.12.mlp.gate_proj",
            "model.layers.12.mlp.up_proj",
            "model.layers.12.mlp.down_proj",
            "model.layers.12.mlp.act_fn",
            "model.layers.12.input_layernorm",
            "model.layers.12.post_attention_layernorm",
            "model.layers.13",
            "model.layers.13.self_attn",
            "model.layers.13.self_attn.q_proj",
            "model.layers.13.self_attn.k_proj",
            "model.layers.13.self_attn.v_proj",
            "model.layers.13.self_attn.o_proj",
            "model.layers.13.self_attn.rotary_emb",
            "model.layers.13.mlp",
            "model.layers.13.mlp.gate_proj",
            "model.layers.13.mlp.up_proj",
            "model.layers.13.mlp.down_proj",
            "model.layers.13.mlp.act_fn",
            "model.layers.13.input_layernorm",
            "model.layers.13.post_attention_layernorm",
            "model.layers.14",
            "model.layers.14.self_attn",
            "model.layers.14.self_attn.q_proj",
            "model.layers.14.self_attn.k_proj",
            "model.layers.14.self_attn.v_proj",
            "model.layers.14.self_attn.o_proj",
            "model.layers.14.self_attn.rotary_emb",
            "model.layers.14.mlp",
            "model.layers.14.mlp.gate_proj",
            "model.layers.14.mlp.up_proj",
            "model.layers.14.mlp.down_proj",
            "model.layers.14.mlp.act_fn",
            "model.layers.14.input_layernorm",
            "model.layers.14.post_attention_layernorm",
            "model.layers.15",
            "model.layers.15.self_attn",
            "model.layers.15.self_attn.q_proj",
            "model.layers.15.self_attn.k_proj",
            "model.layers.15.self_attn.v_proj",
            "model.layers.15.self_attn.o_proj",
            "model.layers.15.self_attn.rotary_emb",
            "model.layers.15.mlp",
            "model.layers.15.mlp.gate_proj",
            "model.layers.15.mlp.up_proj",
            "model.layers.15.mlp.down_proj",
            "model.layers.15.mlp.act_fn",
            "model.layers.15.input_layernorm",
            "model.layers.15.post_attention_layernorm",
            "model.layers.16",
            "model.layers.16.self_attn",
            "model.layers.16.self_attn.q_proj",
            "model.layers.16.self_attn.k_proj",
            "model.layers.16.self_attn.v_proj",
            "model.layers.16.self_attn.o_proj",
            "model.layers.16.self_attn.rotary_emb",
            "model.layers.16.mlp",
            "model.layers.16.mlp.gate_proj",
            "model.layers.16.mlp.up_proj",
            "model.layers.16.mlp.down_proj",
            "model.layers.16.mlp.act_fn",
            "model.layers.16.input_layernorm",
            "model.layers.16.post_attention_layernorm",
            "model.layers.17",
            "model.layers.17.self_attn",
            "model.layers.17.self_attn.q_proj",
            "model.layers.17.self_attn.k_proj",
            "model.layers.17.self_attn.v_proj",
            "model.layers.17.self_attn.o_proj",
            "model.layers.17.self_attn.rotary_emb",
            "model.layers.17.mlp",
            "model.layers.17.mlp.gate_proj",
            "model.layers.17.mlp.up_proj",
            "model.layers.17.mlp.down_proj",
            "model.layers.17.mlp.act_fn",
            "model.layers.17.input_layernorm",
            "model.layers.17.post_attention_layernorm",
            "model.layers.18",
            "model.layers.18.self_attn",
            "model.layers.18.self_attn.q_proj",
            "model.layers.18.self_attn.k_proj",
            "model.layers.18.self_attn.v_proj",
            "model.layers.18.self_attn.o_proj",
            "model.layers.18.self_attn.rotary_emb",
            "model.layers.18.mlp",
            "model.layers.18.mlp.gate_proj",
            "model.layers.18.mlp.up_proj",
            "model.layers.18.mlp.down_proj",
            "model.layers.18.mlp.act_fn",
            "model.layers.18.input_layernorm",
            "model.layers.18.post_attention_layernorm",
            "model.layers.19",
            "model.layers.19.self_attn",
            "model.layers.19.self_attn.q_proj",
            "model.layers.19.self_attn.k_proj",
            "model.layers.19.self_attn.v_proj",
            "model.layers.19.self_attn.o_proj",
            "model.layers.19.self_attn.rotary_emb",
            "model.layers.19.mlp",
            "model.layers.19.mlp.gate_proj",
            "model.layers.19.mlp.up_proj",
            "model.layers.19.mlp.down_proj",
            "model.layers.19.mlp.act_fn",
            "model.layers.19.input_layernorm",
            "model.layers.19.post_attention_layernorm",
            "model.layers.20",
            "model.layers.20.self_attn",
            "model.layers.20.self_attn.q_proj",
            "model.layers.20.self_attn.k_proj",
            "model.layers.20.self_attn.v_proj",
            "model.layers.20.self_attn.o_proj",
            "model.layers.20.self_attn.rotary_emb",
            "model.layers.20.mlp",
            "model.layers.20.mlp.gate_proj",
            "model.layers.20.mlp.up_proj",
            "model.layers.20.mlp.down_proj",
            "model.layers.20.mlp.act_fn",
            "model.layers.20.input_layernorm",
            "model.layers.20.post_attention_layernorm",
            "model.layers.21",
            "model.layers.21.self_attn",
            "model.layers.21.self_attn.q_proj",
            "model.layers.21.self_attn.k_proj",
            "model.layers.21.self_attn.v_proj",
            "model.layers.21.self_attn.o_proj",
            "model.layers.21.self_attn.rotary_emb",
            "model.layers.21.mlp",
            "model.layers.21.mlp.gate_proj",
            "model.layers.21.mlp.up_proj",
            "model.layers.21.mlp.down_proj",
            "model.layers.21.mlp.act_fn",
            "model.layers.21.input_layernorm",
            "model.layers.21.post_attention_layernorm",
            "model.layers.22",
            "model.layers.22.self_attn",
            "model.layers.22.self_attn.q_proj",
            "model.layers.22.self_attn.k_proj",
            "model.layers.22.self_attn.v_proj",
            "model.layers.22.self_attn.o_proj",
            "model.layers.22.self_attn.rotary_emb",
            "model.layers.22.mlp",
            "model.layers.22.mlp.gate_proj",
            "model.layers.22.mlp.up_proj",
            "model.layers.22.mlp.down_proj",
            "model.layers.22.mlp.act_fn",
            "model.layers.22.input_layernorm",
            "model.layers.22.post_attention_layernorm",
            "model.layers.23",
            "model.layers.23.self_attn",
            "model.layers.23.self_attn.q_proj",
            "model.layers.23.self_attn.k_proj",
            "model.layers.23.self_attn.v_proj",
            "model.layers.23.self_attn.o_proj",
            "model.layers.23.self_attn.rotary_emb",
            "model.layers.23.mlp",
            "model.layers.23.mlp.gate_proj",
            "model.layers.23.mlp.up_proj",
            "model.layers.23.mlp.down_proj",
            "model.layers.23.mlp.act_fn",
            "model.layers.23.input_layernorm",
            "model.layers.23.post_attention_layernorm",
            "model.layers.24",
            "model.layers.24.self_attn",
            "model.layers.24.self_attn.q_proj",
            "model.layers.24.self_attn.k_proj",
            "model.layers.24.self_attn.v_proj",
            "model.layers.24.self_attn.o_proj",
            "model.layers.24.self_attn.rotary_emb",
            "model.layers.24.mlp",
            "model.layers.24.mlp.gate_proj",
            "model.layers.24.mlp.up_proj",
            "model.layers.24.mlp.down_proj",
            "model.layers.24.mlp.act_fn",
            "model.layers.24.input_layernorm",
            "model.layers.24.post_attention_layernorm",
            "model.layers.25",
            "model.layers.25.self_attn",
            "model.layers.25.self_attn.q_proj",
            "model.layers.25.self_attn.k_proj",
            "model.layers.25.self_attn.v_proj",
            "model.layers.25.self_attn.o_proj",
            "model.layers.25.self_attn.rotary_emb",
            "model.layers.25.mlp",
            "model.layers.25.mlp.gate_proj",
            "model.layers.25.mlp.up_proj",
            "model.layers.25.mlp.down_proj",
            "model.layers.25.mlp.act_fn",
            "model.layers.25.input_layernorm",
            "model.layers.25.post_attention_layernorm",
            "model.layers.26",
            "model.layers.26.self_attn",
            "model.layers.26.self_attn.q_proj",
            "model.layers.26.self_attn.k_proj",
            "model.layers.26.self_attn.v_proj",
            "model.layers.26.self_attn.o_proj",
            "model.layers.26.self_attn.rotary_emb",
            "model.layers.26.mlp",
            "model.layers.26.mlp.gate_proj",
            "model.layers.26.mlp.up_proj",
            "model.layers.26.mlp.down_proj",
            "model.layers.26.mlp.act_fn",
            "model.layers.26.input_layernorm",
            "model.layers.26.post_attention_layernorm",
            "model.layers.27",
            "model.layers.27.self_attn",
            "model.layers.27.self_attn.q_proj",
            "model.layers.27.self_attn.k_proj",
            "model.layers.27.self_attn.v_proj",
            "model.layers.27.self_attn.o_proj",
            "model.layers.27.self_attn.rotary_emb",
            "model.layers.27.mlp",
            "model.layers.27.mlp.gate_proj",
            "model.layers.27.mlp.up_proj",
            "model.layers.27.mlp.down_proj",
            "model.layers.27.mlp.act_fn",
            "model.layers.27.input_layernorm",
            "model.layers.27.post_attention_layernorm",
            "model.layers.28",
            "model.layers.28.self_attn",
            "model.layers.28.self_attn.q_proj",
            "model.layers.28.self_attn.k_proj",
            "model.layers.28.self_attn.v_proj",
            "model.layers.28.self_attn.o_proj",
            "model.layers.28.self_attn.rotary_emb",
            "model.layers.28.mlp",
            "model.layers.28.mlp.gate_proj",
            "model.layers.28.mlp.up_proj",
            "model.layers.28.mlp.down_proj",
            "model.layers.28.mlp.act_fn",
            "model.layers.28.input_layernorm",
            "model.layers.28.post_attention_layernorm",
            "model.layers.29",
            "model.layers.29.self_attn",
            "model.layers.29.self_attn.q_proj",
            "model.layers.29.self_attn.k_proj",
            "model.layers.29.self_attn.v_proj",
            "model.layers.29.self_attn.o_proj",
            "model.layers.29.self_attn.rotary_emb",
            "model.layers.29.mlp",
            "model.layers.29.mlp.gate_proj",
            "model.layers.29.mlp.up_proj",
            "model.layers.29.mlp.down_proj",
            "model.layers.29.mlp.act_fn",
            "model.layers.29.input_layernorm",
            "model.layers.29.post_attention_layernorm",
            "model.norm"
           ],
           [
            "MobileLLMForCausalLM",
            "MobileLLMModel",
            "Embedding",
            "ModuleList",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaDecoderLayer",
            "LlamaSdpaAttention",
            "Linear",
            "Linear",
            "Linear",
            "Linear",
            "LlamaRotaryEmbedding",
            "LlamaMLP",
            "Linear",
            "Linear",
            "Linear",
            "SiLU",
            "LlamaRMSNorm",
            "LlamaRMSNorm",
            "LlamaRMSNorm"
           ],
           [
            "-",
            "-",
            "18,432,000 = [32000, 576]",
            "-",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "-",
            "-",
            "331,776 = [576, 576]",
            "110,592 = [192, 576]",
            "110,592 = [192, 576]",
            "331,776 = [576, 576]",
            "-",
            "-",
            "884,736 = [1536, 576]",
            "884,736 = [1536, 576]",
            "884,736 = [576, 1536]",
            "-",
            "576 = [576]",
            "576 = [576]",
            "576 = [576]"
           ],
           [
            "-",
            "-",
            "14.79%",
            "-",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "-",
            "-",
            "0.27%",
            "0.09%",
            "0.09%",
            "0.27%",
            "----",
            "-",
            "0.71%",
            "0.71%",
            "0.71%",
            "----",
            "0.00%",
            "0.00%",
            "0.00%"
           ],
           [
            "Container",
            "Container",
            "float32 (100%)",
            "Container",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "Container",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "Container",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)",
            "N/A",
            "float32 (100%)",
            "float32 (100%)",
            "float32 (100%)"
           ],
           [
            "Container",
            "Container",
            "cpu (100%)",
            "Container",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "Container",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "Container",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)",
            "N/A",
            "cpu (100%)",
            "cpu (100%)",
            "cpu (100%)"
           ],
           [
            "0 B",
            "0 B",
            "70.31 MB",
            "0 B",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "0 B",
            "0 B",
            "1.27 MB",
            "432.0 KB",
            "432.0 KB",
            "1.27 MB",
            "0 B",
            "0 B",
            "3.38 MB",
            "3.38 MB",
            "3.38 MB",
            "0 B",
            "2.25 KB",
            "2.25 KB",
            "2.25 KB"
           ],
           [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
           ]
          ]
         },
         "columnwidth": [
          3,
          1.25,
          2,
          0.75,
          1.25,
          1.15,
          0.75,
          0.6
         ],
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           0.5
          ]
         },
         "header": {
          "align": "left",
          "fill": {
           "color": "#404040"
          },
          "font": {
           "color": "white",
           "size": 12
          },
          "line": {
           "width": 0
          },
          "values": [
           "Module Name",
           "Type",
           "Params (Shape)",
           "% Total",
           "Dtypes (% module)",
           "Device(s) (% module)",
           "Est. Size",
           "Trainable"
          ]
         },
         "type": "table"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 12
          },
          "showarrow": false,
          "text": "Parameter Status",
          "x": 0.15,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper",
          "yshift": -80
         },
         {
          "font": {
           "size": 12
          },
          "showarrow": false,
          "text": "Parameter Data Types",
          "x": 0.49999999999999994,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper",
          "yshift": -80
         },
         {
          "font": {
           "size": 12
          },
          "showarrow": false,
          "text": "Parameter Devices",
          "x": 0.85,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper",
          "yshift": -80
         }
        ],
        "height": 1100,
        "margin": {
         "b": 25,
         "l": 25,
         "r": 25,
         "t": 25
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 16
         },
         "text": "<b>MobileLLMForCausalLM</b><br><sub>Source: C:\\Users\\radup\\.cache\\huggingface\\modules\\transformers_modules\\facebook\\MobileLLM-125M\\f6820a829b347aaa6674a705c82be3db47b1f9ee\\modeling_mobilellm.py</sub><br><sub>Total Parameters: 124,635,456 | Estimated Size: 475.45 MB</sub>",
         "x": 0.5,
         "y": 0.98
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/MobileLLM-125M\", trust_remote_code=True)\n",
    "\n",
    "from flashml.legacy import inspect_model\n",
    "\n",
    "inspect_model(model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc72bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileLLMForCausalLM(\n",
      "  (model): MobileLLMModel(\n",
      "    (embed_tokens): Embedding(32000, 576)\n",
      "    (layers): ModuleList(\n",
      "      (0-29): 30 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
      "          (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
      "          (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
      "          (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
      "          (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
      "          (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d348375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers_modules.facebook.MobileLLM-125M.f6820a829b347aaa6674a705c82be3db47b1f9ee.modeling_mobilellm.LlamaRotaryEmbedding'>\n"
     ]
    }
   ],
   "source": [
    "model._modules['model'].layers[0].self_attn.rotary_emb\n",
    "rotary_emb = model.model.layers[0].self_attn.rotary_emb\n",
    "print(type(rotary_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "model._modules[\"model\"]\n",
    "\n",
    "norm = model._modules[\"model\"].norm\n",
    "with open(f\"params/norm.bin\", \"wb\")as f:\n",
    "    f.write(norm.weight.detach().cpu().numpy().astype(np.float32).tobytes())\n",
    "\n",
    "\n",
    "embed_tokens = model._modules[\"model\"].embed_tokens.weight.detach()\n",
    "embed_tokens_flat = embed_tokens.flatten()\n",
    "\n",
    "os.makedirs(\"params/embed_tokens\", exist_ok=True)\n",
    "\n",
    "num_chunks = 8\n",
    "chunks = torch.chunk(embed_tokens_flat, num_chunks)\n",
    "\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    # Convert to float32 numpy array\n",
    "    np_chunk = chunk.cpu().numpy().astype('float32')\n",
    "    \n",
    "    # Write raw binary\n",
    "    with open(f\"params/embed_tokens/part_{idx}.bin\", \"wb\") as f:\n",
    "        f.write(np_chunk.tobytes())\n",
    "    \n",
    "    print(f\"Saved chunk {idx} with {np_chunk.size} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "for idx, layer in tqdm(enumerate(model._modules[\"model\"].layers)):\n",
    "    self_attn = layer.self_attn\n",
    "    mlp = layer.mlp\n",
    "    input_layernorm = layer.input_layernorm\n",
    "    post_attention_layernorm = layer.post_attention_layernorm\n",
    "    \n",
    "    os.makedirs(f\"params/layer_{idx}\", exist_ok = True)\n",
    "    \n",
    "    # ================================================================ GQA =====================================================\n",
    "    with open(f\"params/layer_{idx}/self_attn_q_proj.bin\", \"wb\")as f:\n",
    "        f.write(self_attn.q_proj.weight.detach().flatten().cpu().numpy().astype(np.float32).tobytes())\n",
    "        \n",
    "    with open(f\"params/layer_{idx}/self_attn_k_proj.bin\", \"wb\")as f:\n",
    "        f.write(self_attn.k_proj.weight.detach().flatten().cpu().numpy().astype(np.float32).tobytes())\n",
    "        \n",
    "    with open(f\"params/layer_{idx}/self_attn_v_proj.bin\", \"wb\")as f:\n",
    "        f.write(self_attn.v_proj.weight.detach().flatten().cpu().numpy().astype(np.float32).tobytes())\n",
    "    with open(f\"params/layer_{idx}/self_attn_o_proj.bin\", \"wb\")as f:\n",
    "        f.write(self_attn.o_proj.weight.detach().flatten().cpu().numpy().astype(np.float32).tobytes())\n",
    "        \n",
    "    \n",
    "    # =============================================================== MLP ======================================================\n",
    "    with open(f\"params/layer_{idx}/mlp_gate_proj.bin\", \"wb\")as f:\n",
    "        f.write(mlp.gate_proj.weight.detach().cpu().flatten().numpy().astype(np.float32).tobytes())\n",
    "    with open(f\"params/layer_{idx}/mlp_up_proj.bin\", \"wb\")as f:\n",
    "        f.write(mlp.up_proj.weight.detach().cpu().flatten().numpy().astype(np.float32).tobytes())\n",
    "    with open(f\"params/layer_{idx}/mlp_down_proj.bin\", \"wb\")as f:\n",
    "        f.write(mlp.down_proj.weight.detach().cpu().flatten().numpy().astype(np.float32).tobytes())\n",
    "        \n",
    "    # ================================================================ RMS =====================================================\n",
    "    with open(f\"params/layer_{idx}/input_layernorm.bin\", \"wb\")as f:\n",
    "        f.write(input_layernorm.weight.detach().cpu().flatten().numpy().astype(np.float32).tobytes())\n",
    "    with open(f\"params/layer_{idx}/post_attention_layernorm.bin\", \"wb\")as f:\n",
    "        f.write(post_attention_layernorm.weight.detach().cpu().flatten().numpy().astype(np.float32).tobytes())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
