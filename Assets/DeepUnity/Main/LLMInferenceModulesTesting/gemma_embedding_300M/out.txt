Registering hooks on ALL modules... (filtering by name in hook)
Registered 414 hooks (filtering applied in hook function)
Input text: 'Whenever I want some pizza'
Tokenized: ['<bos>', 'Whenever', '▁I', '▁want', '▁some', '▁pizza', '<eos>']
Input IDs shape: torch.Size([1, 7])
Input IDs: tensor([[    2, 88108,   564,  1461,  1070, 19406,     1]])

================================================================================
000_embed_tokens: Gemma3TextScaledWordEmbedding (embed_tokens)
================================================================================

  → INPUT[0]: embed_tokens_input_0
     Shape: [1, 7]
     Dtype: torch.int64
     Mean: 15801.713867, Std: 32647.998047
     First 10: [2, 88108, 564, 1461, 1070, 19406, 1]
     Last 10:  [2, 88108, 564, 1461, 1070, 19406, 1]
     Zeros: 0, Total: 7

  → OUTPUT[0]: embed_tokens_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.013574, Std: 1.632227
     First 10: [-2.477302312850952, -1.2636504173278809, 0.3826928734779358, 0.06365708261728287, -0.820263147354126, -0.9725850224494934, 0.4710817039012909, -0.11057573556900024, 1.1160361766815186, 0.26941946148872375]
     Last 10:  [-2.1493282318115234, -0.6306940913200378, -1.1066092252731323, -2.5482146739959717, 1.7686560153961182, 1.0899485349655151, -0.6922177672386169, 5.721008777618408, 3.196016550064087, -1.2484151124954224]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [262144, 768]
     Mean: -0.000163
     First 10: [0.0808246061205864, -0.01816735975444317, 0.02295159175992012, 0.017070919275283813, -0.0995902270078659, -0.36502784490585327, 0.009475629776716232, 0.013409197330474854, -0.021984221413731575, 0.06105685979127884]
     Last 10:  [0.026465948671102524, -0.04095828905701637, 0.06920114159584045, -0.00501775648444891, 0.03168144077062607, -0.0887412503361702, 0.03904152661561966, -0.391409695148468, -0.0521768257021904, 0.01987053081393242]

================================================================================
001_layers.0.input_layernorm: Gemma3RMSNorm (layers.0.input_layernorm)
================================================================================

  → INPUT[0]: layers.0.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.013574, Std: 1.632227
     First 10: [-2.477302312850952, -1.2636504173278809, 0.3826928734779358, 0.06365708261728287, -0.820263147354126, -0.9725850224494934, 0.4710817039012909, -0.11057573556900024, 1.1160361766815186, 0.26941946148872375]
     Last 10:  [-2.1493282318115234, -0.6306940913200378, -1.1066092252731323, -2.5482146739959717, 1.7686560153961182, 1.0899485349655151, -0.6922177672386169, 5.721008777618408, 3.196016550064087, -1.2484151124954224]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.166489, Std: 16.408581
     First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
     Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 13.211769
     First 10: [13.771751403808594, 11.62539291381836, 10.998745918273926, 11.011996269226074, 10.650673866271973, 16.165376663208008, 10.465692520141602, 9.842697143554688, 11.779532432556152, 10.938799858093262]
     Last 10:  [10.880304336547852, 14.434453964233398, 12.227048873901367, 10.614360809326172, 12.919527053833008, 11.79944133758545, 11.457605361938477, 28.650779724121094, 11.849464416503906, 11.724117279052734]

================================================================================
002_layers.0.self_attn.q_proj: Linear (layers.0.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.0.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.166489, Std: 16.408581
     First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
     Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.187788, Std: 7.018822
     First 10: [0.3887830376625061, 3.351538896560669, -3.1458942890167236, 0.48394227027893066, -5.401116371154785, 3.701035976409912, -4.790302276611328, 0.42496490478515625, -6.131454944610596, 2.385254144668579]
     Last 10:  [2.4578323364257812, -7.078050136566162, 1.9613218307495117, -0.4571880102157593, -0.6431244611740112, -2.448065757751465, -1.3958616256713867, 1.229301929473877, -0.23432433605194092, -0.2790461778640747]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000009
     First 10: [0.004457538947463036, 0.004015621729195118, -0.001596560818143189, -0.00750212837010622, -0.0018526655621826649, 0.0037886269856244326, 0.013366032391786575, -0.0033216620795428753, -0.00728971790522337, 0.003818289842456579]
     Last 10:  [0.00806517992168665, -0.0026894814800471067, -0.017908483743667603, 0.0005922439740970731, -0.008424362167716026, -0.013402601704001427, 0.008167159743607044, -0.017401225864887238, -0.004434297326952219, -0.0014318663161247969]

================================================================================
003_layers.0.self_attn.k_proj: Linear (layers.0.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.0.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.166489, Std: 16.408581
     First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
     Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.228117, Std: 6.326502
     First 10: [0.9482555389404297, 0.5784203410148621, 0.15434527397155762, 0.14805006980895996, 0.32564619183540344, 0.821070671081543, -0.9551006555557251, 0.05978959798812866, -9.037637710571289, 0.3974881172180176]
     Last 10:  [3.4061479568481445, 18.547565460205078, -5.63254976272583, -0.6382596492767334, -2.370680809020996, 2.5257697105407715, -2.741736650466919, 3.1282882690429688, -1.7282251119613647, 2.643249034881592]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000009
     First 10: [0.017479531466960907, -0.003520711325109005, -0.000722294207662344, 0.0009113639825955033, 0.008276424370706081, 0.0031664608977735043, -0.005573416594415903, 0.006882806774228811, -0.00567815825343132, 0.001592256361618638]
     Last 10:  [0.01718268357217312, 0.001284840633161366, -0.021971169859170914, -0.0023933062329888344, -0.010611903853714466, -0.007415667176246643, 0.009665676392614841, -0.014863919466733932, -0.01145393867045641, 0.011871544644236565]

================================================================================
004_layers.0.self_attn.v_proj: Linear (layers.0.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.0.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.166489, Std: 16.408581
     First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
     Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.099511, Std: 2.979395
     First 10: [-0.19047972559928894, 0.631655216217041, -2.821593761444092, -0.5566350221633911, -0.6524765491485596, 1.4340227842330933, 0.9365267157554626, 0.07686394453048706, -2.8396809101104736, -1.2724430561065674]
     Last 10:  [1.3050856590270996, 0.10212904214859009, -4.919314384460449, 2.1930313110351562, -0.542229175567627, -1.5569565296173096, 2.8126730918884277, -1.5750327110290527, 3.4985499382019043, -0.08559703826904297]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000003
     First 10: [0.01653893105685711, -0.0005979716079309583, 0.011964324861764908, 0.008740507997572422, -0.0037220576778054237, 0.003735004924237728, -0.0041199130937457085, -0.002800969174131751, -0.001889929873868823, -0.002930165035650134]
     Last 10:  [-0.006778880022466183, -0.008648560382425785, 0.0015731696039438248, -0.0057011740282177925, -0.015193672850728035, -0.008288796059787273, 0.012293526902794838, -0.0003013320383615792, 0.0132667301222682, 0.015290368348360062]

================================================================================
005_layers.0.self_attn.q_norm: Gemma3RMSNorm (layers.0.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.0.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.187788, Std: 7.018822
     First 10: [0.3887830376625061, 3.351538896560669, -3.1458942890167236, 0.48394227027893066, -5.401116371154785, 3.701035976409912, -4.790302276611328, 0.42496490478515625, -6.131454944610596, 2.385254144668579]
     Last 10:  [2.4578323364257812, -7.078050136566162, 1.9613218307495117, -0.4571880102157593, -0.6431244611740112, -2.448065757751465, -1.3958616256713867, 1.229301929473877, -0.23432433605194092, -0.2790461778640747]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.017637, Std: 1.106099
     First 10: [0.1519453227519989, 1.6530735492706299, 0.4565025568008423, 0.0987328514456749, -1.367156982421875, 0.6147310137748718, -1.534438967704773, 0.1036820039153099, -1.1722685098648071, 0.7755711674690247]
     Last 10:  [0.8841097354888916, -3.1796979904174805, 0.7111338973045349, -0.09806857258081436, -0.17871248722076416, -0.9386019110679626, -0.5666730999946594, 0.382217139005661, -0.10534459352493286, -0.10174508392810822]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.449255
     First 10: [1.0459150075912476, 1.5819957256317139, -1.7596380710601807, 0.068011075258255, 0.3250811696052551, -0.13050034642219543, 0.6768503189086914, 0.2771971821784973, 0.0008551343344151974, 0.7021375298500061]
     Last 10:  [0.9843462705612183, 1.478196620941162, 1.0001660585403442, 0.18331007659435272, 0.5329338312149048, 1.115056037902832, 1.2395139932632446, 0.7152013778686523, 1.480038046836853, 1.011411190032959]

================================================================================
006_layers.0.self_attn.k_norm: Gemma3RMSNorm (layers.0.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.0.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.228117, Std: 6.326502
     First 10: [0.9482555389404297, 0.5784203410148621, 0.15434527397155762, 0.14805006980895996, 0.32564619183540344, 0.821070671081543, -0.9551006555557251, 0.05978959798812866, -9.037637710571289, 0.3974881172180176]
     Last 10:  [3.4061479568481445, 18.547565460205078, -5.63254976272583, -0.6382596492767334, -2.370680809020996, 2.5257697105407715, -2.741736650466919, 3.1282882690429688, -1.7282251119613647, 2.643249034881592]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.0.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.062646, Std: 1.004581
     First 10: [0.2459360957145691, 0.11071343719959259, 0.018123731017112732, 0.020769385620951653, 0.07968343049287796, 0.07294320315122604, -0.20613667368888855, 0.009935260750353336, -0.04140132665634155, 0.07572239637374878]
     Last 10:  [0.7992237210273743, 5.201683044433594, -1.4005458354949951, -0.2580697536468506, -0.7257094979286194, 0.5870898365974426, -0.5776166319847107, 0.8694612979888916, -0.32367414236068726, 0.7755516767501831]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.437071
     First 10: [0.8005052804946899, 0.32878378033638, -0.18482321500778198, -0.026104094460606575, 0.6987112164497375, -0.38326042890548706, 0.49831676483154297, 0.153589129447937, -0.9681978225708008, 0.3225061893463135]
     Last 10:  [0.6633381247520447, 0.9880746603012085, 0.7626577615737915, 1.8662590980529785, 1.1700286865234375, 0.6477318406105042, 0.49344658851623535, 0.9702402353286743, 0.3276495039463043, 1.0799285173416138]

================================================================================
007_layers.0.self_attn.o_proj: Linear (layers.0.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.0.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.148220, Std: 1.928052
     First 10: [-0.19047972559928894, 0.631655216217041, -2.821593761444092, -0.5566350221633911, -0.6524765491485596, 1.4340227842330933, 0.9365267157554626, 0.07686394453048706, -2.8396809101104736, -1.2724430561065674]
     Last 10:  [-2.088566541671753, -0.025558926165103912, -0.9876888990402222, 1.3683289289474487, -0.5881507396697998, 0.16551503539085388, 0.809123158454895, -0.6462826728820801, 2.007369041442871, -0.2429787814617157]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.022564, Std: 0.581956
     First 10: [-0.3779955506324768, -0.14444078505039215, 0.3628699779510498, -0.035884685814380646, -0.06462811678647995, -0.6456531882286072, -0.8867893815040588, -0.12370826303958893, 0.012052223086357117, 0.39969393610954285]
     Last 10:  [-0.3356463611125946, -0.028985433280467987, 0.8986057043075562, 1.1091954708099365, 0.5758756399154663, 0.5815268754959106, -1.0386407375335693, 0.07800734043121338, -0.16813135147094727, -0.5977584719657898]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000001
     First 10: [-0.006121734157204628, 0.0072639742866158485, -0.004167680162936449, 0.0005502395215444267, -0.0030461023561656475, 0.0019133321475237608, 0.0006337868981063366, 0.00686594657599926, 0.02246883697807789, -0.0008798274211585522]
     Last 10:  [-0.0048192995600402355, 0.00945169199258089, -0.002436814596876502, 0.009921959601342678, 0.002468767110258341, 0.00503688445314765, -0.00828063115477562, -0.004185948055237532, -0.010936368256807327, 0.009941842406988144]

================================================================================
008_layers.0.self_attn: Gemma3Attention (layers.0.self_attn)
================================================================================

  → OUTPUT[0]: layers.0.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.022564, Std: 0.581956
     First 10: [-0.3779955506324768, -0.14444078505039215, 0.3628699779510498, -0.035884685814380646, -0.06462811678647995, -0.6456531882286072, -0.8867893815040588, -0.12370826303958893, 0.012052223086357117, 0.39969393610954285]
     Last 10:  [-0.3356463611125946, -0.028985433280467987, 0.8986057043075562, 1.1091954708099365, 0.5758756399154663, 0.5815268754959106, -1.0386407375335693, 0.07800734043121338, -0.16813135147094727, -0.5977584719657898]
     Zeros: 0, Total: 5376

================================================================================
009_layers.0.post_attention_layernorm: Gemma3RMSNorm (layers.0.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.0.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.022564, Std: 0.581956
     First 10: [-0.3779955506324768, -0.14444078505039215, 0.3628699779510498, -0.035884685814380646, -0.06462811678647995, -0.6456531882286072, -0.8867893815040588, -0.12370826303958893, 0.012052223086357117, 0.39969393610954285]
     Last 10:  [-0.3356463611125946, -0.028985433280467987, 0.8986057043075562, 1.1091954708099365, 0.5758756399154663, 0.5815268754959106, -1.0386407375335693, 0.07800734043121338, -0.16813135147094727, -0.5977584719657898]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.106367, Std: 1.716240
     First 10: [-3.0801680088043213, -0.05903661996126175, 0.06795834004878998, -0.006062098778784275, -0.038303155452013016, -0.5212643146514893, -0.1841287463903427, -0.028685597702860832, 0.005756846629083157, 0.2436545342206955]
     Last 10:  [-0.08132490515708923, -0.00605315575376153, 0.13139201700687408, 0.0034704909194260836, 0.20731592178344727, 0.2177962213754654, -0.4465637505054474, 0.06332460790872574, -0.06968610733747482, -0.18223796784877777]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: -0.424272
     First 10: [3.0447750091552734, -0.7971204519271851, -0.9070395231246948, -0.9161466360092163, -0.7058155536651611, -0.5992575287818909, -0.8969358205795288, -0.8849009275436401, -0.7629040479660034, -0.6974107027053833]
     Last 10:  [-0.860762357711792, -0.8799901008605957, -0.9159737825393677, -0.9982019662857056, -0.7931197881698608, -0.784773588180542, -0.752922534942627, -0.5334995985031128, -0.7618160247802734, -0.8248023986816406]

================================================================================
010_layers.0.pre_feedforward_layernorm: Gemma3RMSNorm (layers.0.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.0.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.119942, Std: 2.299109
     First 10: [-5.557470321655273, -1.322687029838562, 0.45065122842788696, 0.05759498476982117, -0.8585662841796875, -1.493849277496338, 0.2869529724121094, -0.13926133513450623, 1.1217930316925049, 0.5130739808082581]
     Last 10:  [-2.2306530475616455, -0.6367472410202026, -0.9752172231674194, -2.5447442531585693, 1.9759719371795654, 1.3077447414398193, -1.1387815475463867, 5.784333229064941, 3.1263303756713867, -1.4306530952453613]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.178554, Std: 4.892603
     First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
     Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 4.554407
     First 10: [3.779510021209717, 4.540168762207031, 2.8462135791778564, 2.8857064247131348, 4.01004695892334, 6.90164852142334, 2.664316177368164, 2.4611318111419678, 4.2104949951171875, 4.384153842926025]
     Last 10:  [2.7559077739715576, 3.735137701034546, 2.885916233062744, 4.444358825683594, 4.171792507171631, 4.219438076019287, 4.38552713394165, 16.32645606994629, 4.216498374938965, 4.454622268676758]

================================================================================
011_layers.0.mlp.gate_proj: Linear (layers.0.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.0.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.178554, Std: 4.892603
     First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
     Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.641182, Std: 0.874306
     First 10: [-0.20775730907917023, 0.6305413246154785, -1.6627393960952759, -1.5643736124038696, -0.1845763921737671, -0.018746018409729004, 0.29749056696891785, -0.5662631392478943, -0.34384840726852417, -0.7666267156600952]
     Last 10:  [-0.5577700734138489, -1.3794704675674438, -0.034723371267318726, -0.1392453908920288, -0.854925274848938, -1.9765441417694092, -0.6656848788261414, -1.0517432689666748, -1.5457125902175903, 0.3487890362739563]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000054
     First 10: [0.002265811199322343, -0.005159079562872648, 0.006882420741021633, 0.0019309604540467262, 0.000267310650087893, -0.0008358097984455526, 0.0050742351450026035, -0.002386869164183736, -0.0006998326862230897, 0.000343307969160378]
     Last 10:  [0.007499678060412407, -0.010443990118801594, 0.004513897001743317, 0.0025682561099529266, 0.003898107912391424, 0.004438574425876141, -0.001891224063001573, 0.002832151250913739, 0.0012474427931010723, -0.00535489059984684]

================================================================================
012_layers.0.mlp.act_fn: PytorchGELUTanh (layers.0.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.0.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.641182, Std: 0.874306
     First 10: [-0.20775730907917023, 0.6305413246154785, -1.6627393960952759, -1.5643736124038696, -0.1845763921737671, -0.018746018409729004, 0.29749056696891785, -0.5662631392478943, -0.34384840726852417, -0.7666267156600952]
     Last 10:  [-0.5577700734138489, -1.3794704675674438, -0.034723371267318726, -0.1392453908920288, -0.854925274848938, -1.9765441417694092, -0.6656848788261414, -1.0517432689666748, -1.5457125902175903, 0.3487890362739563]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.0.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.001562, Std: 0.350151
     First 10: [-0.08678273856639862, 0.4639320373535156, -0.08026853948831558, -0.09228496253490448, -0.07877400517463684, -0.009232823736965656, 0.18353557586669922, -0.16175587475299835, -0.12567399442195892, -0.1699979305267334]
     Last 10:  [-0.16094255447387695, -0.11593639105558395, -0.01688077300786972, -0.06191253662109375, -0.16792051494121552, -0.04745147004723549, -0.1683361679315567, -0.1542075127363205, -0.09462754428386688, 0.2219565510749817]
     Zeros: 0, Total: 8064

================================================================================
013_layers.0.mlp.up_proj: Linear (layers.0.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.0.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.178554, Std: 4.892603
     First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
     Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000245, Std: 0.801804
     First 10: [-0.6215949654579163, -0.34889891743659973, 0.2935008704662323, -0.8074559569358826, 0.8279687762260437, 0.13126586377620697, -0.5818911194801331, -0.6940755844116211, -0.09826682507991791, 0.0732971802353859]
     Last 10:  [-0.43286415934562683, 0.47943422198295593, -0.3986634612083435, 0.926375687122345, -0.6728918552398682, 0.4082828760147095, -0.20388725399971008, -2.3840243816375732, -0.6635693311691284, -0.15048916637897491]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000011
     First 10: [-0.002032547490671277, -0.010458935052156448, 0.00579342246055603, 0.009161590598523617, 0.004961106460541487, -0.009475909173488617, 0.005016561131924391, -0.0007457535248249769, -0.0027480577118694782, 0.0002635384735185653]
     Last 10:  [0.002128265332430601, 0.00028487699455581605, 0.003863481804728508, -0.0017481991089880466, 0.003420613706111908, -0.0009135832078754902, -0.0054460554383695126, 0.0010168051812797785, -0.0011955858208239079, 0.007893100380897522]

================================================================================
014_layers.0.mlp.down_proj: Linear (layers.0.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.0.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.001395, Std: 0.744998
     First 10: [0.05394371226429939, -0.16186538338661194, -0.023558886721730232, 0.07451604306697845, -0.06522241979837418, -0.0012119546299800277, -0.1067977249622345, 0.11227080225944519, 0.012349584139883518, -0.012460368685424328]
     Last 10:  [0.06966626644134521, -0.05558387190103531, 0.0067297471687197685, -0.057354267686605453, 0.11299234628677368, -0.01937362179160118, 0.03432159870862961, 0.36763447523117065, 0.06279193609952927, -0.033402055501937866]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.0.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.001042, Std: 0.169039
     First 10: [-0.04582834243774414, -0.017291147261857986, -0.055749066174030304, -0.044060878455638885, 0.09626876562833786, 0.03131965175271034, -0.008971783332526684, 0.05209774896502495, -0.08086703717708588, -0.05818032845854759]
     Last 10:  [-0.10964630544185638, -0.07410191744565964, -0.2569091022014618, 0.3055190443992615, 0.3751865327358246, 0.41724711656570435, -0.6931462287902832, -0.25841009616851807, -0.44807684421539307, 0.22264385223388672]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000000
     First 10: [0.002217522356659174, 0.003364365082234144, -0.0028552310541272163, -0.0031933672726154327, 0.0034336294047534466, -0.0011583297746255994, 0.0004893142613582313, 0.0003330029721837491, -0.0014502847334370017, -0.0007673419313505292]
     Last 10:  [0.003303026780486107, -0.0068576401099562645, -0.008702927269041538, -0.0010446953820064664, 0.0011598898563534021, -0.0020495355129241943, 0.0008530386257916689, -0.0005902773118577898, 0.0010876666055992246, 0.001065832213498652]

================================================================================
015_layers.0.mlp: Gemma3MLP (layers.0.mlp)
================================================================================

  → INPUT[0]: layers.0.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.178554, Std: 4.892603
     First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
     Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.001042, Std: 0.169039
     First 10: [-0.04582834243774414, -0.017291147261857986, -0.055749066174030304, -0.044060878455638885, 0.09626876562833786, 0.03131965175271034, -0.008971783332526684, 0.05209774896502495, -0.08086703717708588, -0.05818032845854759]
     Last 10:  [-0.10964630544185638, -0.07410191744565964, -0.2569091022014618, 0.3055190443992615, 0.3751865327358246, 0.41724711656570435, -0.6931462287902832, -0.25841009616851807, -0.44807684421539307, 0.22264385223388672]
     Zeros: 0, Total: 5376

================================================================================
016_layers.0.post_feedforward_layernorm: Gemma3RMSNorm (layers.0.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.0.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.001042, Std: 0.169039
     First 10: [-0.04582834243774414, -0.017291147261857986, -0.055749066174030304, -0.044060878455638885, 0.09626876562833786, 0.03131965175271034, -0.008971783332526684, 0.05209774896502495, -0.08086703717708588, -0.05818032845854759]
     Last 10:  [-0.10964630544185638, -0.07410191744565964, -0.2569091022014618, 0.3055190443992615, 0.3751865327358246, 0.41724711656570435, -0.6931462287902832, -0.25841009616851807, -0.44807684421539307, 0.22264385223388672]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.0.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.366480, Std: 14.647358
     First 10: [-5.018401145935059, -0.09892900288105011, -0.2165645807981491, -0.12747548520565033, 0.7080104351043701, 0.24819548428058624, -0.03779777139425278, 0.19746749103069305, -0.46800848841667175, -0.4165009558200836]
     Last 10:  [-0.12543471157550812, -0.08793212473392487, -0.21500946581363678, 0.5422981381416321, 0.6047890782356262, 0.7310860753059387, -1.208717703819275, -1.027296543121338, -0.7602019906044006, 0.3011569380760193]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.256210
     First 10: [10.105892181396484, -0.41974079608917236, -0.6060219407081604, -0.7065759301185608, -0.2541070580482483, -0.19629040360450745, -0.572722852230072, -0.6155862808227539, -0.4130455255508423, -0.2739574611186981]
     Last 10:  [-0.5440579652786255, -0.527062177658081, -0.666447639465332, -0.2925662696361542, -0.3575451672077179, -0.3016694188117981, -0.3049982190132141, 0.584426999092102, -0.3238199055194855, -0.46090155839920044]

================================================================================
017_layers.1.input_layernorm: Gemma3RMSNorm (layers.1.input_layernorm)
================================================================================

  → INPUT[0]: layers.1.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.486422, Std: 15.329423
     First 10: [-10.575871467590332, -1.4216160774230957, 0.23408664762973785, -0.06988050043582916, -0.15055584907531738, -1.245653748512268, 0.249155193567276, 0.05820615589618683, 0.6537845134735107, 0.09657302498817444]
     Last 10:  [-2.3560876846313477, -0.7246793508529663, -1.190226674079895, -2.002446174621582, 2.580760955810547, 2.0388307571411133, -2.347499370574951, 4.7570366859436035, 2.366128444671631, -1.1294960975646973]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.240247, Std: 8.536188
     First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
     Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 22.233313
     First 10: [1.8597731590270996, 25.799156188964844, 28.01980972290039, 32.383968353271484, 20.16322898864746, 25.194278717041016, 28.214954376220703, 28.102378845214844, 24.777414321899414, 21.660188674926758]
     Last 10:  [24.85873794555664, 21.863595962524414, 30.899442672729492, 20.906391143798828, 22.843944549560547, 21.8211669921875, 22.410097122192383, 18.31932258605957, 19.970664978027344, 23.224822998046875]

================================================================================
018_layers.1.self_attn.q_proj: Linear (layers.1.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.1.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.240247, Std: 8.536188
     First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
     Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.227430, Std: 3.527764
     First 10: [0.6124878525733948, 0.5231271982192993, -0.31129342317581177, 0.8081249594688416, 0.3285582363605499, 0.8916200995445251, 0.4114353060722351, 0.42764490842819214, 0.2689150869846344, 0.05157384276390076]
     Last 10:  [0.29172056913375854, 0.4805294871330261, -0.021477773785591125, 0.33477264642715454, -0.3854120969772339, -0.2016754150390625, 0.24495382606983185, 0.2473474144935608, 0.3586224913597107, 0.09955033659934998]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000026
     First 10: [0.0048868488520383835, 0.0045542363077402115, -0.00191488116979599, -0.000948253320530057, 0.003895760979503393, -0.00438606645911932, 0.007899225689470768, -0.0007453974103555083, -0.010222862474620342, -0.004022672772407532]
     Last 10:  [-0.005861830897629261, 0.0035666688345372677, 0.0028608455322682858, 0.005950835067778826, -0.0014492106856778264, 0.012894945219159126, -0.005463242065161467, -0.010338779538869858, 0.001413947669789195, -0.0007010415429249406]

================================================================================
019_layers.1.self_attn.k_proj: Linear (layers.1.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.1.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.240247, Std: 8.536188
     First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
     Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.177580, Std: 2.952570
     First 10: [-0.029512323439121246, 0.0036770999431610107, -0.022987838834524155, -0.07440949976444244, 0.0337701290845871, -0.13090761005878448, -0.05024230480194092, -0.02097412943840027, -0.03171498700976372, 0.03588118404150009]
     Last 10:  [0.4185788333415985, -0.1796785295009613, 0.4933841824531555, 1.1130009889602661, 0.5604655146598816, 0.1016218364238739, 0.12205003201961517, 0.5053402781486511, 0.5786342620849609, -0.15862073004245758]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000025
     First 10: [0.00643489696085453, 0.0038983451668173075, -0.0041520195081830025, -0.006401365622878075, 0.00037151333526708186, -0.00602335948497057, -0.007073783315718174, -0.0007642700802534819, -0.00442845281213522, -0.006643814966082573]
     Last 10:  [-0.010391013696789742, 0.015848729759454727, 0.00983209814876318, 0.013724684715270996, 0.005474470090121031, 0.0022206464782357216, -0.007479607593268156, -0.0011443664552643895, -0.011949324980378151, -0.0027174013666808605]

================================================================================
020_layers.1.self_attn.v_proj: Linear (layers.1.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.1.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.240247, Std: 8.536188
     First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
     Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.021767, Std: 1.959199
     First 10: [-0.00632987916469574, -0.13523229956626892, -0.05910938233137131, 0.06699798256158829, -0.06367265433073044, -0.018030205741524696, 0.2024754285812378, -0.005681876093149185, -0.03216393291950226, 0.30808958411216736]
     Last 10:  [0.024603724479675293, 0.07117131352424622, -0.1273249089717865, 0.1884080022573471, 0.24171674251556396, -1.0228400230407715, 0.45299115777015686, -0.27653610706329346, 0.24216628074645996, -0.010611675679683685]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000007
     First 10: [-0.0032568140886723995, -0.002465425292029977, 0.00039303814992308617, -0.012401532381772995, 0.016265377402305603, -0.0017657808493822813, 0.005714076105505228, -0.007654632907360792, -0.0029385779052972794, 0.000394180795410648]
     Last 10:  [0.010766510851681232, 0.0016211888287216425, 0.014631275087594986, 0.006677553988993168, -0.003602298442274332, 0.007937799207866192, 9.486012277193367e-05, -0.006704891100525856, -0.012723654508590698, -0.0024164188653230667]

================================================================================
021_layers.1.self_attn.q_norm: Gemma3RMSNorm (layers.1.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.1.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.227430, Std: 3.527764
     First 10: [0.6124878525733948, 0.5231271982192993, -0.31129342317581177, 0.8081249594688416, 0.3285582363605499, 0.8916200995445251, 0.4114353060722351, 0.42764490842819214, 0.2689150869846344, 0.05157384276390076]
     Last 10:  [0.29172056913375854, 0.4805294871330261, -0.021477773785591125, 0.33477264642715454, -0.3854120969772339, -0.2016754150390625, 0.24495382606983185, 0.2473474144935608, 0.3586224913597107, 0.09955033659934998]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.165219, Std: 1.677917
     First 10: [4.009385108947754, 2.043389081954956, -1.5297473669052124, 3.0244038105010986, 1.783223271369934, 2.8866612911224365, 1.9713298082351685, 1.7137842178344727, 1.295831561088562, 0.25581657886505127]
     Last 10:  [0.9689206480979919, 1.732717752456665, -0.08676992356777191, 1.0620428323745728, -1.5582120418548584, -0.7226658463478088, 0.9391295909881592, 0.9531855583190918, 1.277065396308899, 0.35076236724853516]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 1.303981
     First 10: [2.261998176574707, 0.9464675188064575, 1.4487991333007812, 0.8649390935897827, 1.70456063747406, 0.6133158802986145, 1.3875975608825684, 0.9969915747642517, 1.4012467861175537, 1.4717389345169067]
     Last 10:  [1.1844652891159058, 1.3715473413467407, 1.6570758819580078, 1.0864887237548828, 1.6590421199798584, 1.3567231893539429, 1.5215368270874023, 1.5345103740692139, 1.3420687913894653, 1.3173643350601196]

================================================================================
022_layers.1.self_attn.k_norm: Gemma3RMSNorm (layers.1.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.1.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.177580, Std: 2.952570
     First 10: [-0.029512323439121246, 0.0036770999431610107, -0.022987838834524155, -0.07440949976444244, 0.0337701290845871, -0.13090761005878448, -0.05024230480194092, -0.02097412943840027, -0.03171498700976372, 0.03588118404150009]
     Last 10:  [0.4185788333415985, -0.1796785295009613, 0.4933841824531555, 1.1130009889602661, 0.5604655146598816, 0.1016218364238739, 0.12205003201961517, 0.5053402781486511, 0.5786342620849609, -0.15862073004245758]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.1.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.156810, Std: 1.957492
     First 10: [-0.028727121651172638, 0.006577483378350735, -0.0449017733335495, -0.1285410076379776, 0.06847850233316422, -0.16799931228160858, -0.1169901117682457, -0.033375561237335205, -0.07938093692064285, 0.07487687468528748]
     Last 10:  [0.7815216779708862, -0.29819104075431824, 0.7150827646255493, 2.049163341522217, 0.8346467018127441, 0.17153921723365784, 0.18646255135536194, 0.8000037670135498, 0.956226110458374, -0.27630114555358887]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 1.409485
     First 10: [-0.10979937016963959, 0.6358879208564758, 0.7863416075706482, 0.5798379182815552, 0.8544740676879883, 0.17365868389606476, 1.1295057535171509, 0.45527082681655884, 1.2890267372131348, 0.908447265625]
     Last 10:  [1.7493603229522705, 1.4438035488128662, 1.1342189311981201, 1.7111210823059082, 1.192914605140686, 1.4856746196746826, 1.249684453010559, 1.3311810493469238, 1.4334608316421509, 1.565019130706787]

================================================================================
023_layers.1.self_attn.o_proj: Linear (layers.1.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.1.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.027622, Std: 0.815454
     First 10: [-0.00632987916469574, -0.13523229956626892, -0.05910938233137131, 0.06699798256158829, -0.06367265433073044, -0.018030205741524696, 0.2024754285812378, -0.005681876093149185, -0.03216393291950226, 0.30808958411216736]
     Last 10:  [0.04616662114858627, -0.007932167500257492, -0.03748765215277672, 0.035884931683540344, 0.038612913340330124, -0.6513183116912842, 0.10659945011138916, -0.09423140436410904, 0.4220597743988037, 0.03893042355775833]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.015939, Std: 0.414087
     First 10: [-0.03845176845788956, -0.06503398716449738, 0.2212992012500763, 0.12925636768341064, -0.055878646671772, -0.13894006609916687, -0.16007213294506073, -0.280428022146225, -0.06990984082221985, 0.16293013095855713]
     Last 10:  [0.4090411365032196, -0.05258294194936752, 0.2331312894821167, -0.14305217564105988, -0.0436706505715847, -0.2093750536441803, -0.203327476978302, -0.1739659309387207, -0.05422750487923622, -0.5052568912506104]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000012
     First 10: [0.009873507544398308, 0.004738521296530962, -0.012467284686863422, -0.003922922071069479, 0.007432678248733282, -0.001872678054496646, 0.007788657210767269, 0.0036268788389861584, -0.0016258261166512966, -0.007891411893069744]
     Last 10:  [0.002247951226308942, -0.004708367399871349, 0.0016368161886930466, -0.0054846336133778095, 0.005056409630924463, 0.013429014012217522, -0.007816482335329056, 0.003023565746843815, -0.00197984860278666, 0.012326634488999844]

================================================================================
024_layers.1.self_attn: Gemma3Attention (layers.1.self_attn)
================================================================================

  → OUTPUT[0]: layers.1.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.015939, Std: 0.414087
     First 10: [-0.03845176845788956, -0.06503398716449738, 0.2212992012500763, 0.12925636768341064, -0.055878646671772, -0.13894006609916687, -0.16007213294506073, -0.280428022146225, -0.06990984082221985, 0.16293013095855713]
     Last 10:  [0.4090411365032196, -0.05258294194936752, 0.2331312894821167, -0.14305217564105988, -0.0436706505715847, -0.2093750536441803, -0.203327476978302, -0.1739659309387207, -0.05422750487923622, -0.5052568912506104]
     Zeros: 0, Total: 5376

================================================================================
025_layers.1.post_attention_layernorm: Gemma3RMSNorm (layers.1.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.1.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.015939, Std: 0.414087
     First 10: [-0.03845176845788956, -0.06503398716449738, 0.2212992012500763, 0.12925636768341064, -0.055878646671772, -0.13894006609916687, -0.16007213294506073, -0.280428022146225, -0.06990984082221985, 0.16293013095855713]
     Last 10:  [0.4090411365032196, -0.05258294194936752, 0.2331312894821167, -0.14305217564105988, -0.0436706505715847, -0.2093750536441803, -0.203327476978302, -0.1739659309387207, -0.05422750487923622, -0.5052568912506104]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.187307, Std: 8.121754
     First 10: [-1.273963451385498, -0.15359070897102356, 0.3613540232181549, 0.20257557928562164, -0.14524546265602112, -0.27656200528144836, -0.21255281567573547, -0.45935818552970886, -0.15347011387348175, 0.4855777621269226]
     Last 10:  [0.3562525510787964, -0.041807252913713455, 0.1714819371700287, -0.26884692907333374, -0.04543168470263481, -0.3040570318698883, -0.2657511532306671, -0.546119213104248, -0.06792004406452179, -0.5033805966377258]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.720134
     First 10: [9.916991233825684, -0.22180786728858948, -0.46195900440216064, -0.4835866689682007, -0.1435164511203766, -0.34411564469337463, -0.5624643564224243, -0.4602503776550293, -0.2766510844230652, -0.017981447279453278]
     Last 10:  [-0.4648579955101013, -0.5114772319793701, -0.5480443239212036, 0.1547517329454422, -0.3607846200466156, -0.10770567506551743, -0.19692309200763702, 0.928862452507019, -0.23041537404060364, -0.3878437876701355]

================================================================================
026_layers.1.pre_feedforward_layernorm: Gemma3RMSNorm (layers.1.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.1.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.673729, Std: 19.897224
     First 10: [-11.849834442138672, -1.5752067565917969, 0.595440685749054, 0.13269507884979248, -0.2958013117313385, -1.522215723991394, 0.03660237789154053, -0.40115201473236084, 0.5003144145011902, 0.5821508169174194]
     Last 10:  [-1.9998351335525513, -0.7664865851402283, -1.018744707107544, -2.2712931632995605, 2.5353293418884277, 1.7347737550735474, -2.613250494003296, 4.2109174728393555, 2.298208475112915, -1.6328766345977783]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020971, Std: 2.015995
     First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
     Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 13.716516
     First 10: [1.464638352394104, 15.870649337768555, 10.001569747924805, 10.36759090423584, 14.778430938720703, 18.672855377197266, 8.99025821685791, 9.968029975891113, 16.428176879882812, 15.611835479736328]
     Last 10:  [10.787636756896973, 12.15672492980957, 10.59859561920166, 14.950172424316406, 16.077880859375, 15.680028915405273, 14.943645477294922, 18.942237854003906, 14.90932846069336, 16.246273040771484]

================================================================================
027_layers.1.mlp.gate_proj: Linear (layers.1.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.1.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020971, Std: 2.015995
     First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
     Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.120275, Std: 0.335553
     First 10: [-0.07127414643764496, 0.01362256146967411, -0.048374563455581665, -0.0974014475941658, -0.11092638224363327, -0.05410915985703468, 0.06660674512386322, -0.054953113198280334, 0.20188869535923004, 0.04545402526855469]
     Last 10:  [-0.12045767903327942, -0.39974474906921387, 0.2644624710083008, -0.19441068172454834, -0.2604334056377411, -0.21609994769096375, 0.16585807502269745, -0.24325817823410034, -0.1319679468870163, -0.12777209281921387]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000007
     First 10: [0.019699599593877792, -0.0015209177508950233, 0.0058969417586922646, -0.0061547174118459225, 0.004222312942147255, 0.012663009576499462, -0.0007701860158704221, -0.0051091136410832405, 0.010716141201555729, 0.000388076005037874]
     Last 10:  [-0.00020636070985347033, -0.00775020569562912, 0.0017179751303046942, 0.005448374897241592, 0.005358359310775995, -0.0008987224427983165, 0.0027715961914509535, 0.00045893629430793226, 0.009841017425060272, 0.01042204350233078]

================================================================================
028_layers.1.mlp.act_fn: PytorchGELUTanh (layers.1.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.1.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.120275, Std: 0.335553
     First 10: [-0.07127414643764496, 0.01362256146967411, -0.048374563455581665, -0.0974014475941658, -0.11092638224363327, -0.05410915985703468, 0.06660674512386322, -0.054953113198280334, 0.20188869535923004, 0.04545402526855469]
     Last 10:  [-0.12045767903327942, -0.39974474906921387, 0.2644624710083008, -0.19441068172454834, -0.2604334056377411, -0.21609994769096375, 0.16585807502269745, -0.24325817823410034, -0.1319679468870163, -0.12777209281921387]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.1.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.013192, Std: 0.154458
     First 10: [-0.03361216560006142, 0.006885312031954527, -0.02325408346951008, -0.04492194950580597, -0.05056443810462952, -0.025887129828333855, 0.03507194668054581, -0.026272421702742577, 0.11709453910589218, 0.023550970479846]
     Last 10:  [-0.05445420369505882, -0.13778842985630035, 0.15981002151966095, -0.08222201466560364, -0.10346245020627975, -0.08956438302993774, 0.09385314583778381, -0.09825374186038971, -0.05905639007687569, -0.05739079788327217]
     Zeros: 0, Total: 8064

================================================================================
029_layers.1.mlp.up_proj: Linear (layers.1.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.1.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020971, Std: 2.015995
     First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
     Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.004129, Std: 0.317843
     First 10: [0.13341844081878662, -0.004517419263720512, 0.03417050465941429, 0.0684620663523674, 0.06160465627908707, -0.015334632247686386, 0.027129750698804855, -0.01175076887011528, 0.029869310557842255, 0.1294068843126297]
     Last 10:  [0.8832411766052246, 0.21826523542404175, 0.07913633435964584, -0.1096477210521698, 0.1508164405822754, 0.3041124641895294, 0.21505028009414673, -0.056547652930021286, 0.07689377665519714, 0.2263047993183136]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000000
     First 10: [0.005233707372099161, -0.0006958572193980217, 0.007293093018233776, 0.0016676202649250627, -0.001583422883413732, 0.008574721403419971, 0.001879985211417079, 0.0038242782466113567, 0.001200769911520183, -0.008612179197371006]
     Last 10:  [0.010978734120726585, 0.0034411484375596046, 0.0008352897129952908, 0.0022197256330400705, 0.00772596662864089, -0.010624188929796219, 0.006728265900164843, 0.0019364157924428582, -0.016583004966378212, 0.005418530665338039]

================================================================================
030_layers.1.mlp.down_proj: Linear (layers.1.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.1.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000062, Std: 0.081873
     First 10: [-0.004484482575207949, -3.110384204774164e-05, -0.0007946037803776562, -0.0030754494946449995, -0.0031150048598647118, 0.0003969696117565036, 0.0009514931589365005, 0.0003087211516685784, 0.003497533267363906, 0.0030476576648652554]
     Last 10:  [-0.0480961948633194, -0.03007442317903042, 0.012646779417991638, 0.009015456773340702, -0.015603838488459587, -0.02723764441907406, 0.020183145999908447, 0.005556018557399511, -0.0045410688035190105, -0.012987812981009483]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.1.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000136, Std: 0.026268
     First 10: [0.002910963026806712, 0.0003085295029450208, 0.0006314038764685392, -0.0020582801662385464, -0.002385294297710061, 0.004201765637844801, 0.0012363921850919724, -0.0008050656761042774, -0.0007019420154392719, 0.0021230403799563646]
     Last 10:  [0.005400285590440035, -0.0010172133333981037, 0.0052062030881643295, -0.00724160997197032, 0.0010461467318236828, -0.0027242195792496204, -0.009691147133708, -0.0179337989538908, -0.0040361955761909485, 0.0022561131045222282]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000001
     First 10: [0.00928759016096592, 0.001761008519679308, 0.0022989516146481037, -0.007555094547569752, 0.004482729826122522, -0.0001347691286355257, -0.0018212131690233946, 0.0048743439838290215, 0.007856172509491444, 0.0009652096778154373]
     Last 10:  [0.0008040207903832197, 0.0015717048663645983, -0.004227650351822376, -0.0025294171646237373, 0.0026700387243181467, -0.01031973585486412, 0.0024362255353480577, 0.008579461835324764, 0.0019728054758161306, 0.0008590059587731957]

================================================================================
031_layers.1.mlp: Gemma3MLP (layers.1.mlp)
================================================================================

  → INPUT[0]: layers.1.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020971, Std: 2.015995
     First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
     Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000136, Std: 0.026268
     First 10: [0.002910963026806712, 0.0003085295029450208, 0.0006314038764685392, -0.0020582801662385464, -0.002385294297710061, 0.004201765637844801, 0.0012363921850919724, -0.0008050656761042774, -0.0007019420154392719, 0.0021230403799563646]
     Last 10:  [0.005400285590440035, -0.0010172133333981037, 0.0052062030881643295, -0.00724160997197032, 0.0010461467318236828, -0.0027242195792496204, -0.009691147133708, -0.0179337989538908, -0.0040361955761909485, 0.0022561131045222282]
     Zeros: 0, Total: 5376

================================================================================
032_layers.1.post_feedforward_layernorm: Gemma3RMSNorm (layers.1.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.1.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000136, Std: 0.026268
     First 10: [0.002910963026806712, 0.0003085295029450208, 0.0006314038764685392, -0.0020582801662385464, -0.002385294297710061, 0.004201765637844801, 0.0012363921850919724, -0.0008050656761042774, -0.0007019420154392719, 0.0021230403799563646]
     Last 10:  [0.005400285590440035, -0.0010172133333981037, 0.0052062030881643295, -0.00724160997197032, 0.0010461467318236828, -0.0027242195792496204, -0.009691147133708, -0.0179337989538908, -0.0040361955761909485, 0.0022561131045222282]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.1.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.031468, Std: 4.030575
     First 10: [11.874693870544434, 0.09452100843191147, 0.11465039104223251, -0.3292507231235504, -0.9207574129104614, 1.1562845706939697, 0.21611712872982025, -0.1344224363565445, -0.22409769892692566, 0.7729232907295227]
     Last 10:  [0.27437031269073486, -0.06021535396575928, 0.18261933326721191, -0.7792431712150574, 0.07369881868362427, -0.20097064971923828, -0.7667845487594604, -1.6380910873413086, -0.33648356795310974, 0.14867855608463287]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.708472
     First 10: [10.632843017578125, -0.12636145949363708, -0.48219239711761475, -0.5438345670700073, 0.10078725963830948, -0.21524691581726074, -0.5015368461608887, -0.5238535404205322, -0.08959153294563293, 0.03819342702627182]
     Last 10:  [-0.40615636110305786, -0.3080942630767822, -0.5900061130523682, 0.257736474275589, -0.17658334970474243, -0.13773202896118164, -0.07519558072090149, 0.06762191653251648, -0.02558630332350731, -0.22973665595054626]

================================================================================
033_layers.2.input_layernorm: Gemma3RMSNorm (layers.2.input_layernorm)
================================================================================

  → INPUT[0]: layers.2.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.642261, Std: 20.243124
     First 10: [0.02485942840576172, -1.4806857109069824, 0.7100910544395447, -0.19655564427375793, -1.2165586948394775, -0.3659311532974243, 0.252719521522522, -0.5355744361877441, 0.2762167155742645, 1.355074167251587]
     Last 10:  [-1.7254648208618164, -0.8267019391059875, -0.836125373840332, -3.0505363941192627, 2.6090281009674072, 1.533803105354309, -3.380034923553467, 2.572826385498047, 1.961724877357483, -1.4841980934143066]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.026103, Std: 4.754027
     First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
     Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 26.423407
     First 10: [3.027484893798828, 27.366954803466797, 31.784854888916016, 31.845699310302734, 21.134410858154297, 30.225242614746094, 29.884090423583984, 27.88405990600586, 28.701499938964844, 24.540679931640625]
     Last 10:  [30.746891021728516, 33.804832458496094, 33.66103744506836, 20.557044982910156, 29.039363861083984, 25.611797332763672, 26.11319351196289, 19.35609245300293, 25.680681228637695, 30.136741638183594]

================================================================================
034_layers.2.self_attn.q_proj: Linear (layers.2.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.2.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.026103, Std: 4.754027
     First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
     Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.046460, Std: 1.801459
     First 10: [-0.36334437131881714, 0.017857879400253296, -0.021441936492919922, -0.5530362725257874, -0.38796016573905945, 1.274657130241394, 0.29073214530944824, -0.487531453371048, 0.5537347793579102, 0.33335721492767334]
     Last 10:  [0.29533475637435913, 0.41967833042144775, 1.1354382038116455, 0.3936917185783386, -0.5400428771972656, -0.6574865579605103, 0.26659446954727173, -0.022056810557842255, 0.2536875605583191, -1.0901076793670654]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000003
     First 10: [0.005874411202967167, -0.007787564769387245, 0.002201601630076766, 0.003384698648005724, 0.0009149935794994235, 0.007124283351004124, -0.0008926455047912896, -0.002326279180124402, 0.008530697785317898, -0.004663852974772453]
     Last 10:  [-0.0002522101276554167, -0.004206049721688032, 0.002451798180118203, -0.008894359692931175, 0.004478105343878269, -0.017879927530884743, -0.00747540220618248, -0.007788742892444134, 0.0026484099216759205, -0.00758125726133585]

================================================================================
035_layers.2.self_attn.k_proj: Linear (layers.2.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.2.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.026103, Std: 4.754027
     First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
     Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.094431, Std: 1.859646
     First 10: [-1.0551759004592896, -1.948734164237976, -0.4912123382091522, -1.1269705295562744, -1.3528980016708374, 0.7888169288635254, -0.11417031288146973, -1.213828206062317, 0.6067166924476624, 1.5700477361679077]
     Last 10:  [3.677457571029663, 2.713850975036621, 7.206689834594727, 2.639547348022461, -3.0033864974975586, -2.7033843994140625, 3.2159948348999023, 3.167816162109375, 0.792203426361084, 0.20938019454479218]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000009
     First 10: [0.007219929248094559, 0.0005539559642784297, 0.011095413006842136, 0.00019695078663062304, 0.010166207328438759, 0.010674947872757912, 0.0008095325902104378, -0.0028179646469652653, 0.004654970020055771, 0.004116514697670937]
     Last 10:  [0.00034602341474965215, 0.011554133147001266, -0.007854336872696877, 0.004465506877750158, -0.002790431259199977, 0.005314076319336891, 0.0018315749475732446, -0.004766340367496014, 0.0041898502968251705, 0.005876585841178894]

================================================================================
036_layers.2.self_attn.v_proj: Linear (layers.2.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.2.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.026103, Std: 4.754027
     First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
     Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.005879, Std: 0.904993
     First 10: [0.09928067028522491, -0.016716446727514267, -0.20497094094753265, -0.10366927832365036, 0.025770358741283417, -0.10563710331916809, -0.20119136571884155, 0.04089313745498657, 0.19365032017230988, 0.17264938354492188]
     Last 10:  [-1.121331810951233, -0.38518744707107544, -0.4193658232688904, 0.18737810850143433, -0.3953475058078766, 0.10543012619018555, 0.08753445744514465, 0.27651330828666687, -0.23474937677383423, 1.9442005157470703]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000033
     First 10: [-0.005308684892952442, 0.0155850974842906, 0.0017599742859601974, -0.000986919505521655, -0.011374102905392647, 0.010069191455841064, 0.0035870391875505447, -0.008164105005562305, -0.022710612043738365, -0.0068602487444877625]
     Last 10:  [0.005754345562309027, 0.003554615657776594, 0.0028578396886587143, -0.005542494356632233, 0.009315461851656437, -0.002093757502734661, -0.0017817497719079256, -0.0065138014033436775, -0.00011115895176772028, -0.0052938382141292095]

================================================================================
037_layers.2.self_attn.q_norm: Gemma3RMSNorm (layers.2.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.2.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.046460, Std: 1.801459
     First 10: [-0.36334437131881714, 0.017857879400253296, -0.021441936492919922, -0.5530362725257874, -0.38796016573905945, 1.274657130241394, 0.29073214530944824, -0.487531453371048, 0.5537347793579102, 0.33335721492767334]
     Last 10:  [0.29533475637435913, 0.41967833042144775, 1.1354382038116455, 0.3936917185783386, -0.5400428771972656, -0.6574865579605103, 0.26659446954727173, -0.022056810557842255, 0.2536875605583191, -1.0901076793670654]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.042880, Std: 1.479561
     First 10: [-1.9673094749450684, 0.020288221538066864, -0.14283299446105957, -2.768562078475952, -2.0828802585601807, 4.021634578704834, 1.2630131244659424, -1.4972803592681885, 2.1579360961914062, 1.621669888496399]
     Last 10:  [0.5908542275428772, 0.4938216507434845, 1.5157097578048706, 0.5722675323486328, -0.9914202094078064, -0.8356114625930786, 0.41073930263519287, -0.040680814534425735, 0.4229012131690979, -1.8225127458572388]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.639680
     First 10: [0.8257337808609009, -0.6169130802154541, 1.2461962699890137, 0.6880442500114441, 0.8103410005569458, 0.06387943774461746, 0.4648664593696594, 0.03558005392551422, 0.31407448649406433, 0.6403471827507019]
     Last 10:  [1.2413268089294434, 0.31823551654815674, 0.49551907181739807, 0.6284792423248291, 1.0566904544830322, 0.4238259196281433, 0.7260545492172241, 1.066266417503357, 0.8675798177719116, 0.873012125492096]

================================================================================
038_layers.2.self_attn.k_norm: Gemma3RMSNorm (layers.2.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.2.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.094431, Std: 1.859646
     First 10: [-1.0551759004592896, -1.948734164237976, -0.4912123382091522, -1.1269705295562744, -1.3528980016708374, 0.7888169288635254, -0.11417031288146973, -1.213828206062317, 0.6067166924476624, 1.5700477361679077]
     Last 10:  [3.677457571029663, 2.713850975036621, 7.206689834594727, 2.639547348022461, -3.0033864974975586, -2.7033843994140625, 3.2159948348999023, 3.167816162109375, 0.792203426361084, 0.20938019454479218]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.2.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.088166, Std: 3.102985
     First 10: [-2.8802244663238525, -3.157100200653076, -0.8592400550842285, -1.6301077604293823, -1.8473399877548218, 1.1344377994537354, -0.23634913563728333, -2.120568037033081, 0.6022592782974243, 1.115332007408142]
     Last 10:  [4.155835151672363, 5.0257954597473145, 10.735418319702148, 3.897294044494629, -3.4731411933898926, -4.453522682189941, 4.465592384338379, 3.75076961517334, 1.0371109247207642, 0.3067752718925476]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 1.011649
     First 10: [1.4677650928497314, 0.46466436982154846, 0.5814212560653687, 0.30769383907318115, 0.2344801425933838, 0.3001900017261505, 0.8715574741363525, 0.5794187784194946, -0.10257138311862946, -0.35776546597480774]
     Last 10:  [0.6932139992713928, 1.774725317955017, 1.2319493293762207, 1.2122536897659302, 0.7326562404632568, 1.4682948589324951, 1.0804868936538696, 0.774032711982727, 0.9615060091018677, 1.1952598094940186]

================================================================================
039_layers.2.self_attn.o_proj: Linear (layers.2.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.2.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001366, Std: 0.682374
     First 10: [0.09928067028522491, -0.016716446727514267, -0.20497094094753265, -0.10366927832365036, 0.025770358741283417, -0.10563710331916809, -0.20119136571884155, 0.04089313745498657, 0.19365032017230988, 0.17264938354492188]
     Last 10:  [-0.0854857861995697, -1.1065808534622192, -0.4098498523235321, 0.1805793046951294, 0.2039640247821808, -0.6879286170005798, -0.4501395523548126, 0.09166073054075241, 0.05141796916723251, -4.75787878036499]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005249, Std: 0.274977
     First 10: [0.02823609486222267, 0.03672467917203903, -0.00804198533296585, 0.09384729713201523, -0.05652657896280289, -0.07385166734457016, -0.011170231737196445, -0.04899873211979866, -0.02543088234961033, -0.004873378202319145]
     Last 10:  [-0.21234281361103058, 0.04082677513360977, 0.5334573984146118, -0.12419344484806061, -0.00542566180229187, -0.3276468515396118, 0.2406778484582901, -0.42357438802719116, -0.06206699460744858, -0.11366133391857147]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000006
     First 10: [-0.006040327250957489, 0.011419935151934624, -0.0065649161115288734, 0.010005129501223564, -0.01088897604495287, 0.014957975596189499, -0.018513301387429237, -0.006144082639366388, -7.981729868333787e-05, -0.0009508468210697174]
     Last 10:  [0.009724443778395653, -0.00217102887108922, 0.002009529620409012, -0.016330210492014885, -0.004406299442052841, -0.0038787364028394222, 0.0034729337785393, -0.005183593835681677, -0.002608590992167592, 0.00012073434481862932]

================================================================================
040_layers.2.self_attn: Gemma3Attention (layers.2.self_attn)
================================================================================

  → OUTPUT[0]: layers.2.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005249, Std: 0.274977
     First 10: [0.02823609486222267, 0.03672467917203903, -0.00804198533296585, 0.09384729713201523, -0.05652657896280289, -0.07385166734457016, -0.011170231737196445, -0.04899873211979866, -0.02543088234961033, -0.004873378202319145]
     Last 10:  [-0.21234281361103058, 0.04082677513360977, 0.5334573984146118, -0.12419344484806061, -0.00542566180229187, -0.3276468515396118, 0.2406778484582901, -0.42357438802719116, -0.06206699460744858, -0.11366133391857147]
     Zeros: 0, Total: 5376

================================================================================
041_layers.2.post_attention_layernorm: Gemma3RMSNorm (layers.2.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.2.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005249, Std: 0.274977
     First 10: [0.02823609486222267, 0.03672467917203903, -0.00804198533296585, 0.09384729713201523, -0.05652657896280289, -0.07385166734457016, -0.011170231737196445, -0.04899873211979866, -0.02543088234961033, -0.004873378202319145]
     Last 10:  [-0.21234281361103058, 0.04082677513360977, 0.5334573984146118, -0.12419344484806061, -0.00542566180229187, -0.3276468515396118, 0.2406778484582901, -0.42357438802719116, -0.06206699460744858, -0.11366133391857147]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.012212, Std: 9.402136
     First 10: [2.6012983322143555, 0.15047016739845276, -0.018052563071250916, 0.16019277274608612, -0.21596364676952362, -0.2862200438976288, -0.024880945682525635, -0.10637471079826355, -0.12475689500570297, -0.02494468353688717]
     Last 10:  [-0.2245132476091385, 0.041580505669116974, 0.34282591938972473, -0.5356549620628357, -0.010441051796078682, -0.45830848813056946, 0.33245083689689636, -2.0652337074279785, -0.10623007267713547, -0.23491325974464417]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.918192
     First 10: [12.173349380493164, -0.41412752866744995, -0.6790138483047485, -0.7559201717376709, -0.45369064807891846, -0.44582051038742065, -0.6814956068992615, -0.6895695924758911, -0.29852235317230225, -0.2680884599685669]
     Last 10:  [-0.6143442988395691, -0.6285160779953003, -0.7655937075614929, 0.5731922388076782, -0.2980812191963196, -0.4897920489311218, -0.4961669445037842, 0.7784221172332764, -0.3757161498069763, -0.24614103138446808]

================================================================================
042_layers.2.pre_feedforward_layernorm: Gemma3RMSNorm (layers.2.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.2.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.654473, Std: 17.171438
     First 10: [2.626157760620117, -1.330215573310852, 0.6920384764671326, -0.036362871527671814, -1.4325222969055176, -0.6521512269973755, 0.22783857583999634, -0.6419491767883301, 0.15145981311798096, 1.3301295042037964]
     Last 10:  [-1.9499781131744385, -0.7851214408874512, -0.4932994544506073, -3.586191415786743, 2.5985870361328125, 1.075494647026062, -3.047584056854248, 0.5075926780700684, 1.8554948568344116, -1.7191113233566284]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.052867, Std: 3.134514
     First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
     Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 23.098120
     First 10: [1.1377294063568115, 29.12203025817871, 21.540481567382812, 20.486610412597656, 23.284503936767578, 31.13308334350586, 18.04965591430664, 19.77271270751953, 27.44459342956543, 25.47051239013672]
     Last 10:  [21.30609130859375, 23.019533157348633, 20.443920135498047, 22.954994201660156, 27.464771270751953, 27.416269302368164, 27.371505737304688, 21.012920379638672, 24.532493591308594, 29.575847625732422]

================================================================================
043_layers.2.mlp.gate_proj: Linear (layers.2.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.2.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.052867, Std: 3.134514
     First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
     Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.390194, Std: 0.568921
     First 10: [-0.032689712941646576, -0.049942102283239365, 0.06258758902549744, -0.15238383412361145, -0.018055252730846405, 0.099705271422863, -0.2726435661315918, 0.20162516832351685, -0.1838446855545044, -0.0074073150753974915]
     Last 10:  [-0.8337905406951904, -0.314787358045578, -0.28080546855926514, -0.2970106899738312, -0.0792415589094162, -0.6461949944496155, -0.11522801220417023, -0.9790428876876831, -0.3196631073951721, -0.6443208456039429]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000061
     First 10: [0.00665671844035387, -0.007430246099829674, 0.004869026131927967, -0.0007919698255136609, -0.0013069240376353264, 0.0053901681676507, -0.008050530217587948, -0.0015129937091842294, -0.001731157535687089, 0.0013315639225766063]
     Last 10:  [-0.0021357405930757523, -0.00245486106723547, 0.00559333385899663, -0.005756009370088577, 0.004406705964356661, -0.0006576173473149538, -0.001810824265703559, 0.0006644403329119086, -0.012779247015714645, -0.0077705588191747665]

================================================================================
044_layers.2.mlp.act_fn: PytorchGELUTanh (layers.2.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.2.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.390194, Std: 0.568921
     First 10: [-0.032689712941646576, -0.049942102283239365, 0.06258758902549744, -0.15238383412361145, -0.018055252730846405, 0.099705271422863, -0.2726435661315918, 0.20162516832351685, -0.1838446855545044, -0.0074073150753974915]
     Last 10:  [-0.8337905406951904, -0.314787358045578, -0.28080546855926514, -0.2970106899738312, -0.0792415589094162, -0.6461949944496155, -0.11522801220417023, -0.9790428876876831, -0.3196631073951721, -0.6443208456039429]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.2.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.042223, Std: 0.206244
     First 10: [-0.015918616205453873, -0.023976419121026993, 0.03285551071166992, -0.0669640451669693, -0.00889758113771677, 0.05381198227405548, -0.10703166574239731, 0.11692092567682266, -0.0785144791007042, -0.003681768663227558]
     Last 10:  [-0.1686868965625763, -0.11850835382938385, -0.10935595631599426, -0.11382556706666946, -0.03711836412549019, -0.16745640337467194, -0.05232881009578705, -0.160492405295372, -0.11975278705358505, -0.16736163198947906]
     Zeros: 0, Total: 8064

================================================================================
045_layers.2.mlp.up_proj: Linear (layers.2.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.2.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.052867, Std: 3.134514
     First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
     Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.001235, Std: 0.535849
     First 10: [-0.010250693187117577, -0.3237747848033905, 0.02593904733657837, -0.035400088876485825, 0.151950865983963, -0.20820970833301544, 0.16876435279846191, -0.29318922758102417, 0.2106885313987732, 0.12538564205169678]
     Last 10:  [-0.029880091547966003, -0.2194540798664093, 0.08097942173480988, -0.2075425386428833, 0.23828892409801483, -0.04915416240692139, -0.2174989879131317, 0.0808962732553482, -1.2447271347045898, 0.1727088987827301]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000012
     First 10: [0.006582364439964294, 0.00923644844442606, -0.006712194066494703, 0.0029652323573827744, 0.005954846739768982, -0.004814131651073694, -0.0017556097591295838, -0.001005456899292767, 0.005498941987752914, -0.0026073099579662085]
     Last 10:  [0.009152376092970371, 0.006858495995402336, -0.003301236778497696, 0.0069337571039795876, -0.004275296814739704, -0.006053195334970951, -0.006625382229685783, 4.534376785159111e-06, -0.004268332850188017, -0.0023414238821715117]

================================================================================
046_layers.2.mlp.down_proj: Linear (layers.2.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.2.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.001651, Std: 0.166671
     First 10: [0.00016317685367539525, 0.007762960158288479, 0.0008522406569682062, 0.0023705330677330494, -0.0013519951608031988, -0.011204177513718605, -0.018063129857182503, -0.0342799574136734, -0.01654209941625595, -0.0004616409132722765]
     Last 10:  [0.005040379706770182, 0.026007141917943954, -0.00885558221489191, 0.023623647168278694, -0.008844895288348198, 0.008231178857386112, 0.011381463147699833, -0.012983237393200397, 0.14905954897403717, -0.02890484407544136]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.2.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001058, Std: 0.078724
     First 10: [0.012004838325083256, -0.006629047449678183, -0.006676972843706608, 0.002998131327331066, -0.0020404274109750986, 0.005859403870999813, -0.0017380919307470322, -0.003668359015136957, -0.004967392422258854, -0.001908790203742683]
     Last 10:  [0.010193292051553726, 0.01077516470104456, 0.014597687870264053, 0.030868591740727425, 0.005632299464195967, -0.03513884171843529, 0.025990480557084084, -0.02402442879974842, 0.017063895240426064, 0.003353796899318695]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000001
     First 10: [0.00051321234786883, -0.003208459820598364, 0.0007023614598438144, 0.00018871351494453847, -0.0005798278143629432, 0.003301780205219984, -0.005696023814380169, 0.0033138124272227287, -0.003909047227352858, 0.0038655512034893036]
     Last 10:  [-6.938192382222041e-05, -0.006208191625773907, -0.008323975838720798, 0.01185250747948885, -0.006960803642868996, 0.0037848278880119324, -0.0002359145728405565, 0.00022963571245782077, -0.00594490859657526, 0.0003095608844887465]

================================================================================
047_layers.2.mlp: Gemma3MLP (layers.2.mlp)
================================================================================

  → INPUT[0]: layers.2.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.052867, Std: 3.134514
     First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
     Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001058, Std: 0.078724
     First 10: [0.012004838325083256, -0.006629047449678183, -0.006676972843706608, 0.002998131327331066, -0.0020404274109750986, 0.005859403870999813, -0.0017380919307470322, -0.003668359015136957, -0.004967392422258854, -0.001908790203742683]
     Last 10:  [0.010193292051553726, 0.01077516470104456, 0.014597687870264053, 0.030868591740727425, 0.005632299464195967, -0.03513884171843529, 0.025990480557084084, -0.02402442879974842, 0.017063895240426064, 0.003353796899318695]
     Zeros: 0, Total: 5376

================================================================================
048_layers.2.post_feedforward_layernorm: Gemma3RMSNorm (layers.2.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.2.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001058, Std: 0.078724
     First 10: [0.012004838325083256, -0.006629047449678183, -0.006676972843706608, 0.002998131327331066, -0.0020404274109750986, 0.005859403870999813, -0.0017380919307470322, -0.003668359015136957, -0.004967392422258854, -0.001908790203742683]
     Last 10:  [0.010193292051553726, 0.01077516470104456, 0.014597687870264053, 0.030868591740727425, 0.005632299464195967, -0.03513884171843529, 0.025990480557084084, -0.02402442879974842, 0.017063895240426064, 0.003353796899318695]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.2.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.156588, Std: 7.204574
     First 10: [12.67269515991211, -0.6051055192947388, -0.32405057549476624, 0.10981320589780807, -0.22105488181114197, 0.49228745698928833, -0.09195002913475037, -0.18093745410442352, -0.4969541132450104, -0.21979975700378418]
     Last 10:  [0.3182140290737152, 0.3240564465522766, 0.3106733560562134, 2.793078660964966, 0.2573801577091217, -1.5145682096481323, 1.424516201019287, -1.6110018491744995, 0.8563956022262573, 0.16673821210861206]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 1.490947
     First 10: [13.594320297241211, 0.2619761824607849, -0.3290279805660248, -0.4936216473579407, 0.49778735637664795, 0.16154634952545166, -0.2686077356338501, -0.31808874011039734, 0.3831174373626709, 0.5919896364212036]
     Last 10:  [-0.13021163642406464, -0.16207432746887207, -0.4070355296134949, 1.5210130214691162, 0.27320417761802673, 0.2009091079235077, 0.5270799994468689, 0.86832195520401, 0.39831483364105225, 0.3851829171180725]

================================================================================
049_layers.3.input_layernorm: Gemma3RMSNorm (layers.3.input_layernorm)
================================================================================

  → INPUT[0]: layers.3.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.811061, Std: 21.139889
     First 10: [15.298852920532227, -1.9353210926055908, 0.36798790097236633, 0.07345033437013626, -1.653577208518982, -0.15986377000808716, 0.13588854670524597, -0.8228866457939148, -0.3454943001270294, 1.1103297472000122]
     Last 10:  [-1.6317640542984009, -0.46106499433517456, -0.18262609839439392, -0.7931127548217773, 2.8559672832489014, -0.4390735626220703, -1.623067855834961, -1.1034091711044312, 2.711890459060669, -1.5523731708526611]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.059826, Std: 4.460990
     First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
     Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 30.287369
     First 10: [3.924304962158203, 34.430294036865234, 33.793155670166016, 30.849018096923828, 26.182716369628906, 33.82292175292969, 29.004791259765625, 28.842716217041016, 31.878116607666016, 28.80209732055664]
     Last 10:  [31.835403442382812, 37.76252365112305, 32.01969909667969, 23.73250961303711, 32.74983215332031, 34.3238639831543, 33.113990783691406, 20.734851837158203, 30.933284759521484, 39.79521179199219]

================================================================================
050_layers.3.self_attn.q_proj: Linear (layers.3.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.3.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.059826, Std: 4.460990
     First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
     Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.075081, Std: 1.795474
     First 10: [5.27870512008667, 0.9697731137275696, -0.023747868835926056, -0.33054471015930176, 0.19091086089611053, 0.19677618145942688, 0.6259857416152954, 0.8535281419754028, -0.09705960005521774, 0.34126782417297363]
     Last 10:  [0.39680060744285583, -0.5330816507339478, 0.5797348618507385, -0.12298648059368134, 0.25590670108795166, -0.6416741609573364, -0.5962934494018555, -0.445017546415329, -1.0649075508117676, 0.4235389828681946]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000012
     First 10: [-0.02473447471857071, 0.00747658358886838, -0.009663837030529976, -0.004981466569006443, -0.007092875428497791, -0.010268435813486576, 0.005116593558341265, 0.002469222992658615, -0.01671775057911873, 0.00032376727904193103]
     Last 10:  [0.010036980733275414, -0.007164615206420422, -0.013899873942136765, 0.0026920116506516933, -0.004060684237629175, 0.0015144918579608202, -0.004937817808240652, 0.007890965789556503, 0.004378284327685833, -0.0012482586316764355]

================================================================================
051_layers.3.self_attn.k_proj: Linear (layers.3.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.3.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.059826, Std: 4.460990
     First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
     Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.069509, Std: 1.955774
     First 10: [1.3439936637878418, -0.32221704721450806, 0.05881437659263611, -0.16233588755130768, -0.3924422264099121, 2.4740941524505615, 0.6671534776687622, 0.4409787356853485, 0.008452504873275757, 0.5024046897888184]
     Last 10:  [0.2524745464324951, -0.8102883696556091, 0.698316216468811, 0.09909147024154663, -1.4675397872924805, 1.4179701805114746, -0.3621646463871002, 0.6354324221611023, -0.4580196142196655, 1.356261968612671]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000001
     First 10: [-0.012710785493254662, -0.0007936148322187364, -0.007372924126684666, -0.0013880024198442698, 0.0037204702384769917, -0.0012551846448332071, -0.0021564573980867863, 0.0023723351769149303, -0.006406356580555439, -0.005065133795142174]
     Last 10:  [0.006642278749495745, -0.0075077274814248085, 0.006764727644622326, -0.006694461219012737, 0.002997090108692646, -0.0022883142810314894, 0.021816669031977654, -0.004267510026693344, -0.017092423513531685, -0.0021589864045381546]

================================================================================
052_layers.3.self_attn.v_proj: Linear (layers.3.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.3.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.059826, Std: 4.460990
     First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
     Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.030189, Std: 0.942193
     First 10: [0.6075347661972046, -0.42021098732948303, 0.4340025782585144, 0.023828014731407166, 0.07199177145957947, 0.17016369104385376, 0.503790557384491, -0.2691144645214081, -0.2737869620323181, 0.48845216631889343]
     Last 10:  [0.7529522180557251, -0.06331443786621094, -0.14544378221035004, -0.15088340640068054, -0.5530520677566528, -0.37817004323005676, -0.07560047507286072, 0.40298786759376526, -0.2962351441383362, -0.4666005074977875]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000004
     First 10: [0.010619835928082466, 0.00296597508713603, -0.003507524263113737, 0.0002626265923026949, 0.00437252689152956, 0.0029724088963121176, -0.005663004703819752, 0.0035930490121245384, -0.005073553416877985, 0.003945102449506521]
     Last 10:  [0.0054832338355481625, 0.0013294019736349583, -0.00799004640430212, 0.0061554680578410625, 0.02431531995534897, -5.7273602578788996e-05, 0.014811843633651733, 0.00297141307964921, -0.013571808114647865, -0.004653362091630697]

================================================================================
053_layers.3.self_attn.q_norm: Gemma3RMSNorm (layers.3.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.3.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.075081, Std: 1.795474
     First 10: [5.27870512008667, 0.9697731137275696, -0.023747868835926056, -0.33054471015930176, 0.19091086089611053, 0.19677618145942688, 0.6259857416152954, 0.8535281419754028, -0.09705960005521774, 0.34126782417297363]
     Last 10:  [0.39680060744285583, -0.5330816507339478, 0.5797348618507385, -0.12298648059368134, 0.25590670108795166, -0.6416741609573364, -0.5962934494018555, -0.445017546415329, -1.0649075508117676, 0.4235389828681946]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.030101, Std: 1.334758
     First 10: [14.881897926330566, 1.8810877799987793, -0.04842377454042435, -0.7044716477394104, 0.37411898374557495, 0.14404939115047455, 0.9528961181640625, 2.0417819023132324, -0.21162833273410797, 0.5745779871940613]
     Last 10:  [0.41022682189941406, -0.31897205114364624, 0.4335772693157196, -0.12138792127370834, 0.2090539187192917, -0.6446216106414795, -0.5271077752113342, -0.5089263916015625, -0.7899011373519897, 0.44846752285957336]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.262050
     First 10: [1.025693655014038, 0.3937399387359619, 0.4651321768760681, 0.5313559174537659, 0.4080623984336853, -0.4740048944950104, 0.09376475214958191, 0.7188354730606079, 0.5666722059249878, 0.20975229144096375]
     Last 10:  [0.372350811958313, -0.20572246611118317, -0.007225743029266596, 0.3101816177368164, 0.08440132439136505, 0.3335328698158264, 0.17341817915439606, 0.5180681347846985, -0.015367327257990837, 0.4055653214454651]

================================================================================
054_layers.3.self_attn.k_norm: Gemma3RMSNorm (layers.3.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.3.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.069509, Std: 1.955774
     First 10: [1.3439936637878418, -0.32221704721450806, 0.05881437659263611, -0.16233588755130768, -0.3924422264099121, 2.4740941524505615, 0.6671534776687622, 0.4409787356853485, 0.008452504873275757, 0.5024046897888184]
     Last 10:  [0.2524745464324951, -0.8102883696556091, 0.698316216468811, 0.09909147024154663, -1.4675397872924805, 1.4179701805114746, -0.3621646463871002, 0.6354324221611023, -0.4580196142196655, 1.356261968612671]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.3.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.093442, Std: 1.536873
     First 10: [1.2437915802001953, -0.42851004004478455, 0.0775265321135521, -0.1494944840669632, -0.47322511672973633, 1.7534525394439697, 0.42483702301979065, 0.4671519994735718, 0.010844283737242222, 0.019883062690496445]
     Last 10:  [0.20633482933044434, -0.900826096534729, 0.7094592452049255, 0.0872325599193573, -1.3293918371200562, 1.133787989616394, -0.34825578331947327, 0.5455424189567566, -0.4419648051261902, 1.0593016147613525]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.535987
     First 10: [0.26536262035369873, 0.8183484077453613, 0.8023180961608887, 0.25914353132247925, 0.6487571001052856, -0.03095841035246849, -0.12931470572948456, 0.4484555423259735, 0.754203736782074, -0.9458879232406616]
     Last 10:  [0.33466196060180664, 0.8155896067619324, 0.6591730713844299, 0.4376683235168457, 0.4793791174888611, 0.30581334233283997, 0.5703940987586975, 0.4020887315273285, 0.5758684277534485, 0.27553513646125793]

================================================================================
055_layers.3.self_attn.o_proj: Linear (layers.3.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.3.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.023787, Std: 0.711618
     First 10: [0.6075347661972046, -0.42021098732948303, 0.4340025782585144, 0.023828014731407166, 0.07199177145957947, 0.17016369104385376, 0.503790557384491, -0.2691144645214081, -0.2737869620323181, 0.48845216631889343]
     Last 10:  [-0.3799763321876526, -0.2270483374595642, -0.21431121230125427, 0.01856204867362976, 0.5147045850753784, 0.07324805855751038, 0.2661823034286499, 0.14580003917217255, 0.06988730281591415, 0.1202896311879158]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005366, Std: 0.325539
     First 10: [0.07736073434352875, -0.13666430115699768, 0.022870009765028954, -1.4198710918426514, -0.25494304299354553, -0.01596187800168991, -0.005810592323541641, -0.05218188464641571, -0.09109882265329361, 0.12817645072937012]
     Last 10:  [0.3095112442970276, -0.15470106899738312, -0.13348500430583954, 0.27271005511283875, 0.2615244388580322, 0.1882404386997223, -0.20827709138393402, -0.2415952980518341, 0.053962528705596924, 0.029189620167016983]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000000
     First 10: [-0.018208077177405357, -0.010510880500078201, 0.0038210293278098106, 0.00970765482634306, 0.0005347476690076292, -0.006091131363064051, -0.003269240725785494, -0.010968759655952454, 0.005033397581428289, 0.0003612983273342252]
     Last 10:  [0.0033064857125282288, -0.003283140482380986, -0.0052651697769761086, -0.003890354186296463, 0.0075989775359630585, 0.0053966534323990345, 0.00028112204745411873, -0.0039504109881818295, 0.001646243967115879, -0.009546038694679737]

================================================================================
056_layers.3.self_attn: Gemma3Attention (layers.3.self_attn)
================================================================================

  → OUTPUT[0]: layers.3.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005366, Std: 0.325539
     First 10: [0.07736073434352875, -0.13666430115699768, 0.022870009765028954, -1.4198710918426514, -0.25494304299354553, -0.01596187800168991, -0.005810592323541641, -0.05218188464641571, -0.09109882265329361, 0.12817645072937012]
     Last 10:  [0.3095112442970276, -0.15470106899738312, -0.13348500430583954, 0.27271005511283875, 0.2615244388580322, 0.1882404386997223, -0.20827709138393402, -0.2415952980518341, 0.053962528705596924, 0.029189620167016983]
     Zeros: 0, Total: 5376

================================================================================
057_layers.3.post_attention_layernorm: Gemma3RMSNorm (layers.3.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.3.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005366, Std: 0.325539
     First 10: [0.07736073434352875, -0.13666430115699768, 0.022870009765028954, -1.4198710918426514, -0.25494304299354553, -0.01596187800168991, -0.005810592323541641, -0.05218188464641571, -0.09109882265329361, 0.12817645072937012]
     Last 10:  [0.3095112442970276, -0.15470106899738312, -0.13348500430583954, 0.27271005511283875, 0.2615244388580322, 0.1882404386997223, -0.20827709138393402, -0.2415952980518341, 0.053962528705596924, 0.029189620167016983]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.449305, Std: 10.823559
     First 10: [2.5858347415924072, -0.4077173173427582, 0.019658956676721573, -0.05586138367652893, -0.9262765645980835, -0.05996449291706085, -0.007037626579403877, -0.04921206831932068, -0.33035343885421753, 0.5727789998054504]
     Last 10:  [0.12477358430624008, -0.057168830186128616, -0.08541831374168396, 1.4020951986312866, 0.5478277802467346, 0.3417673110961914, -0.41895878314971924, -1.185265064239502, 0.10198970884084702, 0.08589426428079605]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.784519
     First 10: [6.856459617614746, -0.29878562688827515, -0.7979583740234375, -0.9907528162002563, -0.1460268795490265, -0.11700770258903503, -0.7153229117393494, -0.7783342599868774, -0.14766016602516174, 0.05032957345247269]
     Last 10:  [-0.8414157629013062, -0.854628324508667, -0.7482715249061584, 1.0225077867507935, -0.17596516013145447, -0.28578099608421326, -0.20869553089141846, 0.9299267530441284, -0.2565053105354309, 0.15757611393928528]

================================================================================
058_layers.3.pre_feedforward_layernorm: Gemma3RMSNorm (layers.3.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.3.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.361756, Std: 18.592110
     First 10: [17.884687423706055, -2.343038320541382, 0.3876468539237976, 0.01758895069360733, -2.5798537731170654, -0.219828262925148, 0.12885092198848724, -0.8720986843109131, -0.6758477687835693, 1.6831088066101074]
     Last 10:  [-1.5069904327392578, -0.5182338356971741, -0.2680444121360779, 0.6089824438095093, 3.403795003890991, -0.0973062515258789, -2.0420265197753906, -2.2886743545532227, 2.813880205154419, -1.466478943824768]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.043312, Std: 2.849301
     First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
     Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 17.232321
     First 10: [0.6981693506240845, 21.762659072875977, 18.668678283691406, 17.858308792114258, 17.218881607055664, 21.93596076965332, 17.104236602783203, 16.749656677246094, 20.06707191467285, 17.796178817749023]
     Last 10:  [19.653064727783203, 21.1882381439209, 18.33876609802246, 13.20434284210205, 19.793638229370117, 20.252670288085938, 19.344676971435547, 12.635019302368164, 17.804845809936523, 20.60694694519043]

================================================================================
059_layers.3.mlp.gate_proj: Linear (layers.3.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.3.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.043312, Std: 2.849301
     First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
     Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.352430, Std: 0.544698
     First 10: [-0.07084888964891434, -0.18283990025520325, -0.22277596592903137, 0.21060164272785187, 0.01612473465502262, 0.007492784410715103, 0.07497682422399521, -0.14284296333789825, 0.012564491480588913, -0.13575641810894012]
     Last 10:  [-0.26270657777786255, -0.40185970067977905, -0.48565801978111267, -0.1234157606959343, 0.05971186235547066, -0.04699007794260979, -0.2791433036327362, 0.12028338760137558, 0.24023769795894623, 0.048303112387657166]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000063
     First 10: [0.0034132585860788822, 0.002351657720282674, -0.0001338132278760895, -0.0010976963676512241, -0.0024652541615068913, -0.007725394330918789, 0.0017309169052168727, -0.000539175292942673, 0.0029734745621681213, -0.0014220350421965122]
     Last 10:  [-0.0012804721482098103, 0.002071891212835908, 0.0006026042392477393, -0.0016705174930393696, -0.00849995668977499, -0.004608519375324249, -0.006866618525236845, 0.005702848080545664, 0.0051081255078315735, -0.0052831596694886684]

================================================================================
060_layers.3.mlp.act_fn: PytorchGELUTanh (layers.3.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.3.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.352430, Std: 0.544698
     First 10: [-0.07084888964891434, -0.18283990025520325, -0.22277596592903137, 0.21060164272785187, 0.01612473465502262, 0.007492784410715103, 0.07497682422399521, -0.14284296333789825, 0.012564491480588913, -0.13575641810894012]
     Last 10:  [-0.26270657777786255, -0.40185970067977905, -0.48565801978111267, -0.1234157606959343, 0.05971186235547066, -0.04699007794260979, -0.2791433036327362, 0.12028338760137558, 0.24023769795894623, 0.048303112387657166]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.3.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.040765, Std: 0.196113
     First 10: [-0.03342361003160477, -0.07815743237733841, -0.09175216406583786, 0.12286457419395447, 0.008166090585291386, 0.0037687893491238356, 0.03972896561026573, -0.06330914795398712, 0.006345224101096392, -0.060548409819602966]
     Last 10:  [-0.10413532704114914, -0.1382046490907669, -0.15232019126415253, -0.055646877735853195, 0.03127751126885414, -0.02261447347700596, -0.10888659954071045, 0.06589967012405396, 0.14292283356189728, 0.025081999599933624]
     Zeros: 0, Total: 8064

================================================================================
061_layers.3.mlp.up_proj: Linear (layers.3.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.3.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.043312, Std: 2.849301
     First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
     Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.005127, Std: 0.477205
     First 10: [-0.11400371044874191, -0.18644334375858307, -0.0863964706659317, 0.0509701669216156, -0.09478780627250671, 0.03514707833528519, -0.019085437059402466, -0.21105001866817474, -0.2080688178539276, -0.23981821537017822]
     Last 10:  [0.23056812584400177, -0.23218762874603271, -0.06676831096410751, 0.27007389068603516, -0.10065621137619019, -0.3287680745124817, 0.21089354157447815, 0.23527228832244873, -0.22566327452659607, -0.10350172966718674]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000003
     First 10: [-0.001252165180630982, 0.001500436570495367, 0.006025002337992191, -0.003123433096334338, -0.00037242521648295224, -0.0016231409972533584, -0.002766622696071863, 0.00020560268603730947, -0.010431679897010326, 0.0037100110203027725]
     Last 10:  [-0.003685074858367443, -0.004614641889929771, -0.010175708681344986, 0.001734535675495863, 0.0021713380701839924, 0.003609919920563698, 0.009490974247455597, -0.0005920286057516932, -0.004094598814845085, 0.003645730670541525]

================================================================================
062_layers.3.mlp.down_proj: Linear (layers.3.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.3.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000333, Std: 0.149697
     First 10: [0.0038104155100882053, 0.014571933075785637, 0.007927062921226025, 0.006262427661567926, -0.0007740458240732551, 0.00013246193702798337, -0.0007582446560263634, 0.013361397199332714, -0.0013202432310208678, 0.014520611613988876]
     Last 10:  [-0.02401028759777546, 0.03208940848708153, 0.010170161724090576, -0.01502876915037632, -0.0031482758931815624, 0.00743491668254137, -0.02296348102390766, 0.015504365786910057, -0.03225243464112282, -0.002596030244603753]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.3.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001876, Std: 0.047310
     First 10: [0.00988748949021101, -0.0016319871647283435, -0.002810006495565176, 0.00253739720210433, -0.0021906206384301186, -0.00230024429038167, 3.4377328120172024e-05, -0.002132640453055501, -0.0010078410850837827, -0.007609821856021881]
     Last 10:  [0.013000523671507835, -0.01447188388556242, 0.0038546277210116386, 0.003431163029745221, 0.00859474204480648, 0.00100653525441885, -0.007862483151257038, -0.0091759217903018, 0.007515238597989082, 0.008473170921206474]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000005
     First 10: [0.0019462569616734982, 0.004236411303281784, -0.00710854958742857, -0.003567312378436327, 0.0009078872390091419, 0.0053781988099217415, -0.002110288944095373, -0.0046844519674777985, -0.004813321866095066, 0.000777245091740042]
     Last 10:  [-0.0052063800394535065, 0.0011115337256342173, -0.005117303691804409, -0.008337238803505898, 0.0015922014135867357, 0.005518989637494087, 0.003995458595454693, -0.01126091182231903, 0.0004456371534615755, 0.00192588334903121]

================================================================================
063_layers.3.mlp: Gemma3MLP (layers.3.mlp)
================================================================================

  → INPUT[0]: layers.3.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.043312, Std: 2.849301
     First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
     Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001876, Std: 0.047310
     First 10: [0.00988748949021101, -0.0016319871647283435, -0.002810006495565176, 0.00253739720210433, -0.0021906206384301186, -0.00230024429038167, 3.4377328120172024e-05, -0.002132640453055501, -0.0010078410850837827, -0.007609821856021881]
     Last 10:  [0.013000523671507835, -0.01447188388556242, 0.0038546277210116386, 0.003431163029745221, 0.00859474204480648, 0.00100653525441885, -0.007862483151257038, -0.0091759217903018, 0.007515238597989082, 0.008473170921206474]
     Zeros: 0, Total: 5376

================================================================================
064_layers.3.post_feedforward_layernorm: Gemma3RMSNorm (layers.3.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.3.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001876, Std: 0.047310
     First 10: [0.00988748949021101, -0.0016319871647283435, -0.002810006495565176, 0.00253739720210433, -0.0021906206384301186, -0.00230024429038167, 3.4377328120172024e-05, -0.002132640453055501, -0.0010078410850837827, -0.007609821856021881]
     Last 10:  [0.013000523671507835, -0.01447188388556242, 0.0038546277210116386, 0.003431163029745221, 0.00859474204480648, 0.00100653525441885, -0.007862483151257038, -0.0091759217903018, 0.007515238597989082, 0.008473170921206474]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.3.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.333951, Std: 14.892618
     First 10: [15.690444946289062, -0.19420620799064636, -0.16625581681728363, 0.11464894562959671, -0.3918304145336151, -0.3535054326057434, 0.002100064419209957, -0.11386733502149582, -0.16140559315681458, -1.2639120817184448]
     Last 10:  [0.49900510907173157, -0.6048781275749207, 0.0936402827501297, 0.6753284335136414, 0.7552799582481384, 0.08121141791343689, -0.7302577495574951, -1.358172059059143, 0.6901171803474426, 0.8474723696708679]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 2.698411
     First 10: [16.19301414489746, 0.2892857789993286, -0.35897889733314514, -0.5104642510414124, 0.9379107356071472, 0.6650410890579224, -0.3381442725658417, -0.42152538895606995, 0.7351193428039551, 0.7994723320007324]
     Last 10:  [-0.23542994260787964, -0.16743914783000946, -0.5161024332046509, 2.920548439025879, 0.7504441738128662, 0.6071679592132568, 0.8500760793685913, 1.9483447074890137, 0.8291662931442261, 0.992290735244751]

================================================================================
065_layers.4.input_layernorm: Gemma3RMSNorm (layers.4.input_layernorm)
================================================================================

  → INPUT[0]: layers.4.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.027805, Std: 25.062201
     First 10: [33.57513427734375, -2.5372445583343506, 0.22139103710651398, 0.13223789632320404, -2.971684217453003, -0.5733336806297302, 0.13095098733901978, -0.9859660267829895, -0.8372533321380615, 0.4191967248916626]
     Last 10:  [-1.0079853534698486, -1.1231119632720947, -0.17440412938594818, 1.2843108177185059, 4.159074783325195, -0.016094833612442017, -2.7722842693328857, -3.646846294403076, 3.503997325897217, -0.6190065741539001]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.054486, Std: 6.085320
     First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
     Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 30.053549
     First 10: [3.5011961460113525, 34.038761138916016, 43.628719329833984, 44.82903289794922, 25.38436508178711, 33.90012741088867, 36.82551956176758, 39.42230987548828, 31.57954978942871, 27.59619903564453]
     Last 10:  [37.823970794677734, 40.64173889160156, 43.61260986328125, 21.141952514648438, 29.624412536621094, 31.42223358154297, 30.19664764404297, 20.042173385620117, 27.509361267089844, 35.318119049072266]

================================================================================
066_layers.4.self_attn.q_proj: Linear (layers.4.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.4.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.054486, Std: 6.085320
     First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
     Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.128718, Std: 2.056209
     First 10: [-1.3003647327423096, 0.2258465588092804, 0.18628384172916412, 0.10066002607345581, -0.38012808561325073, -0.5542322397232056, -1.250847339630127, 0.5661227703094482, -0.515535831451416, 0.11348970234394073]
     Last 10:  [-0.11105728149414062, 0.32519063353538513, 0.29016372561454773, -0.8885889053344727, 0.04653879255056381, -0.22440002858638763, -0.4166398048400879, -0.19353613257408142, -0.029963389039039612, -0.00011694245040416718]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000012
     First 10: [0.015923626720905304, -0.0021433306392282248, 0.002669490408152342, 0.003584738355129957, 0.0046543884091079235, -0.0065332199446856976, -0.004227713216096163, 0.0028054879512637854, -0.014256205409765244, -0.0036290022544562817]
     Last 10:  [0.006604360416531563, 0.003199347062036395, 0.0033200783655047417, -0.002815719461068511, 0.0014751756098121405, -0.003681167494505644, 0.004084416199475527, 0.008177787065505981, 0.015509731136262417, 0.0013018768513575196]

================================================================================
067_layers.4.self_attn.k_proj: Linear (layers.4.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.4.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.054486, Std: 6.085320
     First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
     Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.252606, Std: 2.220254
     First 10: [0.1747579127550125, 0.03840899467468262, -0.5019262433052063, -0.08137509971857071, 0.1490200012922287, -0.4019699990749359, 0.2811308801174164, 0.3252238631248474, -0.1669502556324005, 0.003788955509662628]
     Last 10:  [-0.09925991296768188, 1.2903430461883545, -1.269709825515747, -0.5569393634796143, -0.46465837955474854, -1.7159514427185059, 0.7715805768966675, 0.4556434154510498, 0.043789297342300415, 0.7574905753135681]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000026
     First 10: [0.0016466802917420864, 0.0011188746429979801, -0.0029975022189319134, 0.0023991817142814398, 0.006305144168436527, -0.008996712043881416, 0.0027288729324936867, 0.0027264696545898914, 0.0068862782791256905, 0.009563600644469261]
     Last 10:  [-0.009137351997196674, -0.004768060520291328, -0.007838345132768154, -0.01320749893784523, 0.007921493612229824, -0.002556559396907687, -0.0005732194986194372, 0.0008528364123776555, -0.006121305748820305, 0.007684455253183842]

================================================================================
068_layers.4.self_attn.v_proj: Linear (layers.4.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.4.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.054486, Std: 6.085320
     First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
     Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.018024, Std: 1.299405
     First 10: [0.35552769899368286, 0.07439523935317993, -0.26891568303108215, -0.04349346458911896, 0.19978776574134827, -0.006230875849723816, -0.42201948165893555, 0.29892539978027344, 0.09775888919830322, 0.26005351543426514]
     Last 10:  [0.22149068117141724, -0.2593604624271393, 0.3115338683128357, -0.07205217331647873, -0.0030505768954753876, -0.23764684796333313, 0.16726790368556976, -0.14450547099113464, 0.1104220300912857, -0.08823485672473907]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000003
     First 10: [-0.0062811714597046375, 0.0026892456226050854, 0.008111756294965744, -0.0007738098502159119, -0.007776749320328236, -0.005026442464441061, 0.006078682839870453, -0.010466749779880047, 0.027908921241760254, -0.008585875853896141]
     Last 10:  [0.00766225578263402, -9.779594984138384e-05, -0.008763829246163368, -0.017053013667464256, 0.0008924002177082002, 0.007069902494549751, 0.007435306906700134, 0.0069771441631019115, 0.003427910152822733, -0.0002792257582768798]

================================================================================
069_layers.4.self_attn.q_norm: Gemma3RMSNorm (layers.4.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.4.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.128718, Std: 2.056209
     First 10: [-1.3003647327423096, 0.2258465588092804, 0.18628384172916412, 0.10066002607345581, -0.38012808561325073, -0.5542322397232056, -1.250847339630127, 0.5661227703094482, -0.515535831451416, 0.11348970234394073]
     Last 10:  [-0.11105728149414062, 0.32519063353538513, 0.29016372561454773, -0.8885889053344727, 0.04653879255056381, -0.22440002858638763, -0.4166398048400879, -0.19353613257408142, -0.029963389039039612, -0.00011694245040416718]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.070463, Std: 1.395111
     First 10: [-4.0822343826293945, 0.6525353789329529, 0.5451899170875549, 0.2914077937602997, -1.097116231918335, -0.9762637615203857, -3.485938787460327, 1.4749176502227783, -1.3194186687469482, 0.23538611829280853]
     Last 10:  [-0.2757661044597626, 1.2404624223709106, 0.9970362782478333, -2.7414257526397705, 0.13000279664993286, -0.7447633743286133, -1.5398623943328857, -0.7079785466194153, -0.08108490705490112, -0.0002886266738642007]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.362248
     First 10: [0.6341115832328796, 0.5039713382720947, 0.5234267711639404, 0.5069301128387451, 0.5023518204689026, -0.08309494704008102, 0.4506559371948242, 0.35614505410194397, 0.3322101831436157, 0.07962603867053986]
     Last 10:  [0.13945408165454865, 0.7504456043243408, 0.5767790675163269, 0.415723979473114, 0.28186002373695374, 0.5229946970939636, 0.6959935426712036, 0.6786535978317261, 0.24180123209953308, 0.13257591426372528]

================================================================================
070_layers.4.self_attn.k_norm: Gemma3RMSNorm (layers.4.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.4.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.252606, Std: 2.220254
     First 10: [0.1747579127550125, 0.03840899467468262, -0.5019262433052063, -0.08137509971857071, 0.1490200012922287, -0.4019699990749359, 0.2811308801174164, 0.3252238631248474, -0.1669502556324005, 0.003788955509662628]
     Last 10:  [-0.09925991296768188, 1.2903430461883545, -1.269709825515747, -0.5569393634796143, -0.46465837955474854, -1.7159514427185059, 0.7715805768966675, 0.4556434154510498, 0.043789297342300415, 0.7574905753135681]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.4.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.057136, Std: 1.377365
     First 10: [0.1737399697303772, 0.05580642446875572, -0.8446398377418518, -0.09585341066122055, 0.15438324213027954, -0.4901633858680725, 0.2758810520172119, 0.4866156280040741, -0.18139946460723877, 0.005308731459081173]
     Last 10:  [-0.111277274787426, 1.2815203666687012, -1.3333845138549805, -0.5321565270423889, -0.5818893909454346, -1.6759469509124756, 0.797446608543396, 0.3600291609764099, 0.05690978094935417, 1.0351741313934326]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.445765
     First 10: [-0.0327310748398304, 0.41362959146499634, 0.6372537612915039, 0.1460416167974472, 0.007952234707772732, 0.18640118837356567, -0.04523245617747307, 0.45575398206710815, 0.05714188888669014, 0.36318743228912354]
     Last 10:  [0.3327537775039673, 0.18069498240947723, 0.248441681265831, 0.13592292368412018, 0.4887577295303345, 0.16110801696777344, 0.22867688536643982, -0.06064455956220627, 0.5450278520584106, 0.6246263980865479]

================================================================================
071_layers.4.self_attn.o_proj: Linear (layers.4.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.4.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.010674, Std: 0.744312
     First 10: [0.35552769899368286, 0.07439523935317993, -0.26891568303108215, -0.04349346458911896, 0.19978776574134827, -0.006230875849723816, -0.42201948165893555, 0.29892539978027344, 0.09775888919830322, 0.26005351543426514]
     Last 10:  [0.12048257142305374, -0.15959219634532928, 0.2263602465391159, -0.04229557141661644, 0.04798565059900284, -0.28840941190719604, 0.0410408079624176, -0.1332937777042389, 0.005188792943954468, -0.0297364704310894]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008274, Std: 0.264323
     First 10: [0.07013438642024994, -0.02277786284685135, 0.035652726888656616, -0.07001519203186035, 0.0020276717841625214, -0.06461795419454575, -0.062479034066200256, 0.022180359810590744, -0.09435208886861801, 0.027010587975382805]
     Last 10:  [-0.14023488759994507, 0.07838107645511627, -0.10736659169197083, 0.00969766452908516, -0.1169893816113472, 0.05185773968696594, -0.011285662651062012, -0.17035627365112305, -0.12618526816368103, -0.05198054388165474]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000012
     First 10: [0.004939989186823368, -0.009276050142943859, -0.0031781871803104877, 0.005720284301787615, 0.0025303037837147713, 0.0009211247088387609, -0.0027359132654964924, -0.00011590971553232521, -0.006941339932382107, -0.0018675283063203096]
     Last 10:  [0.011519965715706348, -7.893152360338718e-05, 0.004742820281535387, -0.004479412455111742, 0.018105583265423775, -0.007297869771718979, 0.008593114092946053, -7.371079118456692e-05, 0.01168813556432724, 0.011855040676891804]

================================================================================
072_layers.4.self_attn: Gemma3Attention (layers.4.self_attn)
================================================================================

  → OUTPUT[0]: layers.4.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008274, Std: 0.264323
     First 10: [0.07013438642024994, -0.02277786284685135, 0.035652726888656616, -0.07001519203186035, 0.0020276717841625214, -0.06461795419454575, -0.062479034066200256, 0.022180359810590744, -0.09435208886861801, 0.027010587975382805]
     Last 10:  [-0.14023488759994507, 0.07838107645511627, -0.10736659169197083, 0.00969766452908516, -0.1169893816113472, 0.05185773968696594, -0.011285662651062012, -0.17035627365112305, -0.12618526816368103, -0.05198054388165474]
     Zeros: 0, Total: 5376

================================================================================
073_layers.4.post_attention_layernorm: Gemma3RMSNorm (layers.4.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.4.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008274, Std: 0.264323
     First 10: [0.07013438642024994, -0.02277786284685135, 0.035652726888656616, -0.07001519203186035, 0.0020276717841625214, -0.06461795419454575, -0.062479034066200256, 0.022180359810590744, -0.09435208886861801, 0.027010587975382805]
     Last 10:  [-0.14023488759994507, 0.07838107645511627, -0.10736659169197083, 0.00969766452908516, -0.1169893816113472, 0.05185773968696594, -0.011285662651062012, -0.17035627365112305, -0.12618526816368103, -0.05198054388165474]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.203157, Std: 4.951511
     First 10: [2.811494827270508, -0.11620846390724182, 0.030258726328611374, -0.061204202473163605, 0.012642545625567436, -0.45691394805908203, -0.07427477836608887, 0.018411392346024513, -0.643004298210144, 0.22905509173870087]
     Last 10:  [-0.11435713618993759, 0.058000970631837845, -0.07437372952699661, 0.13958856463432312, -0.874189019203186, 0.3526437282562256, -0.07218769937753677, -1.9812443256378174, -0.7202491164207458, -0.6112315058708191]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 1.568858
     First 10: [7.19985294342041, 0.04357725381851196, -0.8263968229293823, -0.8211912512779236, 0.2753714323043823, 0.44637539982795715, -0.7568317651748657, -0.8302077651023865, 0.3939978778362274, 0.7346252799034119]
     Last 10:  [-0.8162345886230469, -0.8332443237304688, -0.8438985347747803, 2.2436892986297607, 0.6838969588279724, 0.532424807548523, 0.4414272904396057, 1.6208158731460571, 0.28626564145088196, 1.6498514413833618]

================================================================================
074_layers.4.pre_feedforward_layernorm: Gemma3RMSNorm (layers.4.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.4.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.175352, Std: 23.267481
     First 10: [36.386627197265625, -2.6534531116485596, 0.25164976716041565, 0.07103369385004044, -2.9590415954589844, -1.030247688293457, 0.05667620897293091, -0.9675546288490295, -1.4802576303482056, 0.6482518315315247]
     Last 10:  [-1.1223424673080444, -1.0651110410690308, -0.2487778663635254, 1.4238994121551514, 3.284885883331299, 0.33654889464378357, -2.8444719314575195, -5.628090858459473, 2.783748149871826, -1.2302380800247192]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008037, Std: 3.812306
     First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
     Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 18.926020
     First 10: [0.7999581098556519, 24.128704071044922, 24.076936721801758, 23.652040481567383, 19.446035385131836, 22.746252059936523, 21.807090759277344, 24.019975662231445, 20.48129653930664, 18.52987289428711]
     Last 10:  [24.27666473388672, 29.06945037841797, 25.004642486572266, 11.1429443359375, 20.734098434448242, 21.620779037475586, 20.095592498779297, 12.247453689575195, 19.558992385864258, 17.14889144897461]

================================================================================
075_layers.4.mlp.gate_proj: Linear (layers.4.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.4.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008037, Std: 3.812306
     First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
     Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.532002, Std: 0.776529
     First 10: [-0.2433040291070938, -0.2199590653181076, -0.025291763246059418, -0.22469228506088257, -0.6570779085159302, -0.2255728840827942, -0.22156882286071777, -0.04523707926273346, -0.05315668135881424, -0.1563359797000885]
     Last 10:  [0.4588277339935303, 0.10540883988142014, -0.06063370779156685, -0.13590772449970245, -0.2392680048942566, 0.06479018926620483, 0.025217141956090927, 0.8626278638839722, 0.14050805568695068, -0.12124986201524734]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000059
     First 10: [0.0069617838598787785, 0.0023062368854880333, 0.0012736886274069548, 0.0021115480922162533, -0.008288366720080376, -0.014618877321481705, -0.004488079342991114, 0.0014578435802832246, 0.0046605514362454414, 0.008388355374336243]
     Last 10:  [0.00431363470852375, -0.003913611173629761, 0.0028059976175427437, -0.010628093034029007, -0.006146181374788284, -0.007693157531321049, 0.00521867536008358, -0.007443943992257118, -0.005136200226843357, -0.001207544468343258]

================================================================================
076_layers.4.mlp.act_fn: PytorchGELUTanh (layers.4.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.4.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.532002, Std: 0.776529
     First 10: [-0.2433040291070938, -0.2199590653181076, -0.025291763246059418, -0.22469228506088257, -0.6570779085159302, -0.2255728840827942, -0.22156882286071777, -0.04523707926273346, -0.05315668135881424, -0.1563359797000885]
     Last 10:  [0.4588277339935303, 0.10540883988142014, -0.06063370779156685, -0.13590772449970245, -0.2392680048942566, 0.06479018926620483, 0.025217141956090927, 0.8626278638839722, 0.14050805568695068, -0.12124986201524734]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.4.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.022440, Std: 0.248153
     First 10: [-0.09826793521642685, -0.09083317220211029, -0.012390716932713985, -0.09237390756607056, -0.16797126829624176, -0.09265868365764618, -0.09135908633470535, -0.021802425384521484, -0.02545160986483097, -0.06845723092556]
     Last 10:  [0.31053170561790466, 0.057128846645355225, -0.028851067647337914, -0.06060776486992836, -0.0970119759440422, 0.03406858444213867, 0.012862233445048332, 0.6950259804725647, 0.07810419052839279, -0.05477428063750267]
     Zeros: 0, Total: 8064

================================================================================
077_layers.4.mlp.up_proj: Linear (layers.4.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.4.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008037, Std: 3.812306
     First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
     Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.018667, Std: 0.656962
     First 10: [-0.07482915371656418, 0.20824719965457916, -0.1833893060684204, -0.026981636881828308, -0.04808507114648819, -0.23260554671287537, -0.17104984819889069, 0.32192689180374146, 0.3443179130554199, 0.2210167944431305]
     Last 10:  [-0.1666335016489029, -0.08376934379339218, 0.21405565738677979, -0.09443143010139465, -0.42135483026504517, -0.3598727285861969, 0.17925535142421722, -0.23852309584617615, 0.22429916262626648, 0.18247124552726746]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000001
     First 10: [0.011271459981799126, -0.007240707520395517, -0.0040602004155516624, 0.001447848742827773, -0.002439265139400959, -0.0009078993462026119, -0.004891451448202133, -0.0002823368995450437, -0.00886033196002245, 0.0017920949030667543]
     Last 10:  [-0.01350376382470131, -0.009532928466796875, -0.010541806928813457, -0.001217068755067885, 0.0022407621145248413, -0.0005179073777981102, -0.0033329881262034178, -0.005676034837961197, -0.0017607470508664846, 0.011621421203017235]

================================================================================
078_layers.4.mlp.down_proj: Linear (layers.4.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.4.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.003881, Std: 0.238542
     First 10: [0.007353306282311678, -0.018915753811597824, 0.0022723248694092035, 0.002492399187758565, 0.008076909929513931, 0.021552924066781998, 0.015626957640051842, -0.007018786855041981, -0.008763445541262627, -0.015130197629332542]
     Last 10:  [-0.051744986325502396, -0.004785646218806505, -0.006175734102725983, 0.005723278038203716, 0.04087646305561066, -0.01226035412400961, 0.0023056240752339363, -0.16577975451946259, 0.017518704757094383, -0.009994731284677982]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.4.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000898, Std: 0.064236
     First 10: [0.016506865620613098, 0.012730066664516926, 0.004437127150595188, -0.00526181748136878, -0.0026479382067918777, 0.0001356686552753672, 0.008064948953688145, -0.008999384939670563, -0.0007766254129819572, 0.002039021346718073]
     Last 10:  [0.004823110997676849, 0.00025620352244004607, -0.0014824876561760902, 0.002598237944766879, 0.00329629541374743, 0.005703882314264774, 0.0011940994299948215, 0.0003665557596832514, 0.0006752926856279373, -0.0019562644883990288]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000001
     First 10: [0.0031596655026078224, -0.0005879935342818499, -0.004245835822075605, 0.002509906655177474, -0.0004605755675584078, -7.170820026658475e-08, 0.0011775465682148933, 0.003347658086568117, -0.00019857820007018745, -0.0024393487256020308]
     Last 10:  [0.005178314633667469, -0.006805201061069965, 0.004538679961115122, -0.00014529094914905727, -0.0040743048302829266, 0.00256634340621531, -0.00036258279578760266, 0.004330095835030079, -0.008603168651461601, -0.0022270698100328445]

================================================================================
079_layers.4.mlp: Gemma3MLP (layers.4.mlp)
================================================================================

  → INPUT[0]: layers.4.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008037, Std: 3.812306
     First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
     Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000898, Std: 0.064236
     First 10: [0.016506865620613098, 0.012730066664516926, 0.004437127150595188, -0.00526181748136878, -0.0026479382067918777, 0.0001356686552753672, 0.008064948953688145, -0.008999384939670563, -0.0007766254129819572, 0.002039021346718073]
     Last 10:  [0.004823110997676849, 0.00025620352244004607, -0.0014824876561760902, 0.002598237944766879, 0.00329629541374743, 0.005703882314264774, 0.0011940994299948215, 0.0003665557596832514, 0.0006752926856279373, -0.0019562644883990288]
     Zeros: 0, Total: 5376

================================================================================
080_layers.4.post_feedforward_layernorm: Gemma3RMSNorm (layers.4.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.4.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000898, Std: 0.064236
     First 10: [0.016506865620613098, 0.012730066664516926, 0.004437127150595188, -0.00526181748136878, -0.0026479382067918777, 0.0001356686552753672, 0.008064948953688145, -0.008999384939670563, -0.0007766254129819572, 0.002039021346718073]
     Last 10:  [0.004823110997676849, 0.00025620352244004607, -0.0014824876561760902, 0.002598237944766879, 0.00329629541374743, 0.005703882314264774, 0.0011940994299948215, 0.0003665557596832514, 0.0006752926856279373, -0.0019562644883990288]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.4.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.123660, Std: 14.204190
     First 10: [13.617456436157227, 1.2953903675079346, 0.1348228007555008, -0.13247188925743103, -0.3941936790943146, 0.017186861485242844, 0.29084891080856323, -0.24068281054496765, -0.11646171659231186, 0.3421156108379364]
     Last 10:  [0.3306266963481903, 0.020900847390294075, -0.05535745993256569, 1.2262427806854248, 0.8037211894989014, 1.2321528196334839, 0.30467066168785095, 0.12004515528678894, 0.163411945104599, -0.529354453086853]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 2.749710
     First 10: [12.417652130126953, 0.6550652384757996, -0.5057955384254456, -0.5905196070671082, 1.4212908744812012, 1.0604506731033325, -0.4134420156478882, -0.5650118589401245, 1.4390276670455933, 1.7289543151855469]
     Last 10:  [-0.30211320519447327, -0.16947424411773682, -0.6198461651802063, 3.8047618865966797, 1.4822962284088135, 1.1992181539535522, 1.5975532531738281, 2.3341023921966553, 1.4635769128799438, 1.7548205852508545]

================================================================================
081_layers.5.input_layernorm: Gemma3RMSNorm (layers.5.input_layernorm)
================================================================================

  → INPUT[0]: layers.5.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.299011, Std: 28.675858
     First 10: [50.00408172607422, -1.358062744140625, 0.38647258281707764, -0.061438195407390594, -3.3532352447509766, -1.0130608081817627, 0.34752511978149414, -1.2082374095916748, -1.5967193841934204, 0.9903674125671387]
     Last 10:  [-0.7917157411575317, -1.0442101955413818, -0.3041353225708008, 2.650142192840576, 4.088606834411621, 1.5687017440795898, -2.5398013591766357, -5.508045673370361, 2.947160005569458, -1.7595925331115723]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.017976, Std: 3.510119
     First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
     Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 14.830829
     First 10: [1.2742711305618286, 13.574835777282715, 40.08369827270508, 61.52623748779297, 8.069757461547852, 11.577266693115234, 32.08300018310547, 47.554534912109375, 9.628746032714844, 9.027345657348633]
     Last 10:  [23.782522201538086, 21.331403732299805, 55.930782318115234, 5.929203033447266, 10.355016708374023, 10.666390419006348, 9.829347610473633, 7.2143354415893555, 9.38251781463623, 10.386371612548828]

================================================================================
082_layers.5.self_attn.q_proj: Linear (layers.5.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.5.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.017976, Std: 3.510119
     First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
     Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.003083, Std: 1.959772
     First 10: [0.3435963988304138, -0.8238925337791443, -0.5850796699523926, 0.5215917825698853, 0.833429217338562, 1.023348331451416, -0.6344496607780457, -1.1658132076263428, 0.6053445339202881, -0.9074148535728455]
     Last 10:  [-0.17620936036109924, 0.04484046995639801, 0.0753069594502449, 0.6970285177230835, 0.09042491763830185, -0.15865793824195862, -0.109433114528656, 0.13280242681503296, -0.207976832985878, 0.08010171353816986]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000011
     First 10: [-0.00045388046419247985, -0.0002922211424447596, -0.0006172721041366458, -0.003377859480679035, -0.003890646854415536, -0.00016312184743583202, 0.0009483472676947713, 0.0019211680628359318, 0.005745221860706806, -0.0014445866690948606]
     Last 10:  [-0.0009605095256119967, -0.00288126477971673, 0.004893929697573185, -0.00782737322151661, -0.016704136505723, 0.01003770250827074, -0.0067700911313295364, 0.004026071634143591, -0.0034850994125008583, 0.0055162422358989716]

================================================================================
083_layers.5.self_attn.k_proj: Linear (layers.5.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.5.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.017976, Std: 3.510119
     First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
     Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.032304, Std: 1.118277
     First 10: [-0.32856476306915283, 0.4253772795200348, 0.5012852549552917, -0.23478823900222778, -0.6292316317558289, -0.6332000494003296, 0.5806336402893066, 0.7183332443237305, -0.350685715675354, 0.43357163667678833]
     Last 10:  [-1.2204737663269043, 0.2628942131996155, -0.5726051926612854, 1.5888240337371826, 1.0807337760925293, -0.5544968843460083, -0.8628553748130798, -0.05456794798374176, -0.7803530693054199, 0.4297964572906494]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000011
     First 10: [0.0018002809956669807, -0.0014139346312731504, 0.0013738288544118404, -0.0010732304072007537, 0.0012714312179014087, -0.004350459668785334, -0.005642164498567581, -0.0027403831481933594, 0.0010238646063953638, 0.0015159612521529198]
     Last 10:  [-0.03640391677618027, -0.0123594980686903, 0.006455507129430771, -0.012104012072086334, 0.0016918971668928862, 0.01236751675605774, 0.0019380230223760009, 0.01291240006685257, 0.003908245824277401, 0.00854592863470316]

================================================================================
084_layers.5.self_attn.v_proj: Linear (layers.5.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.5.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.017976, Std: 3.510119
     First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
     Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.023424, Std: 0.701207
     First 10: [-0.18729406595230103, -0.6642611026763916, -0.6630067825317383, 0.1364155113697052, 0.03617032989859581, 0.15833841264247894, 0.3766028881072998, 0.10187871754169464, 0.0008386000990867615, 0.7521985769271851]
     Last 10:  [-0.22159415483474731, 0.20331120491027832, -0.11347837746143341, -0.3656628429889679, -0.022672876715660095, 0.07251614332199097, 0.09820893406867981, 0.11884456872940063, -0.0043951719999313354, -0.19001463055610657]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000024
     First 10: [0.006471353117376566, 0.0033953720703721046, 0.003023033495992422, -0.0027186472434550524, 0.017420584335923195, 0.0007671260391362011, -0.007065834477543831, 0.0035259099677205086, -0.0037396596744656563, -0.001328684389591217]
     Last 10:  [0.0045031774789094925, 0.016839945688843727, -0.0016253688372671604, 0.002175101777538657, 0.008348653092980385, 0.0018580949399620295, 0.0016746424371376634, -0.0025999443605542183, -0.010400472208857536, -0.001975895371288061]

================================================================================
085_layers.5.self_attn.q_norm: Gemma3RMSNorm (layers.5.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.5.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.003083, Std: 1.959772
     First 10: [0.3435963988304138, -0.8238925337791443, -0.5850796699523926, 0.5215917825698853, 0.833429217338562, 1.023348331451416, -0.6344496607780457, -1.1658132076263428, 0.6053445339202881, -0.9074148535728455]
     Last 10:  [-0.17620936036109924, 0.04484046995639801, 0.0753069594502449, 0.6970285177230835, 0.09042491763830185, -0.15865793824195862, -0.109433114528656, 0.13280242681503296, -0.207976832985878, 0.08010171353816986]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.034788, Std: 1.330069
     First 10: [0.7491567730903625, -1.0988593101501465, -0.5799961686134338, 0.6482558846473694, 0.7619922161102295, 1.1293338537216187, -0.6823820471763611, -1.2502248287200928, 0.6221124529838562, -1.2545554637908936]
     Last 10:  [-0.4889146089553833, 0.10989035665988922, 0.17953625321388245, 1.8139169216156006, 0.2425702065229416, -0.4021260738372803, -0.2881060838699341, 0.25207382440567017, -0.5073937773704529, 0.21538400650024414]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.938661
     First 10: [0.666273295879364, 0.0192804504185915, -0.2424134612083435, -0.05018755793571472, -0.3012787401676178, -0.1566244214773178, -0.17803645133972168, -0.18043898046016693, -0.21460449695587158, 0.05658908560872078]
     Last 10:  [0.26287686824798584, 0.11544045805931091, 0.0851106196641922, 0.1844692975282669, 0.22097370028495789, 0.15360569953918457, 0.19828641414642334, -0.1360696256160736, 0.11041967570781708, 0.22385123372077942]

================================================================================
086_layers.5.self_attn.k_norm: Gemma3RMSNorm (layers.5.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.5.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.032304, Std: 1.118277
     First 10: [-0.32856476306915283, 0.4253772795200348, 0.5012852549552917, -0.23478823900222778, -0.6292316317558289, -0.6332000494003296, 0.5806336402893066, 0.7183332443237305, -0.350685715675354, 0.43357163667678833]
     Last 10:  [-1.2204737663269043, 0.2628942131996155, -0.5726051926612854, 1.5888240337371826, 1.0807337760925293, -0.5544968843460083, -0.8628553748130798, -0.05456794798374176, -0.7803530693054199, 0.4297964572906494]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.5.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.050333, Std: 2.715901
     First 10: [-0.5265185236930847, 0.4871973991394043, 1.4220259189605713, -0.2873842418193817, -1.9846969842910767, -1.7208930253982544, 1.7191245555877686, 1.9557185173034668, -0.3138028383255005, 0.3583470582962036]
     Last 10:  [-8.504571914672852, 1.8737486600875854, -4.18779993057251, 11.032317161560059, 8.001799583435059, -3.92203688621521, -6.254220008850098, -0.4947076737880707, -5.4822540283203125, 2.8989500999450684]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.861877
     First 10: [0.6130709648132324, 0.15289945900440216, 1.855507731437683, 0.23210422694683075, 2.1750051975250244, 1.7357330322265625, 1.9803410768508911, 1.7405717372894287, -0.09925976395606995, -0.16803738474845886]
     Last 10:  [2.295072555541992, 2.370321035385132, 2.45837140083313, 2.283461332321167, 2.501143455505371, 2.344672203063965, 2.4274895191192627, 3.286985397338867, 2.3220715522766113, 2.1894726753234863]

================================================================================
087_layers.5.self_attn.o_proj: Linear (layers.5.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.5.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.017123, Std: 0.504531
     First 10: [-0.18729406595230103, -0.6642611026763916, -0.6630067825317383, 0.1364155113697052, 0.03617032989859581, 0.15833841264247894, 0.3766028881072998, 0.10187871754169464, 0.0008386000990867615, 0.7521985769271851]
     Last 10:  [-0.21994152665138245, 0.2003229707479477, -0.11402162164449692, -0.3645123243331909, -0.027654623612761497, 0.07523023337125778, 0.09487675875425339, 0.1152477040886879, -0.006584251765161753, -0.19205912947654724]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.004213, Std: 0.243797
     First 10: [0.3297337293624878, -0.026250962167978287, -0.019959639757871628, 0.3316638767719269, 0.000552251935005188, -0.2645221948623657, 0.4683080315589905, 0.5044411420822144, 0.10519514232873917, -0.06506234407424927]
     Last 10:  [0.10227788239717484, -0.00046186894178390503, -0.003080049529671669, 0.07474000751972198, -0.08899757266044617, 0.04381008446216583, -0.16858626902103424, -0.08501040190458298, 0.013002429157495499, 0.08716219663619995]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000013
     First 10: [0.004874152597039938, 0.003577282652258873, -0.005429934244602919, 0.009239908307790756, -0.0011671952670440078, 0.010221810080111027, -0.012473421171307564, -0.008516010828316212, 0.000463348173070699, -0.0026219296269118786]
     Last 10:  [0.0020150882191956043, -0.0016292864456772804, -0.005500109400600195, 0.0006065171328373253, 0.0014438339276239276, 0.017893796786665916, 0.0038101712707430124, -0.004707306623458862, -0.0009527470683678985, -0.0016923367511481047]

================================================================================
088_layers.5.self_attn: Gemma3Attention (layers.5.self_attn)
================================================================================

  → OUTPUT[0]: layers.5.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.004213, Std: 0.243797
     First 10: [0.3297337293624878, -0.026250962167978287, -0.019959639757871628, 0.3316638767719269, 0.000552251935005188, -0.2645221948623657, 0.4683080315589905, 0.5044411420822144, 0.10519514232873917, -0.06506234407424927]
     Last 10:  [0.10227788239717484, -0.00046186894178390503, -0.003080049529671669, 0.07474000751972198, -0.08899757266044617, 0.04381008446216583, -0.16858626902103424, -0.08501040190458298, 0.013002429157495499, 0.08716219663619995]
     Zeros: 0, Total: 5376

================================================================================
089_layers.5.post_attention_layernorm: Gemma3RMSNorm (layers.5.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.5.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.004213, Std: 0.243797
     First 10: [0.3297337293624878, -0.026250962167978287, -0.019959639757871628, 0.3316638767719269, 0.000552251935005188, -0.2645221948623657, 0.4683080315589905, 0.5044411420822144, 0.10519514232873917, -0.06506234407424927]
     Last 10:  [0.10227788239717484, -0.00046186894178390503, -0.003080049529671669, 0.07474000751972198, -0.08899757266044617, 0.04381008446216583, -0.16858626902103424, -0.08501040190458298, 0.013002429157495499, 0.08716219663619995]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.546489, Std: 10.290910
     First 10: [13.371333122253418, -0.14551414549350739, -0.009859991259872913, 0.03625224158167839, 0.003768774913623929, -2.0020790100097656, 0.2959776818752289, 0.19209809601306915, 0.6666984558105469, -0.6306414008140564]
     Last 10:  [0.08635198324918747, 3.0255745514295995e-05, -0.003566921688616276, 4.2407355308532715, -1.9975206851959229, 0.6813219785690308, -2.750837802886963, -3.8418102264404297, 0.15440253913402557, 2.6208882331848145]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 2.037554
     First 10: [9.023433685302734, 0.37014082074165344, -0.877896249294281, -0.9729827046394348, 0.6868177056312561, 0.8707865476608276, -0.8437814712524414, -0.9058722257614136, 0.5665308833122253, 1.3958408832550049]
     Last 10:  [-0.9097657203674316, -1.0070011615753174, -0.8762295842170715, 5.0641374588012695, 1.3988003730773926, 0.6621081233024597, 0.743908703327179, 3.8299741744995117, 0.26914405822753906, 2.213670253753662]

================================================================================
090_layers.5.pre_feedforward_layernorm: Gemma3RMSNorm (layers.5.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.5.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.247478, Std: 24.092289
     First 10: [63.37541580200195, -1.5035768747329712, 0.3766126036643982, -0.025185953825712204, -3.349466562271118, -3.0151398181915283, 0.6435028314590454, -1.016139268875122, -0.9300209283828735, 0.3597260117530823]
     Last 10:  [-0.7053637504577637, -1.044179916381836, -0.3077022433280945, 6.890877723693848, 2.0910861492156982, 2.25002384185791, -5.2906389236450195, -9.349855422973633, 3.1015625, 0.8612957000732422]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.038860, Std: 3.106304
     First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
     Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 15.136345
     First 10: [0.8466981649398804, 20.69942283630371, 20.25566864013672, 19.20132064819336, 14.492057800292969, 17.436920166015625, 19.065628051757812, 19.335006713867188, 15.423555374145508, 13.718368530273438]
     Last 10:  [21.66969108581543, 25.144271850585938, 19.7653751373291, 7.143292427062988, 15.080755233764648, 16.22563362121582, 15.77112865447998, 9.268531799316406, 15.764542579650879, 12.364262580871582]

================================================================================
091_layers.5.mlp.gate_proj: Linear (layers.5.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.5.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.038860, Std: 3.106304
     First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
     Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.391299, Std: 0.629577
     First 10: [0.02877137064933777, -0.6331754922866821, -0.26515066623687744, 0.28761565685272217, -0.7272838950157166, 0.5175226926803589, 0.03199346363544464, -0.09256668388843536, -0.060559168457984924, -0.22323153913021088]
     Last 10:  [0.009463325142860413, -0.17048652470111847, 0.014853917062282562, 0.044093020260334015, -0.1398654580116272, -0.15750913321971893, -0.20382940769195557, -0.8908457159996033, -0.04318623244762421, -0.19850178062915802]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000041
     First 10: [0.003326206002384424, 0.000687567749992013, -0.0015038063284009695, -0.007788390852510929, -0.00032721570460125804, 0.006389757618308067, -0.004699667915701866, -0.00953840371221304, -0.0038642645813524723, 0.001291726715862751]
     Last 10:  [0.0034142411313951015, -0.00025432612164877355, -0.004486825782805681, -0.0042905439622700214, -0.0032608737237751484, -0.010539218783378601, -0.006284702103585005, -0.005104533396661282, -0.0008716374868527055, 0.007524070795625448]

================================================================================
092_layers.5.mlp.act_fn: PytorchGELUTanh (layers.5.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.5.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.391299, Std: 0.629577
     First 10: [0.02877137064933777, -0.6331754922866821, -0.26515066623687744, 0.28761565685272217, -0.7272838950157166, 0.5175226926803589, 0.03199346363544464, -0.09256668388843536, -0.060559168457984924, -0.22323153913021088]
     Last 10:  [0.009463325142860413, -0.17048652470111847, 0.014853917062282562, 0.044093020260334015, -0.1398654580116272, -0.15750913321971893, -0.20382940769195557, -0.8908457159996033, -0.04318623244762421, -0.19850178062915802]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.5.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.029117, Std: 0.209296
     First 10: [0.014715880155563354, -0.16676074266433716, -0.1048545092344284, 0.17635789513587952, -0.1699022650718689, 0.36100655794143677, 0.01640501245856285, -0.04286986589431763, -0.028817396610975266, -0.09190022200345993]
     Last 10:  [0.004767389036715031, -0.07370394468307495, 0.00751497782766819, 0.022821879014372826, -0.062153976410627365, -0.06889812648296356, -0.08545468747615814, -0.16626223921775818, -0.020849300548434258, -0.08363451063632965]
     Zeros: 0, Total: 8064

================================================================================
093_layers.5.mlp.up_proj: Linear (layers.5.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.5.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.038860, Std: 3.106304
     First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
     Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.008198, Std: 0.552294
     First 10: [-0.22471049427986145, -0.04140250384807587, -0.18849781155586243, -0.2998359203338623, 1.6828224658966064, 0.015173113904893398, -0.003897935152053833, -0.021450629457831383, -0.037054598331451416, -0.24090734124183655]
     Last 10:  [0.15915650129318237, 0.000818789005279541, 0.03584031015634537, -1.0316874980926514, -0.041844867169857025, 0.23295414447784424, -0.09408757090568542, -0.6292651295661926, 0.09948500990867615, 0.2083302140235901]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000003
     First 10: [0.005875934846699238, -0.00750676728785038, -0.002311283489689231, -0.010614218190312386, 0.00822029821574688, 0.0015490915393456817, 0.0025646034628152847, 0.0004982511163689196, 0.0022639085073024035, 0.0018242099322378635]
     Last 10:  [-0.002445329213514924, 0.0012343102134764194, -0.008512997068464756, 0.0034030601382255554, 0.003698886837810278, -0.0017962061101570725, -0.006051006726920605, 0.00013325866893865168, -0.0026603122241795063, 0.008932309225201607]

================================================================================
094_layers.5.mlp.down_proj: Linear (layers.5.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.5.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.002147, Std: 0.166352
     First 10: [-0.003306812606751919, 0.006904312409460545, 0.019764846190810204, -0.05287843197584152, -0.285915344953537, 0.005477593746036291, -6.394567753886804e-05, 0.000919585581868887, 0.0010678170947358012, 0.02213943749666214]
     Last 10:  [0.0007587609579786658, -6.0347978433128446e-05, 0.00026933912886306643, -0.023545047268271446, 0.0026008249260485172, -0.016050104051828384, 0.008040224201977253, 0.10462302714586258, -0.00207419297657907, -0.0174235962331295]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.5.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.002165, Std: 0.054250
     First 10: [-0.0009648120030760765, 0.003008507192134857, -0.01828138716518879, -0.24516165256500244, 0.0015844423323869705, -0.013097355142235756, -0.002461325842887163, 0.0009445161558687687, -0.00655019748955965, 0.026850104331970215]
     Last 10:  [0.003286368679255247, 0.005061447620391846, 0.00836451631039381, -0.003524386091157794, -0.0015884670428931713, 0.001512336079031229, -0.001298633636906743, -0.0005852117319591343, -0.0014101224951446056, -0.006745236460119486]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000001
     First 10: [0.00968688353896141, -0.002087312052026391, 0.000637753983028233, -0.0012948352377861738, -0.0012766991276293993, 0.006092655006796122, -0.0008076562662608922, -0.0020379580091685057, -0.003566979430615902, -0.0038836514577269554]
     Last 10:  [-0.00227484293282032, 0.00445903092622757, -0.0023033018223941326, -0.0020072031766176224, -0.0021205961238592863, 0.00021495080727618188, -0.008323576301336288, 0.001525246538221836, 0.0008822362869977951, 0.01104497816413641]

================================================================================
095_layers.5.mlp: Gemma3MLP (layers.5.mlp)
================================================================================

  → INPUT[0]: layers.5.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.038860, Std: 3.106304
     First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
     Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.002165, Std: 0.054250
     First 10: [-0.0009648120030760765, 0.003008507192134857, -0.01828138716518879, -0.24516165256500244, 0.0015844423323869705, -0.013097355142235756, -0.002461325842887163, 0.0009445161558687687, -0.00655019748955965, 0.026850104331970215]
     Last 10:  [0.003286368679255247, 0.005061447620391846, 0.00836451631039381, -0.003524386091157794, -0.0015884670428931713, 0.001512336079031229, -0.001298633636906743, -0.0005852117319591343, -0.0014101224951446056, -0.006745236460119486]
     Zeros: 0, Total: 5376

================================================================================
096_layers.5.post_feedforward_layernorm: Gemma3RMSNorm (layers.5.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.5.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.002165, Std: 0.054250
     First 10: [-0.0009648120030760765, 0.003008507192134857, -0.01828138716518879, -0.24516165256500244, 0.0015844423323869705, -0.013097355142235756, -0.002461325842887163, 0.0009445161558687687, -0.00655019748955965, 0.026850104331970215]
     Last 10:  [0.003286368679255247, 0.005061447620391846, 0.00836451631039381, -0.003524386091157794, -0.0015884670428931713, 0.001512336079031229, -0.001298633636906743, -0.0005852117319591343, -0.0014101224951446056, -0.006745236460119486]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.5.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.399568, Std: 16.089525
     First 10: [-0.3506588339805603, 0.1745542734861374, -0.2329130470752716, -0.33557093143463135, 0.13900311291217804, -1.120367169380188, -0.0309966541826725, 0.010442123748362064, -0.604693591594696, 2.7555291652679443]
     Last 10:  [0.18887940049171448, 0.34358248114585876, 0.24204234778881073, -2.2528860569000244, -0.6064938902854919, 0.40758800506591797, -0.4978914260864258, -0.32810476422309875, -0.45444566011428833, -3.18894100189209]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 4.636819
     First 10: [13.434188842773438, 1.304250717163086, -0.4940181374549866, -0.9456396698951721, 2.4841623306274414, 2.3972463607788086, -0.4998549222946167, -0.5609340667724609, 2.666327476501465, 3.0757668018341064]
     Last 10:  [-0.36037176847457886, -0.24453279376029968, -0.6779599785804749, 6.114019393920898, 3.24920392036438, 1.9993864297866821, 3.2668492794036865, 5.239629745483398, 2.5866124629974365, 4.261488437652588]

================================================================================
097_layers.6.input_layernorm: Gemma3RMSNorm (layers.6.input_layernorm)
================================================================================

  → INPUT[0]: layers.6.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.152090, Std: 35.324909
     First 10: [63.024757385253906, -1.3290226459503174, 0.1436995565891266, -0.36075687408447266, -3.210463523864746, -4.135507106781006, 0.6125061511993408, -1.0056971311569214, -1.5347144603729248, 3.115255117416382]
     Last 10:  [-0.5164843797683716, -0.7005974054336548, -0.06565989553928375, 4.637991905212402, 1.4845921993255615, 2.657611846923828, -5.788530349731445, -9.677960395812988, 2.6471168994903564, -2.3276453018188477]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.008112, Std: 4.792890
     First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
     Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 23.848883
     First 10: [2.4458630084991455, 31.210041046142578, 32.21712875366211, 29.118755340576172, 21.373682022094727, 21.87308692932129, 27.456378936767578, 28.429046630859375, 22.8026123046875, 19.852458953857422]
     Last 10:  [33.30595016479492, 50.24824523925781, 28.596153259277344, 11.533724784851074, 20.718963623046875, 24.88772964477539, 20.940208435058594, 11.083166122436523, 23.68665313720703, 17.063844680786133]

================================================================================
098_layers.6.self_attn.q_proj: Linear (layers.6.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.6.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.008112, Std: 4.792890
     First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
     Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.042702, Std: 1.918274
     First 10: [0.14327573776245117, 0.2968392074108124, -0.17443940043449402, -0.5721753239631653, -0.05072745680809021, -1.0570058822631836, -0.1343490481376648, -0.7743239998817444, -0.21355396509170532, -1.1742801666259766]
     Last 10:  [0.04512564092874527, -0.29525813460350037, -0.5819755792617798, -0.5884723663330078, -0.1443282663822174, -0.3701057434082031, -0.016013965010643005, -0.20694798231124878, -0.4433669447898865, 0.10566351562738419]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000020
     First 10: [0.00935920886695385, 0.00024950510123744607, 0.009412507526576519, 0.008521520532667637, -0.013704242184758186, 9.130094258580357e-05, 0.011835077777504921, 5.5589363910257816e-05, -0.006370806135237217, 0.004685096442699432]
     Last 10:  [0.01120700966566801, -0.020748166367411613, 0.005354946479201317, 0.006577372085303068, 0.0005649459781125188, -0.009834250435233116, -0.015480874106287956, 0.0021695285104215145, 0.002476863097399473, 0.008960057981312275]

================================================================================
099_layers.6.self_attn.k_proj: Linear (layers.6.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.6.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.008112, Std: 4.792890
     First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
     Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.097255, Std: 1.984499
     First 10: [-0.30353057384490967, 0.6019998788833618, 0.3208559453487396, -0.23235483467578888, 0.5574093461036682, 0.899836540222168, 0.8410823345184326, -1.0979262590408325, 2.678884506225586, 0.6798723936080933]
     Last 10:  [1.4125584363937378, 0.9977766275405884, -0.9503301382064819, -1.7522881031036377, 0.47577667236328125, -1.057414174079895, 0.8809548020362854, -1.448569416999817, -0.7725968360900879, 0.6956427693367004]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000004
     First 10: [0.00425267219543457, -0.0014858799986541271, -0.001914548920467496, 0.00863409973680973, 0.006435638293623924, -0.00016715240781195462, -0.0043022520840168, -0.00798068568110466, -0.0006659141508862376, -0.0060478150844573975]
     Last 10:  [0.002882696222513914, -0.003933785483241081, -0.0025218292139470577, -0.007080875337123871, -0.0017175308894366026, 0.0004982913378626108, 0.003460756503045559, 0.012087548151612282, 0.0057304794900119305, -0.007876293733716011]

================================================================================
100_layers.6.self_attn.v_proj: Linear (layers.6.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.6.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.008112, Std: 4.792890
     First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
     Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.041952, Std: 1.106261
     First 10: [0.19194035232067108, -0.2043537199497223, -0.8504716157913208, 0.022621557116508484, -0.42504599690437317, 0.31335774064064026, 0.488045334815979, -0.21698057651519775, 0.49385786056518555, -0.12780530750751495]
     Last 10:  [0.19130395352840424, 0.3566189408302307, 0.06716808676719666, -0.230184406042099, 0.05417200177907944, 0.031561143696308136, 0.19935011863708496, 0.16878502070903778, 0.45267194509506226, -0.3658459186553955]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000021
     First 10: [-0.0035395482555031776, 0.002846898976713419, -0.00871892087161541, -0.0052900006994605064, 0.02110578864812851, -0.0064144860953092575, 0.004589082673192024, -0.004695715382695198, -0.0013196100480854511, -0.006507102400064468]
     Last 10:  [0.010286865755915642, 0.015241282060742378, 0.018117249011993408, -0.011038579978048801, 0.004624940920621157, -0.0006296838400885463, 0.011229614727199078, -0.004157524090260267, 0.01953457109630108, 0.006476743146777153]

================================================================================
101_layers.6.self_attn.q_norm: Gemma3RMSNorm (layers.6.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.6.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.042702, Std: 1.918274
     First 10: [0.14327573776245117, 0.2968392074108124, -0.17443940043449402, -0.5721753239631653, -0.05072745680809021, -1.0570058822631836, -0.1343490481376648, -0.7743239998817444, -0.21355396509170532, -1.1742801666259766]
     Last 10:  [0.04512564092874527, -0.29525813460350037, -0.5819755792617798, -0.5884723663330078, -0.1443282663822174, -0.3701057434082031, -0.016013965010643005, -0.20694798231124878, -0.4433669447898865, 0.10566351562738419]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.023853, Std: 1.078872
     First 10: [0.17996715009212494, 0.330476313829422, -0.19148372113704681, -0.3485027849674225, -0.05959152430295944, -0.7692082524299622, -0.12068133056163788, -0.5305924415588379, -0.13892462849617004, -1.9361149072647095]
     Last 10:  [0.1073635071516037, -0.3989931046962738, -5.6870646476745605, -1.7756233215332031, -0.1529327630996704, -0.5279085636138916, -0.041021011769771576, -0.25063636898994446, -0.7693237066268921, 0.11961238831281662]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.320920
     First 10: [0.6317787170410156, 0.4463045597076416, 0.42602765560150146, -0.20874251425266266, 0.526096761226654, -0.05461824685335159, 0.16693368554115295, -0.10981756448745728, -0.15489186346530914, 1.1419044733047485]
     Last 10:  [0.5166491866111755, -0.13857917487621307, 5.229242324829102, 0.9234309196472168, -0.3245379328727722, -0.09074705094099045, 0.6328989863395691, -0.22796902060508728, 0.10610835999250412, -0.2783893644809723]

================================================================================
102_layers.6.self_attn.k_norm: Gemma3RMSNorm (layers.6.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.6.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.097255, Std: 1.984499
     First 10: [-0.30353057384490967, 0.6019998788833618, 0.3208559453487396, -0.23235483467578888, 0.5574093461036682, 0.899836540222168, 0.8410823345184326, -1.0979262590408325, 2.678884506225586, 0.6798723936080933]
     Last 10:  [1.4125584363937378, 0.9977766275405884, -0.9503301382064819, -1.7522881031036377, 0.47577667236328125, -1.057414174079895, 0.8809548020362854, -1.448569416999817, -0.7725968360900879, 0.6956427693367004]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.6.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.024105, Std: 1.612834
     First 10: [-0.25837022066116333, 0.464072048664093, 0.36655372381210327, -0.26156994700431824, 0.4507996737957001, 0.5224059820175171, 0.6693564057350159, 0.012522566132247448, 1.0097755193710327, 0.5100921988487244]
     Last 10:  [3.0650718212127686, 3.6916518211364746, -0.4654194116592407, -3.075366973876953, 2.28810453414917, -3.9262754917144775, 1.8397516012191772, -5.629446506500244, -2.266714334487915, 3.0263850688934326]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.673052
     First 10: [0.3886534571647644, 0.25760117173194885, 0.8637232184410095, 0.8364961743354797, 0.31935983896255493, -0.05289437994360924, 0.29829326272010803, -1.0186069011688232, -0.385071337223053, 0.22398234903812408]
     Last 10:  [0.5236468315124512, 1.5979900360107422, -0.6561095714569092, 0.23237104713916779, 2.3769357204437256, 1.6072684526443481, 0.46641087532043457, 1.7288298606872559, 1.0601269006729126, 2.0548367500305176]

================================================================================
103_layers.6.self_attn.o_proj: Linear (layers.6.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.6.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.022864, Std: 0.617378
     First 10: [0.19194035232067108, -0.2043537199497223, -0.8504716157913208, 0.022621557116508484, -0.42504599690437317, 0.31335774064064026, 0.488045334815979, -0.21698057651519775, 0.49385786056518555, -0.12780530750751495]
     Last 10:  [-0.5958857536315918, 0.34729546308517456, -0.4479677081108093, -0.20617568492889404, -0.15168073773384094, 0.11476361006498337, 0.2084617018699646, -0.018320254981517792, 0.25284168124198914, -0.034005120396614075]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012906, Std: 0.202212
     First 10: [0.05031392350792885, 0.03156943619251251, -0.10082419961690903, 0.4057666063308716, -0.08210524171590805, 0.011960698291659355, -0.8786852955818176, 0.516616702079773, -0.11017249524593353, -0.002619369886815548]
     Last 10:  [-0.08533892780542374, -0.011552748270332813, -0.009593963623046875, -0.09305529296398163, 0.02681528776884079, -0.007388741243630648, -0.0746922492980957, -0.03289960324764252, -0.09478618949651718, -0.09884050488471985]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000024
     First 10: [0.007167658768594265, -0.0003088933299295604, -0.003741903230547905, 0.004381000064313412, -0.0013503117952495813, -0.00336388498544693, -0.0001036623289110139, -0.0034802984446287155, -0.0008710438851267099, 0.009265498258173466]
     Last 10:  [0.009176929481327534, -0.0072808340191841125, 7.158960215747356e-07, 0.009599495679140091, -0.005153310019522905, -0.011080952361226082, -0.01372082531452179, 0.0030604000203311443, -0.009691269136965275, -0.0019509387202560902]

================================================================================
104_layers.6.self_attn: Gemma3Attention (layers.6.self_attn)
================================================================================

  → OUTPUT[0]: layers.6.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012906, Std: 0.202212
     First 10: [0.05031392350792885, 0.03156943619251251, -0.10082419961690903, 0.4057666063308716, -0.08210524171590805, 0.011960698291659355, -0.8786852955818176, 0.516616702079773, -0.11017249524593353, -0.002619369886815548]
     Last 10:  [-0.08533892780542374, -0.011552748270332813, -0.009593963623046875, -0.09305529296398163, 0.02681528776884079, -0.007388741243630648, -0.0746922492980957, -0.03289960324764252, -0.09478618949651718, -0.09884050488471985]
     Zeros: 0, Total: 5376

================================================================================
105_layers.6.post_attention_layernorm: Gemma3RMSNorm (layers.6.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.6.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012906, Std: 0.202212
     First 10: [0.05031392350792885, 0.03156943619251251, -0.10082419961690903, 0.4057666063308716, -0.08210524171590805, 0.011960698291659355, -0.8786852955818176, 0.516616702079773, -0.11017249524593353, -0.002619369886815548]
     Last 10:  [-0.08533892780542374, -0.011552748270332813, -0.009593963623046875, -0.09305529296398163, 0.02681528776884079, -0.007388741243630648, -0.0746922492980957, -0.03289960324764252, -0.09478618949651718, -0.09884050488471985]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.363730, Std: 11.079844
     First 10: [1.1099894046783447, 0.3342331349849701, -0.03848286718130112, 0.022486235946416855, -0.9552391171455383, 0.17584216594696045, -0.09741358458995819, 0.13770562410354614, -1.7967027425765991, -0.04564639925956726]
     Last 10:  [-0.14492326974868774, -0.029406988993287086, -0.0005356306792236865, -3.5251638889312744, 1.110536813735962, -0.2057226002216339, -2.465404987335205, -0.8607967495918274, -2.4174249172210693, -3.8764822483062744]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 2.562892
     First 10: [4.34218692779541, 1.563723087310791, -0.9075746536254883, -0.9865807294845581, 1.8172776699066162, 2.5600407123565674, -0.9731543064117432, -0.9354536533355713, 2.9490396976470947, 3.2198610305786133]
     Last 10:  [-0.7911849021911621, -0.687005877494812, -0.9931350350379944, 3.6581039428710938, 4.092387676239014, 2.423595905303955, 3.0586695671081543, 2.217221260070801, 2.1360204219818115, 3.8225173950195312]

================================================================================
106_layers.6.pre_feedforward_layernorm: Gemma3RMSNorm (layers.6.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.6.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.211640, Std: 28.749672
     First 10: [64.13475036621094, -0.9947894811630249, 0.10521668940782547, -0.3382706344127655, -4.165702819824219, -3.959664821624756, 0.5150925517082214, -0.8679915070533752, -3.3314170837402344, 3.069608688354492]
     Last 10:  [-0.6614076495170593, -0.7300043702125549, -0.0661955252289772, 1.112828016281128, 2.5951290130615234, 2.4518892765045166, -8.253934860229492, -10.53875732421875, 0.2296919822692871, -6.204127311706543]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.034622, Std: 3.463174
     First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
     Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 14.992329
     First 10: [0.5886443853378296, 18.71040916442871, 28.212387084960938, 28.692161560058594, 12.805246353149414, 12.858770370483398, 24.283233642578125, 26.440162658691406, 11.938103675842285, 10.530670166015625]
     Last 10:  [26.924911499023438, 30.579349517822266, 28.292747497558594, 5.447788238525391, 10.480565071105957, 13.21638298034668, 11.594365119934082, 6.0809855461120605, 12.199661254882812, 8.061553955078125]

================================================================================
107_layers.6.mlp.gate_proj: Linear (layers.6.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.6.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.034622, Std: 3.463174
     First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
     Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.592478, Std: 0.745965
     First 10: [-0.5440196990966797, -0.6878746747970581, -0.8888449668884277, -0.35568535327911377, -0.1946469098329544, -0.201930433511734, -0.8482429385185242, -0.12103144079446793, -0.3996831774711609, -0.4813653826713562]
     Last 10:  [0.20294269919395447, 0.02571805566549301, -0.2132638394832611, 0.041842199862003326, 0.00018084794282913208, -0.1005886048078537, -0.18988926708698273, -0.13068997859954834, -0.1406102329492569, 0.028667893260717392]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000055
     First 10: [0.0051871188916265965, -0.006395054515451193, 0.00019207014702260494, 0.002182224066928029, -0.0009157679160125554, -0.0023474376648664474, -0.001297338050790131, -0.001813383656553924, 0.014270888641476631, 0.000801693822722882]
     Last 10:  [-0.010013345628976822, 0.006223455537110567, 0.0002704533690121025, 0.00552742974832654, -0.006058870814740658, 0.0013416028814390302, -0.009115094318985939, 0.0029893345199525356, -0.006080029532313347, 0.0003997106687165797]

================================================================================
108_layers.6.mlp.act_fn: PytorchGELUTanh (layers.6.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.6.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.592478, Std: 0.745965
     First 10: [-0.5440196990966797, -0.6878746747970581, -0.8888449668884277, -0.35568535327911377, -0.1946469098329544, -0.201930433511734, -0.8482429385185242, -0.12103144079446793, -0.3996831774711609, -0.4813653826713562]
     Last 10:  [0.20294269919395447, 0.02571805566549301, -0.2132638394832611, 0.041842199862003326, 0.00018084794282913208, -0.1005886048078537, -0.18988926708698273, -0.13068997859954834, -0.1406102329492569, 0.028667893260717392]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.6.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.043078, Std: 0.212399
     First 10: [-0.15953750908374786, -0.1691083461046219, -0.16636590659618378, -0.12842079997062683, -0.08230392634868622, -0.08480839431285858, -0.16818013787269592, -0.05468607693910599, -0.13777627050876617, -0.15170690417289734]
     Last 10:  [0.11778945475816727, 0.013122866861522198, -0.08862470090389252, 0.02161935158073902, 9.043701720656827e-05, -0.04626460745930672, -0.08064600080251694, -0.05855054780840874, -0.0624435730278492, 0.014661772176623344]
     Zeros: 0, Total: 8064

================================================================================
109_layers.6.mlp.up_proj: Linear (layers.6.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.6.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.034622, Std: 3.463174
     First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
     Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.006085, Std: 0.615140
     First 10: [0.030279632657766342, -0.30094286799430847, 0.22125594317913055, 0.20676761865615845, 0.027686983346939087, 0.3134256899356842, -0.13073188066482544, -0.09233465045690536, -0.05976252257823944, -0.03421647846698761]
     Last 10:  [-0.1983657330274582, -0.0359877347946167, 0.11531883478164673, 0.010895349085330963, -0.0684266984462738, -0.1353670060634613, -0.08209416270256042, 0.014871313236653805, 0.14535276591777802, -0.002670787274837494]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000007
     First 10: [0.0034225978888571262, -0.0064173610880970955, 0.006006592884659767, -0.001427537645213306, -0.00024202512577176094, 0.003837580792605877, 0.0036454363726079464, 0.010663937777280807, 0.005098393652588129, 0.0014575868844985962]
     Last 10:  [0.004047792870551348, 0.006113710813224316, -0.004003476817160845, -0.0038048597052693367, -0.0068150293081998825, 0.0075708432123064995, 0.008238470181822777, 0.00018221387290395796, 0.00116474530659616, -0.0007139267981983721]

================================================================================
110_layers.6.mlp.down_proj: Linear (layers.6.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.6.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.004063, Std: 0.210955
     First 10: [-0.004830737132579088, 0.050891950726509094, -0.036809444427490234, -0.026553263887763023, -0.0022787475027143955, -0.02658112905919552, 0.021986505016684532, 0.005049419589340687, 0.008233857341110706, 0.005190875846892595]
     Last 10:  [-0.023365391418337822, -0.00047226223978213966, -0.010220097377896309, 0.00023555038205813617, -6.188306542753708e-06, 0.006262701470404863, 0.0066205658949911594, -0.0008707235101610422, -0.009076345711946487, -3.915847628377378e-05]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.6.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000629, Std: 0.057071
     First 10: [0.00634501688182354, 0.004376271273940802, 0.0012677377089858055, 0.035662345588207245, -0.0008410429581999779, -0.022754300385713577, -0.026448791846632957, -0.013995904475450516, -0.0022758401464670897, -0.013856747187674046]
     Last 10:  [0.0028572631999850273, -7.190450560301542e-06, -0.025598108768463135, 0.002208554185926914, 0.004026091191917658, 3.731984179466963e-06, 0.000786306569352746, -0.00026517288642935455, -0.000956143019720912, -0.00013687252067029476]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000010
     First 10: [0.004935146775096655, 0.006389796268194914, -0.008762260898947716, 0.0034008813090622425, -0.0004544723778963089, -0.00100394815672189, -0.0030625788494944572, -0.0007326412596739829, -0.004424428101629019, -0.0030747351702302694]
     Last 10:  [0.0013643840793520212, 0.000460898969322443, 0.0022449768148362637, 0.004871778655797243, 0.002801442751660943, -0.005024342332035303, 0.004246087279170752, 0.002872287528589368, 0.012425057590007782, 0.0038285665214061737]

================================================================================
111_layers.6.mlp: Gemma3MLP (layers.6.mlp)
================================================================================

  → INPUT[0]: layers.6.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.034622, Std: 3.463174
     First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
     Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000629, Std: 0.057071
     First 10: [0.00634501688182354, 0.004376271273940802, 0.0012677377089858055, 0.035662345588207245, -0.0008410429581999779, -0.022754300385713577, -0.026448791846632957, -0.013995904475450516, -0.0022758401464670897, -0.013856747187674046]
     Last 10:  [0.0028572631999850273, -7.190450560301542e-06, -0.025598108768463135, 0.002208554185926914, 0.004026091191917658, 3.731984179466963e-06, 0.000786306569352746, -0.00026517288642935455, -0.000956143019720912, -0.00013687252067029476]
     Zeros: 0, Total: 5376

================================================================================
112_layers.6.post_feedforward_layernorm: Gemma3RMSNorm (layers.6.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.6.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000629, Std: 0.057071
     First 10: [0.00634501688182354, 0.004376271273940802, 0.0012677377089858055, 0.035662345588207245, -0.0008410429581999779, -0.022754300385713577, -0.026448791846632957, -0.013995904475450516, -0.0022758401464670897, -0.013856747187674046]
     Last 10:  [0.0028572631999850273, -7.190450560301542e-06, -0.025598108768463135, 0.002208554185926914, 0.004026091191917658, 3.731984179466963e-06, 0.000786306569352746, -0.00026517288642935455, -0.000956143019720912, -0.00013687252067029476]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.6.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.216741, Std: 24.623375
     First 10: [2.419426679611206, 0.5197418332099915, 0.02015558071434498, 0.32179951667785645, -0.16849274933338165, -4.366389751434326, -0.36000385880470276, -0.17356623709201813, -0.4994187653064728, -3.1046905517578125]
     Last 10:  [0.4658999741077423, -0.0014572901418432593, -0.4041871726512909, 4.263004779815674, 7.978884696960449, 0.004802596289664507, 1.3551628589630127, -0.3614208698272705, -1.2833293676376343, -0.24761907756328583]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 4.815946
     First 10: [9.543004035949707, 2.2837352752685547, -0.5604071617126465, -0.7505059838294983, 4.539208889007568, 4.3057122230529785, -0.6236551403999329, -0.6571146249771118, 5.067471981048584, 5.195005416870117]
     Last 10:  [-0.38667795062065125, -0.2376822531223297, -0.9406089782714844, 6.260288715362549, 6.454262733459473, 3.8404133319854736, 5.482547760009766, 4.126609802246094, 4.048488616943359, 5.804778099060059]

================================================================================
113_layers.7.input_layernorm: Gemma3RMSNorm (layers.7.input_layernorm)
================================================================================

  → INPUT[0]: layers.7.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.428381, Std: 20.526878
     First 10: [66.5541763305664, -0.47504764795303345, 0.1253722757101059, -0.016471117734909058, -4.334195613861084, -8.326054573059082, 0.15508869290351868, -1.041557788848877, -3.8308358192443848, -0.03508186340332031]
     Last 10:  [-0.19550767540931702, -0.7314616441726685, -0.4703826904296875, 5.375832557678223, 10.574013710021973, 2.4566919803619385, -6.898772239685059, -10.900177955627441, -1.0536373853683472, -6.451746463775635]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.133090, Std: 7.411880
     First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
     Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 28.588394
     First 10: [4.933473110198975, 29.322303771972656, 55.575050354003906, 46.1673698425293, 18.80538558959961, 16.679643630981445, 48.779518127441406, 52.04003143310547, 14.944881439208984, 15.271346092224121]
     Last 10:  [68.4476089477539, 66.59353637695312, 47.6156120300293, 12.029930114746094, 14.338266372680664, 17.350963592529297, 14.420719146728516, 13.18758773803711, 17.193204879760742, 15.006488800048828]

================================================================================
114_layers.7.self_attn.q_proj: Linear (layers.7.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.7.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.133090, Std: 7.411880
     First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
     Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.003301, Std: 2.606306
     First 10: [-4.223196029663086, -0.5169938206672668, 3.632781505584717, 2.9991183280944824, -2.431966781616211, -2.573936700820923, -6.604992866516113, -3.9174771308898926, -0.954897940158844, -2.7613744735717773]
     Last 10:  [0.6811474561691284, -1.5387005805969238, 0.057238832116127014, 1.8257091045379639, -0.1769227385520935, 0.88812255859375, 0.38037705421447754, -0.8882836103439331, 0.27367228269577026, 0.24918851256370544]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000019
     First 10: [-0.01693323440849781, 0.009442080743610859, 0.010228806175291538, -0.006002204492688179, -0.005636201240122318, 0.00479655247181654, 0.00083599251229316, -0.010727413929998875, -0.00578022887930274, 0.001946382806636393]
     Last 10:  [-0.006170099601149559, 0.0014925901778042316, -0.007625622674822807, 0.015493953600525856, 0.007830895483493805, -0.004707245621830225, 0.011359685100615025, -0.011797783896327019, 0.007629595696926117, 5.3754833061248064e-05]

================================================================================
115_layers.7.self_attn.k_proj: Linear (layers.7.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.7.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.133090, Std: 7.411880
     First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
     Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.146019, Std: 3.185627
     First 10: [-3.815772533416748, -0.7051448225975037, 0.1709478497505188, 0.5272495746612549, -0.05298486351966858, -5.23608922958374, -2.343763589859009, -0.5868213772773743, -2.9956228733062744, 1.9162503480911255]
     Last 10:  [-0.7095701098442078, 3.136915683746338, -0.07073283195495605, 3.576366901397705, 0.6303370594978333, -4.247355937957764, 0.9756876826286316, 1.5503613948822021, -0.0047494471073150635, 5.394392490386963]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000031
     First 10: [0.010693242773413658, -0.005407994147390127, 0.0036253700964152813, -0.0030761922243982553, 0.003527418477460742, 0.0034937430173158646, 0.000278520310530439, -0.0052805994637310505, -0.0005616178386844695, 0.0029051105957478285]
     Last 10:  [-0.005265023093670607, -0.004210839048027992, 0.006996833719313145, -0.007577941752970219, -0.000638721976429224, 0.007056308910250664, -0.0023952648043632507, 0.0036120633594691753, 0.0066115837544202805, -0.010084470734000206]

================================================================================
116_layers.7.self_attn.v_proj: Linear (layers.7.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.7.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.133090, Std: 7.411880
     First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
     Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.053327, Std: 1.597128
     First 10: [0.4400979280471802, -0.5012692213058472, -0.14221903681755066, 0.387668639421463, 0.194087415933609, -0.8690145015716553, -0.13597248494625092, -0.7789811491966248, -0.6410876512527466, -0.627556562423706]
     Last 10:  [-0.07089030742645264, -1.3574899435043335, -2.1258625984191895, 1.5627870559692383, 0.5206422805786133, 0.8376187682151794, 1.5522445440292358, -1.0755716562271118, -0.5039283037185669, -2.0208306312561035]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000015
     First 10: [0.001236622454598546, 0.007642543874680996, -0.0010080045321956277, -0.006164290010929108, 0.0030989637598395348, 0.004521371331065893, -0.00014316124725155532, 3.9745529647916555e-05, 0.006645300891250372, 0.008451787754893303]
     Last 10:  [-0.004935132339596748, -0.006461091805249453, 0.012761933729052544, 0.007054424844682217, -0.014203783124685287, 0.006680120714008808, 0.0021220967173576355, 0.012998420745134354, 0.005882910452783108, -0.00011371530126780272]

================================================================================
117_layers.7.self_attn.q_norm: Gemma3RMSNorm (layers.7.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.7.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.003301, Std: 2.606306
     First 10: [-4.223196029663086, -0.5169938206672668, 3.632781505584717, 2.9991183280944824, -2.431966781616211, -2.573936700820923, -6.604992866516113, -3.9174771308898926, -0.954897940158844, -2.7613744735717773]
     Last 10:  [0.6811474561691284, -1.5387005805969238, 0.057238832116127014, 1.8257091045379639, -0.1769227385520935, 0.88812255859375, 0.38037705421447754, -0.8882836103439331, 0.27367228269577026, 0.24918851256370544]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.010468, Std: 0.992830
     First 10: [-0.848550021648407, 0.011364876292645931, 2.426466226577759, 1.6333039999008179, -2.545416831970215, -0.6489803194999695, -1.028720736503601, -2.387176513671875, -0.4872666895389557, -1.3402745723724365]
     Last 10:  [0.35203149914741516, -0.8567473292350769, 0.024089345708489418, 1.2759817838668823, -0.11965087801218033, 0.6047213077545166, 0.3154619634151459, -0.5101438760757446, 0.1904856413602829, 0.11584224551916122]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.195412
     First 10: [-0.6483033895492554, -1.038477897644043, 0.16914108395576477, -0.046753138303756714, 0.8320326805114746, -0.558667778968811, -0.7273803949356079, 0.06662075966596603, -0.10681436955928802, -0.15042757987976074]
     Last 10:  [0.16816836595535278, 0.25853031873703003, -0.04873984307050705, 0.5797121524810791, 0.5286121368408203, 0.5390311479568481, 0.8745532035827637, 0.2980937361717224, 0.5732454657554626, 0.05076126009225845]

================================================================================
118_layers.7.self_attn.k_norm: Gemma3RMSNorm (layers.7.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.7.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.146019, Std: 3.185627
     First 10: [-3.815772533416748, -0.7051448225975037, 0.1709478497505188, 0.5272495746612549, -0.05298486351966858, -5.23608922958374, -2.343763589859009, -0.5868213772773743, -2.9956228733062744, 1.9162503480911255]
     Last 10:  [-0.7095701098442078, 3.136915683746338, -0.07073283195495605, 3.576366901397705, 0.6303370594978333, -4.247355937957764, 0.9756876826286316, 1.5503613948822021, -0.0047494471073150635, 5.394392490386963]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.7.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.050059, Std: 1.533870
     First 10: [-1.7176523208618164, -0.16750359535217285, 0.0704079419374466, 0.22107620537281036, -0.030606655403971672, -1.5295729637145996, -1.2169368267059326, -0.3119720220565796, -1.052018404006958, 0.7318155765533447]
     Last 10:  [-0.35902321338653564, 1.1994738578796387, -0.045408234000205994, 1.1816037893295288, 0.2743886113166809, -1.1580835580825806, 0.32961520552635193, 0.725878119468689, -0.0019792956300079823, 2.4584474563598633]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.555092
     First 10: [0.1711626946926117, -0.38196897506713867, 0.07157479226589203, 0.09091335535049438, 0.5028946399688721, -0.2399754524230957, 0.3508860170841217, 0.38316553831100464, -0.08630620688199997, -0.00639472808688879]
     Last 10:  [1.2703436613082886, 0.7157435417175293, 1.8805670738220215, 0.4824983477592468, 0.9532492160797119, 0.22344838082790375, 0.5158661603927612, 1.1008505821228027, 0.8699586391448975, 1.0449506044387817]

================================================================================
119_layers.7.self_attn.o_proj: Linear (layers.7.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.7.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.016267, Std: 0.974338
     First 10: [0.4400979280471802, -0.5012692213058472, -0.14221903681755066, 0.387668639421463, 0.194087415933609, -0.8690145015716553, -0.13597248494625092, -0.7789811491966248, -0.6410876512527466, -0.627556562423706]
     Last 10:  [-0.5475466847419739, -0.3356672525405884, -0.2727785110473633, -1.240326166152954, -0.569685161113739, 1.0148969888687134, -0.43601930141448975, -0.7802430391311646, 0.5486963391304016, 0.5103546380996704]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006377, Std: 0.361557
     First 10: [0.4419093430042267, -0.11456971615552902, -0.7630380392074585, 0.34656599164009094, 0.14343559741973877, 0.24089360237121582, 0.2682955861091614, 0.4884958565235138, 0.36980965733528137, 0.5119692087173462]
     Last 10:  [-0.42560476064682007, 0.29745689034461975, -0.291105180978775, -0.12519881129264832, -0.25898289680480957, -0.26777029037475586, -0.024022243916988373, 0.5190296769142151, -0.31364119052886963, -0.12858785688877106]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000007
     First 10: [0.011601204052567482, -0.005862519610673189, -0.007135591935366392, -0.0073233069851994514, -0.00598543044179678, -0.0017549037002027035, -0.0027156241703778505, -0.007846152409911156, 0.004470807034522295, -0.0055893524549901485]
     Last 10:  [-0.0034086438827216625, -0.009278347715735435, 0.011095939204096794, -0.0024659549817442894, 0.011291515082120895, -0.006890363059937954, -0.011139984242618084, -0.0076703098602592945, -0.00017503113485872746, -0.003607811639085412]

================================================================================
120_layers.7.self_attn: Gemma3Attention (layers.7.self_attn)
================================================================================

  → OUTPUT[0]: layers.7.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006377, Std: 0.361557
     First 10: [0.4419093430042267, -0.11456971615552902, -0.7630380392074585, 0.34656599164009094, 0.14343559741973877, 0.24089360237121582, 0.2682955861091614, 0.4884958565235138, 0.36980965733528137, 0.5119692087173462]
     Last 10:  [-0.42560476064682007, 0.29745689034461975, -0.291105180978775, -0.12519881129264832, -0.25898289680480957, -0.26777029037475586, -0.024022243916988373, 0.5190296769142151, -0.31364119052886963, -0.12858785688877106]
     Zeros: 0, Total: 5376

================================================================================
121_layers.7.post_attention_layernorm: Gemma3RMSNorm (layers.7.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.7.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006377, Std: 0.361557
     First 10: [0.4419093430042267, -0.11456971615552902, -0.7630380392074585, 0.34656599164009094, 0.14343559741973877, 0.24089360237121582, 0.2682955861091614, 0.4884958565235138, 0.36980965733528137, 0.5119692087173462]
     Last 10:  [-0.42560476064682007, 0.29745689034461975, -0.291105180978775, -0.12519881129264832, -0.25898289680480957, -0.26777029037475586, -0.024022243916988373, 0.5190296769142151, -0.31364119052886963, -0.12858785688877106]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.260268, Std: 6.522995
     First 10: [7.117562770843506, -1.9654557704925537, -0.15486136078834534, 0.03231007978320122, 1.258903980255127, 3.1706888675689697, 0.03701484203338623, 0.05386624485254288, 4.810990333557129, 8.88559627532959]
     Last 10:  [-0.06615622341632843, 0.08324179798364639, -0.036571159958839417, -1.768336534500122, -4.6586198806762695, -3.3745169639587402, -0.3030528128147125, 5.51243257522583, -2.350674867630005, -2.2881431579589844]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 3.568632
     First 10: [4.751120090484619, 5.125587463378906, -0.9275311827659607, -0.9667105674743652, 2.13393497467041, 3.6998353004455566, -0.950737476348877, -0.960625946521759, 3.6452651023864746, 5.197221755981445]
     Last 10:  [-0.9399271011352539, -0.8918486833572388, -0.9514484405517578, 4.458572864532471, 5.951852798461914, 3.8703885078430176, 3.875499725341797, 3.1045494079589844, 1.8965022563934326, 5.876977443695068]

================================================================================
122_layers.7.pre_feedforward_layernorm: Gemma3RMSNorm (layers.7.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.7.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.688649, Std: 22.778650
     First 10: [73.67173767089844, -2.4405033588409424, -0.02948908507823944, 0.01583896204829216, -3.075291633605957, -5.155365943908691, 0.1921035349369049, -0.9876915216445923, 0.9801545143127441, 8.85051441192627]
     Last 10:  [-0.26166391372680664, -0.6482198238372803, -0.5069538354873657, 3.6074960231781006, 5.915393829345703, -0.9178249835968018, -7.201825141906738, -5.387745380401611, -3.4043121337890625, -8.739889144897461]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.019878, Std: 2.871474
     First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
     Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 12.227965
     First 10: [0.7668445110321045, 11.152155876159668, 23.036773681640625, 21.592147827148438, 9.66164779663086, 9.393608093261719, 21.145296096801758, 22.420413970947266, 8.457149505615234, 7.402960300445557]
     Last 10:  [24.28118133544922, 27.198307037353516, 23.15151596069336, 4.973855018615723, 6.469637393951416, 9.564277648925781, 8.111307144165039, 6.127179145812988, 9.947186470031738, 6.26353645324707]

================================================================================
123_layers.7.mlp.gate_proj: Linear (layers.7.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.7.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.019878, Std: 2.871474
     First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
     Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.251895, Std: 0.531517
     First 10: [0.15232856571674347, -0.25741755962371826, 0.3169572949409485, 0.254840224981308, 0.27500417828559875, 0.3429062068462372, 0.07665270566940308, -0.13700029253959656, -0.30639809370040894, 0.2957385182380676]
     Last 10:  [-0.15574222803115845, -0.11063674092292786, -0.043479375541210175, -0.41014349460601807, 0.11076068878173828, -0.02211076393723488, 0.05155554413795471, -0.25060707330703735, -0.13173255324363708, 0.5366371870040894]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000047
     First 10: [0.0020117692183703184, 0.004589589778333902, 0.0014747113455086946, -0.0005285401712171733, 0.008454362861812115, -1.1195836123079062e-05, -0.00316850608214736, -0.003081914968788624, -0.0005942191346548498, 0.011664976365864277]
     Last 10:  [-0.0027873977087438107, -0.0016166483983397484, -0.002374989679083228, 0.003699513617902994, 0.0030432543717324734, 0.006876448635011911, 0.000559713807888329, -0.0022749523632228374, -0.004983610473573208, 0.0031627649441361427]

================================================================================
124_layers.7.mlp.act_fn: PytorchGELUTanh (layers.7.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.7.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.251895, Std: 0.531517
     First 10: [0.15232856571674347, -0.25741755962371826, 0.3169572949409485, 0.254840224981308, 0.27500417828559875, 0.3429062068462372, 0.07665270566940308, -0.13700029253959656, -0.30639809370040894, 0.2957385182380676]
     Last 10:  [-0.15574222803115845, -0.11063674092292786, -0.043479375541210175, -0.41014349460601807, 0.11076068878173828, -0.02211076393723488, 0.05155554413795471, -0.25060707330703735, -0.13173255324363708, 0.5366371870040894]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.7.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.010971, Std: 0.225540
     First 10: [0.08538548648357391, -0.10256379842758179, 0.19789299368858337, 0.1530497968196869, 0.16729521751403809, 0.21745508909225464, 0.04066808894276619, -0.06103583797812462, -0.11632699519395828, 0.18225687742233276]
     Last 10:  [-0.0682336762547493, -0.05044511333107948, -0.020985743030905724, -0.13980582356452942, 0.06026449799537659, -0.010860360227525234, 0.026837678626179695, -0.10050945729017258, -0.058963313698768616, 0.3778996169567108]
     Zeros: 0, Total: 8064

================================================================================
125_layers.7.mlp.up_proj: Linear (layers.7.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.7.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.019878, Std: 2.871474
     First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
     Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.014265, Std: 0.505875
     First 10: [-0.24799680709838867, 0.6161417365074158, 0.34367406368255615, -0.001232176087796688, -0.125099316239357, 0.1914304494857788, -0.2307918816804886, 0.09608514606952667, 0.17156316339969635, 0.23690165579319]
     Last 10:  [-0.24736300110816956, 0.18767327070236206, 0.1535607874393463, -1.0377447605133057, 0.31615838408470154, 0.3575296700000763, -0.5684059262275696, -0.09489428251981735, -0.24996069073677063, 0.1050192266702652]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000001
     First 10: [0.001952779944986105, -0.005532493349164724, -0.0009504068875685334, -0.0003275986819062382, 0.0007583640981465578, 0.006039884872734547, -0.005673624575138092, -0.00275927921757102, -0.0008874457562342286, -0.0004823373747058213]
     Last 10:  [0.006025625858455896, -0.0013335517141968012, 0.00275557697750628, 0.0035014753229916096, -0.007076459936797619, -9.303422120865434e-05, 0.0035392316058278084, 0.007320338860154152, 0.006599316839128733, 0.0014214750844985247]

================================================================================
126_layers.7.mlp.down_proj: Linear (layers.7.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.7.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000538, Std: 0.136891
     First 10: [-0.021175328642129898, -0.06319383531808853, 0.06801068782806396, -0.00018858429393731058, -0.0209285169839859, 0.04162752628326416, -0.009385865181684494, -0.005864637438207865, -0.01995742693543434, 0.043176956474781036]
     Last 10:  [0.016878487542271614, -0.009467199444770813, -0.0032225872855633497, 0.1450827568769455, 0.019053125753998756, -0.003882901044562459, -0.015254695899784565, 0.009537773206830025, 0.014738510362803936, 0.03968672454357147]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.7.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000575, Std: 0.037296
     First 10: [0.05536491051316261, 0.01840168610215187, 0.008803915232419968, -0.12111048400402069, -0.017574012279510498, -0.005831789691001177, -0.022392939776182175, 0.052352067083120346, 0.026740672066807747, -0.006215983536094427]
     Last 10:  [-0.0012983432970941067, -0.023360606282949448, -0.00026936037465929985, 0.016890205442905426, 0.018106434494256973, 0.007753157988190651, -0.005200939252972603, 0.0007503838278353214, -0.009557616896927357, -0.02597605623304844]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000001
     First 10: [0.004926085472106934, -0.0012588767567649484, -0.0004321240703575313, -0.004531107377260923, -0.003680364228785038, -0.0052763656713068485, -0.0006490410887636244, -0.004330707248300314, -0.0016795848496258259, -0.0013360060984268785]
     Last 10:  [0.0029188827611505985, -0.0012819732073694468, 0.0017836233600974083, 0.0022665546275675297, -0.008303593844175339, -0.008962087333202362, 0.002195715671405196, 0.0015886696055531502, -0.003787148278206587, 0.00015868805348873138]

================================================================================
127_layers.7.mlp: Gemma3MLP (layers.7.mlp)
================================================================================

  → INPUT[0]: layers.7.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.019878, Std: 2.871474
     First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
     Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000575, Std: 0.037296
     First 10: [0.05536491051316261, 0.01840168610215187, 0.008803915232419968, -0.12111048400402069, -0.017574012279510498, -0.005831789691001177, -0.022392939776182175, 0.052352067083120346, 0.026740672066807747, -0.006215983536094427]
     Last 10:  [-0.0012983432970941067, -0.023360606282949448, -0.00026936037465929985, 0.016890205442905426, 0.018106434494256973, 0.007753157988190651, -0.005200939252972603, 0.0007503838278353214, -0.009557616896927357, -0.02597605623304844]
     Zeros: 0, Total: 5376

================================================================================
128_layers.7.post_feedforward_layernorm: Gemma3RMSNorm (layers.7.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.7.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000575, Std: 0.037296
     First 10: [0.05536491051316261, 0.01840168610215187, 0.008803915232419968, -0.12111048400402069, -0.017574012279510498, -0.005831789691001177, -0.022392939776182175, 0.052352067083120346, 0.026740672066807747, -0.006215983536094427]
     Last 10:  [-0.0012983432970941067, -0.023360606282949448, -0.00026936037465929985, 0.016890205442905426, 0.018106434494256973, 0.007753157988190651, -0.005200939252972603, 0.0007503838278353214, -0.009557616896927357, -0.02597605623304844]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.7.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 1.086789, Std: 40.632660
     First 10: [17.59507942199707, 2.7183680534362793, 0.10772810131311417, -0.5726056098937988, -4.0927300453186035, -1.405979037284851, -0.2877838611602783, 0.5575938820838928, 7.603008270263672, -1.7671234607696533]
     Last 10:  [-0.03336841240525246, -0.7911984324455261, -0.0035207299515604973, 7.47305965423584, 8.904891967773438, 2.6661040782928467, -2.3462138175964355, 0.21614669263362885, -2.9964587688446045, -12.301118850708008]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 6.747643
     First 10: [8.95364761352539, 3.6267528533935547, -0.6167529821395874, -0.8519189357757568, 6.294034004211426, 6.550968170166016, -0.5974860191345215, -0.6664124727249146, 7.905099868774414, 7.903949737548828]
     Last 10:  [-0.4650382995605469, -0.2950180172920227, -0.7279331088066101, 8.209588050842285, 9.236992835998535, 6.157727241516113, 8.389932632446289, 4.995726585388184, 5.525824546813965, 8.857074737548828]

================================================================================
129_layers.8.input_layernorm: Gemma3RMSNorm (layers.8.input_layernorm)
================================================================================

  → INPUT[0]: layers.8.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.398140, Std: 49.361523
     First 10: [91.26681518554688, 0.2778646945953369, 0.07823901623487473, -0.5567666292190552, -7.1680216789245605, -6.561345100402832, -0.09568032622337341, -0.43009763956069946, 8.583162307739258, 7.083391189575195]
     Last 10:  [-0.2950323224067688, -1.4394183158874512, -0.5104745626449585, 11.08055591583252, 14.82028579711914, 1.748279094696045, -9.548038482666016, -5.1715989112854, -6.400771141052246, -21.04100799560547]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.070726, Std: 6.093462
     First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
     Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 25.392935
     First 10: [4.930263996124268, 34.81569290161133, 43.64964294433594, 46.06105422973633, 19.07356834411621, 18.329673767089844, 41.00139236450195, 38.788509368896484, 16.662382125854492, 16.890960693359375]
     Last 10:  [43.34963607788086, 44.615074157714844, 50.82707977294922, 13.22226333618164, 13.23153305053711, 21.99422836303711, 14.693656921386719, 16.6297664642334, 19.69869041442871, 15.405460357666016]

================================================================================
130_layers.8.self_attn.q_proj: Linear (layers.8.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.8.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.070726, Std: 6.093462
     First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
     Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.135690, Std: 2.320163
     First 10: [0.23136797547340393, 0.9997062683105469, 0.6384376287460327, -0.3165666162967682, 0.8686844110488892, 0.2633551359176636, -0.7059409022331238, 0.4156378507614136, 0.10963167250156403, -2.074816942214966]
     Last 10:  [-0.4906226396560669, 0.42897266149520874, -0.7689382433891296, 0.019621163606643677, -0.44520220160484314, 0.8766031265258789, 0.3753315806388855, -0.8456871509552002, -0.32136431336402893, -0.6847308874130249]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000036
     First 10: [-0.010796666145324707, 0.00239009503275156, 0.0027274652384221554, -0.004474998917430639, 0.0018854928202927113, 0.0033421306870877743, 0.0031455871649086475, 0.004846746567636728, -0.000970634922850877, 0.0007398256566375494]
     Last 10:  [0.010107583366334438, 0.003830293193459511, -0.005682303104549646, -0.006932464428246021, 0.0019512271974235773, -0.009417712688446045, -0.0035100942477583885, -0.0032899826765060425, -0.0006082264008000493, 0.0004619796818587929]

================================================================================
131_layers.8.self_attn.k_proj: Linear (layers.8.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.8.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.070726, Std: 6.093462
     First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
     Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.091760, Std: 2.586420
     First 10: [0.2132103443145752, -1.0478852987289429, -0.01173257827758789, 0.5306379795074463, -1.1320075988769531, -0.018470972776412964, 0.002465352416038513, -1.2199022769927979, 0.6086537837982178, -0.1363930106163025]
     Last 10:  [2.486532211303711, 1.8488750457763672, -2.639826774597168, 1.7773514986038208, -0.9401611685752869, 2.1703412532806396, -0.44885122776031494, -2.9708292484283447, -2.3916609287261963, -2.927790641784668]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000025
     First 10: [-0.022683266550302505, -0.004412191919982433, -0.007349704392254353, 0.003069153055548668, -0.0009154375875368714, -0.0017546323360875249, -0.0011520326370373368, -0.0005815248005092144, -0.003641101997345686, -0.0023114557843655348]
     Last 10:  [0.01674828864634037, 0.008974707685410976, -0.002579986583441496, 0.005915784742683172, 0.006003588438034058, 0.009514117613434792, -0.005435677245259285, 0.01158529706299305, 0.008947975933551788, -0.00171754602342844]

================================================================================
132_layers.8.self_attn.v_proj: Linear (layers.8.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.8.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.070726, Std: 6.093462
     First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
     Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.021070, Std: 1.393743
     First 10: [-0.11598235368728638, -0.2668547034263611, -0.6445173621177673, 0.4491630494594574, 0.7806375622749329, 0.30412137508392334, 1.5936214923858643, 0.2586211562156677, 0.2932492196559906, 0.4429655075073242]
     Last 10:  [-0.3856288194656372, -0.10197493433952332, 0.3624061942100525, 0.4622375965118408, -0.0023049991577863693, 0.12164025008678436, -0.20833665132522583, -0.2916319668292999, -0.2909829616546631, -0.23868553340435028]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000021
     First 10: [7.204095891211182e-05, 0.0016935032326728106, -0.0030976920388638973, 0.005979588255286217, 0.004251648206263781, 0.00460835499688983, 0.0007156503852456808, 0.007063339464366436, -0.016419576480984688, -0.004557449370622635]
     Last 10:  [-0.009583204053342342, -0.005749799776822329, -0.015444629825651646, -0.0014858487993478775, -0.0001483763917349279, -0.01200941763818264, 0.009871618822216988, 0.009727263823151588, 0.004435543902218342, 0.01849164254963398]

================================================================================
133_layers.8.self_attn.q_norm: Gemma3RMSNorm (layers.8.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.8.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.135690, Std: 2.320163
     First 10: [0.23136797547340393, 0.9997062683105469, 0.6384376287460327, -0.3165666162967682, 0.8686844110488892, 0.2633551359176636, -0.7059409022331238, 0.4156378507614136, 0.10963167250156403, -2.074816942214966]
     Last 10:  [-0.4906226396560669, 0.42897266149520874, -0.7689382433891296, 0.019621163606643677, -0.44520220160484314, 0.8766031265258789, 0.3753315806388855, -0.8456871509552002, -0.32136431336402893, -0.6847308874130249]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.052719, Std: 1.183598
     First 10: [0.6027870774269104, 1.0836869478225708, 2.5114634037017822, -1.1668769121170044, 0.5611018538475037, 0.6127721667289734, -2.596522808074951, 0.22389104962348938, 0.1934043914079666, -0.9943795800209045]
     Last 10:  [-0.3928007483482361, 0.3771650791168213, -1.1457568407058716, 0.021717574447393417, -0.6592866778373718, 1.3039953708648682, 0.9249271154403687, -0.9633112549781799, -0.5093561410903931, -0.5180079936981201]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.157315
     First 10: [0.7458158135414124, -0.2736111879348755, 1.6360042095184326, 1.4700038433074951, -0.5671699643135071, 0.5591751933097839, 1.4646854400634766, -0.6390397548675537, 0.18213751912117004, -0.678848385810852]
     Last 10:  [-0.27110522985458374, -0.19953572750091553, 0.35656657814979553, 0.007689322344958782, 0.3482085168361664, 0.3542945683002472, 1.2435332536697388, 0.03704356402158737, 0.4429922103881836, -0.31125789880752563]

================================================================================
134_layers.8.self_attn.k_norm: Gemma3RMSNorm (layers.8.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.8.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.091760, Std: 2.586420
     First 10: [0.2132103443145752, -1.0478852987289429, -0.01173257827758789, 0.5306379795074463, -1.1320075988769531, -0.018470972776412964, 0.002465352416038513, -1.2199022769927979, 0.6086537837982178, -0.1363930106163025]
     Last 10:  [2.486532211303711, 1.8488750457763672, -2.639826774597168, 1.7773514986038208, -0.9401611685752869, 2.1703412532806396, -0.44885122776031494, -2.9708292484283447, -2.3916609287261963, -2.927790641784668]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.8.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.008510, Std: 1.761029
     First 10: [0.3069399893283844, -0.48919203877449036, -0.008260846138000488, 0.3655574321746826, -1.212753176689148, -0.020853709429502487, 0.0016939332708716393, -1.7175416946411133, 0.9070112705230713, 0.07263458520174026]
     Last 10:  [2.968484878540039, 2.1207633018493652, -1.700260877609253, 1.2637357711791992, -0.5362961292266846, 0.8655752539634705, -0.17810387909412384, -2.472322702407837, -1.1833361387252808, -2.9109697341918945]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.589800
     First 10: [0.9697715640068054, -0.3612420856952667, -0.0366109199821949, -0.057398878037929535, 0.4658641815185547, 0.5447714328765869, -0.059869855642318726, 0.9264285564422607, 1.03898024559021, -1.7286550998687744]
     Last 10:  [1.3234819173812866, 1.2324575185775757, 0.25354140996932983, 0.3838261365890503, 0.11019919812679291, -0.22379688918590546, -0.22772932052612305, 0.6196683049201965, -0.03704255074262619, 0.9350680112838745]

================================================================================
135_layers.8.self_attn.o_proj: Linear (layers.8.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.8.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.014153, Std: 0.752103
     First 10: [-0.11598235368728638, -0.2668547034263611, -0.6445173621177673, 0.4491630494594574, 0.7806375622749329, 0.30412137508392334, 1.5936214923858643, 0.2586211562156677, 0.2932492196559906, 0.4429655075073242]
     Last 10:  [-0.002783447504043579, 0.19933781027793884, 0.0705631822347641, 0.4776221215724945, 0.1944543719291687, 0.21020391583442688, 0.19536617398262024, -0.29081830382347107, -0.42075246572494507, -0.4283957779407501]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.018979, Std: 0.514229
     First 10: [0.1325911581516266, -0.032845638692379, 0.7288525104522705, -1.267212986946106, 0.04053500294685364, 0.038502126932144165, -0.5962883234024048, -1.3378788232803345, -0.26437169313430786, 0.12909261882305145]
     Last 10:  [-1.1305373907089233, 0.034707214683294296, 0.30106058716773987, 0.028965860605239868, -0.29058778285980225, 0.0314028337597847, -0.17769712209701538, 0.04128396138548851, 0.017154958099126816, 0.1695108711719513]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000003
     First 10: [0.005896450951695442, -0.0012227381812408566, -0.003444986417889595, 0.011383624747395515, -0.00697952089831233, 0.003365089651197195, 0.005855883006006479, -0.005042588338255882, 0.011663900688290596, 0.0036253901198506355]
     Last 10:  [-0.0032231889199465513, -0.0018151768017560244, 0.005522986873984337, 0.009902036748826504, 0.003288998268544674, -0.0024052965454757214, 0.002026572357863188, -0.009888872504234314, 0.017150036990642548, -0.012611166574060917]

================================================================================
136_layers.8.self_attn: Gemma3Attention (layers.8.self_attn)
================================================================================

  → OUTPUT[0]: layers.8.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.018979, Std: 0.514229
     First 10: [0.1325911581516266, -0.032845638692379, 0.7288525104522705, -1.267212986946106, 0.04053500294685364, 0.038502126932144165, -0.5962883234024048, -1.3378788232803345, -0.26437169313430786, 0.12909261882305145]
     Last 10:  [-1.1305373907089233, 0.034707214683294296, 0.30106058716773987, 0.028965860605239868, -0.29058778285980225, 0.0314028337597847, -0.17769712209701538, 0.04128396138548851, 0.017154958099126816, 0.1695108711719513]
     Zeros: 0, Total: 5376

================================================================================
137_layers.8.post_attention_layernorm: Gemma3RMSNorm (layers.8.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.8.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.018979, Std: 0.514229
     First 10: [0.1325911581516266, -0.032845638692379, 0.7288525104522705, -1.267212986946106, 0.04053500294685364, 0.038502126932144165, -0.5962883234024048, -1.3378788232803345, -0.26437169313430786, 0.12909261882305145]
     Last 10:  [-1.1305373907089233, 0.034707214683294296, 0.30106058716773987, 0.028965860605239868, -0.29058778285980225, 0.0314028337597847, -0.17769712209701538, 0.04128396138548851, 0.017154958099126816, 0.1695108711719513]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -1.793263, Std: 37.577015
     First 10: [3.828481435775757, -1.5720540285110474, 0.05414615571498871, -0.1097029522061348, 0.9283417463302612, 1.4297144412994385, -0.01246384996920824, 0.011519843712449074, -11.284200668334961, 5.658708095550537]
     Last 10:  [-0.1407741904258728, 0.014473839662969112, 0.058324821293354034, 0.8305338025093079, -12.759029388427734, 1.1014902591705322, -6.195261001586914, 0.8631356954574585, 0.32565122842788696, 7.903704643249512]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 11.670672
     First 10: [11.299614906311035, 19.38775062561035, -0.9683548212051392, -0.963123619556427, 8.755672454833984, 14.817729949951172, -0.9910961985588074, -1.0036678314208984, 17.181739807128906, 17.672197341918945]
     Last 10:  [-0.9410159587860107, -0.8024575710296631, -0.9082310199737549, 12.582111358642578, 19.798725128173828, 15.615303039550781, 15.514886856079102, 8.903623580932617, 7.9920654296875, 21.08663558959961]

================================================================================
138_layers.8.pre_feedforward_layernorm: Gemma3RMSNorm (layers.8.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.8.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -1.395123, Std: 46.813889
     First 10: [95.09529876708984, -1.2941893339157104, 0.13238516449928284, -0.6664695739746094, -6.23967981338501, -5.131630897521973, -0.10814417898654938, -0.41857779026031494, -2.701038360595703, 12.74209976196289]
     Last 10:  [-0.4358065128326416, -1.424944519996643, -0.45214974880218506, 11.911089897155762, 2.0612564086914062, 2.849769353866577, -15.74329948425293, -4.308463096618652, -6.075119972229004, -13.137303352355957]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020318, Std: 3.774287
     First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
     Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 25.906479
     First 10: [4.295438289642334, 14.659589767456055, 58.16114044189453, 53.58955001831055, 17.595537185668945, 15.330365180969238, 49.71038055419922, 55.045989990234375, 13.477176666259766, 11.75933837890625]
     Last 10:  [58.03546905517578, 64.72428894042969, 56.65290832519531, 10.661032676696777, 11.263733863830566, 14.588140487670898, 13.084611892700195, 13.058961868286133, 18.93444061279297, 9.931501388549805]

================================================================================
139_layers.8.mlp.gate_proj: Linear (layers.8.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.8.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020318, Std: 3.774287
     First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
     Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.514568, Std: 0.835373
     First 10: [0.5354303121566772, -0.04544266685843468, -0.2574884295463562, 0.06807553023099899, -1.2819278240203857, -0.19579574465751648, -0.2545359432697296, 0.6520605087280273, -0.23293167352676392, 0.17520317435264587]
     Last 10:  [-0.5340793132781982, 0.27043259143829346, -0.32156652212142944, -0.021483495831489563, -0.36139512062072754, -0.206824392080307, -0.6822670698165894, -0.6076549887657166, -0.2342354953289032, -0.5878432989120483]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000066
     First 10: [0.004396546166390181, -0.007720732130110264, -0.00530974892899394, -0.008482617326080799, -0.0057840365916490555, -0.0048386515118181705, -0.004406585358083248, -1.3910859706811607e-05, 0.006761252414435148, 0.0008024187991395593]
     Last 10:  [0.00725854467600584, -0.007989529520273209, 0.006717360112816095, 0.00897405669093132, -2.4539040168747306e-05, 0.0010288391495123506, -0.0012580400798469782, 0.006921825930476189, 0.0011849261354655027, -0.00394623726606369]

================================================================================
140_layers.8.mlp.act_fn: PytorchGELUTanh (layers.8.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.8.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.514568, Std: 0.835373
     First 10: [0.5354303121566772, -0.04544266685843468, -0.2574884295463562, 0.06807553023099899, -1.2819278240203857, -0.19579574465751648, -0.2545359432697296, 0.6520605087280273, -0.23293167352676392, 0.17520317435264587]
     Last 10:  [-0.5340793132781982, 0.27043259143829346, -0.32156652212142944, -0.021483495831489563, -0.36139512062072754, -0.206824392080307, -0.6822670698165894, -0.6076549887657166, -0.2342354953289032, -0.5878432989120483]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.8.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.001210, Std: 0.301526
     First 10: [0.37682658433914185, -0.02189778722822666, -0.10258499532938004, 0.03588514029979706, -0.12833645939826965, -0.0827016606926918, -0.10169880837202072, 0.48431915044784546, -0.09501545131206512, 0.09978491812944412]
     Last 10:  [-0.15845291316509247, 0.1640390157699585, -0.12023395299911499, -0.010557633824646473, -0.12971056997776031, -0.08646838366985321, -0.1689358651638031, -0.16513922810554504, -0.09542874246835709, -0.16363847255706787]
     Zeros: 0, Total: 8064

================================================================================
141_layers.8.mlp.up_proj: Linear (layers.8.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.8.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020318, Std: 3.774287
     First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
     Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.011300, Std: 0.768343
     First 10: [-0.17938682436943054, -0.10357041656970978, 0.19779498875141144, -0.19597384333610535, -0.8540266156196594, -0.05134892836213112, -0.2166343629360199, -0.04228357970714569, 0.37728285789489746, -0.41750502586364746]
     Last 10:  [0.4832491874694824, 0.43068334460258484, -0.6291753053665161, -0.04431915283203125, 0.13948316872119904, -0.23257678747177124, 0.14517760276794434, -0.19196799397468567, -0.03350755572319031, -0.542410135269165]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000000
     First 10: [0.00802135281264782, -0.006812759675085545, -0.0033238728065043688, 0.005928389262408018, 0.0030518879648298025, -0.003560947719961405, 0.0003641592338681221, -0.010605394840240479, -0.005908967927098274, -0.0029890192672610283]
     Last 10:  [0.0012043797178193927, 0.002700663637369871, -0.01404948066920042, -0.0005537783144973218, -0.0009520563762634993, -0.00921354815363884, 0.0037613811437040567, -0.014918481931090355, -0.0010394890559837222, 0.009277642704546452]

================================================================================
142_layers.8.mlp.down_proj: Linear (layers.8.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.8.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.003476, Std: 0.259300
     First 10: [-0.06759772449731827, 0.002267963020130992, -0.02029079757630825, -0.007032549008727074, 0.10960274934768677, 0.004246641881763935, 0.022031456232070923, -0.0204787477850914, -0.035847701132297516, -0.04166070371866226]
     Last 10:  [-0.0765722393989563, 0.07064887136220932, 0.075648233294487, 0.0004679053963627666, -0.0180924404412508, 0.020110538229346275, -0.024525703862309456, 0.03170144557952881, 0.0031975838355720043, 0.0887591689825058]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.8.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000403, Std: 0.067837
     First 10: [0.02686716988682747, -0.0061106919310987, 0.024766908958554268, 0.20575492084026337, 0.00869075022637844, -0.014572693966329098, 0.05624259263277054, -0.22964581847190857, 0.012694557197391987, -0.003785832319408655]
     Last 10:  [0.003454180434346199, 0.01679644174873829, 0.015389577485620975, -0.006853911560028791, -0.04134400188922882, 0.03915342688560486, 0.016812633723020554, -0.056042205542325974, 0.000387740321457386, 0.009278018958866596]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000007
     First 10: [0.002765981713309884, 0.005623992532491684, -0.0024516936391592026, -0.0026914833579212427, 0.009287230670452118, 0.012499743141233921, -0.00388806639239192, -0.0006293325568549335, 0.0033385874703526497, -0.003771852934733033]
     Last 10:  [0.004361134488135576, 0.004305975046008825, -0.003157295985147357, 0.0018606891389936209, -0.0007144545670598745, -0.0012091925600543618, -0.004875946324318647, -0.0012867152690887451, 0.002467517973855138, 0.0007306088227778673]

================================================================================
143_layers.8.mlp: Gemma3MLP (layers.8.mlp)
================================================================================

  → INPUT[0]: layers.8.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.020318, Std: 3.774287
     First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
     Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000403, Std: 0.067837
     First 10: [0.02686716988682747, -0.0061106919310987, 0.024766908958554268, 0.20575492084026337, 0.00869075022637844, -0.014572693966329098, 0.05624259263277054, -0.22964581847190857, 0.012694557197391987, -0.003785832319408655]
     Last 10:  [0.003454180434346199, 0.01679644174873829, 0.015389577485620975, -0.006853911560028791, -0.04134400188922882, 0.03915342688560486, 0.016812633723020554, -0.056042205542325974, 0.000387740321457386, 0.009278018958866596]
     Zeros: 0, Total: 5376

================================================================================
144_layers.8.post_feedforward_layernorm: Gemma3RMSNorm (layers.8.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.8.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000403, Std: 0.067837
     First 10: [0.02686716988682747, -0.0061106919310987, 0.024766908958554268, 0.20575492084026337, 0.00869075022637844, -0.014572693966329098, 0.05624259263277054, -0.22964581847190857, 0.012694557197391987, -0.003785832319408655]
     Last 10:  [0.003454180434346199, 0.01679644174873829, 0.015389577485620975, -0.006853911560028791, -0.04134400188922882, 0.03915342688560486, 0.016812633723020554, -0.056042205542325974, 0.000387740321457386, 0.009278018958866596]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.8.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 1.279546, Std: 31.713074
     First 10: [8.972832679748535, -1.3591588735580444, 0.22021204233169556, 0.2870769202709198, 2.297525644302368, -5.088879585266113, 0.44379329681396484, -0.14892078936100006, 5.111526966094971, -1.518528938293457]
     Last 10:  [0.047995563596487045, 0.3520873486995697, 0.08506133407354355, -2.120387315750122, -16.283430099487305, 12.435527801513672, 6.111661434173584, -11.430350303649902, 0.09647952020168304, 3.720930814743042]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 9.239451
     First 10: [10.587616920471191, 6.717316627502441, -0.6914995908737183, -0.9515900611877441, 8.172539710998535, 11.116266250610352, -0.726219892501831, -0.9774999618530273, 12.970745086669922, 12.917081832885742]
     Last 10:  [-0.48725128173828125, -0.2264619767665863, -0.7960357666015625, 10.41629695892334, 13.533891677856445, 10.720415115356445, 12.414424896240234, 6.526495933532715, 8.182113647460938, 13.79942512512207]

================================================================================
145_layers.9.input_layernorm: Gemma3RMSNorm (layers.9.input_layernorm)
================================================================================

  → INPUT[0]: layers.9.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.115576, Std: 59.861839
     First 10: [104.06813049316406, -2.653348207473755, 0.3525972068309784, -0.3793926537036896, -3.9421541690826416, -10.220510482788086, 0.33564913272857666, -0.5674985647201538, 2.4104886054992676, 11.223570823669434]
     Last 10:  [-0.38781094551086426, -1.072857141494751, -0.3670884072780609, 9.790702819824219, -14.222173690795898, 15.285297393798828, -9.631637573242188, -15.738813400268555, -5.978640556335449, -9.416372299194336]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.010411, Std: 3.120684
     First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
     Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 22.355370
     First 10: [3.2154479026794434, 14.686393737792969, 56.16846466064453, 49.86494064331055, 10.424263000488281, 8.25523853302002, 37.59574508666992, 45.00311279296875, 7.342601776123047, 7.273305416107178]
     Last 10:  [54.99834442138672, 72.96316528320312, 45.87456512451172, 7.622932434082031, 6.510634422302246, 8.659018516540527, 7.59801721572876, 9.253189086914062, 11.453187942504883, 6.559623718261719]

================================================================================
146_layers.9.self_attn.q_proj: Linear (layers.9.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.9.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.010411, Std: 3.120684
     First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
     Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.036152, Std: 1.286699
     First 10: [-0.6003598570823669, -0.196706622838974, 0.48577195405960083, -0.1411602795124054, 0.8894214630126953, 1.031860113143921, -0.44488590955734253, 0.22515203058719635, -0.2262679785490036, -0.3262194097042084]
     Last 10:  [-1.1671102046966553, 0.09605583548545837, -0.4668017029762268, 0.22229382395744324, 0.8088752031326294, -0.010314390063285828, -0.5170165300369263, 0.10669933259487152, -0.8704776763916016, -0.29626885056495667]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000010
     First 10: [0.0033316819462925196, 0.00552075169980526, -0.006587829440832138, -0.0008180694421753287, 0.005080081056803465, 0.0011031716130673885, -0.009874654933810234, -0.0037852826062589884, 0.007398772984743118, -0.004779486916959286]
     Last 10:  [0.008591314777731895, -0.012238791212439537, 0.005473942495882511, -0.0005225250497460365, 0.014520247466862202, -0.0029792040586471558, -0.004534158390015364, 0.005185128655284643, 0.002654365496709943, -0.0028279167599976063]

================================================================================
147_layers.9.self_attn.k_proj: Linear (layers.9.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.9.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.010411, Std: 3.120684
     First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
     Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.111561, Std: 1.204171
     First 10: [0.07614259421825409, -0.02898043394088745, -1.4051761627197266, -1.140845775604248, 0.0358443483710289, -2.461568832397461, 0.14244864881038666, -0.02645450457930565, -0.22181349992752075, 1.5721005201339722]
     Last 10:  [-2.6710867881774902, -0.45008936524391174, -4.620720863342285, 1.9184460639953613, 5.037489414215088, -3.9948513507843018, -6.398279666900635, -0.45327794551849365, -1.1527889966964722, -1.1172962188720703]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000003
     First 10: [-0.003089292673394084, 0.0024548072833567858, 0.0020518405362963676, 0.0019033579155802727, -0.0008885628776624799, 0.0015690833097323775, 0.0060972124338150024, 0.0015117127913981676, 0.0006336513324640691, -0.001900005154311657]
     Last 10:  [0.0015563396736979485, -0.013580149039626122, 0.005034345202147961, -0.0024257665500044823, 0.008642560802400112, 0.004683074541389942, -0.009500429034233093, 0.005665264558047056, 0.007793620694428682, -0.005508988630026579]

================================================================================
148_layers.9.self_attn.v_proj: Linear (layers.9.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.9.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.010411, Std: 3.120684
     First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
     Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.027820, Std: 0.715945
     First 10: [-0.1266833394765854, 0.5651862621307373, -0.21170511841773987, 0.21897965669631958, 0.04614535719156265, -0.1431199014186859, -0.16944749653339386, -0.11720070242881775, 0.11196364462375641, -0.5168630480766296]
     Last 10:  [0.33685001730918884, -0.04175226390361786, -0.20378762483596802, -0.12236517667770386, 0.43034905195236206, 0.6150254607200623, -0.09351329505443573, -0.1274517923593521, -0.47873109579086304, 0.1678474098443985]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000001
     First 10: [-0.005103698931634426, -0.002307089976966381, -0.0100662000477314, -0.005701238289475441, -0.011111414059996605, -0.0006736977957189083, -0.00343123497441411, -0.002424793317914009, -0.004651096649467945, -0.013875987380743027]
     Last 10:  [-0.0012310778256505728, -0.0033500706776976585, -0.003916244022548199, 0.0018044647295027971, -0.00520338024944067, -0.0167824849486351, -0.018037769943475723, -0.01029799971729517, 0.0018038824200630188, 0.011847187764942646]

================================================================================
149_layers.9.self_attn.q_norm: Gemma3RMSNorm (layers.9.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.9.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.036152, Std: 1.286699
     First 10: [-0.6003598570823669, -0.196706622838974, 0.48577195405960083, -0.1411602795124054, 0.8894214630126953, 1.031860113143921, -0.44488590955734253, 0.22515203058719635, -0.2262679785490036, -0.3262194097042084]
     Last 10:  [-1.1671102046966553, 0.09605583548545837, -0.4668017029762268, 0.22229382395744324, 0.8088752031326294, -0.010314390063285828, -0.5170165300369263, 0.10669933259487152, -0.8704776763916016, -0.29626885056495667]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.021759, Std: 1.114739
     First 10: [-0.9820979237556458, -0.38740137219429016, 0.5120255947113037, -0.1884961724281311, 1.1480494737625122, 0.7934421896934509, -0.5135412812232971, 0.4102477431297302, -0.22454996407032013, -0.2853083312511444]
     Last 10:  [-4.042196273803711, 0.19195783138275146, -1.2350518703460693, 1.2575076818466187, 2.2929725646972656, -0.0381360799074173, -1.7126706838607788, 0.35286861658096313, -1.445129156112671, -0.7262293100357056]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.335935
     First 10: [0.15561078488826752, 0.39126741886138916, -0.2553919851779938, -0.05668128281831741, -0.08815409988164902, -0.4567960500717163, -0.18455402553081512, 0.28717848658561707, -0.2989349663257599, -0.3821640908718109]
     Last 10:  [0.8140531778335571, 0.046710316091775894, 0.3857894539833069, 1.9629731178283691, 0.4847789406776428, 0.936586856842041, 0.7350575923919678, 0.7321910262107849, -0.13045217096805573, 0.2839031517505646]

================================================================================
150_layers.9.self_attn.k_norm: Gemma3RMSNorm (layers.9.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.9.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.111561, Std: 1.204171
     First 10: [0.07614259421825409, -0.02898043394088745, -1.4051761627197266, -1.140845775604248, 0.0358443483710289, -2.461568832397461, 0.14244864881038666, -0.02645450457930565, -0.22181349992752075, 1.5721005201339722]
     Last 10:  [-2.6710867881774902, -0.45008936524391174, -4.620720863342285, 1.9184460639953613, 5.037489414215088, -3.9948513507843018, -6.398279666900635, -0.45327794551849365, -1.1527889966964722, -1.1172962188720703]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.9.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.070423, Std: 1.604714
     First 10: [0.1284542828798294, -0.04800771176815033, 0.018999001011252403, -0.036068856716156006, 0.04730023443698883, -0.13668940961360931, 0.358690083026886, -0.028695106506347656, -0.5920730233192444, -0.047596827149391174]
     Last 10:  [-2.781630754470825, -0.7288652062416077, -5.126715183258057, 1.350743293762207, 6.757702827453613, -4.069862365722656, -5.858631610870361, -0.5248639583587646, -2.4637506008148193, -1.4181329011917114]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.429340
     First 10: [0.2854950726032257, 0.26227977871894836, -1.0103026628494263, -0.9759089946746826, 0.005523182451725006, -0.9576871395111084, 0.918715238571167, -0.1734718382358551, 1.0339336395263672, -1.023069977760315]
     Last 10:  [0.5613129734992981, 1.4278782606124878, 0.6634430289268494, 0.05560561269521713, 1.0112378597259521, 0.5274168252944946, 0.37281328439712524, 0.7360437512397766, 2.204242706298828, 0.9029486775398254]

================================================================================
151_layers.9.self_attn.o_proj: Linear (layers.9.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.9.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.041313, Std: 0.412007
     First 10: [-0.1266833394765854, 0.5651862621307373, -0.21170511841773987, 0.21897965669631958, 0.04614535719156265, -0.1431199014186859, -0.16944749653339386, -0.11720070242881775, 0.11196364462375641, -0.5168630480766296]
     Last 10:  [0.054611459374427795, 0.14244839549064636, 0.14476999640464783, 0.041322555392980576, 0.2782055139541626, 0.29791146516799927, 0.028671905398368835, -0.01952143758535385, -0.3747113347053528, -0.18747276067733765]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000796, Std: 0.135285
     First 10: [0.059194568544626236, -0.01699569821357727, 0.2064433991909027, 0.1933930218219757, 0.057044900953769684, 0.07737097144126892, -0.016686849296092987, -0.07431036978960037, 0.02882661670446396, -0.12376612424850464]
     Last 10:  [-0.014843176119029522, -0.0040070172399282455, -0.05649123340845108, 0.09446848928928375, -0.03461406007409096, -0.04676936939358711, 0.0864887535572052, -0.1023760661482811, 0.05060172826051712, 0.04279104620218277]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000018
     First 10: [0.008707129396498203, 0.0017210007645189762, -0.0012096911668777466, 0.00630299374461174, -0.011976211331784725, 0.0006904329638928175, 0.002077955985441804, -0.007856489159166813, 0.005008826032280922, 0.004301654174923897]
     Last 10:  [-0.00031728032627142966, 0.0027262517251074314, -0.003408580319955945, -0.017023881897330284, 0.008206511847674847, 0.007334754802286625, 0.000590501120314002, 0.007294916547834873, 0.009631609544157982, 0.005944702308624983]

================================================================================
152_layers.9.self_attn: Gemma3Attention (layers.9.self_attn)
================================================================================

  → OUTPUT[0]: layers.9.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000796, Std: 0.135285
     First 10: [0.059194568544626236, -0.01699569821357727, 0.2064433991909027, 0.1933930218219757, 0.057044900953769684, 0.07737097144126892, -0.016686849296092987, -0.07431036978960037, 0.02882661670446396, -0.12376612424850464]
     Last 10:  [-0.014843176119029522, -0.0040070172399282455, -0.05649123340845108, 0.09446848928928375, -0.03461406007409096, -0.04676936939358711, 0.0864887535572052, -0.1023760661482811, 0.05060172826051712, 0.04279104620218277]
     Zeros: 0, Total: 5376

================================================================================
153_layers.9.post_attention_layernorm: Gemma3RMSNorm (layers.9.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.9.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000796, Std: 0.135285
     First 10: [0.059194568544626236, -0.01699569821357727, 0.2064433991909027, 0.1933930218219757, 0.057044900953769684, 0.07737097144126892, -0.016686849296092987, -0.07431036978960037, 0.02882661670446396, -0.12376612424850464]
     Last 10:  [-0.014843176119029522, -0.0040070172399282455, -0.05649123340845108, 0.09446848928928375, -0.03461406007409096, -0.04676936939358711, 0.0864887535572052, -0.1023760661482811, 0.05060172826051712, 0.04279104620218277]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.697687, Std: 19.210552
     First 10: [2.941415548324585, -1.8931573629379272, 0.012385942041873932, 0.026006704196333885, 3.3404765129089355, 8.214856147766113, 0.0065179974772036076, -0.02010747231543064, 3.2961103916168213, -16.82527732849121]
     Last 10:  [-0.010513320565223694, -0.0022820960730314255, -0.014650694094598293, 4.835803985595703, -2.7875514030456543, -4.283390522003174, 6.498577117919922, -3.404336929321289, 2.0345542430877686, 4.377447605133057]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 8.098214
     First 10: [5.025496959686279, 12.507221221923828, -0.9927247762680054, -0.9836934208869934, 6.10084342956543, 11.874792098999023, -1.0473650693893433, -0.9671884775161743, 12.86520767211914, 15.484613418579102]
     Last 10:  [-0.8749113082885742, -0.8994185924530029, -0.9541982412338257, 8.040380477905273, 13.222480773925781, 15.174510955810547, 12.269777297973633, 4.872717380523682, 6.100826263427734, 17.06645965576172]

================================================================================
154_layers.9.pre_feedforward_layernorm: Gemma3RMSNorm (layers.9.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.9.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.813263, Std: 55.374264
     First 10: [107.0095443725586, -4.546505451202393, 0.36498314142227173, -0.35338595509529114, -0.601677656173706, -2.0056543350219727, 0.3421671390533447, -0.5876060128211975, 5.706599235534668, -5.601706504821777]
     Last 10:  [-0.39832425117492676, -1.0751392841339111, -0.3817391097545624, 14.626506805419922, -17.00972557067871, 11.001907348632812, -3.1330604553222656, -19.143150329589844, -3.9440863132476807, -5.038924694061279]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.027625, Std: 3.104226
     First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
     Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 17.059443
     First 10: [3.6721458435058594, 8.344853401184082, 38.81349563598633, 34.78888702392578, 10.594892501831055, 8.294792175292969, 35.3748779296875, 33.44645309448242, 7.294167518615723, 6.281545639038086]
     Last 10:  [41.80930709838867, 43.75434875488281, 37.874568939208984, 7.58586311340332, 6.050660133361816, 8.047645568847656, 7.713408470153809, 9.97671127319336, 11.055352210998535, 6.006896018981934]

================================================================================
155_layers.9.mlp.gate_proj: Linear (layers.9.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.9.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.027625, Std: 3.104226
     First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
     Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.316449, Std: 0.660543
     First 10: [-0.4384632706642151, -0.6396448016166687, -0.16982899606227875, -0.022782035171985626, -0.03662486374378204, 0.2186051309108734, -0.1946832239627838, -0.6165542602539062, -0.12686212360858917, -0.11507278680801392]
     Last 10:  [0.13568086922168732, 0.6883193850517273, -0.12580080330371857, -0.37565386295318604, -0.39662647247314453, 0.4005763530731201, -0.6241196393966675, -0.027682073414325714, -0.15641900897026062, -0.2170560657978058]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000031
     First 10: [-5.7165201724274084e-05, -0.0025165181141346693, 0.001750702504068613, 0.01156451366841793, -0.008765392936766148, -0.007715917192399502, 0.0054344115778803825, -0.0007450197590515018, 0.0033109677024185658, -0.008400440216064453]
     Last 10:  [-0.004006718285381794, 0.0006987961824052036, 0.005709351971745491, -0.0026537105441093445, -0.0096077099442482, -0.013382339850068092, -0.0003772717318497598, -0.0003236488555558026, 0.004319345112890005, -0.007623856887221336]

================================================================================
156_layers.9.mlp.act_fn: PytorchGELUTanh (layers.9.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.9.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.316449, Std: 0.660543
     First 10: [-0.4384632706642151, -0.6396448016166687, -0.16982899606227875, -0.022782035171985626, -0.03662486374378204, 0.2186051309108734, -0.1946832239627838, -0.6165542602539062, -0.12686212360858917, -0.11507278680801392]
     Last 10:  [0.13568086922168732, 0.6883193850517273, -0.12580080330371857, -0.37565386295318604, -0.39662647247314453, 0.4005763530731201, -0.6241196393966675, -0.027682073414325714, -0.15641900897026062, -0.2170560657978058]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.9.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.002183, Std: 0.246616
     First 10: [-0.1449338048696518, -0.16711735725402832, -0.07346358895301819, -0.01118397619575262, -0.017777418717741966, 0.12821581959724426, -0.08231651037931442, -0.16574397683143616, -0.057027749717235565, -0.05226539447903633]
     Last 10:  [0.07516209781169891, 0.5191980004310608, -0.05660349875688553, -0.13283230364322662, -0.1371692419052124, 0.2626239061355591, -0.16622485220432281, -0.013535368256270885, -0.0684884712100029, -0.08987978100776672]
     Zeros: 0, Total: 8064

================================================================================
157_layers.9.mlp.up_proj: Linear (layers.9.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.9.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.027625, Std: 3.104226
     First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
     Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.008001, Std: 0.574858
     First 10: [-0.2237587422132492, 0.34771716594696045, -0.28441405296325684, -0.2070593535900116, 0.09408167749643326, -0.061830081045627594, 0.09338714182376862, -0.40350228548049927, -0.2476229965686798, -0.14350809156894684]
     Last 10:  [0.1811629831790924, -0.24391087889671326, -0.6161313056945801, -0.06923380494117737, -0.08539508283138275, -0.5772427320480347, -0.18432283401489258, 0.15946602821350098, -0.006444871425628662, -0.5001517534255981]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000011
     First 10: [-0.001529238885268569, -0.002361697144806385, 0.0011433259351179004, -0.00011048749729525298, -0.0056943828240036964, -0.00975027959793806, 0.0003251852176617831, -0.0018404091242700815, -0.0033263321965932846, 0.01197410561144352]
     Last 10:  [0.0026623394805938005, 0.0005992513033561409, -0.008208610117435455, -0.013025382533669472, -0.006476079113781452, -0.005814807023853064, 0.003706675488501787, -0.00010044973896583542, -0.0038551753386855125, 0.005315499380230904]

================================================================================
158_layers.9.mlp.down_proj: Linear (layers.9.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.9.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.001411, Std: 0.156758
     First 10: [0.03243020549416542, -0.058109574019908905, 0.02089407667517662, 0.0023157468531280756, -0.0016725293826311827, -0.00792759470641613, -0.007687303703278303, 0.0668780729174614, 0.014121382497251034, 0.007500506937503815]
     Last 10:  [0.013616589829325676, -0.1266380399465561, 0.034875188022851944, 0.00919648539274931, 0.01171357836574316, -0.1515977382659912, 0.030639035627245903, -0.0021584313362836838, 0.0004413994029164314, 0.04495352879166603]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.9.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001575, Std: 0.039374
     First 10: [0.045741356909275055, 0.010571747086942196, 0.016032230108976364, -0.014087729156017303, -0.01987428590655327, -0.0010112444870173931, 0.026660192757844925, 0.05390277877449989, -0.0020642774179577827, 0.003971022553741932]
     Last 10:  [0.014186738058924675, 0.005833907052874565, 0.006155320908874273, 0.00930024590343237, 0.010828102938830853, 0.008878645487129688, 0.002906620502471924, 0.0022366580087691545, 0.016298720613121986, 0.008661651983857155]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000002
     First 10: [0.0019520741188898683, 0.00707271508872509, -0.003592471592128277, 0.006619387771934271, -0.0050041936337947845, -0.00017479418602306396, -6.922229658812284e-05, -0.00274015124887228, -0.005703026428818703, 0.002619243459776044]
     Last 10:  [0.0068159885704517365, -0.0035373293794691563, -0.011561466380953789, 0.007185519672930241, -0.0020438265055418015, 0.0013081103097647429, -0.005364762619137764, -0.00285441055893898, -0.006607087329030037, 0.0007231872878037393]

================================================================================
159_layers.9.mlp: Gemma3MLP (layers.9.mlp)
================================================================================

  → INPUT[0]: layers.9.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.027625, Std: 3.104226
     First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
     Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001575, Std: 0.039374
     First 10: [0.045741356909275055, 0.010571747086942196, 0.016032230108976364, -0.014087729156017303, -0.01987428590655327, -0.0010112444870173931, 0.026660192757844925, 0.05390277877449989, -0.0020642774179577827, 0.003971022553741932]
     Last 10:  [0.014186738058924675, 0.005833907052874565, 0.006155320908874273, 0.00930024590343237, 0.010828102938830853, 0.008878645487129688, 0.002906620502471924, 0.0022366580087691545, 0.016298720613121986, 0.008661651983857155]
     Zeros: 0, Total: 5376

================================================================================
160_layers.9.post_feedforward_layernorm: Gemma3RMSNorm (layers.9.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.9.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001575, Std: 0.039374
     First 10: [0.045741356909275055, 0.010571747086942196, 0.016032230108976364, -0.014087729156017303, -0.01987428590655327, -0.0010112444870173931, 0.026660192757844925, 0.05390277877449989, -0.0020642774179577827, 0.003971022553741932]
     Last 10:  [0.014186738058924675, 0.005833907052874565, 0.006155320908874273, 0.00930024590343237, 0.010828102938830853, 0.008878645487129688, 0.002906620502471924, 0.0022366580087691545, 0.016298720613121986, 0.008661651983857155]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.9.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 1.487013, Std: 38.032009
     First 10: [28.49126434326172, 8.671907424926758, 0.16775557398796082, -0.061303965747356415, -13.13699722290039, -1.1041773557662964, 0.14295276999473572, 0.10914087295532227, -2.3340344429016113, 5.011218070983887]
     Last 10:  [0.20864500105381012, 0.1285853236913681, 0.04285602644085884, 6.248290061950684, 10.558403015136719, 9.18568229675293, 2.8715615272521973, 0.9648259878158569, 9.390739440917969, 9.8519868850708]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 12.372260
     First 10: [10.107888221740723, 13.628395080566406, -0.8133999109268188, -0.9223973751068115, 10.787817001342773, 18.4720401763916, -0.9043779373168945, -0.963891863822937, 19.163597106933594, 21.504520416259766]
     Last 10:  [-0.7025530338287354, -0.5542247295379639, -0.8591861724853516, 12.587852478027344, 18.721046447753906, 19.924196243286133, 18.980846405029297, 7.724358558654785, 10.652802467346191, 22.00420379638672]

================================================================================
161_layers.10.input_layernorm: Gemma3RMSNorm (layers.10.input_layernorm)
================================================================================

  → INPUT[0]: layers.10.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.673750, Std: 78.747818
     First 10: [135.5008087158203, 4.125401973724365, 0.5327386856079102, -0.41468992829322815, -13.738675117492676, -3.1098318099975586, 0.48511990904808044, -0.47846513986587524, 3.3725647926330566, -0.5904884338378906]
     Last 10:  [-0.18967925012111664, -0.9465539455413818, -0.33888307213783264, 20.874797821044922, -6.451322555541992, 20.187589645385742, -0.26149892807006836, -18.17832374572754, 5.446653366088867, 4.8130621910095215]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.032235, Std: 4.787254
     First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
     Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 26.779985
     First 10: [6.7824015617370605, 11.958724975585938, 92.44446563720703, 140.9332733154297, 14.094599723815918, 9.701221466064453, 80.31151580810547, 82.42394256591797, 8.325969696044922, 8.005438804626465]
     Last 10:  [56.99547576904297, 57.47532653808594, 127.90562438964844, 9.434161186218262, 7.143181800842285, 9.491470336914062, 8.434064865112305, 12.556173324584961, 13.103645324707031, 7.777210712432861]

================================================================================
162_layers.10.self_attn.q_proj: Linear (layers.10.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.10.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.032235, Std: 4.787254
     First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
     Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.018493, Std: 1.657976
     First 10: [-1.0678211450576782, -0.0728258490562439, 0.2084197998046875, -0.5983860492706299, -0.40541839599609375, 0.8403134942054749, 0.176253080368042, 0.6481025815010071, -0.6037862300872803, -2.895703077316284]
     Last 10:  [0.47437429428100586, -0.7743321061134338, 0.18208062648773193, -0.43556734919548035, -0.10939088463783264, -0.34626132249832153, -0.005111187696456909, 0.42120182514190674, -0.26664215326309204, -0.3194923400878906]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000011
     First 10: [0.006821450777351856, 0.011755615472793579, 0.0057063293643295765, 0.005145481787621975, 0.018638987094163895, 0.0007465016096830368, 0.0029132021591067314, -0.006536617875099182, 0.0027961155865341425, 0.0060117472894489765]
     Last 10:  [0.0002021951659116894, 0.01208814699202776, 0.003973974380642176, -0.0017045224085450172, 0.004613627213984728, -0.0034406394697725773, 0.0271659716963768, 0.014221430756151676, -0.016917070373892784, -0.03297099098563194]

================================================================================
163_layers.10.self_attn.k_proj: Linear (layers.10.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.10.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.032235, Std: 4.787254
     First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
     Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.008436, Std: 2.068873
     First 10: [0.5706704258918762, 0.15423715114593506, 0.4762849509716034, 0.536907970905304, -0.32628747820854187, 0.17519299685955048, 0.8784173727035522, 0.6061020493507385, -1.8863917589187622, 0.39095327258110046]
     Last 10:  [1.0912690162658691, 0.3328990042209625, 1.3697811365127563, -0.9509172439575195, -0.9190304279327393, -1.8802253007888794, 0.9496269226074219, -0.019326239824295044, 0.2780712842941284, 2.5585649013519287]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000014
     First 10: [0.01083375047892332, 0.0017700514290481806, -0.0014126446330919862, -0.0014044790295884013, -0.011467043310403824, -0.004786808975040913, -0.00020747166126966476, 0.005275939591228962, -0.0043220240622758865, -0.00829411018639803]
     Last 10:  [-0.016410358250141144, 0.004197095055133104, -0.004300638567656279, 0.0033464310690760612, -0.017504112794995308, 0.020564701408147812, 0.014733375050127506, -0.008996137417852879, 0.016545619815587997, -0.004663729574531317]

================================================================================
164_layers.10.self_attn.v_proj: Linear (layers.10.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.10.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.032235, Std: 4.787254
     First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
     Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.008511, Std: 1.147287
     First 10: [-0.6150282025337219, 1.076550006866455, -0.5600451231002808, -0.01631423830986023, -0.0039937421679496765, 0.7776657342910767, 1.303105354309082, 0.24787095189094543, -0.17604845762252808, -0.26193928718566895]
     Last 10:  [0.04848024621605873, 0.0865318775177002, -0.20355474948883057, 0.32468870282173157, -0.022418759763240814, -0.4204830527305603, -0.026636749505996704, -0.14448118209838867, -0.17191867530345917, -0.0009204372763633728]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000001
     First 10: [0.00010905489762080833, -0.0017139494884759188, -0.004182676784694195, -0.0015147874364629388, 0.012844374403357506, -0.0024036758113652468, -0.003314188215881586, 0.000503372575622052, 0.0014133125077933073, -0.003548126434907317]
     Last 10:  [0.007459294982254505, -0.002120373072102666, 0.0006933259428478777, -0.006115997210144997, -0.002696400973945856, 0.009784095920622349, -0.004332997836172581, 0.003248305758461356, -0.0039273593574762344, 0.013082081452012062]

================================================================================
165_layers.10.self_attn.q_norm: Gemma3RMSNorm (layers.10.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.10.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.018493, Std: 1.657976
     First 10: [-1.0678211450576782, -0.0728258490562439, 0.2084197998046875, -0.5983860492706299, -0.40541839599609375, 0.8403134942054749, 0.176253080368042, 0.6481025815010071, -0.6037862300872803, -2.895703077316284]
     Last 10:  [0.47437429428100586, -0.7743321061134338, 0.18208062648773193, -0.43556734919548035, -0.10939088463783264, -0.34626132249832153, -0.005111187696456909, 0.42120182514190674, -0.26664215326309204, -0.3194923400878906]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.025527, Std: 1.441827
     First 10: [-2.7014760971069336, -0.1867826133966446, 0.4201945662498474, -1.0601913928985596, -0.7861958742141724, 1.4781757593154907, 0.12446189671754837, 0.9691815972328186, -0.41361117362976074, 0.21886485815048218]
     Last 10:  [0.41678810119628906, -0.48910075426101685, 0.10557984560728073, -0.2644821107387543, -0.11311029642820358, -0.13131028413772583, -0.004373955074697733, 0.30115199089050293, -0.22703143954277039, -0.17774012684822083]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.297345
     First 10: [0.7557517290115356, 0.7799646854400635, 0.39917469024658203, 0.22959835827350616, 0.34582263231277466, 0.2208019196987152, -0.5099276900291443, 0.03781968355178833, -0.5245886445045471, -1.0524544715881348]
     Last 10:  [-0.07389915734529495, -0.3342131972312927, -0.388802707195282, -0.35996299982070923, 0.08989603817462921, -0.6002772450447083, -0.09797908365726471, -0.24636751413345337, -0.10252714902162552, -0.41360655426979065]

================================================================================
166_layers.10.self_attn.k_norm: Gemma3RMSNorm (layers.10.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.10.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.008436, Std: 2.068873
     First 10: [0.5706704258918762, 0.15423715114593506, 0.4762849509716034, 0.536907970905304, -0.32628747820854187, 0.17519299685955048, 0.8784173727035522, 0.6061020493507385, -1.8863917589187622, 0.39095327258110046]
     Last 10:  [1.0912690162658691, 0.3328990042209625, 1.3697811365127563, -0.9509172439575195, -0.9190304279327393, -1.8802253007888794, 0.9496269226074219, -0.019326239824295044, 0.2780712842941284, 2.5585649013519287]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.10.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.039321, Std: 2.487803
     First 10: [0.22347848117351532, 0.10667050629854202, 0.328497976064682, 0.303237646818161, -0.17876030504703522, 0.1927831768989563, 1.4777112007141113, 0.4528779983520508, -0.7190179228782654, 0.16522181034088135]
     Last 10:  [1.5787482261657715, 0.7135182619094849, 3.0485377311706543, -2.0072104930877686, -1.1388312578201294, -6.211282253265381, 1.4778177738189697, -0.029452254995703697, 0.37079107761383057, 5.3479790687561035]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 1.076180
     First 10: [-0.3763943910598755, 0.10132385790348053, 0.09831152856349945, -0.1006205603480339, -0.12757043540477753, 0.752314567565918, 1.6788495779037476, 0.18985812366008759, -0.3930296301841736, -0.32701992988586426]
     Last 10:  [0.7840991616249084, 1.6432030200958252, 1.7445955276489258, 1.603083610534668, 0.5281550288200378, 3.073890209197998, 0.9191364049911499, 0.8793563842773438, 0.6444137096405029, 1.577693223953247]

================================================================================
167_layers.10.self_attn.o_proj: Linear (layers.10.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.10.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.005636, Std: 0.639963
     First 10: [-0.6150282025337219, 1.076550006866455, -0.5600451231002808, -0.01631423830986023, -0.0039937421679496765, 0.7776657342910767, 1.303105354309082, 0.24787095189094543, -0.17604845762252808, -0.26193928718566895]
     Last 10:  [-0.22523105144500732, 0.18859215080738068, 0.21379142999649048, 0.019026361405849457, -0.1339663863182068, -0.06691275537014008, -0.15701518952846527, -0.09413884580135345, 0.18972241878509521, -0.028892191126942635]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.003449, Std: 0.323051
     First 10: [-0.01422254741191864, -0.2069137990474701, -0.23555901646614075, -0.3846706748008728, 0.0008076075464487076, 0.05993238463997841, 0.8263041973114014, 0.6470094919204712, -0.2453005611896515, 0.03419297933578491]
     Last 10:  [-0.04648622125387192, 0.07606767117977142, 0.03814473748207092, 0.04050071910023689, -0.05014830827713013, 0.13038089871406555, 0.0059653595089912415, -0.12078195810317993, -0.19959163665771484, 0.11028923094272614]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000006
     First 10: [-0.007911289110779762, 0.0013517620973289013, 0.00028429541271179914, -0.007618587464094162, -0.0024062241427600384, -0.005837937351316214, 0.00914782751351595, 0.010542389936745167, 0.005888552870601416, -0.00962385255843401]
     Last 10:  [-0.003936652094125748, -0.011627467349171638, 0.01544068194925785, -0.0005539476405829191, 0.00527587765827775, 0.003153424710035324, 0.003568518441170454, 0.006883162073791027, 0.006510568782687187, -0.0147935152053833]

================================================================================
168_layers.10.self_attn: Gemma3Attention (layers.10.self_attn)
================================================================================

  → OUTPUT[0]: layers.10.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.003449, Std: 0.323051
     First 10: [-0.01422254741191864, -0.2069137990474701, -0.23555901646614075, -0.3846706748008728, 0.0008076075464487076, 0.05993238463997841, 0.8263041973114014, 0.6470094919204712, -0.2453005611896515, 0.03419297933578491]
     Last 10:  [-0.04648622125387192, 0.07606767117977142, 0.03814473748207092, 0.04050071910023689, -0.05014830827713013, 0.13038089871406555, 0.0059653595089912415, -0.12078195810317993, -0.19959163665771484, 0.11028923094272614]
     Zeros: 0, Total: 5376

================================================================================
169_layers.10.post_attention_layernorm: Gemma3RMSNorm (layers.10.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.10.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.003449, Std: 0.323051
     First 10: [-0.01422254741191864, -0.2069137990474701, -0.23555901646614075, -0.3846706748008728, 0.0008076075464487076, 0.05993238463997841, 0.8263041973114014, 0.6470094919204712, -0.2453005611896515, 0.03419297933578491]
     Last 10:  [-0.04648622125387192, 0.07606767117977142, 0.03814473748207092, 0.04050071910023689, -0.05014830827713013, 0.13038089871406555, 0.0059653595089912415, -0.12078195810317993, -0.19959163665771484, 0.11028923094272614]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.646258, Std: 22.548883
     First 10: [-0.3770410418510437, -43.31430435180664, 0.062326934188604355, -0.06573646515607834, 0.03056534379720688, 4.2708740234375, -0.1401454210281372, 0.06057007983326912, -17.10334587097168, 3.1395158767700195]
     Last 10:  [-0.010127308778464794, 0.03528875857591629, -0.01420315820723772, 1.891629934310913, -5.118750095367432, 19.320446014404297, 0.5046502351760864, -3.964210033416748, -8.750176429748535, 11.845114707946777]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 18.129446
     First 10: [7.25770902633667, 64.20640563964844, -1.082418441772461, -0.9467688798904419, 10.789008140563965, 21.197473526000977, -1.0528308153152466, -0.9708394408226013, 20.71855354309082, 27.60053062438965]
     Last 10:  [-0.9422985315322876, -0.8771278858184814, -1.0986205339431763, 11.370593070983887, 26.034896850585938, 38.24824523925781, 21.406341552734375, 7.693039894104004, 10.61158561706543, 27.446130752563477]

================================================================================
170_layers.10.pre_feedforward_layernorm: Gemma3RMSNorm (layers.10.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.10.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.027492, Std: 69.936043
     First 10: [135.12376403808594, -39.18890380859375, 0.5950655937194824, -0.4804264008998871, -13.708109855651855, 1.1610422134399414, 0.34497448801994324, -0.41789504885673523, -13.730781555175781, 2.549027442932129]
     Last 10:  [-0.1998065561056137, -0.9112651944160461, -0.3530862331390381, 22.766427993774414, -11.570072174072266, 39.508033752441406, 0.24315130710601807, -22.142534255981445, -3.303523063659668, 16.65817642211914]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.022425, Std: 1.806885
     First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
     Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 10.723625
     First 10: [1.9986422061920166, 1.2624082565307617, 30.873512268066406, 34.05863952636719, 4.425259590148926, 2.6085124015808105, 26.927181243896484, 26.539653778076172, 2.418611526489258, 2.0922274589538574]
     Last 10:  [31.912044525146484, 30.207733154296875, 37.68935775756836, 2.9622509479522705, 2.269251823425293, 2.205892562866211, 2.422727108001709, 4.746851921081543, 4.252186298370361, 1.912212610244751]

================================================================================
171_layers.10.mlp.gate_proj: Linear (layers.10.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.10.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.022425, Std: 1.806885
     First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
     Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.142018, Std: 0.405221
     First 10: [0.08816401660442352, -0.0607757605612278, -0.10053574293851852, -0.14158545434474945, 0.08552953600883484, -0.216712087392807, -0.06933435052633286, -0.017048589885234833, -0.14203928411006927, -0.14726318418979645]
     Last 10:  [-0.08458366990089417, 0.08225631713867188, 0.3171066343784332, -0.2373175472021103, -0.298464834690094, 0.057482603937387466, 0.015380747616291046, -0.2755654454231262, -0.3339303135871887, -0.20978350937366486]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000031
     First 10: [0.01214195229113102, -0.001878618961200118, -0.005187781993299723, 0.00608417484909296, -0.008946138434112072, -0.0059172967448830605, 0.006240042857825756, 0.00284670596010983, -0.0016439284663647413, -0.011576180346310139]
     Last 10:  [-0.01358748972415924, 0.0049093132838606834, 0.0021807109005749226, 0.010074988007545471, -0.0056709726341068745, -0.00820404477417469, -0.0022291908971965313, 0.005762371700257063, -0.003772652242332697, -0.006758388131856918]

================================================================================
172_layers.10.mlp.act_fn: PytorchGELUTanh (layers.10.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.10.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.142018, Std: 0.405221
     First 10: [0.08816401660442352, -0.0607757605612278, -0.10053574293851852, -0.14158545434474945, 0.08552953600883484, -0.216712087392807, -0.06933435052633286, -0.017048589885234833, -0.14203928411006927, -0.14726318418979645]
     Last 10:  [-0.08458366990089417, 0.08225631713867188, 0.3171066343784332, -0.2373175472021103, -0.298464834690094, 0.057482603937387466, 0.015380747616291046, -0.2755654454231262, -0.3339303135871887, -0.20978350937366486]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.10.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.011080, Std: 0.139327
     First 10: [0.04717891290783882, -0.028915222734212875, -0.046242404729127884, -0.062822125852108, 0.04567958042025566, -0.08976639807224274, -0.03275090456008911, -0.008408346213400364, -0.06299803406000137, -0.06501127034425735]
     Last 10:  [-0.0394410602748394, 0.04382438585162163, 0.19800420105457306, -0.09640063345432281, -0.11421724408864975, 0.03005877695977688, 0.007784746587276459, -0.10786939412355423, -0.12329622358083725, -0.08746320754289627]
     Zeros: 0, Total: 8064

================================================================================
173_layers.10.mlp.up_proj: Linear (layers.10.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.10.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.022425, Std: 1.806885
     First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
     Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.003523, Std: 0.297430
     First 10: [-0.07381104677915573, -0.20803222060203552, 0.21475844085216522, -0.12599027156829834, -0.07823003828525543, -0.008628346025943756, -0.14163535833358765, 0.01524711400270462, -0.07757746428251266, -0.007031451910734177]
     Last 10:  [-0.02409861423075199, -0.22197870910167694, 0.34128910303115845, -0.2067723423242569, -0.2064887434244156, -0.06914513558149338, -0.10537631809711456, -0.07425980269908905, -0.038289640098810196, -0.1352376639842987]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000006
     First 10: [0.016246547922492027, -0.007046476937830448, -0.0014547514729201794, -0.0005722185014747083, 0.006120380479842424, -0.001819445053115487, 0.0042997440323233604, 0.0008005886920727789, 0.010987993329763412, -0.0073397522792220116]
     Last 10:  [-0.010917400941252708, 0.00883389450609684, -0.007561166770756245, -0.011265136301517487, -0.010127115063369274, 0.003683696500957012, -0.0022807030472904444, 0.0011142718140035868, -0.002146234270185232, -0.010256008245050907]

================================================================================
174_layers.10.mlp.down_proj: Linear (layers.10.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.10.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000449, Std: 0.048832
     First 10: [-0.003482325002551079, 0.006015297956764698, -0.009930946864187717, 0.00791497714817524, -0.0035735152196139097, 0.0007745355251245201, 0.0046386863104999065, -0.000128203013446182, 0.004887227900326252, 0.0004571236204355955]
     Last 10:  [0.0009504748741164804, -0.009728080593049526, 0.06757667660713196, 0.019932985305786133, 0.023584574460983276, -0.002078418154269457, -0.0008203279576264322, 0.008010359480977058, 0.004720968194305897, 0.011828320100903511]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.10.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000543, Std: 0.013593
     First 10: [0.010458292439579964, 0.000565237132832408, -0.001533660339191556, 0.010764668695628643, -0.0020619195420295, 0.0011394532630220056, 0.006673688068985939, 0.004166203085333109, 0.006167241837829351, 0.0011687192600220442]
     Last 10:  [0.0003994796425104141, 0.0008639742154628038, -0.004224345553666353, 0.0021077936980873346, -0.002784663811326027, 0.001395173603668809, 0.0002562707522884011, -0.0025051215197890997, 0.0015519093722105026, -0.0022064035292714834]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000000
     First 10: [-0.009458662942051888, -0.00016062533541116863, -0.007927054539322853, -0.0018356300424784422, -0.0027776139322668314, 0.004351356998085976, 0.003689988050609827, 0.001667217118665576, -0.0008611830417066813, 0.009887046180665493]
     Last 10:  [0.0033950116485357285, -0.004929863382130861, 0.008388256654143333, 0.0002777553163468838, 0.0036399629898369312, 6.154657603474334e-05, 0.003885901067405939, 0.0010138950310647488, -0.003213191870599985, -0.009673907421529293]

================================================================================
175_layers.10.mlp: Gemma3MLP (layers.10.mlp)
================================================================================

  → INPUT[0]: layers.10.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.022425, Std: 1.806885
     First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
     Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000543, Std: 0.013593
     First 10: [0.010458292439579964, 0.000565237132832408, -0.001533660339191556, 0.010764668695628643, -0.0020619195420295, 0.0011394532630220056, 0.006673688068985939, 0.004166203085333109, 0.006167241837829351, 0.0011687192600220442]
     Last 10:  [0.0003994796425104141, 0.0008639742154628038, -0.004224345553666353, 0.0021077936980873346, -0.002784663811326027, 0.001395173603668809, 0.0002562707522884011, -0.0025051215197890997, 0.0015519093722105026, -0.0022064035292714834]
     Zeros: 0, Total: 5376

================================================================================
176_layers.10.post_feedforward_layernorm: Gemma3RMSNorm (layers.10.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.10.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000543, Std: 0.013593
     First 10: [0.010458292439579964, 0.000565237132832408, -0.001533660339191556, 0.010764668695628643, -0.0020619195420295, 0.0011394532630220056, 0.006673688068985939, 0.004166203085333109, 0.006167241837829351, 0.0011687192600220442]
     Last 10:  [0.0003994796425104141, 0.0008639742154628038, -0.004224345553666353, 0.0021077936980873346, -0.002784663811326027, 0.001395173603668809, 0.0002562707522884011, -0.0025051215197890997, 0.0015519093722105026, -0.0022064035292714834]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.10.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.328299, Std: 37.294270
     First 10: [34.12296676635742, 3.6017274856567383, -0.04993508756160736, -0.012380721047520638, -7.4208784103393555, 7.338292598724365, 0.2408878058195114, 0.09581567347049713, 39.18910217285156, 8.297354698181152]
     Last 10:  [0.04290032386779785, 0.14453132450580597, -0.21473000943660736, 12.157130241394043, -27.347509384155273, 17.710033416748047, 2.6461753845214844, -10.201940536499023, 8.61826229095459, -26.83121681213379]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 18.728531
     First 10: [14.408260345458984, 29.091773986816406, -0.8462396860122681, -1.0054314136505127, 15.996175765991211, 29.413480758666992, -0.829542338848114, -0.8913915157318115, 29.008338928222656, 32.527183532714844]
     Last 10:  [-0.6748766899108887, -0.4935421049594879, -0.8461081981658936, 16.461645126342773, 28.732208251953125, 37.430259704589844, 30.26091766357422, 11.329236030578613, 15.812625885009766, 35.81608200073242]

================================================================================
177_layers.11.input_layernorm: Gemma3RMSNorm (layers.11.input_layernorm)
================================================================================

  → INPUT[0]: layers.11.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.355791, Std: 82.082832
     First 10: [169.24673461914062, -35.58717727661133, 0.5451304912567139, -0.4928071200847626, -21.12898826599121, 8.499334335327148, 0.5858622789382935, -0.3220793604850769, 25.45832061767578, 10.846382141113281]
     Last 10:  [-0.15690623223781586, -0.7667338848114014, -0.5678162574768066, 34.92355728149414, -38.917579650878906, 57.21806716918945, 2.889326572418213, -32.34447479248047, 5.314739227294922, -10.173040390014648]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.006655, Std: 1.573720
     First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
     Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 18.237368
     First 10: [0.7508485317230225, 0.6974968910217285, 70.41297912597656, 85.42329406738281, 0.38698750734329224, 0.014856408350169659, 71.59649658203125, 69.467041015625, -0.0843995064496994, -0.04669782891869545]
     Last 10:  [64.70891571044922, 49.912193298339844, 85.66531372070312, 0.5800476670265198, 0.6667475700378418, 0.24994701147079468, -0.1609935313463211, 1.7740001678466797, 0.4690907597541809, -0.07349638640880585]

================================================================================
178_layers.11.self_attn.q_proj: Linear (layers.11.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.11.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.006655, Std: 1.573720
     First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
     Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001039, Std: 0.611310
     First 10: [-0.09156732261180878, 0.3459119200706482, 0.19846586883068085, -0.48402148485183716, -0.23424744606018066, 0.19631995260715485, 0.04110550880432129, 0.23962023854255676, -0.30840134620666504, 0.15131571888923645]
     Last 10:  [0.26486700773239136, 0.24146471917629242, -0.4796066880226135, 0.42644205689430237, 0.43191808462142944, -0.3650445342063904, -0.37736809253692627, 0.23516127467155457, 0.2788996696472168, 0.1399633288383484]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000003
     First 10: [0.01984897442162037, 0.0049714334309101105, -0.001989500131458044, 0.0077314116060733795, -0.013953017070889473, -0.02266821824014187, -0.006855143699795008, 0.009309770539402962, -0.03766685724258423, -0.01603219285607338]
     Last 10:  [-0.0008237573783844709, 0.0005622982862405479, -0.015015695244073868, 0.007652820087969303, 0.011945512145757675, 0.006604851223528385, 0.006579617969691753, 0.0028965589590370655, 0.01082751713693142, -0.00440725963562727]

================================================================================
179_layers.11.self_attn.k_proj: Linear (layers.11.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.11.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.006655, Std: 1.573720
     First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
     Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.027585, Std: 0.472891
     First 10: [0.046045608818531036, 0.1744554191827774, 0.012274806387722492, 0.2555646300315857, 0.1650231033563614, 0.09937448799610138, 0.10243315994739532, 0.15716998279094696, -0.03965344280004501, -0.03249487280845642]
     Last 10:  [0.19297710061073303, -0.05566868185997009, -1.6119849681854248, 1.1931569576263428, 1.0026549100875854, -1.2613270282745361, -1.1065199375152588, 0.5563743114471436, 1.1152448654174805, 0.9930656552314758]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000011
     First 10: [0.007887505926191807, 0.002174019580706954, -0.004072722513228655, -0.0012180425692349672, -0.007265853229910135, -0.012934406287968159, -0.000785638636443764, -0.001615868415683508, -0.014060040935873985, -0.021006222814321518]
     Last 10:  [-0.007659364026039839, -0.0027074841782450676, -0.02087920904159546, -0.002622318686917424, 0.016980474814772606, -0.011879884637892246, -0.0018181473715230823, -0.011682894080877304, 0.004060067236423492, -0.002697451040148735]

================================================================================
180_layers.11.self_attn.v_proj: Linear (layers.11.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.11.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.006655, Std: 1.573720
     First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
     Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.001210, Std: 0.330970
     First 10: [-0.15349380671977997, 0.00564942229539156, -0.005607791244983673, 0.0222473181784153, 0.05821211263537407, -0.056732892990112305, -0.18139448761940002, -0.012423541396856308, 0.08332851529121399, 0.06380753964185715]
     Last 10:  [-0.3696819543838501, 0.11895468831062317, 0.1926790177822113, 0.2663939297199249, -0.2067018449306488, -0.058590829372406006, 0.03164631128311157, 0.1266070455312729, 0.14239056408405304, -0.2026577591896057]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000010
     First 10: [-0.0009571445407345891, -0.014393722638487816, -0.00411500409245491, -0.0062153879553079605, 0.0026901382952928543, -0.001535983756184578, -0.00774643337354064, 0.003883540164679289, -0.002175134140998125, 0.00716797262430191]
     Last 10:  [-0.0018691879231482744, 0.006158589851111174, -0.002620966173708439, 0.003949970938265324, -0.003644402604550123, -0.0021560078021138906, 0.009214893914759159, 0.0041122036054730415, -0.0009029111824929714, -0.004654512740671635]

================================================================================
181_layers.11.self_attn.q_norm: Gemma3RMSNorm (layers.11.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.11.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.001039, Std: 0.611310
     First 10: [-0.09156732261180878, 0.3459119200706482, 0.19846586883068085, -0.48402148485183716, -0.23424744606018066, 0.19631995260715485, 0.04110550880432129, 0.23962023854255676, -0.30840134620666504, 0.15131571888923645]
     Last 10:  [0.26486700773239136, 0.24146471917629242, -0.4796066880226135, 0.42644205689430237, 0.43191808462142944, -0.3650445342063904, -0.37736809253692627, 0.23516127467155457, 0.2788996696472168, 0.1399633288383484]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.022283, Std: 1.210421
     First 10: [-0.8192920088768005, -0.04526694118976593, 4.827511787414551, 0.056779589504003525, 0.04163285717368126, 2.775134563446045, 0.9300568103790283, 3.391101598739624, -0.04886486008763313, 0.041965629905462265]
     Last 10:  [0.3099839985370636, 0.3441033363342285, -0.760554313659668, 4.6932291984558105, 0.45289933681488037, -0.49922868609428406, -0.40257394313812256, 0.22047704458236694, 0.4309048354625702, 0.20892184972763062]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.380387
     First 10: [0.5239938497543335, -1.022289514541626, 3.1430721282958984, -1.019980788230896, -1.030272364616394, 1.4077123403549194, 2.853847026824951, 1.4104732275009155, -0.9730123281478882, -0.9527616500854492]
     Last 10:  [-0.6617087125778198, -0.5880783796310425, -0.5416213274002075, 2.181201219558716, -0.6969043612480164, -0.6046943068504333, -0.691638708114624, -0.7289952039718628, -0.5534061193466187, -0.5685316324234009]

================================================================================
182_layers.11.self_attn.k_norm: Gemma3RMSNorm (layers.11.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.11.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.027585, Std: 0.472891
     First 10: [0.046045608818531036, 0.1744554191827774, 0.012274806387722492, 0.2555646300315857, 0.1650231033563614, 0.09937448799610138, 0.10243315994739532, 0.15716998279094696, -0.03965344280004501, -0.03249487280845642]
     Last 10:  [0.19297710061073303, -0.05566868185997009, -1.6119849681854248, 1.1931569576263428, 1.0026549100875854, -1.2613270282745361, -1.1065199375152588, 0.5563743114471436, 1.1152448654174805, 0.9930656552314758]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.11.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.401193, Std: 6.568158
     First 10: [0.2812678813934326, 0.003122471971437335, 0.05148325860500336, 0.09161295741796494, 0.017753679305315018, 0.37447667121887207, 0.38712987303733826, 0.5596069693565369, -0.0033908409532159567, 0.007323098368942738]
     Last 10:  [4.315730094909668, -1.1337100267410278, -30.22579574584961, 5.5522966384887695, 24.085351943969727, -25.227201461791992, -29.137876510620117, 13.677152633666992, 20.990201950073242, 18.690034866333008]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 1.479310
     First 10: [0.5159820914268494, -0.9955580234527588, 0.04091086611151695, -0.9110351800918579, -0.9733003377914429, -0.06478378921747208, -0.06205305829644203, -0.11635936796665192, -0.9787778854370117, -1.0559296607971191]
     Last 10:  [9.008038520812988, 8.113633155822754, 7.3910675048828125, 1.082454800605774, 9.749839782714844, 7.950387954711914, 10.784173965454102, 10.000922203063965, 7.422613143920898, 7.422337532043457]

================================================================================
183_layers.11.self_attn.o_proj: Linear (layers.11.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.11.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000596, Std: 0.264628
     First 10: [-0.15349380671977997, 0.00564942229539156, -0.005607791244983673, 0.0222473181784153, 0.05821211263537407, -0.056732892990112305, -0.18139448761940002, -0.012423541396856308, 0.08332851529121399, 0.06380753964185715]
     Last 10:  [-0.3667054772377014, 0.11834569275379181, 0.18895280361175537, 0.2649455964565277, -0.20332516729831696, -0.05846085026860237, 0.031943388283252716, 0.12683136761188507, 0.14136430621147156, -0.20110945403575897]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000446, Std: 0.098691
     First 10: [-0.02052891254425049, -0.004613460972905159, 0.040831632912158966, -0.16776414215564728, -0.00996142253279686, -0.008936421945691109, -0.030869871377944946, -0.004106689244508743, 0.00041606929153203964, -0.027991265058517456]
     Last 10:  [-0.04314298927783966, -0.0048136040568351746, 0.43728044629096985, -0.027412191033363342, 0.09565167129039764, -0.04336071014404297, -0.023723481222987175, 0.0534840002655983, 0.025535201653838158, 0.02990374155342579]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000035
     First 10: [-0.0044518038630485535, 0.0009826968889683485, 0.0008415853371843696, 0.0034696380607783794, -0.0022713730577379465, -0.011722220107913017, 0.0008133512455970049, -0.00675827544182539, -0.0047237384133040905, 0.001252523623406887]
     Last 10:  [-0.010870401747524738, 0.0018172685522586107, 6.709759327350184e-05, 0.004105191212147474, 0.0159895122051239, -0.011970365419983864, -0.0006198689807206392, 0.002038558479398489, -0.002101295627653599, 0.0006996270967647433]

================================================================================
184_layers.11.self_attn: Gemma3Attention (layers.11.self_attn)
================================================================================

  → OUTPUT[0]: layers.11.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000446, Std: 0.098691
     First 10: [-0.02052891254425049, -0.004613460972905159, 0.040831632912158966, -0.16776414215564728, -0.00996142253279686, -0.008936421945691109, -0.030869871377944946, -0.004106689244508743, 0.00041606929153203964, -0.027991265058517456]
     Last 10:  [-0.04314298927783966, -0.0048136040568351746, 0.43728044629096985, -0.027412191033363342, 0.09565167129039764, -0.04336071014404297, -0.023723481222987175, 0.0534840002655983, 0.025535201653838158, 0.02990374155342579]
     Zeros: 0, Total: 5376

================================================================================
185_layers.11.post_attention_layernorm: Gemma3RMSNorm (layers.11.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.11.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000446, Std: 0.098691
     First 10: [-0.02052891254425049, -0.004613460972905159, 0.040831632912158966, -0.16776414215564728, -0.00996142253279686, -0.008936421945691109, -0.030869871377944946, -0.004106689244508743, 0.00041606929153203964, -0.027991265058517456]
     Last 10:  [-0.04314298927783966, -0.0048136040568351746, 0.43728044629096985, -0.027412191033363342, 0.09565167129039764, -0.04336071014404297, -0.023723481222987175, 0.0534840002655983, 0.025535201653838158, 0.02990374155342579]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.689809, Std: 33.282619
     First 10: [-9.178921699523926, -6.560518264770508, 0.0027526868507266045, 0.11581756919622421, -3.2563059329986572, -6.331864833831787, -0.00954048614948988, -0.004173110239207745, 0.2813100516796112, -21.94794273376465]
     Last 10:  [-0.4141189157962799, -0.09490440785884857, -0.048198848962783813, -3.7988693714141846, 44.4823112487793, -20.178651809692383, -4.809895992279053, 7.430749416351318, 3.15907883644104, 10.2652006149292]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 25.808859
     First 10: [19.01253890991211, 62.64844512939453, -0.9969825744628906, -1.0308995246887207, 13.63121223449707, 30.713520050048828, -0.9861671328544617, -0.9545174837112427, 29.261890411376953, 34.0952033996582]
     Last 10:  [0.1317395567893982, 1.3245972394943237, -1.012995958328247, 15.339632987976074, 53.83103942871094, 53.869049072265625, 22.905012130737305, 15.381000518798828, 13.586559295654297, 39.47376251220703]

================================================================================
186_layers.11.pre_feedforward_layernorm: Gemma3RMSNorm (layers.11.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.11.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 1.045600, Std: 88.690735
     First 10: [160.06781005859375, -42.14769744873047, 0.547883152961731, -0.37698954343795776, -24.38529396057129, 2.1674695014953613, 0.5763217806816101, -0.32625246047973633, 25.7396297454834, -11.101560592651367]
     Last 10:  [-0.5710251331329346, -0.8616383075714111, -0.6160150766372681, 31.12468719482422, 5.564731597900391, 37.03941345214844, -1.9205694198608398, -24.913724899291992, 8.473817825317383, 0.09216022491455078]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.029638, Std: 1.885465
     First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
     Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 20.641964
     First 10: [2.33691143989563, 0.47163277864456177, 80.19587707519531, 87.29922485351562, 4.1694183349609375, 1.5999298095703125, 76.67972564697266, 72.95740509033203, 1.5988001823425293, 1.3986085653305054]
     Last 10:  [64.50140380859375, 58.59003448486328, 84.26722717285156, 2.7605807781219482, -0.046750664710998535, 0.3713192343711853, 1.9117435216903687, 4.0637102127075195, 4.09044075012207, 1.0391888618469238]

================================================================================
187_layers.11.mlp.gate_proj: Linear (layers.11.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.11.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.029638, Std: 1.885465
     First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
     Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.022888, Std: 0.415940
     First 10: [0.03617463633418083, -0.10488053411245346, 0.24704128503799438, 0.0035113394260406494, 0.10809838771820068, 0.19250638782978058, -0.13973060250282288, -0.03689698129892349, 0.07491662353277206, -0.10153275728225708]
     Last 10:  [-0.10446126013994217, -0.061193808913230896, 0.3088166117668152, -0.19580431282520294, -0.1983404904603958, -0.015726163983345032, 0.12720420956611633, 0.15382327139377594, 0.039929959923028946, -0.34532269835472107]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000004
     First 10: [-0.0006638994673267007, -0.004509840626269579, 0.0005897459923289716, -0.0009499017614871264, -0.0003750637115444988, -0.0032061832025647163, -0.004740110132843256, -0.0041680834256112576, 0.0007579296361654997, -0.0020463247783482075]
     Last 10:  [-0.002227796008810401, 0.0025464524514973164, 0.0019875371363013983, 0.005302206613123417, 0.004535471089184284, -0.001472753705456853, -0.002176073146983981, 0.0037376603577286005, -0.0005761939100921154, -0.0035322108305990696]

================================================================================
188_layers.11.mlp.act_fn: PytorchGELUTanh (layers.11.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.11.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.022888, Std: 0.415940
     First 10: [0.03617463633418083, -0.10488053411245346, 0.24704128503799438, 0.0035113394260406494, 0.10809838771820068, 0.19250638782978058, -0.13973060250282288, -0.03689698129892349, 0.07491662353277206, -0.10153275728225708]
     Last 10:  [-0.10446126013994217, -0.061193808913230896, 0.3088166117668152, -0.19580431282520294, -0.1983404904603958, -0.015726163983345032, 0.12720420956611633, 0.15382327139377594, 0.039929959923028946, -0.34532269835472107]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.11.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.049827, Std: 0.236241
     First 10: [0.018609261140227318, -0.04806000366806984, 0.1476212739944458, 0.0017605884931981564, 0.05870182812213898, 0.11094623059034348, -0.062101490795612335, -0.017905499786138535, 0.03969527408480644, -0.046660810708999634]
     Last 10:  [-0.04788525402545929, -0.029103929176926613, 0.1918555349111557, -0.08270462602376938, -0.08357906341552734, -0.0077644228003919125, 0.07003990560770035, 0.08631397038698196, 0.020600885152816772, -0.12602148950099945]
     Zeros: 0, Total: 8064

================================================================================
189_layers.11.mlp.up_proj: Linear (layers.11.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.11.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.029638, Std: 1.885465
     First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
     Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000341, Std: 0.319445
     First 10: [0.1178276538848877, -0.1282694935798645, 0.10161206871271133, -0.06015774607658386, 0.03943557292222977, 0.11978377401828766, 0.06380180269479752, 0.0325949490070343, -0.07597626000642776, 0.20454417169094086]
     Last 10:  [-0.08025982975959778, 0.14978045225143433, -0.14887215197086334, -0.19248171150684357, -0.09445177763700485, 0.3154454231262207, -0.288366436958313, -0.004110246896743774, 0.017934367060661316, 0.2301751673221588]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000008
     First 10: [-0.0024525208864361048, -0.007171991281211376, 0.005621954798698425, 0.00347306951880455, -0.003941167611628771, -0.0029986293520778418, -0.0005876144277863204, 0.0053661721758544445, 0.0003620467323344201, -0.0011035744100809097]
     Last 10:  [-0.0020039051305502653, -0.006772727705538273, -0.0031456430442631245, -0.0013720376882702112, 0.0025235533248633146, -0.0057355971075594425, -0.005433680023998022, 0.004766011610627174, -0.010732513852417469, -0.0006964812055230141]

================================================================================
190_layers.11.mlp.down_proj: Linear (layers.11.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.11.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000679, Std: 0.082805
     First 10: [0.0021926856134086847, 0.006164632271975279, 0.015000103041529655, -0.00010591303725959733, 0.0023149403277784586, 0.0132895577698946, -0.003962187096476555, -0.0005836288328282535, -0.0030158984009176493, -0.009544196538627148]
     Last 10:  [0.0038432623259723186, -0.004359199665486813, -0.028561946004629135, 0.01591912843286991, 0.007894190959632397, -0.002449251711368561, -0.020197158679366112, -0.00035477173514664173, 0.00036946384352631867, -0.029007017612457275]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.11.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000539, Std: 0.020795
     First 10: [0.0018350998871028423, 7.917040056781843e-05, 0.0012390915071591735, -0.002071141032502055, -0.0012225244427099824, 0.003739813808351755, -0.0016483452636748552, -0.0019259187392890453, -0.003110730554908514, 0.0020603295415639877]
     Last 10:  [-0.0008136935066431761, -0.0024531472008675337, -0.010591590777039528, -7.204432040452957e-05, 0.0062161823734641075, 0.003502915147691965, 0.004403927829116583, 0.005129925906658173, -0.004834230989217758, -0.005289529450237751]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000009
     First 10: [0.0008735087467357516, 0.006673682481050491, -0.001902528339996934, 0.00014903822739142925, 0.007538521662354469, -0.0006319123785942793, 0.0010130524169653654, -0.0006406091270036995, 0.0022237980738282204, -0.0035308822989463806]
     Last 10:  [0.007157539948821068, 0.0008576714899390936, 0.003458276391029358, -0.0056354813277721405, -0.0030589140951633453, 0.0020291227847337723, 0.0029276625718921423, -0.0015268860151991248, 0.0066159009002149105, 0.005444918293505907]

================================================================================
191_layers.11.mlp: Gemma3MLP (layers.11.mlp)
================================================================================

  → INPUT[0]: layers.11.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.029638, Std: 1.885465
     First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
     Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000539, Std: 0.020795
     First 10: [0.0018350998871028423, 7.917040056781843e-05, 0.0012390915071591735, -0.002071141032502055, -0.0012225244427099824, 0.003739813808351755, -0.0016483452636748552, -0.0019259187392890453, -0.003110730554908514, 0.0020603295415639877]
     Last 10:  [-0.0008136935066431761, -0.0024531472008675337, -0.010591590777039528, -7.204432040452957e-05, 0.0062161823734641075, 0.003502915147691965, 0.004403927829116583, 0.005129925906658173, -0.004834230989217758, -0.005289529450237751]
     Zeros: 0, Total: 5376

================================================================================
192_layers.11.post_feedforward_layernorm: Gemma3RMSNorm (layers.11.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.11.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000539, Std: 0.020795
     First 10: [0.0018350998871028423, 7.917040056781843e-05, 0.0012390915071591735, -0.002071141032502055, -0.0012225244427099824, 0.003739813808351755, -0.0016483452636748552, -0.0019259187392890453, -0.003110730554908514, 0.0020603295415639877]
     Last 10:  [-0.0008136935066431761, -0.0024531472008675337, -0.010591590777039528, -7.204432040452957e-05, 0.0062161823734641075, 0.003502915147691965, 0.004403927829116583, 0.005129925906658173, -0.004834230989217758, -0.005289529450237751]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.11.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 2.304401, Std: 74.105316
     First 10: [10.505766868591309, 0.9498871564865112, 1.3887830972671509, -2.1586830615997314, -5.487325668334961, 29.72430419921875, -2.0400543212890625, -2.12039852142334, -24.925981521606445, 17.8207950592041]
     Last 10:  [-0.5759255886077881, -1.8118822574615479, -7.454408168792725, -0.21545833349227905, 39.34021759033203, 27.131750106811523, 22.58598518371582, 12.515430450439453, -13.679925918579102, -33.960350036621094]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 28.846571
     First 10: [23.601564407348633, 50.558921813964844, 3.8164350986480713, 3.4789257049560547, 18.28847312927246, 33.1551628112793, 4.318488121032715, 3.731231212615967, 33.43376541137695, 36.16935729980469]
     Last 10:  [3.7289366722106934, 3.9347407817840576, 3.7022957801818848, 18.981197357177734, 41.28350830078125, 50.7495002746582, 33.265480041503906, 15.300189971923828, 17.906639099121094, 41.89563751220703]

================================================================================
193_layers.12.input_layernorm: Gemma3RMSNorm (layers.12.input_layernorm)
================================================================================

  → INPUT[0]: layers.12.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 3.350000, Std: 135.506973
     First 10: [170.57357788085938, -41.197811126708984, 1.9366662502288818, -2.535672664642334, -29.87261962890625, 31.891773223876953, -1.4637324810028076, -2.446650981903076, 0.8136482238769531, 6.719234466552734]
     Last 10:  [-1.1469507217407227, -2.673520565032959, -8.070423126220703, 30.909229278564453, 44.90494918823242, 64.1711654663086, 20.665416717529297, -12.398294448852539, -5.206108093261719, -33.86819076538086]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.047915, Std: 3.885965
     First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
     Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 26.468756
     First 10: [6.651108741760254, 6.9314961433410645, 68.99244689941406, 79.47562408447266, 13.833049774169922, 7.620536804199219, 67.08609008789062, 66.822265625, 7.609445571899414, 7.070932388305664]
     Last 10:  [62.767372131347656, 84.24502563476562, 69.49029541015625, 11.100231170654297, 3.981511116027832, 3.5871739387512207, 7.947286605834961, 12.957664489746094, 13.936573028564453, 5.964159965515137]

================================================================================
194_layers.12.self_attn.q_proj: Linear (layers.12.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.12.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.047915, Std: 3.885965
     First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
     Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012480, Std: 1.535521
     First 10: [-0.804032564163208, 0.37707000970840454, -0.8528565764427185, -0.40152794122695923, 3.8703808784484863, 0.5866332054138184, -2.3382296562194824, 0.747713565826416, 0.298966646194458, 3.5231122970581055]
     Last 10:  [-1.9151663780212402, 0.5873419642448425, 0.12516561150550842, 0.03597442805767059, -0.00978928804397583, -0.42343395948410034, -0.42343905568122864, 0.2664339244365692, 0.9900935292243958, -1.9853806495666504]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000000
     First 10: [0.00894941296428442, 0.0034465272910892963, -0.0026616263203322887, 0.004264826886355877, -0.008493619039654732, 0.0017269258387386799, -0.0015320719685405493, -0.011955060064792633, -0.011807970702648163, 0.004879599902778864]
     Last 10:  [-0.01259261928498745, -0.0029184494633227587, -0.003144005313515663, 0.0036001820117235184, 0.0019454762805253267, -0.006841837428510189, 0.011380555108189583, -0.0075241755694150925, 0.0014839016366750002, -0.005345487967133522]

================================================================================
195_layers.12.self_attn.k_proj: Linear (layers.12.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.12.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.047915, Std: 3.885965
     First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
     Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.007322, Std: 1.416668
     First 10: [0.2104572355747223, -0.019714832305908203, 0.3573058843612671, 0.12048636376857758, -0.6234138011932373, -0.08012927323579788, -3.7463607788085938, -0.5013067126274109, 0.05337300896644592, 1.600102424621582]
     Last 10:  [-5.884676933288574, 2.2959229946136475, 1.233973503112793, -1.0790659189224243, -1.9169360399246216, -0.6775946021080017, -0.9330291152000427, 2.7042794227600098, 1.749098777770996, -0.5477821826934814]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000015
     First 10: [0.0017489560414105654, -0.00676166033372283, 0.010920201428234577, -0.008439489640295506, 0.011813688091933727, -0.0012507782084867358, 0.0007416579755954444, 0.005644222255796194, 0.0035445685498416424, 0.002297724597156048]
     Last 10:  [0.007438287138938904, 0.0041683451272547245, -0.0007983963587321341, -0.0025568450801074505, 0.0014203558675944805, 0.0021630635019391775, 0.0031095542944967747, -0.002238270826637745, 0.012339434586465359, 0.003668098244816065]

================================================================================
196_layers.12.self_attn.v_proj: Linear (layers.12.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.12.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.047915, Std: 3.885965
     First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
     Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.013955, Std: 0.862566
     First 10: [0.02118532359600067, -0.34404104948043823, -0.04512466490268707, -0.03596951812505722, 0.062094204127788544, 0.47610732913017273, 0.3312092423439026, -0.41256383061408997, 0.008246857672929764, -0.3073456287384033]
     Last 10:  [0.4186096787452698, -0.6452377438545227, 0.014433741569519043, 0.6810883283615112, 0.5483975410461426, 0.8453601598739624, 0.36293888092041016, -0.016039013862609863, 0.17271602153778076, -1.2644233703613281]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000019
     First 10: [0.0027125095948576927, -0.0017233826220035553, -0.014686133712530136, 0.0021221444476395845, -0.005628903396427631, -0.0062447525560855865, -0.005822270177304745, 0.010219366289675236, -0.0051945713348686695, 0.009507122449576855]
     Last 10:  [0.0049423412419855595, 0.00400722399353981, 0.009045148268342018, -0.0054817465133965015, -0.003890726715326309, 0.007897283881902695, -0.00615833280608058, 0.005301086697727442, 0.0016335428226739168, 0.024378428235650063]

================================================================================
197_layers.12.self_attn.q_norm: Gemma3RMSNorm (layers.12.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.12.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.012480, Std: 1.535521
     First 10: [-0.804032564163208, 0.37707000970840454, -0.8528565764427185, -0.40152794122695923, 3.8703808784484863, 0.5866332054138184, -2.3382296562194824, 0.747713565826416, 0.298966646194458, 3.5231122970581055]
     Last 10:  [-1.9151663780212402, 0.5873419642448425, 0.12516561150550842, 0.03597442805767059, -0.00978928804397583, -0.42343395948410034, -0.42343905568122864, 0.2664339244365692, 0.9900935292243958, -1.9853806495666504]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.053893, Std: 1.026035
     First 10: [-0.9810542464256287, 0.35052061080932617, -2.1246585845947266, -0.3041011691093445, -0.4188075661659241, 0.7541762590408325, -0.01668388769030571, 0.49581456184387207, 0.584750771522522, -1.097120761871338]
     Last 10:  [-13.123527526855469, 0.36365312337875366, 0.128529891371727, 0.01234135590493679, -0.010364540852606297, -0.7878853678703308, -0.31607967615127563, 0.15702155232429504, 1.3470075130462646, -9.620278358459473]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.269653
     First 10: [0.016497939825057983, -0.22557619214057922, 1.075392723083496, -0.36905795335769653, -1.0901463031768799, 0.0710095539689064, -0.9940557479858398, -0.4475777745246887, 0.6294280886650085, -1.2594269514083862]
     Last 10:  [3.861171245574951, -0.5607688426971436, -0.27152276039123535, -0.7566306591033936, -0.2489033341407776, 0.32000088691711426, -0.47045546770095825, -0.5819130539894104, -0.03485926613211632, 2.4374842643737793]

================================================================================
198_layers.12.self_attn.k_norm: Gemma3RMSNorm (layers.12.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.12.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.007322, Std: 1.416668
     First 10: [0.2104572355747223, -0.019714832305908203, 0.3573058843612671, 0.12048636376857758, -0.6234138011932373, -0.08012927323579788, -3.7463607788085938, -0.5013067126274109, 0.05337300896644592, 1.600102424621582]
     Last 10:  [-5.884676933288574, 2.2959229946136475, 1.233973503112793, -1.0790659189224243, -1.9169360399246216, -0.6775946021080017, -0.9330291152000427, 2.7042794227600098, 1.749098777770996, -0.5477821826934814]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.12.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.058824, Std: 1.837179
     First 10: [0.13420966267585754, -0.024540286511182785, 0.20930597186088562, 0.26599448919296265, -0.004592957906424999, -0.10389760136604309, -0.03927338495850563, -0.0648767501115799, 0.05853899568319321, 0.0023185608442872763]
     Last 10:  [-2.392063856124878, 8.450733184814453, 2.749326467514038, -7.1906657218933105, -4.214174747467041, -0.7789255380630493, -2.922283172607422, 10.981688499450684, 3.0672366619110107, -0.5333201885223389]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.641884
     First 10: [-0.33229386806488037, 0.3033226430416107, -0.38665205240249634, 1.3115335702896118, -0.992285966873169, 0.35762476921081543, -0.989023745059967, -0.8644963502883911, 0.14838898181915283, -0.9984828233718872]
     Last 10:  [-0.38380563259124756, 4.579620361328125, 2.377443313598633, 9.10156536102295, 2.3325178623199463, 0.7425833940505981, 3.7478246688842773, 5.155808925628662, 1.6582788228988647, 0.47586870193481445]

================================================================================
199_layers.12.self_attn.o_proj: Linear (layers.12.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.12.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.017142, Std: 0.461440
     First 10: [0.02118532359600067, -0.34404104948043823, -0.04512466490268707, -0.03596951812505722, 0.062094204127788544, 0.47610732913017273, 0.3312092423439026, -0.41256383061408997, 0.008246857672929764, -0.3073456287384033]
     Last 10:  [0.22768241167068481, -0.31409764289855957, -0.1116405501961708, 0.6132321953773499, 0.22976411879062653, 0.530254602432251, 0.19460050761699677, -0.03244711831212044, -0.06575445085763931, -1.019191026687622]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001088, Std: 0.166376
     First 10: [-0.04107115417718887, -0.06875456869602203, 0.2451094388961792, -0.037204355001449585, -0.02468542940914631, -0.02276606112718582, -0.12125665694475174, -0.11597006767988205, -0.02610476128757, 0.05870819091796875]
     Last 10:  [0.012472093105316162, -0.34136953949928284, -0.11113515496253967, 0.00604768842458725, 0.07735893130302429, -0.02525918558239937, 0.24240943789482117, 0.013309326022863388, -0.07271507382392883, 0.07985234260559082]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000010
     First 10: [-0.0032945373095571995, -0.005840620957314968, 0.0033280705101788044, -0.001858359668403864, 0.004263336304575205, -0.0025063299108296633, -0.015221044421195984, 0.008896177634596825, 0.00048441014951094985, -0.0016752008814364672]
     Last 10:  [0.0029919135849922895, -0.005964368116110563, 0.0015724787954241037, 0.007765859365463257, -0.005646524019539356, -0.0049993121065199375, 0.0006905555492267013, 0.011824608780443668, 0.0002275847946293652, -0.007349828258156776]

================================================================================
200_layers.12.self_attn: Gemma3Attention (layers.12.self_attn)
================================================================================

  → OUTPUT[0]: layers.12.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001088, Std: 0.166376
     First 10: [-0.04107115417718887, -0.06875456869602203, 0.2451094388961792, -0.037204355001449585, -0.02468542940914631, -0.02276606112718582, -0.12125665694475174, -0.11597006767988205, -0.02610476128757, 0.05870819091796875]
     Last 10:  [0.012472093105316162, -0.34136953949928284, -0.11113515496253967, 0.00604768842458725, 0.07735893130302429, -0.02525918558239937, 0.24240943789482117, 0.013309326022863388, -0.07271507382392883, 0.07985234260559082]
     Zeros: 0, Total: 5376

================================================================================
201_layers.12.post_attention_layernorm: Gemma3RMSNorm (layers.12.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.12.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001088, Std: 0.166376
     First 10: [-0.04107115417718887, -0.06875456869602203, 0.2451094388961792, -0.037204355001449585, -0.02468542940914631, -0.02276606112718582, -0.12125665694475174, -0.11597006767988205, -0.02610476128757, 0.05870819091796875]
     Last 10:  [0.012472093105316162, -0.34136953949928284, -0.11113515496253967, 0.00604768842458725, 0.07735893130302429, -0.02525918558239937, 0.24240943789482117, 0.013309326022863388, -0.07271507382392883, 0.07985234260559082]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.178083, Std: 16.829136
     First 10: [-1.8329373598098755, -18.78799057006836, 5.436163902282715, -1.0219370126724243, -2.152355670928955, -3.0890607833862305, -3.6098432540893555, -2.8711442947387695, -3.4299378395080566, 9.84205436706543]
     Last 10:  [0.2913830578327179, -4.157111644744873, -2.520211696624756, 0.46962836384773254, 10.500821113586426, -4.822738170623779, 32.78165054321289, 0.7129244208335876, -6.708139896392822, 14.69610595703125]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 16.643095
     First 10: [6.668177604675293, 45.95266342163086, 2.8107807636260986, 3.7196717262268066, 13.981483459472656, 22.314172744750977, 4.115218639373779, 3.253931999206543, 21.576051712036133, 27.805042266845703]
     Last 10:  [2.945470094680786, 1.0565565824508667, 2.8296523094177246, 12.114107131958008, 21.923799514770508, 31.243942260742188, 21.837844848632812, 8.046096801757812, 14.579426765441895, 30.080530166625977]

================================================================================
202_layers.12.pre_feedforward_layernorm: Gemma3RMSNorm (layers.12.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.12.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 3.171916, Std: 127.510208
     First 10: [168.7406463623047, -59.985801696777344, 7.372830390930176, -3.5576095581054688, -32.02497482299805, 28.802711486816406, -5.073575973510742, -5.317795276641846, -2.6162896156311035, 16.561288833618164]
     Last 10:  [-0.8555676937103271, -6.830632209777832, -10.590635299682617, 31.37885856628418, 55.40576934814453, 59.348426818847656, 53.44706726074219, -11.685370445251465, -11.914247512817383, -19.17208480834961]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058533, Std: 1.650225
     First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
     Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 10.990865
     First 10: [2.954144239425659, 0.8151454329490662, 31.476116180419922, 33.93648910522461, 5.293455600738525, 2.4223124980926514, 28.67906951904297, 32.38774108886719, 2.657703161239624, 2.392764091491699]
     Last 10:  [30.373212814331055, 31.724071502685547, 34.04891586303711, 4.15443229675293, 0.6608733534812927, 0.8871768116950989, 2.9255881309509277, 5.385080814361572, 5.257719993591309, 1.837809681892395]

================================================================================
203_layers.12.mlp.gate_proj: Linear (layers.12.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.12.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058533, Std: 1.650225
     First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
     Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.104813, Std: 0.300468
     First 10: [-0.022982895374298096, -0.20530149340629578, -0.08957429230213165, -0.12830787897109985, -0.0981706827878952, -0.15481024980545044, -0.1020633727312088, -0.1902666985988617, 0.13335318863391876, -0.04614615812897682]
     Last 10:  [-0.1434941589832306, 0.19373413920402527, -0.26234978437423706, -0.8278949856758118, 0.07833276689052582, -0.07045590877532959, -0.1476972997188568, -0.31951433420181274, -0.20305182039737701, -0.6358994841575623]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000012
     First 10: [-0.008766974322497845, 0.005505302455276251, -0.007538122590631247, -0.01439967006444931, -0.0004528391291387379, -0.0036734293680638075, 0.004767390433698893, -0.011136475950479507, 0.004049727227538824, -0.0028382069431245327]
     Last 10:  [0.005953346379101276, -0.002074723830446601, -0.007125081028789282, -0.0015016257530078292, -0.00974856037646532, 0.00475440314039588, 0.004081600345671177, 0.004442822653800249, 0.0044324928894639015, -0.00045955434325151145]

================================================================================
204_layers.12.mlp.act_fn: PytorchGELUTanh (layers.12.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.12.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.104813, Std: 0.300468
     First 10: [-0.022982895374298096, -0.20530149340629578, -0.08957429230213165, -0.12830787897109985, -0.0981706827878952, -0.15481024980545044, -0.1020633727312088, -0.1902666985988617, 0.13335318863391876, -0.04614615812897682]
     Last 10:  [-0.1434941589832306, 0.19373413920402527, -0.26234978437423706, -0.8278949856758118, 0.07833276689052582, -0.07045590877532959, -0.1476972997188568, -0.31951433420181274, -0.20305182039737701, -0.6358994841575623]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.12.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.014765, Std: 0.134785
     First 10: [-0.011280739679932594, -0.08595378696918488, -0.041590508073568344, -0.05760425329208374, -0.04524673894047737, -0.0678822249174118, -0.04688316956162453, -0.08077815920114517, 0.07374993711709976, -0.02222384698688984]
     Last 10:  [-0.0635608658194542, 0.11174694448709488, -0.10402996838092804, -0.16887173056602478, 0.04161179065704346, -0.03324923664331436, -0.06517761945724487, -0.11971507221460342, -0.08519037812948227, -0.16691353917121887]
     Zeros: 0, Total: 8064

================================================================================
205_layers.12.mlp.up_proj: Linear (layers.12.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.12.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058533, Std: 1.650225
     First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
     Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000586, Std: 0.293478
     First 10: [0.02123599499464035, 0.07039011269807816, 0.06042609363794327, -0.05637071281671524, -0.08315056562423706, 0.16270342469215393, 0.11544345319271088, 0.11698631197214127, -0.12754835188388824, -0.07499265670776367]
     Last 10:  [-0.2852236330509186, -0.17267188429832458, -0.14019858837127686, 0.644933819770813, 0.23454919457435608, -0.010507181286811829, 0.14551949501037598, 0.12502118945121765, -0.257402628660202, 0.12464164197444916]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000001
     First 10: [0.006364917382597923, -0.001082041533663869, -0.005723560228943825, 0.001281159115023911, -0.004318699706345797, -0.004075093660503626, 0.0012937961146235466, 0.0032121031545102596, -0.0014557505492120981, -0.0074810972437262535]
     Last 10:  [-0.008028418757021427, -0.007226842455565929, -0.006121098529547453, -0.0040992130525410175, -0.008192312903702259, 0.00017907671281136572, 0.003872529836371541, 3.923356416635215e-06, 0.010138547979295254, -0.0027072117663919926]

================================================================================
206_layers.12.mlp.down_proj: Linear (layers.12.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.12.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000070, Std: 0.053040
     First 10: [-0.00023955773212946951, -0.00605029659345746, -0.0025131518486887217, 0.0032471928279846907, 0.0037622919771820307, -0.011044670827686787, -0.005412355065345764, -0.009449939243495464, -0.009406683035194874, 0.0016666253795847297]
     Last 10:  [0.01812906190752983, -0.019295554608106613, 0.014584855176508427, -0.10891108959913254, 0.009760011918842793, 0.00034935574512928724, -0.009484614245593548, -0.01496692094951868, 0.021928226575255394, -0.020804377272725105]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.12.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000482, Std: 0.017125
     First 10: [0.0020637139678001404, -0.00023306722869165242, -0.0020020543597638607, 0.00027065069298259914, 0.0009393703076057136, -0.0005907444283366203, 0.0006556111620739102, 0.0017650971421971917, -6.506458157673478e-05, -0.0013531404547393322]
     Last 10:  [-0.007020239718258381, -0.007523358799517155, -0.0034375921823084354, 0.003751582931727171, 0.005033687688410282, 0.0005947427125647664, -0.0023683509789407253, -0.00093159603420645, -0.0014653141843155026, 0.0028231372125446796]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000009
     First 10: [-3.841752914013341e-05, 0.000683282152749598, 0.0017128578620031476, -0.0046198368072509766, 0.00859104935079813, -0.0021190939005464315, -0.004248455166816711, -0.010479557327926159, -0.0010544478427618742, 0.00243322248570621]
     Last 10:  [0.003773230127990246, 0.00036320899380370975, 0.0009930405067279935, 0.009061030112206936, 0.009298335760831833, 0.00866386666893959, -0.0029197614639997482, -0.008275935426354408, 0.0066647762432694435, 0.0063880011439323425]

================================================================================
207_layers.12.mlp: Gemma3MLP (layers.12.mlp)
================================================================================

  → INPUT[0]: layers.12.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058533, Std: 1.650225
     First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
     Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000482, Std: 0.017125
     First 10: [0.0020637139678001404, -0.00023306722869165242, -0.0020020543597638607, 0.00027065069298259914, 0.0009393703076057136, -0.0005907444283366203, 0.0006556111620739102, 0.0017650971421971917, -6.506458157673478e-05, -0.0013531404547393322]
     Last 10:  [-0.007020239718258381, -0.007523358799517155, -0.0034375921823084354, 0.003751582931727171, 0.005033687688410282, 0.0005947427125647664, -0.0023683509789407253, -0.00093159603420645, -0.0014653141843155026, 0.0028231372125446796]
     Zeros: 0, Total: 5376

================================================================================
208_layers.12.post_feedforward_layernorm: Gemma3RMSNorm (layers.12.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.12.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000482, Std: 0.017125
     First 10: [0.0020637139678001404, -0.00023306722869165242, -0.0020020543597638607, 0.00027065069298259914, 0.0009393703076057136, -0.0005907444283366203, 0.0006556111620739102, 0.0017650971421971917, -6.506458157673478e-05, -0.0013531404547393322]
     Last 10:  [-0.007020239718258381, -0.007523358799517155, -0.0034375921823084354, 0.003751582931727171, 0.005033687688410282, 0.0005947427125647664, -0.0023683509789407253, -0.00093159603420645, -0.0014653141843155026, 0.0028231372125446796]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.12.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 2.770514, Std: 116.501724
     First 10: [8.000317573547363, -2.435619592666626, -3.0871739387512207, 0.46263647079467773, 4.762817859649658, -4.873488426208496, 1.2409080266952515, 2.6048433780670166, -0.5370645523071289, -11.960341453552246]
     Last 10:  [-10.02040958404541, -6.7268195152282715, -4.912494659423828, 16.25006675720215, 36.858985900878906, 6.057577610015869, -19.51620864868164, -2.851673126220703, -6.811434268951416, 26.02605628967285]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 29.933502
     First 10: [19.006288528442383, 52.930824279785156, 6.957818984985352, 7.821440696716309, 25.165916442871094, 41.57445526123047, 8.767919540405273, 6.615910530090332, 41.598140716552734, 44.61519241333008]
     Last 10:  [6.634617805480957, 3.7824645042419434, 6.643662452697754, 22.168312072753906, 38.1661491394043, 53.478309631347656, 43.07609939575195, 15.372908592224121, 23.863460540771484, 48.3094482421875]

================================================================================
209_layers.13.input_layernorm: Gemma3RMSNorm (layers.13.input_layernorm)
================================================================================

  → INPUT[0]: layers.13.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 5.942430, Std: 212.997604
     First 10: [176.740966796875, -62.42142105102539, 4.285656452178955, -3.094973087310791, -27.262157440185547, 23.929222106933594, -3.832667827606201, -2.712951898574829, -3.1533541679382324, 4.600947380065918]
     Last 10:  [-10.875977516174316, -13.557451248168945, -15.503129959106445, 47.62892532348633, 92.26475524902344, 65.406005859375, 33.93085861206055, -14.537043571472168, -18.72568130493164, 6.853971481323242]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.054176, Std: 5.218561
     First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
     Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 25.962729
     First 10: [11.75266170501709, 2.8299925327301025, 61.58631134033203, 61.371009826660156, 13.614543914794922, 7.25384521484375, 51.447410583496094, 64.24146270751953, 7.923786163330078, 6.990154266357422]
     Last 10:  [60.170623779296875, 75.0103759765625, 74.50689697265625, 13.721010208129883, 4.464089870452881, 4.112610340118408, 8.22525405883789, 17.502111434936523, 13.42376708984375, 5.748326301574707]

================================================================================
210_layers.13.self_attn.q_proj: Linear (layers.13.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.13.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.054176, Std: 5.218561
     First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
     Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.071761, Std: 1.772350
     First 10: [0.8364247679710388, -0.4532351493835449, 0.7776120901107788, -0.47673994302749634, 0.9883427619934082, 0.24520409107208252, 2.4637582302093506, -1.2464847564697266, -0.29622364044189453, -0.30926695466041565]
     Last 10:  [-0.3050664961338043, 1.0661121606826782, 0.23267847299575806, -0.5322763323783875, -0.41054007411003113, 0.5130617618560791, 0.45901283621788025, -0.18490785360336304, 0.15671074390411377, 1.076202392578125]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000000
     First 10: [-0.01735401153564453, -0.013745905831456184, -0.0030706021934747696, 0.00015259694191627204, 0.0043752724304795265, 0.012335523962974548, -0.001249709166586399, -0.0010607123840600252, -0.00892326608300209, 0.004299227613955736]
     Last 10:  [-0.0033456888049840927, -0.010465085506439209, 0.004857621155679226, 0.00546306325122714, 0.005283770617097616, -0.007719013839960098, -0.005058978218585253, -0.017042171210050583, -0.014472909271717072, 0.0053587304428219795]

================================================================================
211_layers.13.self_attn.k_proj: Linear (layers.13.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.13.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.054176, Std: 5.218561
     First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
     Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.027784, Std: 2.013980
     First 10: [0.007019702345132828, 0.11941589415073395, 0.7390118837356567, 0.1345953643321991, 0.9551467299461365, -0.07838650792837143, -0.6739803552627563, -0.6394873857498169, 0.14342156052589417, -0.39992213249206543]
     Last 10:  [-1.3505351543426514, 1.8229715824127197, 0.05259718745946884, -0.018563412129878998, -0.8138828873634338, 2.008383274078369, 1.163895845413208, -1.538025975227356, 0.6274494528770447, 2.1304666996002197]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000031
     First 10: [-0.01751762628555298, -0.024302247911691666, -0.00283314217813313, -0.009299823082983494, 0.003993513993918896, 0.01309354230761528, -0.006253868341445923, -0.001191433402709663, 0.010284069925546646, 0.008218345232307911]
     Last 10:  [-0.0016868712846189737, 0.0028651333414018154, -0.009620741941034794, -0.002951390342786908, -0.0030931327491998672, -0.0036987983621656895, 0.002204641466960311, -0.00038424605736508965, 0.003923662006855011, -0.015046079643070698]

================================================================================
212_layers.13.self_attn.v_proj: Linear (layers.13.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.13.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.054176, Std: 5.218561
     First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
     Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.006436, Std: 1.005554
     First 10: [0.45034146308898926, -0.4081689119338989, 0.24878141283988953, -0.49970880150794983, -0.051942989230155945, -0.3459335267543793, -0.5095895528793335, -0.25714099407196045, 0.6120578050613403, -0.3974817991256714]
     Last 10:  [-0.21557466685771942, -0.022943012416362762, -0.6692516207695007, 0.4855843484401703, -0.10301446914672852, -0.259247362613678, -0.09954842925071716, -0.16998042166233063, -0.670846164226532, -0.08857104182243347]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000040
     First 10: [0.0013409169623628259, 0.007548077031970024, 0.0016407883958891034, -0.0056447372771799564, 0.006317107006907463, 0.011103669181466103, 0.00329471193253994, -0.005857614800333977, 0.004067391622811556, 0.021515335887670517]
     Last 10:  [0.004732926841825247, -0.0017648257780820131, -0.020428180694580078, -0.012792205438017845, 0.003125750459730625, -0.0032688139472156763, -0.014224495738744736, -0.010961518622934818, -0.0002236751897726208, 0.004761512391269207]

================================================================================
213_layers.13.self_attn.q_norm: Gemma3RMSNorm (layers.13.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.13.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.071761, Std: 1.772350
     First 10: [0.8364247679710388, -0.4532351493835449, 0.7776120901107788, -0.47673994302749634, 0.9883427619934082, 0.24520409107208252, 2.4637582302093506, -1.2464847564697266, -0.29622364044189453, -0.30926695466041565]
     Last 10:  [-0.3050664961338043, 1.0661121606826782, 0.23267847299575806, -0.5322763323783875, -0.41054007411003113, 0.5130617618560791, 0.45901283621788025, -0.18490785360336304, 0.15671074390411377, 1.076202392578125]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.034570, Std: 1.282260
     First 10: [1.7442165613174438, -1.104560136795044, 1.1223775148391724, -1.0668585300445557, 1.7916052341461182, 0.34625256061553955, -0.3750143349170685, -2.5772624015808105, -0.5066099762916565, -0.5889802575111389]
     Last 10:  [-0.40384751558303833, 2.0955889225006104, 0.3443293571472168, -0.4951009750366211, -0.9615939259529114, 0.5001615881919861, 0.5896702408790588, -0.2578638195991516, 0.1713263988494873, 1.2032439708709717]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.335631
     First 10: [0.3776225447654724, 0.6099874377250671, -0.04647368937730789, 0.4783661365509033, 0.1975439488887787, -0.06712809205055237, -1.100555658340454, 0.36592987179756165, 0.12982387840747833, 0.2581256031990051]
     Last 10:  [-0.2189910113811493, 0.15967513620853424, -0.12692619860172272, -0.4512307345867157, 0.3818765878677368, -0.4248597025871277, -0.24209019541740417, -0.17724944651126862, -0.3550015687942505, -0.3403814435005188]

================================================================================
214_layers.13.self_attn.k_norm: Gemma3RMSNorm (layers.13.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.13.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.027784, Std: 2.013980
     First 10: [0.007019702345132828, 0.11941589415073395, 0.7390118837356567, 0.1345953643321991, 0.9551467299461365, -0.07838650792837143, -0.6739803552627563, -0.6394873857498169, 0.14342156052589417, -0.39992213249206543]
     Last 10:  [-1.3505351543426514, 1.8229715824127197, 0.05259718745946884, -0.018563412129878998, -0.8138828873634338, 2.008383274078369, 1.163895845413208, -1.538025975227356, 0.6274494528770447, 2.1304666996002197]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.13.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.053946, Std: 2.089630
     First 10: [0.004087395034730434, 0.13581787049770355, 0.8140512704849243, 0.22478584945201874, 1.160390019416809, -0.23296472430229187, -0.39481431245803833, -0.8376200199127197, 0.1146681159734726, -0.4332643449306488]
     Last 10:  [-3.073794364929199, 2.5395915508270264, 0.11110297590494156, -0.05622228980064392, -1.1022379398345947, 4.935131072998047, 2.521240711212158, -3.4987099170684814, 1.5758628845214844, 6.105504989624023]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 1.190099
     First 10: [-0.39989012479782104, 0.17218905687332153, 0.13528066873550415, 0.721241295337677, 0.25209343433380127, 2.06303334236145, -0.396261990070343, 0.34995073080062866, -0.17599262297153473, 0.11655564606189728]
     Last 10:  [1.543018102645874, 0.5565553307533264, 1.360172152519226, 2.384007215499878, 0.5131919384002686, 1.7455708980560303, 1.420364499092102, 1.541703224182129, 1.8062105178833008, 2.202044725418091]

================================================================================
215_layers.13.self_attn.o_proj: Linear (layers.13.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.13.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.017604, Std: 0.724271
     First 10: [0.45034146308898926, -0.4081689119338989, 0.24878141283988953, -0.49970880150794983, -0.051942989230155945, -0.3459335267543793, -0.5095895528793335, -0.25714099407196045, 0.6120578050613403, -0.3974817991256714]
     Last 10:  [-0.18219275772571564, 0.07211694866418839, -0.5332483649253845, 0.4648361802101135, -0.09327122569084167, -0.17683327198028564, -0.03819107264280319, -0.16252046823501587, -0.5181922912597656, -0.08235093206167221]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.014945, Std: 0.265551
     First 10: [-0.15213292837142944, -0.015081462450325489, -0.022870853543281555, -0.01687520556151867, -0.007552599534392357, -0.058719463646411896, 0.049116626381874084, -0.08975470066070557, -0.17323821783065796, 0.22528076171875]
     Last 10:  [-0.003948226571083069, 0.005071710795164108, 0.04794684052467346, -0.06946811825037003, -0.04805656149983406, -0.023258188739418983, 0.07940039038658142, 0.07642364501953125, -0.11784300953149796, -0.029977921396493912]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000003
     First 10: [-0.001322498545050621, -0.0009007778135128319, 0.0036293864250183105, 0.0020311137195676565, -0.006898402236402035, 0.005200434010475874, 0.0028193891048431396, 0.008622635155916214, -0.004897840321063995, -0.003504786640405655]
     Last 10:  [0.017295952886343002, 0.00868904683738947, 0.006635603494942188, 0.0026463731192052364, 0.009235094301402569, 0.01484466902911663, -0.008687854744493961, 0.02493879944086075, -0.0030512050725519657, 0.00336092384532094]

================================================================================
216_layers.13.self_attn: Gemma3Attention (layers.13.self_attn)
================================================================================

  → OUTPUT[0]: layers.13.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.014945, Std: 0.265551
     First 10: [-0.15213292837142944, -0.015081462450325489, -0.022870853543281555, -0.01687520556151867, -0.007552599534392357, -0.058719463646411896, 0.049116626381874084, -0.08975470066070557, -0.17323821783065796, 0.22528076171875]
     Last 10:  [-0.003948226571083069, 0.005071710795164108, 0.04794684052467346, -0.06946811825037003, -0.04805656149983406, -0.023258188739418983, 0.07940039038658142, 0.07642364501953125, -0.11784300953149796, -0.029977921396493912]
     Zeros: 0, Total: 5376

================================================================================
217_layers.13.post_attention_layernorm: Gemma3RMSNorm (layers.13.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.13.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.014945, Std: 0.265551
     First 10: [-0.15213292837142944, -0.015081462450325489, -0.022870853543281555, -0.01687520556151867, -0.007552599534392357, -0.058719463646411896, 0.049116626381874084, -0.08975470066070557, -0.17323821783065796, 0.22528076171875]
     Last 10:  [-0.003948226571083069, 0.005071710795164108, 0.04794684052467346, -0.06946811825037003, -0.04805656149983406, -0.023258188739418983, 0.07940039038658142, 0.07642364501953125, -0.11784300953149796, -0.029977921396493912]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -2.197792, Std: 62.527351
     First 10: [-10.064956665039062, -4.032870769500732, -0.791649580001831, -0.755563497543335, -0.7226142883300781, -9.659396171569824, 2.478848934173584, -3.038947105407715, -28.351734161376953, 40.1602668762207]
     Last 10:  [-0.20532387495040894, 0.10868159681558609, 2.529832601547241, -9.388433456420898, -12.188921928405762, -8.446057319641113, 20.02294158935547, 7.456014156341553, -15.894796371459961, -9.30518627166748]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 25.952833
     First 10: [13.88951301574707, 59.181453704833984, 6.7900896072387695, 9.076593399047852, 20.532869338989258, 36.02198791503906, 10.35830020904541, 6.620048522949219, 35.83220672607422, 39.12031173706055]
     Last 10:  [6.787586212158203, 2.208979845046997, 6.901276588439941, 19.23825454711914, 36.98202133178711, 53.380550384521484, 36.76336669921875, 13.609806060791016, 19.198383331298828, 45.482452392578125]

================================================================================
218_layers.13.pre_feedforward_layernorm: Gemma3RMSNorm (layers.13.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.13.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 3.744637, Std: 164.024460
     First 10: [166.67601013183594, -66.45429229736328, 3.494006872177124, -3.850536584854126, -27.984771728515625, 14.26982593536377, -1.3538188934326172, -5.751898765563965, -31.505088806152344, 44.76121520996094]
     Last 10:  [-11.08130168914795, -13.448769569396973, -12.973297119140625, 38.24049377441406, 80.07583618164062, 56.9599494934082, 53.953800201416016, -7.081029415130615, -34.62047576904297, -2.4512147903442383]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058432, Std: 1.746081
     First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
     Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 7.262858
     First 10: [2.7883453369140625, 0.2364659607410431, 19.645368576049805, 17.440643310546875, 4.032129287719727, 1.9286320209503174, 15.077167510986328, 19.94561195373535, 1.8216187953948975, 1.6959514617919922]
     Last 10:  [19.588607788085938, 22.904945373535156, 19.88981819152832, 3.531662940979004, 0.34664416313171387, 0.6397103667259216, 2.1450586318969727, 5.126366138458252, 4.175175666809082, 1.199461579322815]

================================================================================
219_layers.13.mlp.gate_proj: Linear (layers.13.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.13.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058432, Std: 1.746081
     First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
     Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.104752, Std: 0.329033
     First 10: [0.006748717278242111, -0.09960862994194031, 0.07397498935461044, -0.09028328955173492, 0.017488647252321243, 0.18890106678009033, -0.17671608924865723, 0.039600953459739685, -0.2648722529411316, -0.4570804238319397]
     Last 10:  [-0.17768847942352295, 0.18994814157485962, -0.031693316996097565, -0.004064023494720459, -0.00039180368185043335, 0.03942228481173515, 0.03157612681388855, 0.04819710925221443, -0.11810573935508728, -0.15407778322696686]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000002
     First 10: [0.003664974356070161, 0.017331114038825035, -0.005027442704886198, -0.001851389417424798, -0.0007474620942957699, -0.00315635884180665, -0.007808927446603775, 0.005868913605809212, -0.010115284472703934, 0.007711803540587425]
     Last 10:  [0.00046146486420184374, -0.0009726533317007124, -0.009858542121946812, -0.000739477516617626, 0.00630029384046793, -0.0024462202563881874, 0.00612633628770709, 0.010788090527057648, 0.0014083327259868383, -0.003893708810210228]

================================================================================
220_layers.13.mlp.act_fn: PytorchGELUTanh (layers.13.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.13.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.104752, Std: 0.329033
     First 10: [0.006748717278242111, -0.09960862994194031, 0.07397498935461044, -0.09028328955173492, 0.017488647252321243, 0.18890106678009033, -0.17671608924865723, 0.039600953459739685, -0.2648722529411316, -0.4570804238319397]
     Last 10:  [-0.17768847942352295, 0.18994814157485962, -0.031693316996097565, -0.004064023494720459, -0.00039180368185043335, 0.03942228481173515, 0.03157612681388855, 0.04819710925221443, -0.11810573935508728, -0.15407778322696686]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.13.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.009111, Std: 0.142765
     First 10: [0.00339252850972116, -0.045852623879909515, 0.03916862979531288, -0.04189427196979523, 0.008866335265338421, 0.10860161483287811, -0.07596450299024582, 0.02042594738304615, -0.10477280616760254, -0.14801806211471558]
     Last 10:  [-0.07631464302539825, 0.1092815175652504, -0.015446001663804054, -0.002025422640144825, -0.00019584059191402048, 0.02033098414540291, 0.016185762360692024, 0.02502492256462574, -0.053501009941101074, -0.06760554015636444]
     Zeros: 0, Total: 8064

================================================================================
221_layers.13.mlp.up_proj: Linear (layers.13.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.13.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058432, Std: 1.746081
     First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
     Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.001263, Std: 0.310816
     First 10: [-0.07227173447608948, 0.0660347044467926, -0.07152324914932251, 0.012200601398944855, -0.16272211074829102, -0.26572757959365845, -0.013649238273501396, 0.07763451337814331, -0.004814311861991882, 0.1388780176639557]
     Last 10:  [-0.2902665138244629, 0.012585415504872799, -0.1292167603969574, 0.07026379555463791, -0.04178517311811447, -0.28114619851112366, 0.04783618822693825, 0.11752069741487503, -0.20859655737876892, -0.10907648503780365]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000011
     First 10: [-0.0032282653264701366, -0.002715654671192169, -0.00804593600332737, 0.00415591336786747, 0.0060648308135569096, 0.008476347662508488, -0.004948681686073542, -0.000398095726268366, -0.00241677463054657, 0.0030678515322506428]
     Last 10:  [-0.00785447470843792, -0.0020262342877686024, 0.001108177239075303, 0.0024133746046572924, 0.013045249506831169, -0.005836755037307739, -0.0026898332871496677, -0.008222748525440693, 0.0007929347921162844, -0.0015786527656018734]

================================================================================
222_layers.13.mlp.down_proj: Linear (layers.13.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.13.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000258, Std: 0.053467
     First 10: [-0.00024518391001038253, -0.0030278644990175962, -0.002801467664539814, -0.0005111353239044547, -0.0014427488204091787, -0.028858443722128868, 0.0010368576040491462, 0.0015857585240155458, 0.0005044089630246162, -0.020556455478072166]
     Last 10:  [0.022151585668325424, 0.0013753533130511642, 0.0019958822522312403, -0.00014231388922780752, 8.183233148884028e-06, -0.0057159787975251675, 0.000774265150539577, 0.0029409462586045265, 0.011160126887261868, 0.007374174892902374]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.13.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000603, Std: 0.017372
     First 10: [0.004211364313960075, -0.0019049250986427069, -0.00040013561374507844, -0.00012071029050275683, 0.0010902953799813986, 0.0025013103149831295, 0.0009798873215913773, -0.0009930059313774109, 0.0011830583680421114, 0.005010321270674467]
     Last 10:  [-0.0004615726647898555, -0.00014996170648373663, 0.007172790355980396, 0.003221483901143074, 0.000838735606521368, 0.003366317367181182, 0.00033169661764986813, -0.0036381478421390057, -0.0014558428665623069, 0.0021559761371463537]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000011
     First 10: [-0.001125412993133068, 0.00293371407315135, 0.0034643590915948153, -0.002451564185321331, -0.002645738422870636, -0.007124176248908043, -0.0006671236478723586, 0.003420198103412986, -0.00010708625632105395, 0.002635988174006343]
     Last 10:  [-0.0017772731371223927, -0.0058598509058356285, -0.0030951611697673798, -0.0010565024567767978, -0.0006140719051472843, 0.006884859874844551, -0.007966766133904457, -0.002101343357935548, 0.0013645114377140999, -0.004274166189134121]

================================================================================
223_layers.13.mlp: Gemma3MLP (layers.13.mlp)
================================================================================

  → INPUT[0]: layers.13.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.058432, Std: 1.746081
     First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
     Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000603, Std: 0.017372
     First 10: [0.004211364313960075, -0.0019049250986427069, -0.00040013561374507844, -0.00012071029050275683, 0.0010902953799813986, 0.0025013103149831295, 0.0009798873215913773, -0.0009930059313774109, 0.0011830583680421114, 0.005010321270674467]
     Last 10:  [-0.0004615726647898555, -0.00014996170648373663, 0.007172790355980396, 0.003221483901143074, 0.000838735606521368, 0.003366317367181182, 0.00033169661764986813, -0.0036381478421390057, -0.0014558428665623069, 0.0021559761371463537]
     Zeros: 0, Total: 5376

================================================================================
224_layers.13.post_feedforward_layernorm: Gemma3RMSNorm (layers.13.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.13.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000603, Std: 0.017372
     First 10: [0.004211364313960075, -0.0019049250986427069, -0.00040013561374507844, -0.00012071029050275683, 0.0010902953799813986, 0.0025013103149831295, 0.0009798873215913773, -0.0009930059313774109, 0.0011830583680421114, 0.005010321270674467]
     Last 10:  [-0.0004615726647898555, -0.00014996170648373663, 0.007172790355980396, 0.003221483901143074, 0.000838735606521368, 0.003366317367181182, 0.00033169661764986813, -0.0036381478421390057, -0.0014558428665623069, 0.0021559761371463537]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.13.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 2.410892, Std: 88.031578
     First 10: [17.05410385131836, -20.200931549072266, -0.9720085263252258, -0.3194139301776886, 6.542749404907227, 23.45691680908203, 3.0530779361724854, -2.1220381259918213, 11.596570014953613, 51.478458404541016]
     Last 10:  [-1.6369478702545166, -0.23135975003242493, 25.6538028717041, 27.850204467773438, 10.738801956176758, 68.50335693359375, 5.220648288726807, -21.50417709350586, -13.386789321899414, 39.7132682800293]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 35.164944
     First 10: [21.9759578704834, 59.1673698425293, 12.782575607299805, 14.013331413269043, 33.0473747253418, 52.20725631713867, 16.67784309387207, 11.124641418457031, 54.6148681640625, 57.29448699951172]
     Last 10:  [11.340014457702637, 4.368195533752441, 11.4447021484375, 29.081073760986328, 43.5504035949707, 69.80724334716797, 53.76515197753906, 19.566640853881836, 30.995052337646484, 63.093292236328125]

================================================================================
225_layers.14.input_layernorm: Gemma3RMSNorm (layers.14.input_layernorm)
================================================================================

  → INPUT[0]: layers.14.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 6.155529, Std: 239.607086
     First 10: [183.73011779785156, -86.65522766113281, 2.521998405456543, -4.169950485229492, -21.4420223236084, 37.726741790771484, 1.6992590427398682, -7.873936653137207, -19.908519744873047, 96.23966979980469]
     Last 10:  [-12.718249320983887, -13.680129051208496, 12.680505752563477, 66.0906982421875, 90.81463623046875, 125.46330261230469, 59.1744499206543, -28.585206985473633, -48.00726318359375, 37.262054443359375]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.056472, Std: 5.685355
     First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
     Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 21.306219
     First 10: [11.14867877960205, 4.355194568634033, 46.39269256591797, 36.49784469604492, 13.363710403442383, 7.666349411010742, 35.49592971801758, 49.52053451538086, 8.074918746948242, 7.43620491027832]
     Last 10:  [45.10369873046875, 65.51676177978516, 50.27562713623047, 13.472511291503906, 4.327505111694336, 4.19752836227417, 7.734601020812988, 15.80941390991211, 13.68671989440918, 5.791352272033691]

================================================================================
226_layers.14.self_attn.q_proj: Linear (layers.14.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.14.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.056472, Std: 5.685355
     First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
     Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.032740, Std: 1.906701
     First 10: [0.028124824166297913, 0.44571512937545776, 0.25772935152053833, 0.9772237539291382, 2.3116519451141357, -0.22039569914340973, 0.6215305328369141, 0.047316014766693115, -1.471388816833496, -0.21935640275478363]
     Last 10:  [-0.1737244874238968, 0.27111536264419556, 0.39346277713775635, -0.28846055269241333, -0.2518097460269928, -0.27236616611480713, 1.0081894397735596, 0.617536723613739, 0.13530395925045013, 0.34730425477027893]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000003
     First 10: [-0.0016495859017595649, -0.0015251701697707176, 0.0015255684265866876, 0.0002148872590623796, 0.01695064641535282, 0.0028222911059856415, -0.0019058558391407132, -0.0051009561866521835, -0.005580764729529619, -0.003296381328254938]
     Last 10:  [0.013381006196141243, -0.002019617473706603, 0.002925449749454856, -0.0028140831273049116, 0.006924580782651901, -1.2969125236850232e-05, -0.005547680426388979, 0.005484774708747864, 0.021414224058389664, 0.008391737006604671]

================================================================================
227_layers.14.self_attn.k_proj: Linear (layers.14.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.14.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.056472, Std: 5.685355
     First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
     Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.111514, Std: 1.932355
     First 10: [-0.2207908034324646, -0.04775351285934448, -0.07402798533439636, 0.11566570401191711, -0.29033151268959045, 2.072566032409668, -0.5297539234161377, 0.5046263933181763, -0.10775488615036011, 0.6581724882125854]
     Last 10:  [-0.05878379940986633, 1.723232388496399, 1.3115403652191162, -0.6094167828559875, -1.9947216510772705, 1.8402093648910522, 2.0767550468444824, 2.681412935256958, -4.059468746185303, 0.4617413282394409]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000004
     First 10: [0.004332804121077061, 0.01017892174422741, -0.0015357774682343006, 0.0029683930333703756, -0.009811388328671455, -0.0030958226416260004, 0.001211092690937221, 0.005301570985466242, -0.0016097178449854255, -0.006596377119421959]
     Last 10:  [0.0033961888402700424, -0.007631484419107437, 0.0070458101108670235, 0.014070196077227592, -0.0041608260944485664, -0.004549121484160423, -0.0023262540344148874, 0.0034784763120114803, 0.011874144896864891, 0.008915512822568417]

================================================================================
228_layers.14.self_attn.v_proj: Linear (layers.14.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.14.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.056472, Std: 5.685355
     First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
     Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.004478, Std: 1.178115
     First 10: [-0.501308798789978, 0.9232020378112793, 0.4883410930633545, -0.25761279463768005, 0.37365052103996277, 0.2523801326751709, -0.11057871580123901, -0.1554214507341385, 0.6825931668281555, -0.13478206098079681]
     Last 10:  [-0.28715601563453674, -0.11343425512313843, 0.16109225153923035, 0.7588263154029846, -0.47793760895729065, -0.22729337215423584, -0.170091450214386, 0.11519107222557068, -0.8462551832199097, -0.10331271588802338]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000002
     First 10: [0.0009834056254476309, 0.001580213662236929, 0.0005390846636146307, -0.008062183856964111, -0.004736700095236301, -0.009758185595273972, -0.0014627492055296898, 0.0154617540538311, 0.008311856538057327, 0.00034282999695278704]
     Last 10:  [0.004632480442523956, -0.011736194603145123, 0.0009917299030348659, 0.0037921781186014414, 0.002038094447925687, -0.011759299784898758, 0.0097267534583807, -0.007784771267324686, 0.006726793944835663, 0.0016847981605678797]

================================================================================
229_layers.14.self_attn.q_norm: Gemma3RMSNorm (layers.14.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.14.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.032740, Std: 1.906701
     First 10: [0.028124824166297913, 0.44571512937545776, 0.25772935152053833, 0.9772237539291382, 2.3116519451141357, -0.22039569914340973, 0.6215305328369141, 0.047316014766693115, -1.471388816833496, -0.21935640275478363]
     Last 10:  [-0.1737244874238968, 0.27111536264419556, 0.39346277713775635, -0.28846055269241333, -0.2518097460269928, -0.27236616611480713, 1.0081894397735596, 0.617536723613739, 0.13530395925045013, 0.34730425477027893]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.022471, Std: 1.213354
     First 10: [0.1003028079867363, 1.0526059865951538, 0.8727142214775085, 1.641601324081421, -0.27390366792678833, -0.35076388716697693, 0.8005458116531372, 0.061382513493299484, -0.009351968765258789, -0.7046124339103699]
     Last 10:  [-0.5762138366699219, 0.3556777536869049, 1.2215381860733032, -0.5598868131637573, -0.43046385049819946, -0.6195335388183594, 1.3909661769866943, 0.6647266745567322, 0.2153312712907791, 0.5164086818695068]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.461721
     First 10: [1.1891921758651733, 0.44966983795166016, 1.0785900354385376, 0.03117958828806877, -1.072733759880066, -0.023049935698509216, -0.2093498706817627, -0.20366251468658447, -0.9960984587669373, 0.9717898368835449]
     Last 10:  [1.3576176166534424, -0.06749041378498077, 1.2067549228668213, 0.3796360194683075, 0.21510806679725647, 0.6168227195739746, -0.01932481862604618, -0.23487736284732819, 0.13122066855430603, 0.056900754570961]

================================================================================
230_layers.14.self_attn.k_norm: Gemma3RMSNorm (layers.14.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.14.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.111514, Std: 1.932355
     First 10: [-0.2207908034324646, -0.04775351285934448, -0.07402798533439636, 0.11566570401191711, -0.29033151268959045, 2.072566032409668, -0.5297539234161377, 0.5046263933181763, -0.10775488615036011, 0.6581724882125854]
     Last 10:  [-0.05878379940986633, 1.723232388496399, 1.3115403652191162, -0.6094167828559875, -1.9947216510772705, 1.8402093648910522, 2.0767550468444824, 2.681412935256958, -4.059468746185303, 0.4617413282394409]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.14.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.046633, Std: 1.880148
     First 10: [-0.2256920039653778, -0.05131816864013672, -0.059695590287446976, 0.03600867837667465, -0.0014628918142989278, 0.07795681804418564, -0.9856333136558533, 0.9465233683586121, -0.00020775220764335245, 0.4418083727359772]
     Last 10:  [-0.044420741498470306, 3.232144355773926, 1.1971092224121094, -0.77071613073349, -3.1295506954193115, 2.1062538623809814, 3.7301809787750244, 5.796924591064453, -5.381000995635986, 0.7690918445587158]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.657235
     First 10: [0.032292045652866364, 0.08525847643613815, -0.18564513325691223, -0.6856091022491455, -0.9949115514755249, -0.96201491355896, 0.8789212703704834, 0.8942128419876099, -0.9980529546737671, -0.322106271982193]
     Last 10:  [-0.014271906577050686, 1.4466726779937744, 0.19064173102378845, 0.6497154235839844, 1.0465797185897827, 0.4930434226989746, 1.34300696849823, 1.8200898170471191, 0.7291108965873718, 1.1727434396743774]

================================================================================
231_layers.14.self_attn.o_proj: Linear (layers.14.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.14.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.009665, Std: 0.508602
     First 10: [-0.501308798789978, 0.9232020378112793, 0.4883410930633545, -0.25761279463768005, 0.37365052103996277, 0.2523801326751709, -0.11057871580123901, -0.1554214507341385, 0.6825931668281555, -0.13478206098079681]
     Last 10:  [0.039655208587646484, 0.15596690773963928, -0.03644498437643051, 0.5815441012382507, -0.3286437392234802, 0.028827853500843048, -0.11520837247371674, -0.03017500787973404, -0.43303704261779785, 0.4345278739929199]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.008653, Std: 0.217847
     First 10: [0.12269598990678787, -0.022870689630508423, -0.013895757496356964, 0.07412634789943695, -0.08660323917865753, -0.002777267247438431, -0.03183448314666748, -0.031418878585100174, -0.08178964257240295, -0.09039819985628128]
     Last 10:  [-0.029067542403936386, -0.047225676476955414, 0.05217019468545914, -0.056367505341768265, -0.0705995187163353, 0.07758945971727371, 0.036799684166908264, 0.10514664649963379, -0.16595499217510223, -0.05093392729759216]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000005
     First 10: [-0.006218290887773037, -0.0030132895335555077, 0.008385979570448399, -0.005262488033622503, 0.005770623683929443, 0.0050734966062009335, 0.009629708714783192, 0.010426937602460384, 0.007955770008265972, -0.0011218767613172531]
     Last 10:  [-0.005644422955811024, -0.0034998664632439613, -0.0026640852447599173, 0.004938667640089989, 0.00589369423687458, 0.005413073115050793, -0.012539012357592583, 0.0032271365635097027, 0.0014108374016359448, 0.010694848373532295]

================================================================================
232_layers.14.self_attn: Gemma3Attention (layers.14.self_attn)
================================================================================

  → OUTPUT[0]: layers.14.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.008653, Std: 0.217847
     First 10: [0.12269598990678787, -0.022870689630508423, -0.013895757496356964, 0.07412634789943695, -0.08660323917865753, -0.002777267247438431, -0.03183448314666748, -0.031418878585100174, -0.08178964257240295, -0.09039819985628128]
     Last 10:  [-0.029067542403936386, -0.047225676476955414, 0.05217019468545914, -0.056367505341768265, -0.0705995187163353, 0.07758945971727371, 0.036799684166908264, 0.10514664649963379, -0.16595499217510223, -0.05093392729759216]
     Zeros: 0, Total: 5376

================================================================================
233_layers.14.post_attention_layernorm: Gemma3RMSNorm (layers.14.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.14.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.008653, Std: 0.217847
     First 10: [0.12269598990678787, -0.022870689630508423, -0.013895757496356964, 0.07412634789943695, -0.08660323917865753, -0.002777267247438431, -0.03183448314666748, -0.031418878585100174, -0.08178964257240295, -0.09039819985628128]
     Last 10:  [-0.029067542403936386, -0.047225676476955414, 0.05217019468545914, -0.056367505341768265, -0.0705995187163353, 0.07758945971727371, 0.036799684166908264, 0.10514664649963379, -0.16595499217510223, -0.05093392729759216]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.144088, Std: 16.890066
     First 10: [8.62802791595459, -7.865265846252441, -0.869902491569519, 5.292575836181641, -15.408013343811035, -0.7929950952529907, -3.161799430847168, -1.860727310180664, -21.920698165893555, -26.63882827758789]
     Last 10:  [-1.671074390411377, -1.072404384613037, 3.0777504444122314, -7.039388656616211, -13.41563892364502, 23.908565521240234, 8.664802551269531, 8.241847038269043, -23.259517669677734, -14.986763000488281]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 30.738136
     First 10: [12.073427200317383, 62.93555450439453, 10.638490676879883, 12.274028778076172, 32.076595306396484, 52.08369445800781, 17.46480941772461, 10.010330200195312, 48.82695770263672, 53.785247802734375]
     Last 10:  [10.603568077087402, 3.5833652019500732, 10.907346725463867, 24.206363677978516, 37.35426712036133, 61.194915771484375, 46.524620056152344, 14.820974349975586, 27.288795471191406, 58.388824462890625]

================================================================================
234_layers.14.pre_feedforward_layernorm: Gemma3RMSNorm (layers.14.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.14.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 6.299619, Std: 239.912643
     First 10: [192.35813903808594, -94.52049255371094, 1.652095913887024, 1.1226253509521484, -36.85003662109375, 36.933746337890625, -1.4625403881072998, -9.734663963317871, -41.82921600341797, 69.60084533691406]
     Last 10:  [-14.389324188232422, -14.752532958984375, 15.758255958557129, 59.051307678222656, 77.39899444580078, 149.3718719482422, 67.83924865722656, -20.343360900878906, -71.26678466796875, 22.275291442871094]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016894, Std: 1.438832
     First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
     Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 5.706133
     First 10: [2.6971938610076904, 0.15461410582065582, 14.073863983154297, 11.556535720825195, 3.313985824584961, 1.557701826095581, 9.853123664855957, 14.07278060913086, 1.587183952331543, 1.335620641708374]
     Last 10:  [13.636835098266602, 19.6743221282959, 13.935993194580078, 3.3127872943878174, 0.4063485264778137, 0.5285608768463135, 1.547231674194336, 4.5968852043151855, 3.3596582412719727, 1.0083198547363281]

================================================================================
235_layers.14.mlp.gate_proj: Linear (layers.14.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.14.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016894, Std: 1.438832
     First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
     Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.078370, Std: 0.261370
     First 10: [0.14834237098693848, 0.12829217314720154, -0.02011808753013611, 0.024282237514853477, -0.04086781293153763, 0.07456660270690918, -0.041377656161785126, 0.08108655363321304, -0.0006834724918007851, -0.010279660113155842]
     Last 10:  [-0.021879808977246284, 0.1496003419160843, -0.09056642651557922, -0.048916224390268326, -0.17876023054122925, 0.00806389469653368, -0.10356353223323822, -0.016077920794487, -0.005521934479475021, -0.08705978095531464]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000013
     First 10: [0.0015879909042268991, 0.0028253865893930197, 0.00012201879144413397, -0.0021903133019804955, -0.003086660522967577, -0.006325550377368927, 0.004370560869574547, -0.013092238456010818, -0.001345059834420681, 0.016855642199516296]
     Last 10:  [0.0036793313920497894, 0.007296135649085045, -0.004664287436753511, -0.01320621743798256, -0.0017926888540387154, -0.004718691576272249, 0.0024068672209978104, 0.004249617923051119, 0.004550418816506863, -0.0003469925432000309]

================================================================================
236_layers.14.mlp.act_fn: PytorchGELUTanh (layers.14.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.14.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.078370, Std: 0.261370
     First 10: [0.14834237098693848, 0.12829217314720154, -0.02011808753013611, 0.024282237514853477, -0.04086781293153763, 0.07456660270690918, -0.041377656161785126, 0.08108655363321304, -0.0006834724918007851, -0.010279660113155842]
     Last 10:  [-0.021879808977246284, 0.1496003419160843, -0.09056642651557922, -0.048916224390268326, -0.17876023054122925, 0.00806389469653368, -0.10356353223323822, -0.016077920794487, -0.005521934479475021, -0.08705978095531464]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.14.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.011250, Std: 0.120153
     First 10: [0.08291784673929214, 0.07069417089223862, -0.009897587820887566, 0.012376322411000729, -0.01976778730750084, 0.039499424397945404, -0.02000599168241024, 0.043163448572158813, -0.00034154989407397807, -0.005097674205899239]
     Last 10:  [-0.010748935863375664, 0.08369525521993637, -0.04201546683907509, -0.023503907024860382, -0.07669972628355026, 0.004057888872921467, -0.047510623931884766, -0.007935838773846626, -0.0027488027699291706, -0.04050998017191887]
     Zeros: 0, Total: 8064

================================================================================
237_layers.14.mlp.up_proj: Linear (layers.14.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.14.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016894, Std: 1.438832
     First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
     Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.002904, Std: 0.249255
     First 10: [0.05705193430185318, -0.0037382543087005615, -0.1112263947725296, -0.009159233421087265, -0.08151492476463318, 0.07436574995517731, 0.06018946319818497, -0.12019287049770355, 0.03315173462033272, -0.021319936960935593]
     Last 10:  [-0.06220266968011856, -0.25173962116241455, 0.039261288940906525, -0.08635926246643066, -0.3211487829685211, -0.028728969395160675, 0.00495245773345232, 0.04333190619945526, 0.11583015322685242, -0.0386919304728508]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000004
     First 10: [0.008499182760715485, -0.0013571492163464427, 0.008260185830295086, -0.0038294182159006596, 0.01399899646639824, -0.004029673989862204, -0.00704436469823122, 0.0030111721716821194, -0.003970783203840256, 0.0014557675458490849]
     Last 10:  [-0.002267777454108, 0.006191542372107506, -0.0005120356217958033, -0.0059897154569625854, 0.002111099660396576, -0.007070963736623526, -0.0017563614528626204, -0.004148220643401146, 0.00034691591281443834, -0.0005176804261282086]

================================================================================
238_layers.14.mlp.down_proj: Linear (layers.14.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.14.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.001301, Std: 0.037125
     First 10: [0.004730623681098223, -0.00026427279226481915, 0.0011008729925379157, -0.00011335762246744707, 0.0016113696619868279, 0.00293740420602262, -0.0012041499139741063, -0.005187938921153545, -1.1322971658955794e-05, 0.0001086820921045728]
     Last 10:  [0.0006686124834232032, -0.02106941118836403, -0.0016495813615620136, 0.002029780065640807, 0.02463202364742756, -0.00011657896538963541, -0.00023529435566160828, -0.000343875028192997, -0.0003183942462783307, 0.001567409373819828]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.14.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000614, Std: 0.013653
     First 10: [-0.0012987230438739061, -0.0008989650523290038, 0.0002725987578742206, -0.0004307625931687653, -0.0011674187844619155, 0.0006288615404628217, 0.0023097058292478323, 0.0008910225005820394, 0.00055984704522416, 0.00244341604411602]
     Last 10:  [0.00018927021301351488, 0.0009197206818498671, -0.0004020448250230402, 0.0005610291846096516, -8.46427064971067e-05, -0.0002974697854369879, 0.00014032510807737708, -0.0022252541966736317, 0.0006255374755710363, -0.00010594178456813097]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000009
     First 10: [0.0009247290436178446, -0.00828003790229559, 0.005490461364388466, 0.0011897172080352902, 0.0018904248718172312, 0.0029934500344097614, -0.00325205409899354, -0.003908685874193907, 0.0023043192923069, -0.0008055344223976135]
     Last 10:  [-0.0012751988833770156, 0.006170541048049927, 0.004823196679353714, 3.208655471098609e-05, 0.004273989237844944, 0.0007330311927944422, 0.0014994506491348147, 0.01265199575573206, 0.0019312641816213727, 0.0001475897297495976]

================================================================================
239_layers.14.mlp: Gemma3MLP (layers.14.mlp)
================================================================================

  → INPUT[0]: layers.14.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016894, Std: 1.438832
     First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
     Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000614, Std: 0.013653
     First 10: [-0.0012987230438739061, -0.0008989650523290038, 0.0002725987578742206, -0.0004307625931687653, -0.0011674187844619155, 0.0006288615404628217, 0.0023097058292478323, 0.0008910225005820394, 0.00055984704522416, 0.00244341604411602]
     Last 10:  [0.00018927021301351488, 0.0009197206818498671, -0.0004020448250230402, 0.0005610291846096516, -8.46427064971067e-05, -0.0002974697854369879, 0.00014032510807737708, -0.0022252541966736317, 0.0006255374755710363, -0.00010594178456813097]
     Zeros: 0, Total: 5376

================================================================================
240_layers.14.post_feedforward_layernorm: Gemma3RMSNorm (layers.14.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.14.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000614, Std: 0.013653
     First 10: [-0.0012987230438739061, -0.0008989650523290038, 0.0002725987578742206, -0.0004307625931687653, -0.0011674187844619155, 0.0006288615404628217, 0.0023097058292478323, 0.0008910225005820394, 0.00055984704522416, 0.00244341604411602]
     Last 10:  [0.00018927021301351488, 0.0009197206818498671, -0.0004020448250230402, 0.0005610291846096516, -8.46427064971067e-05, -0.0002974697854369879, 0.00014032510807737708, -0.0022252541966736317, 0.0006255374755710363, -0.00010594178456813097]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.14.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 2.251310, Std: 99.498322
     First 10: [-14.931605339050293, -29.44227409362793, 2.950902223587036, -4.3199028968811035, -23.0322208404541, 19.5983829498291, 30.702062606811523, 7.305133819580078, 17.826879501342773, 83.95952606201172]
     Last 10:  [2.4454541206359863, 4.695501327514648, -5.409968852996826, 15.459521293640137, -3.167933702468872, -17.228734970092773, 6.611525535583496, -36.66097640991211, 17.946247100830078, -6.042235851287842]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 43.596607
     First 10: [24.122848510742188, 70.56611633300781, 22.654285430908203, 20.913660049438477, 42.110992431640625, 67.09952545166016, 28.046232223510742, 16.91506576538086, 68.58007049560547, 74.08470916748047]
     Last 10:  [17.51993179321289, 6.317928314208984, 18.28778648376465, 38.497779846191406, 52.64739990234375, 82.01807403564453, 66.53492736816406, 22.61492156982422, 40.12277603149414, 80.75089263916016]

================================================================================
241_layers.15.input_layernorm: Gemma3RMSNorm (layers.15.input_layernorm)
================================================================================

  → INPUT[0]: layers.15.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 8.550929, Std: 325.543243
     First 10: [177.42652893066406, -123.9627685546875, 4.60299825668335, -3.197277545928955, -59.88225555419922, 56.532127380371094, 29.23952293395996, -2.429530143737793, -24.002336502075195, 153.56036376953125]
     Last 10:  [-11.943870544433594, -10.057031631469727, 10.348287582397461, 74.51082611083984, 74.23106384277344, 132.1431427001953, 74.45077514648438, -57.004337310791016, -53.32053756713867, 16.233055114746094]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.084202, Std: 5.634511
     First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
     Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 18.555494
     First 10: [14.453505516052246, 3.33465576171875, 33.60771942138672, 32.12060546875, 11.048099517822266, 6.458439826965332, 23.931020736694336, 35.20578384399414, 6.355368614196777, 5.729844570159912]
     Last 10:  [34.04849624633789, 56.203765869140625, 36.3524169921875, 12.36893081665039, 4.851395606994629, 3.9882073402404785, 6.420905113220215, 18.65386390686035, 11.115718841552734, 4.995501518249512]

================================================================================
242_layers.15.self_attn.q_proj: Linear (layers.15.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.15.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.084202, Std: 5.634511
     First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
     Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.015853, Std: 2.089638
     First 10: [0.2750684320926666, -3.550524950027466, -0.6223995089530945, 0.0007455646991729736, 2.240058422088623, -2.499338150024414, 0.6067607402801514, -2.0542101860046387, 1.9696431159973145, -0.4023197293281555]
     Last 10:  [-0.13992273807525635, -0.39495664834976196, -1.2112736701965332, -0.30776703357696533, 0.10131454467773438, -0.6142350435256958, -0.520649790763855, 0.10828877985477448, -0.6732699871063232, -0.20795512199401855]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000012
     First 10: [-0.005215735174715519, -0.00667666457593441, -0.006146376021206379, -0.00550357298925519, 0.008597682230174541, -0.008268190547823906, 0.002083924598991871, -0.00598673801869154, -0.009160642512142658, -0.0021733264438807964]
     Last 10:  [0.0010507889091968536, 0.0017251453828066587, 0.005331880878657103, -0.010500015690922737, -0.003555232658982277, 0.0109555060043931, -0.006466877181082964, -0.001165158930234611, -0.001341559924185276, 0.010051140561699867]

================================================================================
243_layers.15.self_attn.k_proj: Linear (layers.15.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.15.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.084202, Std: 5.634511
     First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
     Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.029994, Std: 2.032853
     First 10: [-0.2951665222644806, 1.1768625974655151, 0.00848531723022461, 0.4255927801132202, -0.5154724717140198, 0.7189075946807861, 0.6592564582824707, -0.15552927553653717, 0.06901262700557709, 0.7627174854278564]
     Last 10:  [-1.0547300577163696, 0.5886194705963135, -1.7441225051879883, -1.9584755897521973, -0.6799696683883667, -2.0162978172302246, -1.9833217859268188, -0.803550660610199, 0.22215652465820312, 0.2984813451766968]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000002
     First 10: [0.0037553668953478336, 0.010640186257660389, 0.005888359621167183, 0.0019435039721429348, 0.0011381732765585184, -0.0011256069410592318, 0.004540028050541878, 0.004277666099369526, -0.0026460306253284216, 0.003227963112294674]
     Last 10:  [0.00584073644131422, -0.0012286041164770722, -0.0006507872603833675, -0.009067805483937263, -0.00027849816251546144, 0.0038636131212115288, -0.01764138601720333, -0.005656055640429258, -0.012485392391681671, -0.003304603509604931]

================================================================================
244_layers.15.self_attn.v_proj: Linear (layers.15.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.15.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.084202, Std: 5.634511
     First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
     Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.021755, Std: 1.233423
     First 10: [-0.47365522384643555, -0.18011385202407837, -0.41710925102233887, 0.0747750848531723, 0.35331273078918457, -0.6285364031791687, 0.3741227090358734, 0.125362828373909, -0.3014511466026306, -0.35354703664779663]
     Last 10:  [0.06338294595479965, -0.02208004891872406, -0.1949484497308731, 0.6693199872970581, 0.49223893880844116, -0.02726396918296814, 0.3623366951942444, 0.018864162266254425, 0.0516878142952919, -0.07165651768445969]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000000
     First 10: [0.0008014526101760566, 0.0038679437711834908, 0.005298186559230089, 0.008026313036680222, 0.010794635862112045, 0.0014110642950981855, 0.010947209782898426, 0.01300632581114769, -0.0039885155856609344, 0.0043138302862644196]
     Last 10:  [-0.005729282274842262, 0.004996071569621563, -0.011388317681849003, -0.009645706973969936, 0.006400119513273239, 0.009143172763288021, -0.019981088116765022, 0.006206945516169071, 0.010788872838020325, 0.00701327808201313]

================================================================================
245_layers.15.self_attn.q_norm: Gemma3RMSNorm (layers.15.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.15.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.015853, Std: 2.089638
     First 10: [0.2750684320926666, -3.550524950027466, -0.6223995089530945, 0.0007455646991729736, 2.240058422088623, -2.499338150024414, 0.6067607402801514, -2.0542101860046387, 1.9696431159973145, -0.4023197293281555]
     Last 10:  [-0.13992273807525635, -0.39495664834976196, -1.2112736701965332, -0.30776703357696533, 0.10131454467773438, -0.6142350435256958, -0.520649790763855, 0.10828877985477448, -0.6732699871063232, -0.20795512199401855]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.016387, Std: 0.960839
     First 10: [0.37651678919792175, 0.5727710723876953, -1.027632236480713, -0.0010312963277101517, -0.01267665158957243, -0.06652969121932983, 0.7271559834480286, -1.3628730773925781, 2.019571542739868, -0.0019715651869773865]
     Last 10:  [-0.20435841381549835, -1.2880555391311646, -2.292523145675659, -1.0783475637435913, 0.06972628831863403, -2.3719112873077393, -4.256363391876221, 0.14771999418735504, -1.6556353569030762, -0.20596683025360107]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.263356
     First 10: [0.23191408812999725, -1.145186185836792, 0.4859538674354553, -2.244901418685913, -1.0050930976867676, -0.9760432839393616, 0.07856638729572296, -0.4028995931148529, -0.0771980956196785, -0.9955896139144897]
     Last 10:  [-0.3703548312187195, 0.40597236156463623, -0.18405082821846008, 0.5105264782905579, -0.7033007740974426, 0.6647748947143555, 2.52439546585083, -0.4119049906730652, 0.06014943867921829, -0.5730084180831909]

================================================================================
246_layers.15.self_attn.k_norm: Gemma3RMSNorm (layers.15.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.15.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.029994, Std: 2.032853
     First 10: [-0.2951665222644806, 1.1768625974655151, 0.00848531723022461, 0.4255927801132202, -0.5154724717140198, 0.7189075946807861, 0.6592564582824707, -0.15552927553653717, 0.06901262700557709, 0.7627174854278564]
     Last 10:  [-1.0547300577163696, 0.5886194705963135, -1.7441225051879883, -1.9584755897521973, -0.6799696683883667, -2.0162978172302246, -1.9833217859268188, -0.803550660610199, 0.22215652465820312, 0.2984813451766968]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.15.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.127516, Std: 2.091496
     First 10: [-0.42723512649536133, -0.25166651606559753, 0.011462745256721973, 0.4264484941959381, 0.004845777992159128, 0.028305426239967346, -0.09319332242012024, -0.1508299708366394, -0.06413722038269043, -0.006630311720073223]
     Last 10:  [-5.52408504486084, 1.4959686994552612, -11.68722915649414, -4.993087291717529, -6.895844459533691, -5.663033485412598, -2.1530206203460693, -4.067312240600586, 0.6875457763671875, 2.209059953689575]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.850871
     First 10: [0.31914791464805603, -1.1948916912078857, 0.2311592698097229, -0.08679982274770737, -1.008567452430725, -0.9641168713569641, -1.1288321018218994, -0.11616912484169006, -1.8469840288162231, -1.0079225301742554]
     Last 10:  [3.272152900695801, 1.073077917098999, 4.465908050537109, 1.0795949697494507, 7.2722883224487305, 1.290984869003296, -0.11451186239719391, 3.128782272338867, 1.5244702100753784, 5.036956787109375]

================================================================================
247_layers.15.self_attn.o_proj: Linear (layers.15.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.15.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012734, Std: 0.916316
     First 10: [-0.47365522384643555, -0.18011385202407837, -0.41710925102233887, 0.0747750848531723, 0.35331273078918457, -0.6285364031791687, 0.3741227090358734, 0.125362828373909, -0.3014511466026306, -0.35354703664779663]
     Last 10:  [0.11542350798845291, 0.018483111634850502, -0.2530986964702606, 0.5508170127868652, 0.48238977789878845, -0.050392165780067444, 0.37293508648872375, -0.028464723378419876, 0.026468340307474136, -0.014735020697116852]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008606, Std: 0.359760
     First 10: [-0.053457751870155334, 0.029016204178333282, 0.045305244624614716, 0.004770169034600258, 0.0320814810693264, -0.07723040878772736, 0.14569181203842163, -0.19514091312885284, 0.05640750005841255, -0.118842713534832]
     Last 10:  [-0.018760016188025475, 0.04383497312664986, -0.02402014099061489, -0.005228996276855469, -0.04460621625185013, -0.006841190159320831, -0.02014404907822609, -0.024293426424264908, -0.04879247024655342, 0.07000140845775604]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000002
     First 10: [-0.0007318176794797182, -0.016571125015616417, 0.008856741711497307, 0.005372332874685526, -0.005432480946183205, 0.00016134322504512966, 0.002188588259741664, 0.0013653170317411423, 0.008761920034885406, 0.0039997524581849575]
     Last 10:  [-0.012427566573023796, 0.0028733573853969574, 0.001714153215289116, 0.005918245762586594, 0.012289760634303093, -0.0009759044041857123, -0.002203983021900058, -0.00586630217730999, -0.002114197239279747, 0.0057311514392495155]

================================================================================
248_layers.15.self_attn: Gemma3Attention (layers.15.self_attn)
================================================================================

  → OUTPUT[0]: layers.15.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008606, Std: 0.359760
     First 10: [-0.053457751870155334, 0.029016204178333282, 0.045305244624614716, 0.004770169034600258, 0.0320814810693264, -0.07723040878772736, 0.14569181203842163, -0.19514091312885284, 0.05640750005841255, -0.118842713534832]
     Last 10:  [-0.018760016188025475, 0.04383497312664986, -0.02402014099061489, -0.005228996276855469, -0.04460621625185013, -0.006841190159320831, -0.02014404907822609, -0.024293426424264908, -0.04879247024655342, 0.07000140845775604]
     Zeros: 0, Total: 5376

================================================================================
249_layers.15.post_attention_layernorm: Gemma3RMSNorm (layers.15.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.15.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.008606, Std: 0.359760
     First 10: [-0.053457751870155334, 0.029016204178333282, 0.045305244624614716, 0.004770169034600258, 0.0320814810693264, -0.07723040878772736, 0.14569181203842163, -0.19514091312885284, 0.05640750005841255, -0.118842713534832]
     Last 10:  [-0.018760016188025475, 0.04383497312664986, -0.02402014099061489, -0.005228996276855469, -0.04460621625185013, -0.006841190159320831, -0.02014404907822609, -0.024293426424264908, -0.04879247024655342, 0.07000140845775604]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.773209, Std: 36.193607
     First 10: [-5.056215763092041, 7.695061206817627, 4.610808372497559, 0.4491417407989502, 5.582060813903809, -21.32071304321289, 21.214231491088867, -15.011122703552246, 15.79201602935791, -36.598575592041016]
     Last 10:  [-3.0826714038848877, 2.7122812271118164, -4.06519889831543, -1.6947458982467651, -21.55784797668457, -4.944144248962402, -11.817981719970703, -5.600545406341553, -16.491689682006836, 48.40235137939453]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 53.921402
     First 10: [26.850940704345703, 77.09017944335938, 28.967708587646484, 26.72519302368164, 50.23480987548828, 80.29022979736328, 41.87628173828125, 21.651126861572266, 81.43766784667969, 89.6810531616211]
     Last 10:  [23.113933563232422, 8.080045700073242, 23.83592414855957, 46.5620231628418, 69.9225082397461, 105.05558776855469, 85.09354400634766, 32.83106231689453, 48.60054016113281, 100.46908569335938]

================================================================================
250_layers.15.pre_feedforward_layernorm: Gemma3RMSNorm (layers.15.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.15.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 7.777719, Std: 308.289764
     First 10: [172.3703155517578, -116.26770782470703, 9.21380615234375, -2.748135805130005, -54.300193786621094, 35.2114143371582, 50.45375442504883, -17.44065284729004, -8.210320472717285, 116.9617919921875]
     Last 10:  [-15.026541709899902, -7.34475040435791, 6.283088684082031, 72.81607818603516, 52.6732177734375, 127.1989974975586, 62.63279342651367, -62.604881286621094, -69.81222534179688, 64.63540649414062]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.050048, Std: 1.626903
     First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
     Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 4.498001
     First 10: [3.2200751304626465, 0.11012884974479675, 7.569732666015625, 7.645828723907471, 2.6357877254486084, 1.1557486057281494, 5.67886209487915, 9.214136123657227, 1.2020602226257324, 0.9701664447784424]
     Last 10:  [8.87198257446289, 15.790982246398926, 9.068817138671875, 2.627511739730835, 0.39576029777526855, 0.45439618825912476, 1.2046555280685425, 4.251316070556641, 2.799848794937134, 0.7698068022727966]

================================================================================
251_layers.15.mlp.gate_proj: Linear (layers.15.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.15.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.050048, Std: 1.626903
     First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
     Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.108265, Std: 0.316032
     First 10: [-0.018640421330928802, 0.3564620614051819, 0.1350024789571762, 0.09405145794153214, -0.4554407000541687, -0.2488454431295395, 0.018176045268774033, -0.025425981730222702, -0.17996057868003845, -0.2846835255622864]
     Last 10:  [-0.001682499423623085, -0.00948718748986721, 0.07520028203725815, -0.005328044295310974, -0.07463696599006653, 0.013049734756350517, -0.09310083836317062, -0.04099193960428238, 0.01904069259762764, -0.07473614066839218]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000012
     First 10: [0.0034565485548228025, 0.00011753464059438556, 0.0010283865267410874, -0.0011297597084194422, -0.0010540314251556993, -0.0032914786133915186, 0.00361165264621377, -0.0049185678362846375, -0.001950971782207489, -0.004930921830236912]
     Last 10:  [-0.006486023776233196, 0.0011177817359566689, -0.013959435746073723, 0.007856734097003937, -0.010827090591192245, 0.010143250226974487, 0.0057167913764715195, -0.005650237202644348, 0.0043305703438818455, -0.003445641603320837]

================================================================================
252_layers.15.mlp.act_fn: PytorchGELUTanh (layers.15.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.15.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.108265, Std: 0.316032
     First 10: [-0.018640421330928802, 0.3564620614051819, 0.1350024789571762, 0.09405145794153214, -0.4554407000541687, -0.2488454431295395, 0.018176045268774033, -0.025425981730222702, -0.17996057868003845, -0.2846835255622864]
     Last 10:  [-0.001682499423623085, -0.00948718748986721, 0.07520028203725815, -0.005328044295310974, -0.07463696599006653, 0.013049734756350517, -0.09310083836317062, -0.04099193960428238, 0.01904069259762764, -0.07473614066839218]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.15.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.013322, Std: 0.137072
     First 10: [-0.00918160006403923, 0.22786447405815125, 0.07475009560585022, 0.05054942145943642, -0.14775541424751282, -0.09997241944074631, 0.009219813160598278, -0.012455110438168049, -0.07712996006011963, -0.1104431077837944]
     Last 10:  [-0.0008401204249821603, -0.004707687068730593, 0.039854057133197784, -0.002652697032317519, -0.03509817644953728, 0.006592803169041872, -0.043097496032714844, -0.019825801253318787, 0.009664973244071007, -0.03514186292886734]
     Zeros: 0, Total: 8064

================================================================================
253_layers.15.mlp.up_proj: Linear (layers.15.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.15.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.050048, Std: 1.626903
     First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
     Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.003769, Std: 0.294882
     First 10: [-0.037296112626791, -0.05797937512397766, -0.008805528283119202, -0.004578541032969952, -0.8381357192993164, -0.05140405148267746, -0.07439427822828293, 0.10267028212547302, 0.042106449604034424, 0.015454471111297607]
     Last 10:  [0.025219690054655075, -0.03763987123966217, 0.023936942219734192, -0.09901262819766998, 0.025497576221823692, 0.04697975516319275, 0.03548315167427063, -0.05359477177262306, -0.008468195796012878, 0.0915905311703682]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000016
     First 10: [-0.004660142119973898, 0.000934191863052547, 9.263395622838289e-05, -0.001455948338843882, 0.007598095573484898, -5.31101250089705e-05, 0.00019052754214499146, 0.0029755812138319016, 0.010866167023777962, 0.00475728465244174]
     Last 10:  [-0.004132123664021492, -0.0034736227244138718, 0.0019219215027987957, 0.002552086254581809, 0.0013060063356533647, 0.0030136494897305965, 0.00012101874744985253, 0.0017146702157333493, 0.0015546598006039858, -0.007148243486881256]

================================================================================
254_layers.15.mlp.down_proj: Linear (layers.15.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.15.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000961, Std: 0.054195
     First 10: [0.0003424379974603653, -0.013211439363658428, -0.0006582140922546387, -0.00023144259466789663, 0.12383908778429031, 0.005138987209647894, -0.0006859013228677213, -0.0012787696905434132, -0.003247668733820319, -0.0017068397719413042]
     Last 10:  [-2.118757583957631e-05, 0.00017719673633109778, 0.0009539842722006142, 0.00026265051565133035, -0.0008949184557422996, 0.00030972828972153366, -0.0015292350435629487, 0.0010625593131408095, -8.184488251572475e-05, -0.003218661993741989]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.15.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000275, Std: 0.017983
     First 10: [0.0014592756051570177, 0.0008235244313254952, -6.071146344766021e-05, -0.0014057585503906012, -0.0023643700405955315, 0.001071389764547348, 0.0032004942186176777, 0.0012298669898882508, -0.002775343833491206, 0.004271045792847872]
     Last 10:  [2.489541657269001e-05, -0.00027085962938144803, 0.0011891688918694854, -0.0008950495976023376, 0.00040699378587305546, -0.00043553835712373257, -8.213924593292177e-05, -0.0005206878413446248, 0.0009753420599736273, -0.00046670835581608117]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000007
     First 10: [-0.0038267262279987335, 0.0068062059581279755, 0.00862349197268486, -0.003707407508045435, 0.002110371831804514, -0.00023807160323485732, 0.0008586262119933963, -0.0029368214309215546, -0.0013555961195379496, 0.002701813355088234]
     Last 10:  [0.012307757511734962, -0.00804951973259449, -0.0024258382618427277, 0.001330740749835968, 0.00033376330975443125, 0.004892562050372362, 0.0021354788914322853, 0.0038321709726005793, 0.001997361658141017, 0.007425958290696144]

================================================================================
255_layers.15.mlp: Gemma3MLP (layers.15.mlp)
================================================================================

  → INPUT[0]: layers.15.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.050048, Std: 1.626903
     First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
     Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000275, Std: 0.017983
     First 10: [0.0014592756051570177, 0.0008235244313254952, -6.071146344766021e-05, -0.0014057585503906012, -0.0023643700405955315, 0.001071389764547348, 0.0032004942186176777, 0.0012298669898882508, -0.002775343833491206, 0.004271045792847872]
     Last 10:  [2.489541657269001e-05, -0.00027085962938144803, 0.0011891688918694854, -0.0008950495976023376, 0.00040699378587305546, -0.00043553835712373257, -8.213924593292177e-05, -0.0005206878413446248, 0.0009753420599736273, -0.00046670835581608117]
     Zeros: 0, Total: 5376

================================================================================
256_layers.15.post_feedforward_layernorm: Gemma3RMSNorm (layers.15.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.15.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000275, Std: 0.017983
     First 10: [0.0014592756051570177, 0.0008235244313254952, -6.071146344766021e-05, -0.0014057585503906012, -0.0023643700405955315, 0.001071389764547348, 0.0032004942186176777, 0.0012298669898882508, -0.002775343833491206, 0.004271045792847872]
     Last 10:  [2.489541657269001e-05, -0.00027085962938144803, 0.0011891688918694854, -0.0008950495976023376, 0.00040699378587305546, -0.00043553835712373257, -8.213924593292177e-05, -0.0005206878413446248, 0.0009753420599736273, -0.00046670835581608117]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.15.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 2.256958, Std: 72.825829
     First 10: [24.456777572631836, 33.42272186279297, -1.1520030498504639, -24.27264404296875, -61.76890182495117, 45.822906494140625, 76.6097412109375, 18.297256469726562, -118.28570556640625, 192.639404296875]
     Last 10:  [0.6493815779685974, -2.831252336502075, 39.51802062988281, -46.41456985473633, 27.377927780151367, -47.31842803955078, -7.534228801727295, -19.60750961303711, 51.0959587097168, -49.43213653564453]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 66.700554
     First 10: [37.311973571777344, 91.7764892578125, 42.37660217285156, 38.47107696533203, 58.72099304199219, 96.77047729492188, 53.71917724609375, 33.00951385498047, 96.42896270751953, 102.10589599609375]
     Last 10:  [28.86456298828125, 10.96767807006836, 37.0475959777832, 58.37215805053711, 76.01731872558594, 123.38829040527344, 104.01799011230469, 42.114227294921875, 58.979827880859375, 120.26609802246094]

================================================================================
257_layers.16.input_layernorm: Gemma3RMSNorm (layers.16.input_layernorm)
================================================================================

  → INPUT[0]: layers.16.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 10.034679, Std: 359.662079
     First 10: [196.82708740234375, -82.84498596191406, 8.061802864074707, -27.020780563354492, -116.069091796875, 81.03431701660156, 127.06349182128906, 0.8566036224365234, -126.49602508544922, 309.6011962890625]
     Last 10:  [-14.37716007232666, -10.176002502441406, 45.801109313964844, 26.401508331298828, 80.0511474609375, 79.88056945800781, 55.09856414794922, -82.21238708496094, -18.716266632080078, 15.203269958496094]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.133224, Std: 4.723349
     First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
     Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 15.383217
     First 10: [11.184806823730469, 5.726372718811035, 14.968947410583496, 17.010013580322266, 8.60235595703125, 4.464667320251465, 10.245817184448242, 19.778493881225586, 4.4215850830078125, 4.155135631561279]
     Last 10:  [18.88336181640625, 48.5853157043457, 17.307741165161133, 8.653636932373047, 5.521076679229736, 3.584202289581299, 4.273316383361816, 13.289327621459961, 8.725865364074707, 3.7897400856018066]

================================================================================
258_layers.16.self_attn.q_proj: Linear (layers.16.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.16.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.133224, Std: 4.723349
     First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
     Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.063896, Std: 1.741342
     First 10: [0.0821181908249855, -0.038808032870292664, 0.16820573806762695, -0.5041741132736206, -0.36305880546569824, -0.04728120565414429, 0.1847488135099411, -0.6405004262924194, 5.011054992675781, 5.636178016662598]
     Last 10:  [0.2995896339416504, 0.23130901157855988, 0.6076662540435791, 0.2111247330904007, -0.08041355013847351, -0.12157659232616425, -0.3028453588485718, 0.42278003692626953, 0.09611747413873672, -0.27475106716156006]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000000
     First 10: [0.007560789585113525, -0.0013409532839432359, -0.001271033426746726, 0.006648740731179714, 0.0011865640990436077, -0.0022895329166203737, -0.00020033262262586504, -0.0030440296977758408, 7.2256807470694184e-06, -0.005446983966976404]
     Last 10:  [0.006769891828298569, 0.0022394931875169277, 0.007254059426486492, -0.006197599694132805, -0.009683497250080109, 0.010528539307415485, -0.004412407986819744, -0.0015447982586920261, -0.003239399055019021, -0.008348883129656315]

================================================================================
259_layers.16.self_attn.k_proj: Linear (layers.16.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.16.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.133224, Std: 4.723349
     First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
     Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.014895, Std: 1.599558
     First 10: [-1.0430543422698975, -0.6856472492218018, -0.1530994176864624, -1.6472887992858887, 0.6151814460754395, 0.764738917350769, -0.09283172339200974, 1.4227927923202515, -0.42275291681289673, 1.75962495803833]
     Last 10:  [0.7464443445205688, 0.23397743701934814, -0.16423195600509644, 2.158895254135132, 0.0933859720826149, 0.48242518305778503, -1.8387813568115234, 1.1323245763778687, 0.009632214903831482, -0.3971259891986847]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000002
     First 10: [-0.001661506830714643, 0.0031083612702786922, 0.007837177254259586, -0.005201371852308512, -0.001296522794291377, 0.003733061719685793, -0.0016974160680547357, -0.006364420056343079, -0.0024480954743921757, 0.004896979779005051]
     Last 10:  [-0.0020937707740813494, 0.0039010890759527683, -0.0014331070706248283, 0.0032105331774801016, -0.00932158250361681, 0.012091083452105522, 0.005622693337500095, 0.0032725553028285503, 0.002288708696141839, 0.003944607451558113]

================================================================================
260_layers.16.self_attn.v_proj: Linear (layers.16.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.16.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.133224, Std: 4.723349
     First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
     Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.064398, Std: 0.989014
     First 10: [-0.6418328285217285, -0.3928605020046234, 1.1151726245880127, -0.7391738891601562, -0.13036535680294037, -0.44117534160614014, 0.8351699113845825, -0.11296050250530243, -0.18013650178909302, 0.21958743035793304]
     Last 10:  [-0.1414574831724167, 0.22670885920524597, -0.15669219195842743, 0.193239226937294, -0.3128224313259125, -1.4500670433044434, 0.07908748835325241, 0.1181928813457489, 0.11801724135875702, -0.10641785711050034]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000008
     First 10: [0.006273738108575344, -0.016530537977814674, 0.006372278556227684, -0.00744202733039856, -0.004356146790087223, -0.0036552930250763893, 0.003110205288976431, 0.0002614650584291667, -0.0014389000134542584, 0.011185748502612114]
     Last 10:  [-0.0013311890652403235, -0.007483083289116621, 0.009024050086736679, -0.0052536665461957455, -0.000690607528667897, -0.013438096269965172, -0.004090429283678532, -0.004103211220353842, -0.00843635480850935, -0.001576581271365285]

================================================================================
261_layers.16.self_attn.q_norm: Gemma3RMSNorm (layers.16.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.16.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.063896, Std: 1.741342
     First 10: [0.0821181908249855, -0.038808032870292664, 0.16820573806762695, -0.5041741132736206, -0.36305880546569824, -0.04728120565414429, 0.1847488135099411, -0.6405004262924194, 5.011054992675781, 5.636178016662598]
     Last 10:  [0.2995896339416504, 0.23130901157855988, 0.6076662540435791, 0.2111247330904007, -0.08041355013847351, -0.12157659232616425, -0.3028453588485718, 0.42278003692626953, 0.09611747413873672, -0.27475106716156006]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.041700, Std: 0.950639
     First 10: [0.14055228233337402, -0.05802807956933975, 0.0006027726922184229, 0.0023286594077944756, -0.4200732707977295, 0.000978846219368279, 0.1647787094116211, -0.000790201302152127, -0.06001173332333565, 0.047274816781282425]
     Last 10:  [0.5726515650749207, 0.4938984513282776, 1.3055063486099243, 1.413020133972168, -0.1483013927936554, -0.5105913877487183, -0.44439223408699036, 0.8231408596038818, 0.32543495297431946, -0.634926974773407]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.381455
     First 10: [0.8264874219894409, 0.5956393480300903, -0.9961758852005005, -1.0049288272857666, 0.2347135841846466, -1.0220924615859985, -0.04821784049272537, -0.9986834526062012, -1.0127798318862915, -0.9910491704940796]
     Last 10:  [-0.20721712708473206, -0.11440390348434448, -0.10894514620304108, 1.7758746147155762, -0.2350965440273285, 0.7418634295463562, -0.39139413833618164, -0.19248558580875397, 0.40427589416503906, -0.04153790697455406]

================================================================================
262_layers.16.self_attn.k_norm: Gemma3RMSNorm (layers.16.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.16.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.014895, Std: 1.599558
     First 10: [-1.0430543422698975, -0.6856472492218018, -0.1530994176864624, -1.6472887992858887, 0.6151814460754395, 0.764738917350769, -0.09283172339200974, 1.4227927923202515, -0.42275291681289673, 1.75962495803833]
     Last 10:  [0.7464443445205688, 0.23397743701934814, -0.16423195600509644, 2.158895254135132, 0.0933859720826149, 0.48242518305778503, -1.8387813568115234, 1.1323245763778687, 0.009632214903831482, -0.3971259891986847]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.16.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.059272, Std: 2.079158
     First 10: [-2.3326237201690674, -1.2727173566818237, -0.0011803103843703866, -0.03670081868767738, 1.1186199188232422, 0.012451402842998505, -0.21789956092834473, -0.007450073026120663, -0.004296461585909128, 0.04469418153166771]
     Last 10:  [4.765768527984619, 1.1218132972717285, -0.9314966201782227, 3.3408353328704834, 0.4841102659702301, 1.3612786531448364, -12.182586669921875, 6.189958095550537, 0.03163532912731171, -1.8134199380874634]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.596661
     First 10: [0.9464053511619568, 0.6155737042427063, -0.9932900667190552, -0.9806089401245117, 0.5826135277748108, -0.9858289957046509, 1.0429394245147705, -1.0045573711395264, -0.9911545515060425, -0.9778931736946106]
     Last 10:  [3.274418830871582, 2.2098751068115234, 2.7972145080566406, 0.03601251170039177, 2.4705967903137207, 0.8891158103942871, 3.4355854988098145, 2.6598079204559326, 1.1988102197647095, 2.0571138858795166]

================================================================================
263_layers.16.self_attn.o_proj: Linear (layers.16.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.16.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.068816, Std: 0.837523
     First 10: [-0.6418328285217285, -0.3928605020046234, 1.1151726245880127, -0.7391738891601562, -0.13036535680294037, -0.44117534160614014, 0.8351699113845825, -0.11296050250530243, -0.18013650178909302, 0.21958743035793304]
     Last 10:  [-0.12814335525035858, 0.20896776020526886, -0.14638862013816833, 0.17789873480796814, -0.2821471691131592, -1.4830693006515503, 0.07140576094388962, 0.11675554513931274, 0.12407781183719635, -0.12927919626235962]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000107, Std: 0.198805
     First 10: [-0.04244951531291008, -0.009432187303900719, -0.058707095682621, -0.11231457442045212, 0.006897404789924622, 0.19240403175354004, 0.03562046214938164, 0.03662789240479469, -0.18526023626327515, -0.16735705733299255]
     Last 10:  [0.03406906872987747, 0.041274238377809525, 0.038944266736507416, 0.0525117963552475, 0.09039435535669327, -0.03989114984869957, 0.10661245137453079, 0.005829542875289917, 0.03841768205165863, 0.07806211709976196]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000006
     First 10: [0.0006998053286224604, 0.002326422370970249, -0.005846054293215275, 0.0044138128869235516, 0.001250469358637929, -0.002497702371329069, 0.00021558628941420466, 0.001592813292518258, 0.008905366994440556, 0.0006334181525744498]
     Last 10:  [0.00033497365075163543, -0.003944684285670519, -0.010934963822364807, 0.02391514927148819, -0.0019320884020999074, 0.0005533021758310497, 0.004191674757748842, -0.007180548273026943, -0.004336138721555471, 0.013755417428910732]

================================================================================
264_layers.16.self_attn: Gemma3Attention (layers.16.self_attn)
================================================================================

  → OUTPUT[0]: layers.16.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000107, Std: 0.198805
     First 10: [-0.04244951531291008, -0.009432187303900719, -0.058707095682621, -0.11231457442045212, 0.006897404789924622, 0.19240403175354004, 0.03562046214938164, 0.03662789240479469, -0.18526023626327515, -0.16735705733299255]
     Last 10:  [0.03406906872987747, 0.041274238377809525, 0.038944266736507416, 0.0525117963552475, 0.09039435535669327, -0.03989114984869957, 0.10661245137453079, 0.005829542875289917, 0.03841768205165863, 0.07806211709976196]
     Zeros: 0, Total: 5376

================================================================================
265_layers.16.post_attention_layernorm: Gemma3RMSNorm (layers.16.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.16.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000107, Std: 0.198805
     First 10: [-0.04244951531291008, -0.009432187303900719, -0.058707095682621, -0.11231457442045212, 0.006897404789924622, 0.19240403175354004, 0.03562046214938164, 0.03662789240479469, -0.18526023626327515, -0.16735705733299255]
     Last 10:  [0.03406906872987747, 0.041274238377809525, 0.038944266736507416, 0.0525117963552475, 0.09039435535669327, -0.03989114984869957, 0.10661245137453079, 0.005829542875289917, 0.03841768205165863, 0.07806211709976196]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -2.825767, Std: 91.664742
     First 10: [-6.544094562530518, -7.093411922454834, -14.343620300292969, -27.86068344116211, 2.336379051208496, 90.0130386352539, 10.417393684387207, 9.075632095336914, -90.48550415039062, -99.10968017578125]
     Last 10:  [9.018077850341797, 7.927422046661377, 12.122605323791504, 23.551931381225586, 48.905242919921875, -35.421607971191406, 67.46156311035156, 2.68066143989563, 17.377859115600586, 62.81224822998047]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 50.438297
     First 10: [20.260683059692383, 102.71537780761719, 32.69524002075195, 33.21023178100586, 45.71517562866211, 63.51959228515625, 39.332942962646484, 33.171600341796875, 66.35923767089844, 80.67185974121094]
     Last 10:  [25.82763671875, 18.466218948364258, 30.548675537109375, 44.45674514770508, 53.833099365234375, 88.99542236328125, 63.132347106933594, 45.60539245605469, 44.845191955566406, 80.55164337158203]

================================================================================
266_layers.16.pre_feedforward_layernorm: Gemma3RMSNorm (layers.16.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.16.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 7.208912, Std: 299.971649
     First 10: [190.28298950195312, -89.93840026855469, -6.281817436218262, -54.88146209716797, -113.73271179199219, 171.04736328125, 137.4808807373047, 9.932235717773438, -216.98153686523438, 210.49151611328125]
     Last 10:  [-5.359082221984863, -2.2485804557800293, 57.92371368408203, 49.95343780517578, 128.95639038085938, 44.458961486816406, 122.56012725830078, -79.53172302246094, -1.3384075164794922, 78.01551818847656]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.081439, Std: 2.306295
     First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
     Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 3.857414
     First 10: [4.439868450164795, 0.3094330430030823, 5.165595054626465, 5.282114505767822, 2.392660140991211, 1.293436884880066, 4.225063323974609, 6.360154628753662, 1.267064094543457, 0.9735473990440369]
     Last 10:  [6.100832462310791, 9.786917686462402, 6.353329181671143, 2.42586350440979, 1.2577134370803833, 0.6357231140136719, 1.1952502727508545, 4.297306537628174, 2.723905086517334, 0.7918703556060791]

================================================================================
267_layers.16.mlp.gate_proj: Linear (layers.16.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.16.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.081439, Std: 2.306295
     First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
     Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.310488, Std: 0.553181
     First 10: [-0.1314050257205963, -0.16383230686187744, -0.6103329658508301, 0.5611538887023926, -0.3229793310165405, 0.17225991189479828, 0.006114445626735687, -0.048787087202072144, 0.5801162123680115, -0.11870715022087097]
     Last 10:  [-0.003261435776948929, 0.05744418501853943, -0.19689679145812988, 0.05362384766340256, -0.14796103537082672, 0.0010593235492706299, 0.02988205850124359, -0.03396691381931305, -0.09891755133867264, -0.020195968449115753]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000024
     First 10: [-0.005954342428594828, -0.004031813703477383, 0.0027198370080441236, -0.0006994882714934647, -0.007669598795473576, -6.487992504844442e-05, 0.0031138909980654716, -0.0028752402868121862, -0.011185254901647568, -0.004510686732828617]
     Last 10:  [0.0025696030352264643, -0.004025915637612343, 0.001328623853623867, -0.0035978094674646854, 0.0006200005300343037, 0.004065673798322678, 0.002648233901709318, 0.004301558248698711, 0.006214546039700508, 0.005692251026630402]

================================================================================
268_layers.16.mlp.act_fn: PytorchGELUTanh (layers.16.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.16.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.310488, Std: 0.553181
     First 10: [-0.1314050257205963, -0.16383230686187744, -0.6103329658508301, 0.5611538887023926, -0.3229793310165405, 0.17225991189479828, 0.006114445626735687, -0.048787087202072144, 0.5801162123680115, -0.11870715022087097]
     Last 10:  [-0.003261435776948929, 0.05744418501853943, -0.19689679145812988, 0.05362384766340256, -0.14796103537082672, 0.0010593235492706299, 0.02988205850124359, -0.03396691381931305, -0.09891755133867264, -0.020195968449115753]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.16.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.030285, Std: 0.178546
     First 10: [-0.058833733201026917, -0.07125607877969742, -0.16532567143440247, 0.39988234639167786, -0.12058942019939423, 0.09790939837694168, 0.0030721379444003105, -0.023444367572665215, 0.4171217679977417, -0.05374516546726227]
     Last 10:  [-0.0016264744335785508, 0.030037809163331985, -0.08308190107345581, 0.02795853652060032, -0.06527860462665558, 0.0005301094497554004, 0.015297207050025463, -0.016523266211152077, -0.04556163772940636, -0.009935276582837105]
     Zeros: 0, Total: 8064

================================================================================
269_layers.16.mlp.up_proj: Linear (layers.16.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.16.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.081439, Std: 2.306295
     First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
     Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.012204, Std: 0.447993
     First 10: [-0.09395742416381836, 0.04666103422641754, -0.364766001701355, 0.2615402936935425, -0.24587729573249817, 0.4023342728614807, -0.18297605216503143, 0.29130780696868896, -0.4948385953903198, 0.12745603919029236]
     Last 10:  [0.07557912170886993, -0.051932401955127716, -0.0135548897087574, -0.011789873242378235, -0.008807355538010597, 0.14916223287582397, -0.11478916555643082, -0.05917856842279434, -0.07885716110467911, -0.16659410297870636]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000005
     First 10: [-0.0067926011979579926, -0.011965760961174965, -0.007862970232963562, 0.007877223193645477, -0.007498553954064846, 0.0064048757776618, 0.007701195776462555, 0.00656846584752202, 0.006366816349327564, -0.0053824675269424915]
     Last 10:  [-0.0035773178096860647, 0.0017602662555873394, -0.0031272354535758495, 0.002056300872936845, -0.0007994717452675104, -0.005777927115559578, -0.0011250660754740238, 0.0055223130621016026, -0.005172920413315296, -0.01433495432138443]

================================================================================
270_layers.16.mlp.down_proj: Linear (layers.16.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.16.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000321, Std: 0.097267
     First 10: [0.005527866072952747, -0.003324882360175252, 0.06030518561601639, 0.10458534955978394, 0.02965020015835762, 0.03939230740070343, -0.0005621276795864105, -0.006829527206718922, -0.20640794932842255, -0.006850145757198334]
     Last 10:  [-0.00012292750761844218, -0.0015599356265738606, 0.0011261659674346447, -0.0003296275972388685, 0.0005749318515881896, 7.907230610726401e-05, -0.0017559536499902606, 0.0009778232779353857, 0.0035928613506257534, 0.0016551584703847766]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.16.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000706, Std: 0.039395
     First 10: [0.018145309761166573, 0.005536272190511227, -0.00724404864013195, 0.0067577725276350975, 0.01675591431558132, 0.005521407816559076, 0.009664974175393581, 0.005731484387069941, -0.004609137773513794, -0.008363023400306702]
     Last 10:  [0.003607769962400198, 0.002256703795865178, 0.017945390194654465, 0.0009218337363563478, 0.003465424058958888, -0.0022044284269213676, -0.0004948796704411507, -0.0037707828450948, -0.000382079160772264, 0.0032334281131625175]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000001
     First 10: [0.009342985227704048, -0.0012525039492174983, -0.002104388549923897, -3.509163434500806e-05, 0.0013846233487129211, -0.0012584790820255876, -0.0016406840877607465, 0.00642514880746603, 0.010521650314331055, -0.004294630605727434]
     Last 10:  [-0.004043946973979473, -0.0005893409252166748, -0.0002973712398670614, -0.0004162234254181385, -0.003923133481293917, 0.008073164150118828, 0.0038827424868941307, 0.004329652525484562, -0.00927778147161007, 0.0010950996074825525]

================================================================================
271_layers.16.mlp: Gemma3MLP (layers.16.mlp)
================================================================================

  → INPUT[0]: layers.16.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.081439, Std: 2.306295
     First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
     Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000706, Std: 0.039395
     First 10: [0.018145309761166573, 0.005536272190511227, -0.00724404864013195, 0.0067577725276350975, 0.01675591431558132, 0.005521407816559076, 0.009664974175393581, 0.005731484387069941, -0.004609137773513794, -0.008363023400306702]
     Last 10:  [0.003607769962400198, 0.002256703795865178, 0.017945390194654465, 0.0009218337363563478, 0.003465424058958888, -0.0022044284269213676, -0.0004948796704411507, -0.0037707828450948, -0.000382079160772264, 0.0032334281131625175]
     Zeros: 0, Total: 5376

================================================================================
272_layers.16.post_feedforward_layernorm: Gemma3RMSNorm (layers.16.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.16.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000706, Std: 0.039395
     First 10: [0.018145309761166573, 0.005536272190511227, -0.00724404864013195, 0.0067577725276350975, 0.01675591431558132, 0.005521407816559076, 0.009664974175393581, 0.005731484387069941, -0.004609137773513794, -0.008363023400306702]
     Last 10:  [0.003607769962400198, 0.002256703795865178, 0.017945390194654465, 0.0009218337363563478, 0.003465424058958888, -0.0022044284269213676, -0.0004948796704411507, -0.0037707828450948, -0.000382079160772264, 0.0032334281131625175]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.16.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 2.744242, Std: 111.346214
     First 10: [33.89567947387695, 32.76103210449219, -20.25352668762207, 18.3454532623291, 60.56814956665039, 28.947559356689453, 34.44989776611328, 13.414114952087402, -23.95740509033203, -51.58452606201172]
     Last 10:  [40.443458557128906, 14.429034233093262, 292.05535888671875, 21.065383911132812, 88.27689361572266, -90.2981948852539, -16.67511558532715, -61.03594970703125, -7.756007671356201, 127.9292984008789]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 114.082069
     First 10: [56.14236068725586, 180.01658630371094, 84.52587890625, 82.04302215576172, 109.57435607910156, 159.37637329101562, 108.03489685058594, 70.59342956542969, 158.0004425048828, 187.68368530273438]
     Last 10:  [54.63152313232422, 30.730300903320312, 79.76510620117188, 112.40397644042969, 125.41603088378906, 202.2799530029297, 166.2171173095703, 79.32776641845703, 99.73870849609375, 195.34429931640625]

================================================================================
273_layers.17.input_layernorm: Gemma3RMSNorm (layers.17.input_layernorm)
================================================================================

  → INPUT[0]: layers.17.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 9.953154, Std: 331.399292
     First 10: [224.1786651611328, -57.1773681640625, -26.535343170166016, -36.5360107421875, -53.1645622253418, 199.9949188232422, 171.9307861328125, 23.346351623535156, -240.93893432617188, 158.906982421875]
     Last 10:  [35.08437728881836, 12.18045425415039, 349.97906494140625, 71.0188217163086, 217.2332763671875, -45.8392333984375, 105.885009765625, -140.5676727294922, -9.094415664672852, 205.94482421875]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.186234, Std: 6.954648
     First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
     Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 14.356262
     First 10: [20.28262710571289, 7.830807685852051, 13.503637313842773, 18.648439407348633, 8.984878540039062, 6.175092697143555, 11.881762504577637, 21.111751556396484, 5.469335079193115, 5.6146159172058105]
     Last 10:  [19.9330997467041, 30.811546325683594, 21.19959831237793, 9.981353759765625, 6.136640548706055, 4.285931587219238, 5.661437034606934, 11.488137245178223, 9.1198091506958, 4.745204925537109]

================================================================================
274_layers.17.self_attn.q_proj: Linear (layers.17.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.17.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.186234, Std: 6.954648
     First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
     Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.311863, Std: 4.017663
     First 10: [0.13857966661453247, -8.82702350616455, 0.0628214180469513, 9.121500968933105, 8.699965476989746, -0.6280006766319275, -8.965055465698242, 1.2241649627685547, 8.873095512390137, 9.276311874389648]
     Last 10:  [0.5574794411659241, 0.5186766982078552, 0.8274462223052979, 0.020087286829948425, -0.048790574073791504, 0.32204025983810425, -1.638026475906372, 1.2235217094421387, -0.40435969829559326, 2.126105308532715]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000005
     First 10: [0.006196626927703619, 0.0013273205840960145, 0.0030701281502842903, 0.001168625196442008, 0.004541410133242607, -0.003093881532549858, -0.005608140956610441, -0.0007581788813695312, 0.001833145273849368, -0.0022439565509557724]
     Last 10:  [-0.0027491357177495956, 0.007123713381588459, 0.008755219168961048, 0.010577703826129436, -0.005411603953689337, -0.00203587650321424, 0.010185332968831062, 0.027133231982588768, 0.0028441250324249268, 0.0005111763603053987]

================================================================================
275_layers.17.self_attn.k_proj: Linear (layers.17.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.17.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.186234, Std: 6.954648
     First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
     Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.271005, Std: 3.168662
     First 10: [0.3505149781703949, -3.1803534030914307, 0.23355220258235931, -7.714994430541992, 1.7707030773162842, 0.9917514324188232, 2.9340968132019043, 0.035356372594833374, 0.2736923396587372, -0.8501555919647217]
     Last 10:  [3.3833799362182617, 5.165805816650391, 17.18344497680664, -7.588434219360352, -3.2140440940856934, 1.6651239395141602, -13.826639175415039, 9.17832088470459, -0.38373684883117676, 5.6469502449035645]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000010
     First 10: [-0.00595937529578805, 0.0018902983283624053, -0.004761013202369213, -0.005027094390243292, 0.003415302373468876, 0.001768438145518303, -0.0018676305189728737, -0.010651792399585247, 8.123203588183969e-05, 0.007455076090991497]
     Last 10:  [-0.008670469745993614, 0.0009670004947111011, 0.015965931117534637, 0.0066984230652451515, 0.005742099601775408, -4.94374762638472e-05, 0.007192118093371391, -0.009198829531669617, -0.0017533436184749007, 0.0015993914566934109]

================================================================================
276_layers.17.self_attn.v_proj: Linear (layers.17.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.17.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.186234, Std: 6.954648
     First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
     Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.096592, Std: 1.676072
     First 10: [1.8853219747543335, -0.43604549765586853, -1.0771384239196777, -0.4341403543949127, -0.2480888068675995, -0.6475500464439392, -0.5702807903289795, -0.41407105326652527, 1.435836672782898, 0.03128881752490997]
     Last 10:  [1.235020637512207, -0.46707072854042053, 0.919693648815155, 1.6343183517456055, -0.6363921761512756, 0.06932976841926575, 0.3904760777950287, -0.47385191917419434, -0.32089585065841675, -0.9098753929138184]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000005
     First 10: [-0.010762250982224941, 0.022416409105062485, -0.013636168092489243, 0.0028633959591388702, -0.009530629962682724, -0.005947485566139221, 0.010240785777568817, 0.008094820193946362, -0.011260668747127056, -0.0023478076327592134]
     Last 10:  [0.006382990628480911, 0.010400365106761456, 0.00597954448312521, 0.008205460384488106, -0.0005676017026416957, 0.0034803336020559072, 0.011472286656498909, 0.0003859263379126787, -0.011602994985878468, 0.008656209334731102]

================================================================================
277_layers.17.self_attn.q_norm: Gemma3RMSNorm (layers.17.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.17.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.311863, Std: 4.017663
     First 10: [0.13857966661453247, -8.82702350616455, 0.0628214180469513, 9.121500968933105, 8.699965476989746, -0.6280006766319275, -8.965055465698242, 1.2241649627685547, 8.873095512390137, 9.276311874389648]
     Last 10:  [0.5574794411659241, 0.5186766982078552, 0.8274462223052979, 0.020087286829948425, -0.048790574073791504, 0.32204025983810425, -1.638026475906372, 1.2235217094421387, -0.40435969829559326, 2.126105308532715]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.012446, Std: 1.021709
     First 10: [0.18029747903347015, -0.027406344190239906, 0.13634973764419556, -0.007857843302190304, 0.1501828134059906, -1.0530449151992798, 0.033092644065618515, 2.246753692626953, 0.10806622356176376, -0.24445298314094543]
     Last 10:  [0.07680691033601761, 0.12066474556922913, 0.0834144577383995, 0.010885986499488354, -0.007186017464846373, 0.057424046099185944, -0.15672728419303894, 0.16698266565799713, -0.09048336744308472, 0.9270464181900024]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.695495
     First 10: [2.7624258995056152, -0.9910212755203247, 5.276598930358887, -1.0024912357330322, -0.9500793218612671, 3.8491382598876953, -1.0106747150421143, 4.307540416717529, -0.9647797346115112, -1.0762075185775757]
     Last 10:  [-0.7833954095840454, -0.634253740310669, -0.8415114879608154, -0.14799383282661438, -0.768447995185852, -0.7196633815765381, -0.8495750427246094, -0.7854364514350891, -0.6481989622116089, -0.3144913613796234]

================================================================================
278_layers.17.self_attn.k_norm: Gemma3RMSNorm (layers.17.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.17.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.271005, Std: 3.168662
     First 10: [0.3505149781703949, -3.1803534030914307, 0.23355220258235931, -7.714994430541992, 1.7707030773162842, 0.9917514324188232, 2.9340968132019043, 0.035356372594833374, 0.2736923396587372, -0.8501555919647217]
     Last 10:  [3.3833799362182617, 5.165805816650391, 17.18344497680664, -7.588434219360352, -3.2140440940856934, 1.6651239395141602, -13.826639175415039, 9.17832088470459, -0.38373684883117676, 5.6469502449035645]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.17.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.683395, Std: 7.308217
     First 10: [0.1348065882921219, -0.020096804946660995, 0.047977346926927567, 0.01766389235854149, 0.017619771882891655, 0.27841514348983765, -0.04389505088329315, 0.009516091085970402, 0.0020128744654357433, -0.0006479561561718583]
     Last 10:  [10.378642082214355, 9.963871002197266, 57.42681121826172, -7.017959117889404, -10.160416603088379, 4.68733549118042, -57.844722747802734, 28.779096603393555, -0.8765086531639099, 12.75533676147461]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 1.916614
     First 10: [-0.3125554919242859, -0.988705039024353, -0.6328146457672119, -1.0040924549102783, -0.9822136163711548, -0.4982087016105652, -1.0267407894134521, -0.5189126133918762, -0.9868541955947876, -0.9986376762390137]
     Last 10:  [11.76327133178711, 7.025318145751953, 12.905183792114258, 2.8479630947113037, 12.153215408325195, 10.712556838989258, 16.406816482543945, 12.0462646484375, 8.503748893737793, 8.398319244384766]

================================================================================
279_layers.17.self_attn.o_proj: Linear (layers.17.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.17.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.103143, Std: 1.320695
     First 10: [1.8853219747543335, -0.43604549765586853, -1.0771384239196777, -0.4341403543949127, -0.2480888068675995, -0.6475500464439392, -0.5702807903289795, -0.41407105326652527, 1.435836672782898, 0.03128881752490997]
     Last 10:  [0.859013557434082, -0.1789332926273346, 0.7977057099342346, 1.3088476657867432, -0.6629815101623535, 0.21104279160499573, 0.6292656660079956, -0.8145148754119873, -0.25235381722450256, -0.671532154083252]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005370, Std: 0.829125
     First 10: [-0.13105419278144836, -0.03487660363316536, 0.045117706060409546, -0.04473287984728813, 0.3218005299568176, 0.23208868503570557, 0.1797301173210144, 0.03578261286020279, -0.1155415028333664, -0.1811402142047882]
     Last 10:  [-0.12785762548446655, -0.025170370936393738, -0.07504306733608246, -0.48003023862838745, 0.20806440711021423, -0.01342037320137024, 0.03906511515378952, 0.16481474041938782, -0.05493714660406113, 0.018011868000030518]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000004
     First 10: [0.002645848784595728, -0.0037774404045194387, -0.0010871210834011436, -0.004089989699423313, -0.008573997765779495, -0.0020508687011897564, -0.016026543453335762, 0.006868305616080761, -0.0031082150526344776, 0.004010543692857027]
     Last 10:  [-0.002106929663568735, -0.01262547355145216, 0.002280222252011299, 0.006057330407202244, 0.0007182764820754528, 0.01873204857110977, 0.001193867065012455, 0.0037791715003550053, 0.006180597003549337, 0.012733503244817257]

================================================================================
280_layers.17.self_attn: Gemma3Attention (layers.17.self_attn)
================================================================================

  → OUTPUT[0]: layers.17.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005370, Std: 0.829125
     First 10: [-0.13105419278144836, -0.03487660363316536, 0.045117706060409546, -0.04473287984728813, 0.3218005299568176, 0.23208868503570557, 0.1797301173210144, 0.03578261286020279, -0.1155415028333664, -0.1811402142047882]
     Last 10:  [-0.12785762548446655, -0.025170370936393738, -0.07504306733608246, -0.48003023862838745, 0.20806440711021423, -0.01342037320137024, 0.03906511515378952, 0.16481474041938782, -0.05493714660406113, 0.018011868000030518]
     Zeros: 0, Total: 5376

================================================================================
281_layers.17.post_attention_layernorm: Gemma3RMSNorm (layers.17.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.17.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.005370, Std: 0.829125
     First 10: [-0.13105419278144836, -0.03487660363316536, 0.045117706060409546, -0.04473287984728813, 0.3218005299568176, 0.23208868503570557, 0.1797301173210144, 0.03578261286020279, -0.1155415028333664, -0.1811402142047882]
     Last 10:  [-0.12785762548446655, -0.025170370936393738, -0.07504306733608246, -0.48003023862838745, 0.20806440711021423, -0.01342037320137024, 0.03906511515378952, 0.16481474041938782, -0.05493714660406113, 0.018011868000030518]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -4.750216, Std: 125.622726
     First 10: [-18.045936584472656, -32.569236755371094, 10.212577819824219, -10.507555961608887, 79.1751480102539, 90.41741180419922, 40.399658203125, 6.878398895263672, -46.547943115234375, -76.33650970458984]
     Last 10:  [-9.095890998840332, -1.0184733867645264, -7.68153715133667, -70.52977752685547, 21.238534927368164, -2.711376190185547, 5.9426984786987305, 7.45294713973999, -5.328487873077393, 3.3442492485046387]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 189.625793
     First 10: [77.707763671875, 532.7802124023438, 128.383056640625, 133.2653350830078, 139.63427734375, 221.68304443359375, 127.48306274414062, 108.87638854980469, 229.27752685546875, 239.88319396972656]
     Last 10:  [90.32202911376953, 50.941802978515625, 130.3997344970703, 187.6083221435547, 130.03390502929688, 258.3475341796875, 194.27719116210938, 57.048221588134766, 123.5073013305664, 237.33993530273438]

================================================================================
282_layers.17.pre_feedforward_layernorm: Gemma3RMSNorm (layers.17.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.17.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 5.202938, Std: 275.644623
     First 10: [206.13272094726562, -89.7466049194336, -16.322765350341797, -47.0435676574707, 26.01058578491211, 290.4123229980469, 212.3304443359375, 30.224750518798828, -287.48687744140625, 82.57047271728516]
     Last 10:  [25.988487243652344, 11.161980628967285, 342.2975158691406, 0.489044189453125, 238.47181701660156, -48.55060958862305, 111.82770538330078, -133.11473083496094, -14.422903060913086, 209.28907775878906]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.028222, Std: 1.617025
     First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
     Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 2.004896
     First 10: [3.1536712646484375, -0.0777309387922287, 2.3368325233459473, 2.1906604766845703, 1.003316044807434, 0.37845033407211304, 1.8280584812164307, 2.8097991943359375, 0.3033554255962372, 0.2872796356678009]
     Last 10:  [3.045039176940918, 5.177245140075684, 2.5506372451782227, 1.093575119972229, 0.8177765607833862, 0.05640130117535591, 0.3180082142353058, 2.357560157775879, 1.2181755304336548, 0.22123077511787415]

================================================================================
283_layers.17.mlp.gate_proj: Linear (layers.17.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.17.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.028222, Std: 1.617025
     First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
     Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.171175, Std: 0.350872
     First 10: [-0.020067356526851654, -0.25969627499580383, 0.0644199401140213, -0.07609587907791138, -0.24038158357143402, 0.1670592874288559, -0.06978140771389008, 0.048835840076208115, -0.0325770229101181, 0.027158107608556747]
     Last 10:  [-0.08080010116100311, -0.02211068570613861, -0.07788600027561188, 0.007301550358533859, -0.20040029287338257, -0.06233274191617966, -0.2712494432926178, -0.036856625229120255, 0.021736374124884605, -0.07884566485881805]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000052
     First 10: [-0.0012986636720597744, 0.003286434803158045, 0.006368405185639858, -0.007690422236919403, -0.007189034949988127, 0.001731455558910966, -0.008623088710010052, 0.0023837187327444553, -0.005950574297457933, -0.003280687378719449]
     Last 10:  [0.0200994610786438, 0.013970802538096905, 0.000864326604641974, -0.008513224311172962, -0.0020685784984380007, -0.0035868415143340826, -0.0030057430267333984, 0.009885583072900772, -0.004127595108002424, -0.0027782933320850134]

================================================================================
284_layers.17.mlp.act_fn: PytorchGELUTanh (layers.17.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.17.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.171175, Std: 0.350872
     First 10: [-0.020067356526851654, -0.25969627499580383, 0.0644199401140213, -0.07609587907791138, -0.24038158357143402, 0.1670592874288559, -0.06978140771389008, 0.048835840076208115, -0.0325770229101181, 0.027158107608556747]
     Last 10:  [-0.08080010116100311, -0.02211068570613861, -0.07788600027561188, 0.007301550358533859, -0.20040029287338257, -0.06233274191617966, -0.2712494432926178, -0.036856625229120255, 0.021736374124884605, -0.07884566485881805]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.17.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.030967, Std: 0.135489
     First 10: [-0.009873035363852978, -0.10324342548847198, 0.033864401280879974, -0.035740070044994354, -0.09735973179340363, 0.09461182355880737, -0.03294965997338295, 0.02536899410188198, -0.015865204855799675, 0.013873263262212276]
     Last 10:  [-0.03779834136366844, -0.01086032297462225, -0.03652537986636162, 0.0036720437929034233, -0.08428562432527542, -0.029617341235280037, -0.10662973672151566, -0.017886508256196976, 0.011056660674512386, -0.03694533184170723]
     Zeros: 0, Total: 8064

================================================================================
285_layers.17.mlp.up_proj: Linear (layers.17.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.17.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.028222, Std: 1.617025
     First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
     Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.006298, Std: 0.308781
     First 10: [-0.019437983632087708, 0.15518909692764282, -0.61243736743927, -0.039641156792640686, 0.06762806326150894, -0.07792088389396667, 0.2095772922039032, -0.055818766355514526, 0.13642644882202148, -0.33568185567855835]
     Last 10:  [-0.012301240116357803, -0.09485477209091187, -0.07380126416683197, -0.03080572932958603, -0.0125289186835289, 0.07794427126646042, -0.22445155680179596, -0.013760721310973167, 0.06169222667813301, 0.009290918707847595]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000003
     First 10: [0.00870748795568943, 0.004598632454872131, 0.002323161344975233, 0.0011908502783626318, -0.009187470190227032, 0.0013869558461010456, 0.005665526259690523, -0.003509944537654519, 0.004803090821951628, -0.006127276923507452]
     Last 10:  [0.00463111512362957, -0.005259573459625244, -0.004339580424129963, -0.003973966930061579, 0.004198986105620861, -0.010119888000190258, -0.0022532131988555193, 0.0031550254207104445, -0.0065616583451628685, 0.009069613181054592]

================================================================================
286_layers.17.mlp.down_proj: Linear (layers.17.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.17.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.001078, Std: 0.054392
     First 10: [0.00019191189494449645, -0.016022253781557083, -0.020739825442433357, 0.0014167777262628078, -0.0065842499025166035, -0.0073722368106245995, -0.006905500311404467, -0.001416065962985158, -0.002164433477446437, -0.004657002631574869]
     Last 10:  [0.0004649664624594152, 0.0010301534784957767, 0.0026956191286444664, -0.00011311998969176784, 0.0010560076916590333, -0.002308502094820142, 0.023933209478855133, 0.00024613126879557967, 0.0006821100250817835, -0.0003432560770306736]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.17.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000621, Std: 0.017734
     First 10: [0.014830893836915493, -0.0022054282017052174, -0.020456654950976372, 0.010588185861706734, -0.006462601013481617, 0.014442737214267254, 0.001900000381283462, -0.004931164439767599, 0.0022836157586425543, -0.004706940148025751]
     Last 10:  [-0.0002853651822078973, 0.0007746431510895491, -0.005335040856152773, -0.002247826661914587, 0.0020703605841845274, 0.0005449880845844746, -2.3727596271783113e-05, 0.002417197683826089, 0.001982189482077956, -0.0009052392560988665]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000000
     First 10: [0.003849996253848076, 0.0007286604959517717, -0.00176004390232265, 0.0034232675097882748, -0.00838839914649725, -0.0033511826768517494, 0.0033589904196560383, -0.0017596026882529259, 0.0003196120378561318, 0.008345276117324829]
     Last 10:  [-0.003963155671954155, 0.0030881003476679325, -0.005414232611656189, -0.003918164875358343, 0.0007662131683900952, 0.0058280834928154945, 0.00162716512568295, -0.004555738531053066, -0.011697879061102867, 0.013829931616783142]

================================================================================
287_layers.17.mlp: Gemma3MLP (layers.17.mlp)
================================================================================

  → INPUT[0]: layers.17.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.028222, Std: 1.617025
     First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
     Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000621, Std: 0.017734
     First 10: [0.014830893836915493, -0.0022054282017052174, -0.020456654950976372, 0.010588185861706734, -0.006462601013481617, 0.014442737214267254, 0.001900000381283462, -0.004931164439767599, 0.0022836157586425543, -0.004706940148025751]
     Last 10:  [-0.0002853651822078973, 0.0007746431510895491, -0.005335040856152773, -0.002247826661914587, 0.0020703605841845274, 0.0005449880845844746, -2.3727596271783113e-05, 0.002417197683826089, 0.001982189482077956, -0.0009052392560988665]
     Zeros: 0, Total: 5376

================================================================================
288_layers.17.post_feedforward_layernorm: Gemma3RMSNorm (layers.17.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.17.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000621, Std: 0.017734
     First 10: [0.014830893836915493, -0.0022054282017052174, -0.020456654950976372, 0.010588185861706734, -0.006462601013481617, 0.014442737214267254, 0.001900000381283462, -0.004931164439767599, 0.0022836157586425543, -0.004706940148025751]
     Last 10:  [-0.0002853651822078973, 0.0007746431510895491, -0.005335040856152773, -0.002247826661914587, 0.0020703605841845274, 0.0005449880845844746, -2.3727596271783113e-05, 0.002417197683826089, 0.001982189482077956, -0.0009052392560988665]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.17.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 4.056320, Std: 248.259827
     First 10: [53.58515930175781, -35.57484436035156, -133.1756134033203, 78.62606811523438, -55.07909393310547, 148.32968139648438, 14.99479866027832, -32.27436065673828, 23.399826049804688, -62.352054595947266]
     Last 10:  [-4.5850138664245605, 7.166935443878174, -149.34461975097656, -69.96112060546875, 58.469444274902344, 27.1387939453125, -1.0460755825042725, 41.42734146118164, 47.9119873046875, -43.08349609375]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 140.947922
     First 10: [58.77116012573242, 265.848388671875, 106.6972427368164, 121.84556579589844, 139.9918212890625, 168.89987182617188, 129.55738830566406, 107.27362060546875, 168.513427734375, 218.14248657226562]
     Last 10:  [70.56929016113281, 40.211544036865234, 123.69209289550781, 137.63758850097656, 124.79693603515625, 220.81484985351562, 195.37960815429688, 75.34172821044922, 106.66786193847656, 210.99940490722656]

================================================================================
289_layers.18.input_layernorm: Gemma3RMSNorm (layers.18.input_layernorm)
================================================================================

  → INPUT[0]: layers.18.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 9.259257, Std: 477.690765
     First 10: [259.7178955078125, -125.32144927978516, -149.49838256835938, 31.582500457763672, -29.06850814819336, 438.74200439453125, 227.3252410888672, -2.049610137939453, -264.0870361328125, 20.21841812133789]
     Last 10:  [21.403472900390625, 18.328916549682617, 192.95289611816406, -69.47207641601562, 296.9412536621094, -21.411815643310547, 110.78163146972656, -91.68739318847656, 33.48908233642578, 166.20558166503906]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.068529, Std: 6.911074
     First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
     Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 14.610023
     First 10: [22.370426177978516, 4.306778907775879, 10.856218338012695, 8.48385238647461, 10.740245819091797, 7.466383934020996, 8.950616836547852, 10.12578010559082, 7.393258094787598, 6.430755615234375]
     Last 10:  [17.18761444091797, 29.670778274536133, 8.553488731384277, 10.129830360412598, 7.778879165649414, 4.819099426269531, 6.708392143249512, 22.19830894470215, 11.844152450561523, 5.762073993682861]

================================================================================
290_layers.18.self_attn.q_proj: Linear (layers.18.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.18.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.068529, Std: 6.911074
     First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
     Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.062047, Std: 2.425930
     First 10: [-2.1774837970733643, -0.042265474796295166, 8.275694847106934, 1.1739144325256348, -9.493600845336914, -3.261657476425171, 0.8537642359733582, -0.01603122055530548, 0.9513674974441528, -0.4123399257659912]
     Last 10:  [-0.5237553715705872, 0.1617172360420227, 0.38433629274368286, 0.1967179924249649, -0.2654699385166168, -0.9831024408340454, -0.4114379286766052, -2.561054229736328, 0.35436972975730896, -0.37237581610679626]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000005
     First 10: [0.010377204045653343, 0.010607561096549034, 0.011600105091929436, 0.01844019815325737, -0.0008249374805018306, -0.018986407667398453, 0.015274100005626678, 0.003390618832781911, -0.00779009610414505, 0.0008020806708373129]
     Last 10:  [0.008621126413345337, 0.018412819132208824, -0.004203501157462597, 0.006963036023080349, -0.01848948374390602, -0.006363373249769211, 0.006478989031165838, -0.0007440822082571685, -0.013835696503520012, 0.011805977672338486]

================================================================================
291_layers.18.self_attn.k_proj: Linear (layers.18.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.18.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.068529, Std: 6.911074
     First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
     Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.104629, Std: 2.658833
     First 10: [0.162762850522995, 0.2684285640716553, -0.5371240377426147, -1.3025097846984863, -2.5659079551696777, -5.457845687866211, -2.5228047370910645, 3.0173192024230957, -7.311702728271484, -0.3233160972595215]
     Last 10:  [-2.0583090782165527, -5.3989667892456055, -3.754859447479248, -4.582265377044678, -2.5288443565368652, -1.9453688859939575, 2.989722728729248, -2.247180461883545, 4.377954959869385, -0.1701778918504715]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000046
     First 10: [0.01858072727918625, -0.002505107317119837, -0.012843092903494835, -0.011386226862668991, 0.0008688805974088609, -0.005879261065274477, -0.007991829887032509, -0.00723131000995636, -0.001276899711228907, -0.002457377500832081]
     Last 10:  [0.006220174953341484, 0.0027518407441675663, 0.0025000316090881824, 0.00011414344771765172, 0.005030691623687744, -0.0002500355476513505, -0.005921239033341408, 0.01522790640592575, -0.0071881539188325405, 0.008389896713197231]

================================================================================
292_layers.18.self_attn.v_proj: Linear (layers.18.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.18.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.068529, Std: 6.911074
     First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
     Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.118032, Std: 1.525934
     First 10: [-2.6649892330169678, 1.796452283859253, -0.13894771039485931, 1.1040825843811035, 0.0843687355518341, -0.4004369080066681, -0.44738176465034485, -0.22352451086044312, 1.222933292388916, -0.6613889932632446]
     Last 10:  [-0.054093584418296814, -0.5611344575881958, -0.17963440716266632, -0.3368476629257202, 0.164906844496727, 0.16659802198410034, 0.20967981219291687, 0.9458404183387756, 0.32866865396499634, -0.2231229543685913]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000026
     First 10: [0.0038718157447874546, -0.015521194785833359, 0.002891088370233774, -0.01120581291615963, 0.003734888043254614, 0.006211385130882263, -0.01032900158315897, -0.011474031023681164, -0.006345940753817558, 0.006543049588799477]
     Last 10:  [-0.0066836075857281685, -0.006722116377204657, -0.0030630703549832106, -0.009784504771232605, -0.001989307813346386, -0.008001644164323807, -0.00029727694345638156, 0.0067941173911094666, 0.01386222429573536, -0.011817804537713528]

================================================================================
293_layers.18.self_attn.q_norm: Gemma3RMSNorm (layers.18.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.18.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.062047, Std: 2.425930
     First 10: [-2.1774837970733643, -0.042265474796295166, 8.275694847106934, 1.1739144325256348, -9.493600845336914, -3.261657476425171, 0.8537642359733582, -0.01603122055530548, 0.9513674974441528, -0.4123399257659912]
     Last 10:  [-0.5237553715705872, 0.1617172360420227, 0.38433629274368286, 0.1967179924249649, -0.2654699385166168, -0.9831024408340454, -0.4114379286766052, -2.561054229736328, 0.35436972975730896, -0.37237581610679626]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.046454, Std: 1.144631
     First 10: [-1.9474512338638306, -0.01537019107490778, -0.1596963107585907, 0.6601147651672363, 0.038346391171216965, -0.014301051385700703, 0.16802802681922913, -0.00372096779756248, 0.2638396620750427, -0.272217720746994]
     Last 10:  [-0.7556747198104858, 0.3389131724834442, 0.4232017397880554, 0.2777065932750702, -0.24795357882976532, -2.97719407081604, -0.3859609365463257, -4.463176727294922, 0.6152921915054321, -0.5298264026641846]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.388585
     First 10: [0.7084421515464783, -0.3053242266178131, -1.0368620157241821, 0.07416654378175735, -1.0077158212661743, -0.9916243553161621, -0.6240479946136475, -0.5566180944442749, -0.47023844718933105, 0.26110032200813293]
     Last 10:  [0.2016095519065857, 0.745376467704773, -0.08295001089572906, 0.17570696771144867, -0.22212114930152893, 1.5221176147460938, -0.21873927116394043, 0.45138388872146606, 0.446044921875, 0.1849747598171234]

================================================================================
294_layers.18.self_attn.k_norm: Gemma3RMSNorm (layers.18.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.18.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.104629, Std: 2.658833
     First 10: [0.162762850522995, 0.2684285640716553, -0.5371240377426147, -1.3025097846984863, -2.5659079551696777, -5.457845687866211, -2.5228047370910645, 3.0173192024230957, -7.311702728271484, -0.3233160972595215]
     Last 10:  [-2.0583090782165527, -5.3989667892456055, -3.754859447479248, -4.582265377044678, -2.5288443565368652, -1.9453688859939575, 2.989722728729248, -2.247180461883545, 4.377954959869385, -0.1701778918504715]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.18.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.007139, Std: 1.435282
     First 10: [0.0668410211801529, 0.05782278627157211, -0.04486856237053871, -0.511626124382019, 0.003911871928721666, 0.05830930545926094, 0.11690755933523178, -0.03356814756989479, -0.12521857023239136, -0.12841273844242096]
     Last 10:  [-2.14074444770813, -3.6278793811798096, -5.295547962188721, -4.40044641494751, -4.79129695892334, -0.9543855786323547, 4.517821311950684, -2.6129047870635986, 3.6324167251586914, -0.18597762286663055]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.498036
     First 10: [0.16107094287872314, -0.39096641540527344, -0.7638224959373474, 0.11056157946586609, -1.0043103694915771, -1.0302056074142456, -1.1310176849365234, -1.031454086303711, -0.9515804052352905, 0.12292752414941788]
     Last 10:  [0.8172773122787476, 0.174111008644104, 1.4642467498779297, 0.6779671907424927, 2.3105335235595703, -0.14278671145439148, 1.6403717994689941, 1.0316674709320068, 0.44974398612976074, 0.9095213413238525]

================================================================================
295_layers.18.self_attn.o_proj: Linear (layers.18.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.18.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.091659, Std: 1.014101
     First 10: [-2.6649892330169678, 1.796452283859253, -0.13894771039485931, 1.1040825843811035, 0.0843687355518341, -0.4004369080066681, -0.44738176465034485, -0.22352451086044312, 1.222933292388916, -0.6613889932632446]
     Last 10:  [-0.1822447031736374, -0.30132484436035156, -0.3175017833709717, -0.16374371945858002, -0.19287553429603577, -0.025285527110099792, 0.44553738832473755, 0.6794939041137695, 0.24065211415290833, -0.29227614402770996]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.014936, Std: 0.467728
     First 10: [-0.028786268085241318, -0.24227291345596313, -0.17645567655563354, -0.32700619101524353, -0.0036256052553653717, 0.12427055835723877, -0.033314742147922516, 0.25487828254699707, 0.11698121577501297, -0.1492024064064026]
     Last 10:  [-0.04292595386505127, 0.09079144895076752, -0.17470766603946686, 0.20066092908382416, 0.05006881058216095, 0.008012007921934128, 0.0802340880036354, -0.02887076511979103, 0.027440868318080902, -0.033877477049827576]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000015
     First 10: [-0.00911110918968916, -0.012038052082061768, 0.009870672598481178, 0.0015935986302793026, -0.002640328835695982, 0.013050297275185585, -0.007484874688088894, -0.002126279752701521, -0.00019314134260639548, -0.004243094008415937]
     Last 10:  [-0.005678944755345583, -0.007100291550159454, -0.007505930494517088, 0.006955774500966072, 0.007244051434099674, 0.0025139369536191225, 0.004908598959445953, -0.016035137698054314, 0.01501033827662468, -0.017910534515976906]

================================================================================
296_layers.18.self_attn: Gemma3Attention (layers.18.self_attn)
================================================================================

  → OUTPUT[0]: layers.18.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.014936, Std: 0.467728
     First 10: [-0.028786268085241318, -0.24227291345596313, -0.17645567655563354, -0.32700619101524353, -0.0036256052553653717, 0.12427055835723877, -0.033314742147922516, 0.25487828254699707, 0.11698121577501297, -0.1492024064064026]
     Last 10:  [-0.04292595386505127, 0.09079144895076752, -0.17470766603946686, 0.20066092908382416, 0.05006881058216095, 0.008012007921934128, 0.0802340880036354, -0.02887076511979103, 0.027440868318080902, -0.033877477049827576]
     Zeros: 0, Total: 5376

================================================================================
297_layers.18.post_attention_layernorm: Gemma3RMSNorm (layers.18.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.18.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.014936, Std: 0.467728
     First 10: [-0.028786268085241318, -0.24227291345596313, -0.17645567655563354, -0.32700619101524353, -0.0036256052553653717, 0.12427055835723877, -0.033314742147922516, 0.25487828254699707, 0.11698121577501297, -0.1492024064064026]
     Last 10:  [-0.04292595386505127, 0.09079144895076752, -0.17470766603946686, 0.20066092908382416, 0.05006881058216095, 0.008012007921934128, 0.0802340880036354, -0.02887076511979103, 0.027440868318080902, -0.033877477049827576]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.408070, Std: 74.197464
     First 10: [-2.061854362487793, -74.63522338867188, -21.957693099975586, -43.15880584716797, -0.6440495252609253, 28.67140769958496, -5.1889238357543945, 28.34436798095703, 28.34653663635254, -38.78664016723633]
     Last 10:  [-14.669159889221191, 20.427570343017578, -86.89913940429688, 121.09613800048828, 37.39701461791992, 9.15478515625, 68.94178771972656, -17.1794490814209, 16.96843910217285, -36.32876205444336]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 100.656677
     First 10: [40.56386184692383, 177.76490783691406, 71.2094955444336, 75.58729553222656, 102.0818099975586, 132.882568359375, 89.3824462890625, 63.532310485839844, 139.61354064941406, 149.8514862060547]
     Last 10:  [51.31852722167969, 33.44625473022461, 75.15067291259766, 91.39271545410156, 113.35099029541016, 173.9351348876953, 130.55091857910156, 90.1005859375, 93.67041015625, 163.17604064941406]

================================================================================
298_layers.18.pre_feedforward_layernorm: Gemma3RMSNorm (layers.18.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.18.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 9.667328, Std: 427.382690
     First 10: [257.6560363769531, -199.9566650390625, -171.45606994628906, -11.576305389404297, -29.712556838989258, 467.4134216308594, 222.13632202148438, 26.294757843017578, -235.74049377441406, -18.568222045898438]
     Last 10:  [6.734313011169434, 38.75648498535156, 106.05375671386719, 51.624061584472656, 334.3382568359375, -12.257030487060547, 179.72341918945312, -108.8668441772461, 50.45751953125, 129.87681579589844]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012446, Std: 1.019172
     First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
     Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 1.649356
     First 10: [2.840872049331665, -0.19522035121917725, 1.78648042678833, 1.602668285369873, 0.7913422584533691, 0.30940258502960205, 1.2544571161270142, 1.9865357875823975, 0.3422562777996063, 0.12886957824230194]
     Last 10:  [2.7380142211914062, 4.807297229766846, 1.5690333843231201, 0.8663302659988403, 0.5590643882751465, -0.0006013680249452591, 0.2594406306743622, 2.360715627670288, 1.1961607933044434, 0.08725069463253021]

================================================================================
299_layers.18.mlp.gate_proj: Linear (layers.18.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.18.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012446, Std: 1.019172
     First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
     Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.119476, Std: 0.219135
     First 10: [-0.17988207936286926, -0.21000930666923523, -0.024091005325317383, -0.0394328236579895, -0.11351096630096436, -0.03969129920005798, 0.02730964682996273, -0.1018436923623085, 0.22572197020053864, -0.08108986914157867]
     Last 10:  [0.001233687624335289, -0.0050574736669659615, -0.03471614047884941, -0.10256095230579376, -0.05194105952978134, -0.10231079906225204, -0.05719830095767975, 0.03529198095202446, -0.0854916200041771, 0.00017721671611070633]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000025
     First 10: [0.0035337768495082855, -0.0012281227391213179, 0.001514639938250184, -0.008708945475518703, -0.0008531437488272786, 0.0036372144240885973, -0.0015907965134829283, 0.007907920517027378, -0.002708957763388753, 0.004078199155628681]
     Last 10:  [0.005650129169225693, 0.0017399231437593699, -0.010546451434493065, 0.007472516968846321, 0.0024830661714076996, -0.0037683802656829357, -0.002840675413608551, -0.0022748077753931284, 0.0015162966446951032, -2.9075119527988136e-05]

================================================================================
300_layers.18.mlp.act_fn: PytorchGELUTanh (layers.18.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.18.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.119476, Std: 0.219135
     First 10: [-0.17988207936286926, -0.21000930666923523, -0.024091005325317383, -0.0394328236579895, -0.11351096630096436, -0.03969129920005798, 0.02730964682996273, -0.1018436923623085, 0.22572197020053864, -0.08108986914157867]
     Last 10:  [0.001233687624335289, -0.0050574736669659615, -0.03471614047884941, -0.10256095230579376, -0.05194105952978134, -0.10231079906225204, -0.05719830095767975, 0.03529198095202446, -0.0854916200041771, 0.00017721671611070633]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.18.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.035811, Std: 0.092850
     First 10: [-0.07710185647010803, -0.08753884583711624, -0.011813987977802753, -0.019096238538622856, -0.051626287400722504, -0.019217321649193764, 0.013952323235571384, -0.046791139990091324, 0.13301514089107513, -0.037924546748399734]
     Last 10:  [0.0006174509762786329, -0.0025185327976942062, -0.01687735877931118, -0.04709148406982422, -0.024894719943404198, -0.04698678106069565, -0.027294667437672615, 0.018142778426408768, -0.03983357921242714, 8.862088725436479e-05]
     Zeros: 0, Total: 8064

================================================================================
301_layers.18.mlp.up_proj: Linear (layers.18.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.18.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012446, Std: 1.019172
     First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
     Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.002900, Std: 0.181142
     First 10: [-0.06145596504211426, -0.10385297983884811, -0.08923856914043427, 0.2193443775177002, 0.1481899917125702, -0.07554617524147034, -0.04965831711888313, -0.08212539553642273, 0.004987452179193497, -0.05415832996368408]
     Last 10:  [0.053890079259872437, 0.029755305498838425, 0.08888868987560272, 0.045460186898708344, 0.043922457844018936, -0.07866249978542328, -0.03991434723138809, 0.03006092458963394, -0.02783208154141903, 0.021822761744260788]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000001
     First 10: [0.012114514596760273, 0.009262642823159695, -0.006227127276360989, -0.00329131493344903, 0.0063166264444589615, -0.004090985748916864, -0.005215831100940704, -0.00045202637556940317, 0.002392022404819727, 0.004519414622336626]
     Last 10:  [0.003056487999856472, -0.0031621900852769613, -0.0021566913928836584, 0.0029908395372331142, 0.008053992874920368, 0.0035629943013191223, -0.002037373138591647, -0.006244061514735222, -0.00045004882849752903, 0.009552349336445332]

================================================================================
302_layers.18.mlp.down_proj: Linear (layers.18.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.18.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000024, Std: 0.023587
     First 10: [0.004738369025290012, 0.009091169573366642, 0.0010542634408921003, -0.004188652615994215, -0.007650499232113361, 0.0014517951058223844, -0.000692848872859031, 0.003842740785330534, 0.0006634066812694073, 0.002053930191323161]
     Last 10:  [3.3274482120759785e-05, -7.493971497751772e-05, -0.0015002063009887934, -0.002140787662938237, -0.0010934373131021857, 0.0036960977595299482, 0.0010894488077610731, 0.000545388669706881, 0.0011086513986811042, 1.9339524897077354e-06]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.18.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000227, Std: 0.007934
     First 10: [0.001970715122297406, 0.0019319071434438229, -0.002610577503219247, 0.0013772472739219666, 4.166521830484271e-05, 0.003911722917109728, 0.004739252384752035, -0.004501949530094862, 0.0033819079399108887, -0.0006725167040713131]
     Last 10:  [-0.0005120760179124773, -0.0003324755234643817, -0.0006768406601622701, 2.8345082682790235e-05, 0.0009595267474651337, -0.00018653649021871388, -0.0004320660373196006, 0.00013209789176471531, -0.0003018003480974585, -0.000598056532908231]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000006
     First 10: [0.004501306917518377, 0.008508354425430298, -0.0038330857641994953, 0.003111782483756542, -0.0038670527283102274, -0.006062863860279322, -0.0011171292280778289, 0.00596236065030098, 0.0008047532755881548, -0.0005274470313452184]
     Last 10:  [0.004079008009284735, 0.0016594290500506759, 2.4201050109695643e-05, 0.010604687966406345, 0.014888301491737366, 0.005505437031388283, 0.000523663591593504, -0.007425602991133928, 0.00474301865324378, 0.0029595824889838696]

================================================================================
303_layers.18.mlp: Gemma3MLP (layers.18.mlp)
================================================================================

  → INPUT[0]: layers.18.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012446, Std: 1.019172
     First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
     Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000227, Std: 0.007934
     First 10: [0.001970715122297406, 0.0019319071434438229, -0.002610577503219247, 0.0013772472739219666, 4.166521830484271e-05, 0.003911722917109728, 0.004739252384752035, -0.004501949530094862, 0.0033819079399108887, -0.0006725167040713131]
     Last 10:  [-0.0005120760179124773, -0.0003324755234643817, -0.0006768406601622701, 2.8345082682790235e-05, 0.0009595267474651337, -0.00018653649021871388, -0.0004320660373196006, 0.00013209789176471531, -0.0003018003480974585, -0.000598056532908231]
     Zeros: 0, Total: 5376

================================================================================
304_layers.18.post_feedforward_layernorm: Gemma3RMSNorm (layers.18.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.18.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000227, Std: 0.007934
     First 10: [0.001970715122297406, 0.0019319071434438229, -0.002610577503219247, 0.0013772472739219666, 4.166521830484271e-05, 0.003911722917109728, 0.004739252384752035, -0.004501949530094862, 0.0033819079399108887, -0.0006725167040713131]
     Last 10:  [-0.0005120760179124773, -0.0003324755234643817, -0.0006768406601622701, 2.8345082682790235e-05, 0.0009595267474651337, -0.00018653649021871388, -0.0004320660373196006, 0.00013209789176471531, -0.0003018003480974585, -0.000598056532908231]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.18.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 8.218795, Std: 174.462769
     First 10: [12.856961250305176, 60.41134262084961, -30.209253311157227, 18.07050132751465, 0.7325072288513184, 81.97917938232422, 71.00474548339844, -52.33843994140625, 73.60611724853516, -18.484697341918945]
     Last 10:  [-28.668489456176758, -11.386631965637207, -62.03402328491211, 3.54416561126709, 90.80278778076172, -32.65223693847656, -70.39073181152344, 13.29366397857666, -27.819137573242188, -104.61965942382812]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 152.509689
     First 10: [58.987274169921875, 286.5258483886719, 105.40158081054688, 119.64321899414062, 160.65267944335938, 191.6992950439453, 136.7596893310547, 105.89682006835938, 199.12289428710938, 251.72833251953125]
     Last 10:  [75.1665267944336, 45.59393310546875, 123.69161987304688, 169.11007690429688, 127.74662780761719, 237.14576721191406, 220.64559936523438, 135.91233825683594, 124.40582275390625, 236.99334716796875]

================================================================================
305_layers.19.input_layernorm: Gemma3RMSNorm (layers.19.input_layernorm)
================================================================================

  → INPUT[0]: layers.19.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 17.886124, Std: 549.190369
     First 10: [270.51300048828125, -139.54531860351562, -201.6653289794922, 6.494195938110352, -28.98004913330078, 549.392578125, 293.14105224609375, -26.043682098388672, -162.13436889648438, -37.05291748046875]
     Last 10:  [-21.93417739868164, 27.369853973388672, 44.01973342895508, 55.16822814941406, 425.14105224609375, -44.90926742553711, 109.33268737792969, -95.57318115234375, 22.638381958007812, 25.257156372070312]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.148822, Std: 4.276307
     First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
     Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 8.377877
     First 10: [19.15802001953125, 1.5586423873901367, 7.802962303161621, 6.905177116394043, 5.304550647735596, 4.0889201164245605, 5.9409332275390625, 7.918381690979004, 3.395639419555664, 3.293776273727417]
     Last 10:  [10.967732429504395, 14.90168571472168, 6.59903621673584, 5.842710494995117, 4.863406181335449, 2.2999422550201416, 3.27927565574646, 10.08026123046875, 5.201647758483887, 2.6866612434387207]

================================================================================
306_layers.19.self_attn.q_proj: Linear (layers.19.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.19.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.148822, Std: 4.276307
     First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
     Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.078969, Std: 1.255975
     First 10: [0.9997197389602661, -0.6611632108688354, 1.151519775390625, 1.0701558589935303, 0.8845419883728027, -0.012620992958545685, -0.5445837378501892, 2.924321174621582, -1.1011874675750732, -0.08469951152801514]
     Last 10:  [-0.24868044257164001, 0.4550326466560364, -0.6265720129013062, -0.1513674557209015, 0.26094305515289307, -0.3760688900947571, 0.37938031554222107, -0.5787829160690308, -0.6251511573791504, -1.8353488445281982]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000013
     First 10: [-0.013708921149373055, 0.0023000200744718313, -0.011341370642185211, 0.001061624730937183, -0.006439731456339359, -0.00025982255465351045, 0.00041521014645695686, 0.006739731878042221, -0.010868478566408157, -0.004753760062158108]
     Last 10:  [-0.010700272396206856, -0.002367917448282242, -0.007862584665417671, 0.008216113783419132, -0.007223488762974739, 0.0025449893437325954, -0.003790981136262417, -0.0075637176632881165, -0.003648138139396906, 0.005209693219512701]

================================================================================
307_layers.19.self_attn.k_proj: Linear (layers.19.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.19.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.148822, Std: 4.276307
     First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
     Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.117643, Std: 1.734052
     First 10: [0.8714194297790527, -1.0026236772537231, -0.08344118297100067, -1.9501763582229614, -5.918198585510254, -2.1989688873291016, 2.344635009765625, 2.956681728363037, -0.41049450635910034, 0.4399896562099457]
     Last 10:  [-0.6533032059669495, 1.7090895175933838, -0.3604780435562134, -1.949053168296814, -1.2105743885040283, -1.5888001918792725, -2.3219118118286133, -1.1165657043457031, 0.8111847043037415, -3.1706151962280273]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000011
     First 10: [0.005549221765249968, -0.005590486340224743, -0.0010600517271086574, 0.004374765790998936, 0.008612056262791157, -0.009335143491625786, 0.004453759640455246, -0.0045900410041213036, -0.0021766519639641047, 0.0014751316048204899]
     Last 10:  [0.004454256966710091, 0.008778984658420086, -0.003307210747152567, -0.003736075945198536, -0.01381451915949583, 0.0031248151790350676, -0.008748752996325493, 0.0042513576336205006, -0.009646921418607235, -0.01419112179428339]

================================================================================
308_layers.19.self_attn.v_proj: Linear (layers.19.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.19.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.148822, Std: 4.276307
     First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
     Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.003305, Std: 0.768246
     First 10: [-0.09311835467815399, -1.0133436918258667, -0.5233939290046692, -0.34847012162208557, -0.3432435989379883, 1.136409044265747, -0.8997690081596375, 0.06556414067745209, -0.5830128192901611, -0.7777641415596008]
     Last 10:  [0.2082168161869049, 0.632858395576477, 0.10820508003234863, 0.806389570236206, -1.4193416833877563, -0.24411579966545105, 0.07685770094394684, 0.23310378193855286, 0.4236438274383545, -0.06579846143722534]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000015
     First 10: [0.0037281657569110394, 0.002733090193942189, 0.013581182807683945, 0.005334360525012016, -0.007894928567111492, 0.01061481237411499, -0.01532527431845665, -0.005616428796201944, -0.001558349933475256, -0.002206801902502775]
     Last 10:  [0.00970548577606678, -0.0032689482904970646, 0.014293153770267963, 0.001138382125645876, 0.013276452198624611, 0.0031613344326615334, -0.017524918541312218, -0.0055533843114972115, 0.0020310489926487207, 0.01470995508134365]

================================================================================
309_layers.19.self_attn.q_norm: Gemma3RMSNorm (layers.19.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.19.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.078969, Std: 1.255975
     First 10: [0.9997197389602661, -0.6611632108688354, 1.151519775390625, 1.0701558589935303, 0.8845419883728027, -0.012620992958545685, -0.5445837378501892, 2.924321174621582, -1.1011874675750732, -0.08469951152801514]
     Last 10:  [-0.24868044257164001, 0.4550326466560364, -0.6265720129013062, -0.1513674557209015, 0.26094305515289307, -0.3760688900947571, 0.37938031554222107, -0.5787829160690308, -0.6251511573791504, -1.8353488445281982]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.049582, Std: 1.112609
     First 10: [2.119532823562622, -0.6987621784210205, 1.46214759349823, -0.0036208159290254116, 0.47036099433898926, -0.017586015164852142, -0.5920274257659912, -1.2128721475601196, -4.498411178588867, -0.3093208074569702]
     Last 10:  [-0.3730458617210388, 0.8988171815872192, -1.0296274423599243, -0.2482423335313797, 0.44977715611457825, -0.5969147086143494, 0.5999048948287964, -0.8269142508506775, -0.8912956118583679, -1.792016863822937]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.183203
     First 10: [0.8263064622879028, -0.08959949016571045, 0.0937841385602951, -1.002914547920227, -0.5419375896453857, 0.20028862357139587, -0.06354063004255295, -1.3572742938995361, 2.5189225673675537, 2.145864486694336]
     Last 10:  [0.27789896726608276, 0.6826924085617065, 0.3998614549636841, 0.39707350730895996, 0.46834325790405273, 0.35213738679885864, 0.3470495641231537, 0.21708440780639648, 0.2145424336194992, -0.1682373583316803]

================================================================================
310_layers.19.self_attn.k_norm: Gemma3RMSNorm (layers.19.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.19.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.117643, Std: 1.734052
     First 10: [0.8714194297790527, -1.0026236772537231, -0.08344118297100067, -1.9501763582229614, -5.918198585510254, -2.1989688873291016, 2.344635009765625, 2.956681728363037, -0.41049450635910034, 0.4399896562099457]
     Last 10:  [-0.6533032059669495, 1.7090895175933838, -0.3604780435562134, -1.949053168296814, -1.2105743885040283, -1.5888001918792725, -2.3219118118286133, -1.1165657043457031, 0.8111847043037415, -3.1706151962280273]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.19.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.119696, Std: 1.295088
     First 10: [0.7442797422409058, -2.036738395690918, 0.01738479919731617, 0.0029593482613563538, -2.4216489791870117, -1.0225602388381958, 0.559409499168396, -0.692674458026886, -0.2392766773700714, 0.32603397965431213]
     Last 10:  [-0.7467968463897705, 2.080594062805176, -0.4687407612800598, -2.139889717102051, -1.4993035793304443, -2.262117385864258, -2.8749823570251465, -1.2592108249664307, 1.0839186906814575, -4.547543525695801]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.519761
     First 10: [0.34037744998931885, 2.187979221343994, -1.3269696235656738, -1.002381443977356, -0.35784509778022766, -0.2702265679836273, -0.625568151473999, -1.367656946182251, -0.08523151278495789, 0.16288982331752777]
     Last 10:  [0.4632273316383362, 0.5582841038703918, 0.6644777655601501, 0.40537357330322266, 0.5853391885757446, 0.8225100040435791, 0.5849425792694092, 0.4435713291168213, 0.7104132175445557, 0.8359355926513672]

================================================================================
311_layers.19.self_attn.o_proj: Linear (layers.19.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.19.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.010449, Std: 0.546782
     First 10: [-0.09311835467815399, -1.0133436918258667, -0.5233939290046692, -0.34847012162208557, -0.3432435989379883, 1.136409044265747, -0.8997690081596375, 0.06556414067745209, -0.5830128192901611, -0.7777641415596008]
     Last 10:  [0.14888261258602142, 0.5811675786972046, 0.04036650061607361, 0.6124897003173828, -1.1038317680358887, -0.12090494483709335, -0.1123894602060318, 0.16309703886508942, 0.4210304021835327, -0.031128766015172005]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.009816, Std: 0.233819
     First 10: [-0.04161803424358368, 0.09904502332210541, 0.18690672516822815, 0.06329116225242615, 0.03062961995601654, -0.06561634689569473, 0.06879182904958725, 0.2753956913948059, 0.15538033843040466, 0.01525195874273777]
     Last 10:  [-0.0038687577471137047, 0.028554942458868027, -0.055815063416957855, -0.055135391652584076, 0.16534394025802612, -0.05187083035707474, 0.022894879803061485, -0.07421866804361343, 0.06020951271057129, 0.044333815574645996]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000008
     First 10: [0.007922030054032803, 0.0005214483826421201, 0.00044104730477556586, 0.0036439020186662674, 0.00334372092038393, 0.0007461808272637427, -0.002735306043177843, 0.02430535852909088, -0.0013749557547271252, -0.006514505948871374]
     Last 10:  [0.004863490350544453, 0.005761468783020973, -0.0016594219487160444, -0.010895844548940659, -0.0026636116672307253, 0.0011815917678177357, -0.0038922796957194805, -0.010354512371122837, 0.009914628230035305, 0.011221913620829582]

================================================================================
312_layers.19.self_attn: Gemma3Attention (layers.19.self_attn)
================================================================================

  → OUTPUT[0]: layers.19.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.009816, Std: 0.233819
     First 10: [-0.04161803424358368, 0.09904502332210541, 0.18690672516822815, 0.06329116225242615, 0.03062961995601654, -0.06561634689569473, 0.06879182904958725, 0.2753956913948059, 0.15538033843040466, 0.01525195874273777]
     Last 10:  [-0.0038687577471137047, 0.028554942458868027, -0.055815063416957855, -0.055135391652584076, 0.16534394025802612, -0.05187083035707474, 0.022894879803061485, -0.07421866804361343, 0.06020951271057129, 0.044333815574645996]
     Zeros: 0, Total: 5376

================================================================================
313_layers.19.post_attention_layernorm: Gemma3RMSNorm (layers.19.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.19.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.009816, Std: 0.233819
     First 10: [-0.04161803424358368, 0.09904502332210541, 0.18690672516822815, 0.06329116225242615, 0.03062961995601654, -0.06561634689569473, 0.06879182904958725, 0.2753956913948059, 0.15538033843040466, 0.01525195874273777]
     Last 10:  [-0.0038687577471137047, 0.028554942458868027, -0.055815063416957855, -0.055135391652584076, 0.16534394025802612, -0.05187083035707474, 0.022894879803061485, -0.07421866804361343, 0.06020951271057129, 0.044333815574645996]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -4.487651, Std: 103.673340
     First 10: [-9.721266746520996, 121.05615234375, 114.63024139404297, 51.615543365478516, 18.99530601501465, -45.96036148071289, 51.86756134033203, 171.12130737304688, 135.06651306152344, 15.807371139526367]
     Last 10:  [-0.838489830493927, 2.820838212966919, -28.671588897705078, -20.468490600585938, 51.155792236328125, -30.456390380859375, 12.346565246582031, -12.817898750305176, 16.575565338134766, 24.549116134643555]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 104.723106
     First 10: [37.827003479003906, 202.16400146484375, 100.9452133178711, 134.55950927734375, 102.08541870117188, 115.42974853515625, 124.32899475097656, 102.28553771972656, 143.49212646484375, 171.27671813964844]
     Last 10:  [58.107940673828125, 25.94116973876953, 139.0941162109375, 100.24530792236328, 83.37738800048828, 159.13076782226562, 146.07110595703125, 46.100250244140625, 74.07974243164062, 150.01507568359375]

================================================================================
314_layers.19.pre_feedforward_layernorm: Gemma3RMSNorm (layers.19.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.19.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 13.398470, Std: 495.212769
     First 10: [260.791748046875, -18.489166259765625, -87.03508758544922, 58.1097412109375, -9.984743118286133, 503.4322204589844, 345.00860595703125, 145.07762145996094, -27.067855834960938, -21.245546340942383]
     Last 10:  [-22.772666931152344, 30.190692901611328, 15.34814453125, 34.699737548828125, 476.2968444824219, -75.36566162109375, 121.67925262451172, -108.39108276367188, 39.21394729614258, 49.8062744140625]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.017846, Std: 0.765819
     First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
     Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 1.214840
     First 10: [1.993488073348999, -0.32110050320625305, 1.2296655178070068, 0.8500204086303711, 0.4067174196243286, 0.15344247221946716, 0.7289212942123413, 1.1108366250991821, 0.08726239204406738, -0.07910087704658508]
     Last 10:  [1.9985554218292236, 3.9635183811187744, 0.8571164608001709, 0.4779769480228424, 0.3879135251045227, -0.11828534305095673, 0.041865602135658264, 1.8168048858642578, 0.7242997884750366, -0.0696745365858078]

================================================================================
315_layers.19.mlp.gate_proj: Linear (layers.19.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.19.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.017846, Std: 0.765819
     First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
     Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.040005, Std: 0.147792
     First 10: [-0.02808528020977974, -0.08304241299629211, 0.2624969780445099, 0.1020033061504364, -0.1437465101480484, 0.07065102458000183, -0.114624984562397, 0.018533295020461082, 0.06318080425262451, 0.048162929713726044]
     Last 10:  [0.37262672185897827, -0.03964526578783989, -0.15938477218151093, 0.08839632570743561, -0.027503537014126778, -0.03254815936088562, -0.00853501632809639, 0.025330770760774612, -0.1033533588051796, -0.1038651391863823]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000021
     First 10: [0.006637481041252613, -0.0018240894423797727, 0.008500393480062485, -0.006143001839518547, 0.0006421602447517216, -0.006074460223317146, -0.007551455870270729, -0.004515998065471649, -0.007663797587156296, 0.0004087318084202707]
     Last 10:  [-0.0038065453991293907, 0.013418305665254593, -0.0022444413043558598, -0.0044029150158166885, 0.001960059627890587, 0.0029848378617316484, 0.0058277808129787445, -0.001803763210773468, -0.002532864920794964, 0.006629280745983124]

================================================================================
316_layers.19.mlp.act_fn: PytorchGELUTanh (layers.19.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.19.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.040005, Std: 0.147792
     First 10: [-0.02808528020977974, -0.08304241299629211, 0.2624969780445099, 0.1020033061504364, -0.1437465101480484, 0.07065102458000183, -0.114624984562397, 0.018533295020461082, 0.06318080425262451, 0.048162929713726044]
     Last 10:  [0.37262672185897827, -0.03964526578783989, -0.15938477218151093, 0.08839632570743561, -0.027503537014126778, -0.03254815936088562, -0.00853501632809639, 0.025330770760774612, -0.1033533588051796, -0.1038651391863823]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.19.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.010804, Std: 0.070061
     First 10: [-0.013728003017604351, -0.03877325728535652, 0.1584235280752182, 0.055145297199487686, -0.06365832686424255, 0.03731519356369972, -0.05208234861493111, 0.009403669275343418, 0.03318184241652489, 0.025006519630551338]
     Last 10:  [0.24044537544250488, -0.019195761531591415, -0.06960081309080124, 0.047311387956142426, -0.01345002930611372, -0.015851521864533424, -0.004238446708768606, 0.012921337969601154, -0.04742282256484032, -0.04763655737042427]
     Zeros: 0, Total: 8064

================================================================================
317_layers.19.mlp.up_proj: Linear (layers.19.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.19.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.017846, Std: 0.765819
     First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
     Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000643, Std: 0.127050
     First 10: [-0.153435617685318, -0.017016377300024033, 0.01669328659772873, -0.08019869774580002, 0.02240096777677536, -0.1479894071817398, 0.15653537213802338, 0.17422373592853546, 0.15486571192741394, -0.0769917368888855]
     Last 10:  [0.1641092300415039, 0.012790899723768234, -0.011864956468343735, 0.03773633763194084, -0.04173664376139641, 0.041600435972213745, -0.043008893728256226, 0.039892394095659256, -0.03989381343126297, 0.020413141697645187]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000003
     First 10: [0.0010235026711598039, -0.007842491380870342, -0.0017780136549845338, -0.00040436157723888755, 0.0029880781657993793, 0.0002075446245726198, -0.0009618879412300885, 0.0007406329968944192, 0.010575992986559868, -0.0036583682522177696]
     Last 10:  [0.010568498633801937, 0.00471501424908638, 0.01037983875721693, -0.0004270637291483581, -0.0022516795434057713, -0.0009642810327932239, 0.007765741553157568, -0.00828381348401308, -0.012872884050011635, 0.0029199160635471344]

================================================================================
318_layers.19.mlp.down_proj: Linear (layers.19.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.19.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000088, Std: 0.012721
     First 10: [0.002106364583596587, 0.0006597804022021592, 0.0026446094270795584, -0.004422580823302269, -0.0014260081807151437, -0.005522253457456827, -0.008152729831635952, 0.0016383423935621977, 0.005138729698956013, -0.001925295335240662]
     Last 10:  [0.03945930674672127, -0.00024553106050007045, 0.0008258105954155326, 0.0017853585304692388, 0.0005613591056317091, -0.0006594302249141037, 0.00018229091074317694, 0.0005154631217010319, 0.001891877269372344, -0.0009724117699079216]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.19.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000007, Std: 0.003754
     First 10: [-0.0001366934011457488, -0.0006556336884386837, 0.0025630928575992584, 0.0008437503129243851, 0.0014984960434958339, 0.00017319759353995323, -1.9404746126383543e-05, -0.003034979570657015, -0.0011872879695147276, 0.0024240119382739067]
     Last 10:  [-0.0014284506905823946, -0.0007461392669938505, -0.0014848088612779975, 0.00029378122417256236, 0.0012645829701796174, -0.0005167420604266226, -0.0004040795029141009, 0.0010501946089789271, -9.315123315900564e-05, -0.0007154666818678379]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000004
     First 10: [-0.0026852807495743036, -0.0011877811048179865, -0.0014543846482411027, -0.005482872948050499, -0.004603697452694178, -0.006521227769553661, -0.0009426724864169955, -0.0035429906565696, -0.0017079752869904041, 0.00039919186383485794]
     Last 10:  [-0.005192830227315426, -0.004728297702968121, 0.0041647618636488914, -0.0008196127600967884, 0.00023649759532418102, 0.006708288565278053, -0.004205233417451382, -0.005766335874795914, 0.00257410597987473, 0.0065618110820651054]

================================================================================
319_layers.19.mlp: Gemma3MLP (layers.19.mlp)
================================================================================

  → INPUT[0]: layers.19.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.017846, Std: 0.765819
     First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
     Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000007, Std: 0.003754
     First 10: [-0.0001366934011457488, -0.0006556336884386837, 0.0025630928575992584, 0.0008437503129243851, 0.0014984960434958339, 0.00017319759353995323, -1.9404746126383543e-05, -0.003034979570657015, -0.0011872879695147276, 0.0024240119382739067]
     Last 10:  [-0.0014284506905823946, -0.0007461392669938505, -0.0014848088612779975, 0.00029378122417256236, 0.0012645829701796174, -0.0005167420604266226, -0.0004040795029141009, 0.0010501946089789271, -9.315123315900564e-05, -0.0007154666818678379]
     Zeros: 0, Total: 5376

================================================================================
320_layers.19.post_feedforward_layernorm: Gemma3RMSNorm (layers.19.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.19.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000007, Std: 0.003754
     First 10: [-0.0001366934011457488, -0.0006556336884386837, 0.0025630928575992584, 0.0008437503129243851, 0.0014984960434958339, 0.00017319759353995323, -1.9404746126383543e-05, -0.003034979570657015, -0.0011872879695147276, 0.0024240119382739067]
     Last 10:  [-0.0014284506905823946, -0.0007461392669938505, -0.0014848088612779975, 0.00029378122417256236, 0.0012645829701796174, -0.0005167420604266226, -0.0004040795029141009, 0.0010501946089789271, -9.315123315900564e-05, -0.0007154666818678379]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.19.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 3.678869, Std: 142.907867
     First 10: [-2.207524538040161, -53.18722152709961, 69.3331527709961, 23.621549606323242, 70.34169006347656, 8.949487686157227, -0.6258789896965027, -77.27484893798828, -59.869083404541016, 177.43435668945312]
     Last 10:  [-88.21393585205078, -27.913347244262695, -141.93783569335938, 44.71241760253906, 136.95974731445312, -105.70487213134766, -77.20145416259766, 66.0838851928711, -9.757400512695312, -141.72918701171875]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 184.135437
     First 10: [69.92428588867188, 355.27313232421875, 117.79923248291016, 121.95082092285156, 205.1551513671875, 225.93072509765625, 140.6509246826172, 110.81997680664062, 220.45401000976562, 320.4696350097656]
     Last 10:  [82.14566040039062, 49.36857986450195, 127.7049560546875, 203.9140625, 144.81871032714844, 274.4158020019531, 256.2327880859375, 83.72146606445312, 140.03054809570312, 265.70892333984375]

================================================================================
321_layers.20.input_layernorm: Gemma3RMSNorm (layers.20.input_layernorm)
================================================================================

  → INPUT[0]: layers.20.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 17.077339, Std: 569.007141
     First 10: [258.584228515625, -71.6763916015625, -17.701934814453125, 81.73129272460938, 60.35694885253906, 512.3817138671875, 344.3827209472656, 67.80277252197266, -86.93693542480469, 156.18881225585938]
     Last 10:  [-110.98660278320312, 2.277345657348633, -126.58969116210938, 79.41215515136719, 613.256591796875, -181.07052612304688, 44.47779846191406, -42.30719757080078, 29.456546783447266, -91.92291259765625]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.187797, Std: 6.553228
     First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
     Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 15.578236
     First 10: [26.267141342163086, 3.6770620346069336, 11.89790153503418, 9.67996883392334, 8.869750022888184, 7.249534606933594, 9.295574188232422, 11.832257270812988, 6.735011100769043, 5.547285079956055]
     Last 10:  [21.010242462158203, 38.08509063720703, 9.293664932250977, 9.469446182250977, 8.75476360321045, 4.761654376983643, 6.233358383178711, 16.37337875366211, 11.05013656616211, 5.607439994812012]

================================================================================
322_layers.20.self_attn.q_proj: Linear (layers.20.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.20.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.187797, Std: 6.553228
     First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
     Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.024409, Std: 2.357026
     First 10: [-1.3440251350402832, -0.3703478276729584, -1.1369025707244873, 0.513540506362915, -0.7575384378433228, 1.0102839469909668, -1.8490989208221436, 0.568389892578125, -0.6614009737968445, 0.28585365414619446]
     Last 10:  [-1.3447209596633911, 0.34324491024017334, -1.6670054197311401, -1.0905828475952148, 0.7890999913215637, -0.605061411857605, -0.4653666019439697, 0.7465041279792786, -0.9899506568908691, 1.2571016550064087]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000009
     First 10: [0.005372524727135897, -0.029967620968818665, -0.02064458467066288, 0.014921966940164566, -0.0031278221867978573, -0.009391474537551403, 0.004388058558106422, 0.018486864864826202, -0.014856003224849701, 0.005696967709809542]
     Last 10:  [0.002426014980301261, -0.0013448228128254414, 0.0023590647615492344, 0.0003728456504177302, 0.004490489140152931, -0.0030913925729691982, 0.0047316765412688255, -0.006031336262822151, -0.0011648691724985838, 0.004109364002943039]

================================================================================
323_layers.20.self_attn.k_proj: Linear (layers.20.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.20.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.187797, Std: 6.553228
     First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
     Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.161733, Std: 2.805400
     First 10: [-1.5511553287506104, 0.0686827301979065, 0.3431394398212433, -2.8122968673706055, -0.7340375781059265, 0.25276070833206177, -0.26014888286590576, -1.3399205207824707, 0.12287792563438416, -1.9904743432998657]
     Last 10:  [1.7680693864822388, 1.4631891250610352, 1.8920707702636719, -3.184497594833374, -5.011660575866699, 4.953741073608398, -3.9005789756774902, 4.9099273681640625, -4.502815246582031, 1.9667564630508423]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: -0.000006
     First 10: [-0.00958620198071003, 0.014952023513615131, 0.000331503979396075, -0.0080779530107975, 0.006658794824033976, 0.00288623059168458, 0.0063440934754908085, -0.012774873524904251, 0.008045980706810951, 0.0004801421600859612]
     Last 10:  [0.012924132868647575, -0.0004340461455285549, 0.003974226303398609, 0.012031510472297668, -0.007270996458828449, 0.01598327048122883, 0.019354047253727913, 0.01076818909496069, -0.004679442383348942, 0.011444673873484135]

================================================================================
324_layers.20.self_attn.v_proj: Linear (layers.20.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.20.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.187797, Std: 6.553228
     First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
     Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.080192, Std: 1.302850
     First 10: [0.34779447317123413, 0.8539810180664062, -0.15037167072296143, -0.7638791799545288, 0.4911248981952667, 1.1574691534042358, 1.1371973752975464, -0.95177161693573, 0.12592613697052002, 0.5844687223434448]
     Last 10:  [-0.7123718857765198, 0.5391747951507568, -0.9238556027412415, -0.014662742614746094, 0.5158359408378601, 0.508171796798706, -0.9690453410148621, 0.09781811386346817, 1.1932687759399414, 0.17384730279445648]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000010
     First 10: [-0.0005488523747771978, -0.005612445995211601, 0.009256401099264622, -0.018201559782028198, 0.0063883038237690926, -0.003954674117267132, -0.0015958421863615513, 0.0017348097171634436, 0.01429462805390358, -0.00893524568527937]
     Last 10:  [-0.004813929088413715, -0.023231040686368942, -0.004657894838601351, -8.906002040021122e-05, -0.0004239490663167089, 0.0022075653541833162, 0.009801916778087616, 0.004617351572960615, -0.004061893559992313, -0.011242629028856754]

================================================================================
325_layers.20.self_attn.q_norm: Gemma3RMSNorm (layers.20.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.20.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.024409, Std: 2.357026
     First 10: [-1.3440251350402832, -0.3703478276729584, -1.1369025707244873, 0.513540506362915, -0.7575384378433228, 1.0102839469909668, -1.8490989208221436, 0.568389892578125, -0.6614009737968445, 0.28585365414619446]
     Last 10:  [-1.3447209596633911, 0.34324491024017334, -1.6670054197311401, -1.0905828475952148, 0.7890999913215637, -0.605061411857605, -0.4653666019439697, 0.7465041279792786, -0.9899506568908691, 1.2571016550064087]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.023178, Std: 1.184326
     First 10: [-0.7103258371353149, -0.1769796758890152, -0.6651169657707214, 0.10792825371026993, -0.4096786379814148, 0.4286145269870758, -0.7430889010429382, 0.2477957010269165, -0.3093208074569702, 0.12394540756940842]
     Last 10:  [-0.564628541469574, 0.25831466913223267, -0.40617868304252625, -0.6505017280578613, 0.3764146566390991, -0.2677760720252991, -0.27225181460380554, 0.3438563048839569, -0.6194964647293091, 0.7517917156219482]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.431039
     First 10: [0.20955400168895721, 0.09367583692073822, 0.3389051556587219, -0.5190106630325317, 0.23769500851631165, -0.029046453535556793, -0.08027999103069305, -0.00224838568829, 0.07033395022153854, -0.007657235488295555]
     Last 10:  [-0.14324429631233215, 0.5355759859085083, -0.5028282403945923, 0.21707163751125336, -0.026668362319469452, -0.09697732329368591, 0.19371849298477173, -0.06012287735939026, 0.27688461542129517, 0.22026294469833374]

================================================================================
326_layers.20.self_attn.k_norm: Gemma3RMSNorm (layers.20.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.20.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.161733, Std: 2.805400
     First 10: [-1.5511553287506104, 0.0686827301979065, 0.3431394398212433, -2.8122968673706055, -0.7340375781059265, 0.25276070833206177, -0.26014888286590576, -1.3399205207824707, 0.12287792563438416, -1.9904743432998657]
     Last 10:  [1.7680693864822388, 1.4631891250610352, 1.8920707702636719, -3.184497594833374, -5.011660575866699, 4.953741073608398, -3.9005789756774902, 4.9099273681640625, -4.502815246582031, 1.9667564630508423]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.20.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.007829, Std: 2.404580
     First 10: [-0.7965043187141418, 0.07909199595451355, 0.17118382453918457, -2.9248833656311035, -0.47024714946746826, 0.11251700669527054, -0.09325817972421646, -0.6520357131958008, 0.10392066091299057, -0.9211878776550293]
     Last 10:  [2.279050350189209, 0.9570527672767639, 3.578657627105713, -2.740859031677246, -5.231146335601807, 5.811042308807373, -3.209416627883911, 5.601173400878906, -3.5579376220703125, 1.7080662250518799]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.883833
     First 10: [0.22093115746974945, 1.7380621433258057, 0.18617954850196838, 1.4728952646255493, 0.5232325196266174, 0.05844159796833992, -0.14763951301574707, 0.15704622864723206, 1.010880947113037, 0.1003984659910202]
     Last 10:  [1.9646682739257812, 0.5043777823448181, 3.3501505851745605, 0.9795536398887634, 1.4006935358047485, 1.6980016231536865, 0.892424464225769, 1.6237683296203613, 0.8173379898071289, 0.9974488019943237]

================================================================================
327_layers.20.self_attn.o_proj: Linear (layers.20.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.20.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.081223, Std: 0.925373
     First 10: [0.34779447317123413, 0.8539810180664062, -0.15037167072296143, -0.7638791799545288, 0.4911248981952667, 1.1574691534042358, 1.1371973752975464, -0.95177161693573, 0.12592613697052002, 0.5844687223434448]
     Last 10:  [-1.1329500675201416, -0.2988707423210144, -0.09596550464630127, 0.16949063539505005, 0.0933767557144165, -0.5033852458000183, -0.46598196029663086, 0.22006136178970337, 0.8598257303237915, 0.588088870048523]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000344, Std: 0.339814
     First 10: [-0.058488115668296814, 0.4968450665473938, 0.28777316212654114, 0.26345187425613403, -0.30926060676574707, -0.11739331483840942, -0.1300537884235382, -0.18562503159046173, 0.0504431277513504, 0.2471245676279068]
     Last 10:  [0.14162041246891022, -0.13119004666805267, 0.02552253007888794, -0.1741998940706253, 0.043956100940704346, 0.0424971878528595, 0.186425119638443, -0.19931669533252716, -0.04439568147063255, 0.127413809299469]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000007
     First 10: [-0.0022622118704020977, -0.005282947793602943, -0.004020598717033863, -0.003234528237953782, 0.0030448823235929012, 0.003911050036549568, -0.007616872899234295, 0.010034001432359219, 0.01001163013279438, 0.002395205432549119]
     Last 10:  [0.010321855545043945, -0.01920671947300434, 0.005345319397747517, 0.00424179108813405, -0.003388074692338705, -0.007707127369940281, -0.008971610106527805, 0.020155057311058044, -0.0018856541719287634, 0.008598273620009422]

================================================================================
328_layers.20.self_attn: Gemma3Attention (layers.20.self_attn)
================================================================================

  → OUTPUT[0]: layers.20.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000344, Std: 0.339814
     First 10: [-0.058488115668296814, 0.4968450665473938, 0.28777316212654114, 0.26345187425613403, -0.30926060676574707, -0.11739331483840942, -0.1300537884235382, -0.18562503159046173, 0.0504431277513504, 0.2471245676279068]
     Last 10:  [0.14162041246891022, -0.13119004666805267, 0.02552253007888794, -0.1741998940706253, 0.043956100940704346, 0.0424971878528595, 0.186425119638443, -0.19931669533252716, -0.04439568147063255, 0.127413809299469]
     Zeros: 0, Total: 5376

================================================================================
329_layers.20.post_attention_layernorm: Gemma3RMSNorm (layers.20.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.20.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000344, Std: 0.339814
     First 10: [-0.058488115668296814, 0.4968450665473938, 0.28777316212654114, 0.26345187425613403, -0.30926060676574707, -0.11739331483840942, -0.1300537884235382, -0.18562503159046173, 0.0504431277513504, 0.2471245676279068]
     Last 10:  [0.14162041246891022, -0.13119004666805267, 0.02552253007888794, -0.1741998940706253, 0.043956100940704346, 0.0424971878528595, 0.186425119638443, -0.19931669533252716, -0.04439568147063255, 0.127413809299469]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.293801, Std: 91.704613
     First 10: [-9.60929012298584, 448.73004150390625, 107.68287658691406, 99.04016876220703, -147.64407348632812, -62.59661865234375, -52.752201080322266, -67.20039367675781, 29.50484275817871, 185.05532836914062]
     Last 10:  [30.793262481689453, -19.613698959350586, 7.723239898681641, -70.47991180419922, 14.132282257080078, 23.94338607788086, 94.39569854736328, -28.745384216308594, -13.191473960876465, 67.77994537353516]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 121.437004
     First 10: [41.59246063232422, 233.13870239257812, 96.00752258300781, 96.4583740234375, 122.7657470703125, 137.2345428466797, 104.15420532226562, 92.8521728515625, 150.63531494140625, 193.1309356689453]
     Last 10:  [68.26535034179688, 46.62607955932617, 95.39665985107422, 127.88536834716797, 101.41871643066406, 178.4781494140625, 160.29986572265625, 44.942081451416016, 93.65396118164062, 168.46145629882812]

================================================================================
330_layers.20.pre_feedforward_layernorm: Gemma3RMSNorm (layers.20.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.20.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 17.371140, Std: 586.346680
     First 10: [248.97494506835938, 377.05364990234375, 89.98094177246094, 180.77145385742188, -87.28712463378906, 449.78509521484375, 291.6305236816406, 0.6023788452148438, -57.432090759277344, 341.244140625]
     Last 10:  [-80.19334411621094, -17.336353302001953, -118.866455078125, 8.932243347167969, 627.3888549804688, -157.12713623046875, 138.87350463867188, -71.05258178710938, 16.265071868896484, -24.142967224121094]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.011086, Std: 0.505234
     First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
     Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.586642
     First 10: [1.1619139909744263, -0.520088791847229, 0.585945725440979, 0.42193683981895447, -0.002053933683782816, -0.19776715338230133, 0.2685956358909607, 0.5707326531410217, -0.23874050378799438, -0.37059682607650757]
     Last 10:  [1.145448923110962, 2.3181254863739014, 0.300733357667923, 0.08007138222455978, 0.0448642298579216, -0.34570106863975525, -0.25278961658477783, 1.163560152053833, 0.18831004202365875, -0.28844597935676575]

================================================================================
331_layers.20.mlp.gate_proj: Linear (layers.20.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.20.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.011086, Std: 0.505234
     First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
     Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.016433, Std: 0.093106
     First 10: [-0.02178696170449257, -0.0472281388938427, 0.03130030632019043, -0.02816949039697647, -0.05369313433766365, 0.13603079319000244, -0.22927212715148926, -0.10580705851316452, 0.001876235008239746, 0.02655385434627533]
     Last 10:  [-0.0902700126171112, 0.06619293987751007, -0.08180826902389526, -0.00012089498341083527, 0.026902345940470695, -0.07101458311080933, 0.03528192639350891, 0.09296828508377075, -0.08504308760166168, -0.05496104434132576]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000005
     First 10: [0.00022503006039187312, 0.0030596284195780754, -0.0045544118620455265, -0.003818387631326914, -0.012407511472702026, 0.002413656795397401, -0.006191433407366276, 0.00968907680362463, 0.004134763032197952, -0.012199010699987411]
     Last 10:  [0.0016951332800090313, -0.0040701306425035, 0.0051321107894182205, 0.0015781051479279995, -0.001134286867454648, -0.0041404711082577705, 0.001983975525945425, 0.004253388848155737, 0.008269628509879112, -0.010839891619980335]

================================================================================
332_layers.20.mlp.act_fn: PytorchGELUTanh (layers.20.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.20.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.016433, Std: 0.093106
     First 10: [-0.02178696170449257, -0.0472281388938427, 0.03130030632019043, -0.02816949039697647, -0.05369313433766365, 0.13603079319000244, -0.22927212715148926, -0.10580705851316452, 0.001876235008239746, 0.02655385434627533]
     Last 10:  [-0.0902700126171112, 0.06619293987751007, -0.08180826902389526, -0.00012089498341083527, 0.026902345940470695, -0.07101458311080933, 0.03528192639350891, 0.09296828508377075, -0.08504308760166168, -0.05496104434132576]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.20.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.004676, Std: 0.045887
     First 10: [-0.010704129002988338, -0.022724561393260956, 0.01604093611240387, -0.013768218457698822, -0.02569699101150036, 0.07537475973367691, -0.09384853392839432, -0.048445675522089005, 0.0009395218803547323, 0.013558191247284412]
     Last 10:  [-0.041888587176799774, 0.03484315797686577, -0.03823716565966606, -6.044166366336867e-05, 0.013739866204559803, -0.03349709510803223, 0.01813746988773346, 0.049927257001399994, -0.039639756083488464, -0.026276040822267532]
     Zeros: 0, Total: 8064

================================================================================
333_layers.20.mlp.up_proj: Linear (layers.20.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.20.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.011086, Std: 0.505234
     First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
     Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.003907, Std: 0.086509
     First 10: [0.06017717719078064, 0.05919542908668518, 0.03515588492155075, -0.007379017770290375, 0.03896184265613556, -0.10614454001188278, 0.1325536072254181, 0.018523387610912323, 0.0023583336733281612, -0.002930114045739174]
     Last 10:  [0.016781572252511978, 0.01196132879704237, 0.06597274541854858, -0.04236283153295517, 0.04420832544565201, 0.08220406621694565, 0.010258466005325317, 0.012672610580921173, 0.0204064529389143, 0.0111346784979105]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000011
     First 10: [0.0063102832064032555, -0.006689158268272877, -0.0008023694390431046, -0.00819410290569067, 0.006707513704895973, -0.0035155978985130787, -0.005689550191164017, -0.0022611261811107397, -0.005312457215040922, 0.009207488968968391]
     Last 10:  [0.0019129614811390638, 0.008876463398337364, 0.005233152769505978, -0.005382976960390806, 0.0007346856291405857, -0.004675297532230616, 0.001951103564351797, -7.503150845877826e-05, -0.005515916272997856, 0.009327001869678497]

================================================================================
334_layers.20.mlp.down_proj: Linear (layers.20.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.20.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000079, Std: 0.006150
     First 10: [-0.0006441442528739572, -0.0013451902195811272, 0.0005639332812279463, 0.00010159592784475535, -0.0010012021521106362, -0.008000618778169155, -0.012439961545169353, -0.0008973780204541981, 2.215705990238348e-06, -3.972704507759772e-05]
     Last 10:  [-0.00070295634213835, 0.00041677046101540327, -0.0025226108264178038, 2.560479970270535e-06, 0.0006074164994060993, -0.0027535974513739347, 0.00018606262165121734, 0.0006327086593955755, -0.0008089067996479571, -0.00029257527785375714]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.20.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000030, Std: 0.001813
     First 10: [0.00017601015861146152, 0.00041852964204736054, 0.00109209050424397, 0.0004689863126259297, -0.0011176781263202429, -0.000668035470880568, 0.0006481855525635183, -0.0011860872618854046, -0.00032616296084597707, 0.0007131723687052727]
     Last 10:  [0.00010153447510674596, -0.0003968976379837841, -0.001966560259461403, 0.0006268025608733296, 0.0012043251190334558, -0.0008723011123947799, -0.0008069015457294881, -0.00025963346706703305, -0.0002490523038432002, -0.0006480398587882519]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000007
     First 10: [-0.009002036415040493, -0.003062480129301548, 0.0031381985172629356, -0.0010578916408121586, -0.002031989861279726, -0.005550238769501448, -0.018255891278386116, -0.0003704616683535278, 0.004377180244773626, 0.0011968195904046297]
     Last 10:  [0.006879139691591263, 0.0032797695603221655, 0.00904346164315939, 0.0061350055038928986, -0.0021922423038631678, -0.005568499211221933, -0.003958792891353369, 0.0009969458915293217, -0.004349295049905777, -0.0017340215854346752]

================================================================================
335_layers.20.mlp: Gemma3MLP (layers.20.mlp)
================================================================================

  → INPUT[0]: layers.20.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.011086, Std: 0.505234
     First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
     Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000030, Std: 0.001813
     First 10: [0.00017601015861146152, 0.00041852964204736054, 0.00109209050424397, 0.0004689863126259297, -0.0011176781263202429, -0.000668035470880568, 0.0006481855525635183, -0.0011860872618854046, -0.00032616296084597707, 0.0007131723687052727]
     Last 10:  [0.00010153447510674596, -0.0003968976379837841, -0.001966560259461403, 0.0006268025608733296, 0.0012043251190334558, -0.0008723011123947799, -0.0008069015457294881, -0.00025963346706703305, -0.0002490523038432002, -0.0006480398587882519]
     Zeros: 0, Total: 5376

================================================================================
336_layers.20.post_feedforward_layernorm: Gemma3RMSNorm (layers.20.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.20.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000030, Std: 0.001813
     First 10: [0.00017601015861146152, 0.00041852964204736054, 0.00109209050424397, 0.0004689863126259297, -0.0011176781263202429, -0.000668035470880568, 0.0006481855525635183, -0.0011860872618854046, -0.00032616296084597707, 0.0007131723687052727]
     Last 10:  [0.00010153447510674596, -0.0003968976379837841, -0.001966560259461403, 0.0006268025608733296, 0.0012043251190334558, -0.0008723011123947799, -0.0008069015457294881, -0.00025963346706703305, -0.0002490523038432002, -0.0006480398587882519]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.20.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 3.900361, Std: 155.492065
     First 10: [5.777247428894043, 84.54557037353516, 58.293514251708984, 28.035646438598633, -113.77408599853516, -74.42931365966797, 44.6232795715332, -61.79989242553711, -39.28712463378906, 118.05073547363281]
     Last 10:  [4.037607669830322, -9.772262573242188, -120.04703521728516, 72.02775573730469, 86.53860473632812, -115.79740905761719, -107.16096496582031, -10.80485725402832, -16.19139862060547, -89.4576187133789]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 219.169250
     First 10: [75.60140228271484, 470.43096923828125, 123.57046508789062, 138.50953674316406, 236.56369018554688, 259.0147399902344, 159.66290283203125, 120.59747314453125, 280.1053161621094, 385.3026123046875]
     Last 10:  [91.39281463623047, 56.20634460449219, 140.83119201660156, 265.99102783203125, 165.9528045654297, 307.4324035644531, 307.5628662109375, 95.69097900390625, 150.05023193359375, 319.732666015625]

================================================================================
337_layers.21.input_layernorm: Gemma3RMSNorm (layers.21.input_layernorm)
================================================================================

  → INPUT[0]: layers.21.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 21.271503, Std: 662.954468
     First 10: [254.752197265625, 461.5992126464844, 148.2744598388672, 208.80709838867188, -201.06121826171875, 375.35577392578125, 336.2538146972656, -61.197513580322266, -96.7192153930664, 459.29486083984375]
     Last 10:  [-76.1557388305664, -27.10861587524414, -238.91348266601562, 80.95999908447266, 713.927490234375, -272.924560546875, 31.712539672851562, -81.85743713378906, 0.07367324829101562, -113.6005859375]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.139903, Std: 6.197062
     First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
     Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 16.146418
     First 10: [32.57152557373047, 3.280470132827759, 13.305179595947266, 11.474088668823242, 9.387873649597168, 7.644353866577148, 11.250614166259766, 13.604606628417969, 7.761140823364258, 5.4654541015625]
     Last 10:  [21.54482650756836, 32.280155181884766, 11.514656066894531, 9.539599418640137, 10.754894256591797, 5.606768608093262, 6.617977142333984, 23.12615203857422, 12.510198593139648, 6.262650489807129]

================================================================================
338_layers.21.self_attn.q_proj: Linear (layers.21.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.21.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.139903, Std: 6.197062
     First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
     Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.109239, Std: 2.472522
     First 10: [-0.19218572974205017, -0.2559703588485718, -0.14413082599639893, -1.8379671573638916, 0.6077706217765808, -1.3140063285827637, 1.4457305669784546, 0.3771328032016754, 0.6528590321540833, -0.9798147678375244]
     Last 10:  [-0.3648371398448944, 3.6655635833740234, -0.7931320667266846, -0.9572938084602356, 0.04983040690422058, 0.45743250846862793, -0.02163083851337433, 0.17620426416397095, -4.172752857208252, -1.3119205236434937]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000011
     First 10: [-0.007758457213640213, -0.0020232375245541334, -6.354846118483692e-05, -0.001147215603850782, -0.004159522242844105, -0.0007761633605696261, -0.0026147644966840744, 0.001972960541024804, 0.002210978651419282, -0.0007514598546549678]
     Last 10:  [0.013309692963957787, 0.007541481405496597, -0.0016417945735156536, 0.004086704924702644, -0.009938743896782398, -0.00654089730232954, 0.004057276528328657, -0.0012347070733085275, 0.003203654196113348, 0.0012603354407474399]

================================================================================
339_layers.21.self_attn.k_proj: Linear (layers.21.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.21.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.139903, Std: 6.197062
     First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
     Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.206281, Std: 3.290427
     First 10: [-0.9187471866607666, -0.4273800849914551, -0.07798371464014053, 0.5687648057937622, -1.1755740642547607, 0.19697290658950806, -1.529198169708252, -0.3549632430076599, 0.24987700581550598, 1.3045965433120728]
     Last 10:  [-9.1122407913208, 0.23442280292510986, -3.68198823928833, 1.8998234272003174, -14.99787712097168, 0.7177560329437256, 1.5371174812316895, -0.7239113450050354, -5.350516319274902, -9.8025541305542]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000039
     First 10: [0.0052047716453671455, 0.007671007886528969, -0.0034986890386790037, 0.0017097746022045612, 0.003992399666458368, -0.003017355455085635, -0.0010224778670817614, -0.006770090200006962, 0.0028450924437493086, 0.007467732764780521]
     Last 10:  [0.00713166780769825, -0.001037871465086937, 0.005518805701285601, 0.004900060594081879, -0.005997365340590477, -0.010422609746456146, 0.0014635580591857433, 0.009482509456574917, -0.003300306387245655, -0.004486374091356993]

================================================================================
340_layers.21.self_attn.v_proj: Linear (layers.21.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.21.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.139903, Std: 6.197062
     First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
     Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.011132, Std: 1.331192
     First 10: [-0.1320808082818985, 0.08195514231920242, -0.5747569799423218, 0.391632080078125, 0.7524430155754089, -0.770601212978363, 0.7966300249099731, 0.004085659980773926, -0.59767085313797, 0.17842915654182434]
     Last 10:  [-1.9432055950164795, -0.340876042842865, -0.13599693775177002, -0.8425939083099365, -1.8811516761779785, -0.9611423015594482, -5.390427112579346, -0.20615625381469727, -1.243732213973999, -0.7150604724884033]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000023
     First 10: [0.005022447090595961, 0.00046214708709158003, 0.006751266308128834, -0.0007106109405867755, -0.011584585532546043, -0.01516058947890997, 0.01159663125872612, 0.0024311039596796036, 0.0015255322214215994, -0.003381495364010334]
     Last 10:  [-0.004988234490156174, 0.0027948045171797276, -0.01647084578871727, -0.014631463214755058, -0.006892505567520857, 0.011012179777026176, -0.013432891108095646, -0.014504732564091682, -0.0068550328724086285, 0.003099115565419197]

================================================================================
341_layers.21.self_attn.q_norm: Gemma3RMSNorm (layers.21.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.21.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.109239, Std: 2.472522
     First 10: [-0.19218572974205017, -0.2559703588485718, -0.14413082599639893, -1.8379671573638916, 0.6077706217765808, -1.3140063285827637, 1.4457305669784546, 0.3771328032016754, 0.6528590321540833, -0.9798147678375244]
     Last 10:  [-0.3648371398448944, 3.6655635833740234, -0.7931320667266846, -0.9572938084602356, 0.04983040690422058, 0.45743250846862793, -0.02163083851337433, 0.17620426416397095, -4.172752857208252, -1.3119205236434937]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.042108, Std: 1.027172
     First 10: [-0.15371859073638916, -0.13253024220466614, -0.07927827537059784, -0.5358009934425354, 0.21853923797607422, -0.4262485206127167, 0.6792948246002197, 0.1280854344367981, 0.2800249457359314, -0.25661569833755493]
     Last 10:  [-0.21241535246372223, 2.3051040172576904, -0.2731737196445465, -0.5019936561584473, 0.03164730593562126, 0.12610414624214172, -0.001220033853314817, 0.07911889255046844, -1.0532164573669434, -0.376360148191452]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.197430
     First 10: [0.9686360359191895, 0.27434042096138, 0.3538092374801636, -0.28249335289001465, -0.11498656123876572, -0.20159073173999786, 0.15646125376224518, -0.16407828032970428, 0.05569237843155861, -0.35538649559020996]
     Last 10:  [0.5102425813674927, 0.6312090158462524, -0.10658510029315948, 0.3602314293384552, 0.6474117040634155, -0.28490760922431946, -0.853695273399353, 0.16472555696964264, -0.3452812433242798, -0.25585779547691345]

================================================================================
342_layers.21.self_attn.k_norm: Gemma3RMSNorm (layers.21.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.21.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.206281, Std: 3.290427
     First 10: [-0.9187471866607666, -0.4273800849914551, -0.07798371464014053, 0.5687648057937622, -1.1755740642547607, 0.19697290658950806, -1.529198169708252, -0.3549632430076599, 0.24987700581550598, 1.3045965433120728]
     Last 10:  [-9.1122407913208, 0.23442280292510986, -3.68198823928833, 1.8998234272003174, -14.99787712097168, 0.7177560329437256, 1.5371174812316895, -0.7239113450050354, -5.350516319274902, -9.8025541305542]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.21.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.027630, Std: 1.070587
     First 10: [-0.33037132024765015, -0.09926631301641464, -0.015683896839618683, 0.18599826097488403, -0.291397362947464, 0.053973160684108734, -0.339073121547699, -0.09571564942598343, 0.05632392689585686, 0.35254767537117004]
     Last 10:  [-1.939253568649292, 0.08367564529180527, -1.451658010482788, 0.4529729187488556, -2.8118197917938232, 0.31843090057373047, 3.186762809753418, -0.2153470665216446, -3.5930094718933105, -3.9782094955444336]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.324199
     First 10: [0.029337219893932343, -0.3351266086101532, -0.4242931604385376, -0.06388866156339645, -0.2904435396194458, -0.21562698483467102, -0.3652818202972412, -0.22811803221702576, -0.3547649085521698, -0.226441890001297]
     Last 10:  [0.05818396806716919, 0.7748062610626221, 0.9603502750396729, 0.1855250895023346, -0.06779922544956207, 1.2059216499328613, 9.30847454071045, 0.479126513004303, 2.338984489440918, 1.0179023742675781]

================================================================================
343_layers.21.self_attn.o_proj: Linear (layers.21.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.21.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.003022, Std: 0.839146
     First 10: [-0.1320808082818985, 0.08195514231920242, -0.5747569799423218, 0.391632080078125, 0.7524430155754089, -0.770601212978363, 0.7966300249099731, 0.004085659980773926, -0.59767085313797, 0.17842915654182434]
     Last 10:  [-0.5243580937385559, -0.08183103799819946, -0.5590373873710632, -1.0080268383026123, 0.403024286031723, -0.5109790563583374, -0.5735402703285217, 0.8143228888511658, 0.349712073802948, -0.719255805015564]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.028547, Std: 0.551426
     First 10: [-0.03071139007806778, -0.04881244897842407, 0.017889641225337982, 0.08466877043247223, 0.21650660037994385, 0.14434614777565002, -0.1616826355457306, 0.02618226408958435, -0.12065969407558441, -0.008144095540046692]
     Last 10:  [0.007482957094907761, -0.0610712394118309, 0.1595326066017151, -0.14421889185905457, 0.002379700541496277, 0.07041843980550766, -0.1985519677400589, 0.20562228560447693, 0.18276390433311462, 0.15772560238838196]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000014
     First 10: [-0.00692657008767128, 0.004208146594464779, 0.008200199343264103, 0.00843644980341196, -0.001012575114145875, 0.009642583318054676, -0.01088564284145832, 0.002027368638664484, -0.0006396037642844021, 0.006648552604019642]
     Last 10:  [-0.0005232341936789453, 0.01095332857221365, -0.004423939622938633, -0.0006791522027924657, 0.008479142561554909, -0.008312193676829338, -0.0003535112482495606, 0.003161666914820671, 0.013579009100794792, 0.00804057251662016]

================================================================================
344_layers.21.self_attn: Gemma3Attention (layers.21.self_attn)
================================================================================

  → OUTPUT[0]: layers.21.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.028547, Std: 0.551426
     First 10: [-0.03071139007806778, -0.04881244897842407, 0.017889641225337982, 0.08466877043247223, 0.21650660037994385, 0.14434614777565002, -0.1616826355457306, 0.02618226408958435, -0.12065969407558441, -0.008144095540046692]
     Last 10:  [0.007482957094907761, -0.0610712394118309, 0.1595326066017151, -0.14421889185905457, 0.002379700541496277, 0.07041843980550766, -0.1985519677400589, 0.20562228560447693, 0.18276390433311462, 0.15772560238838196]
     Zeros: 0, Total: 5376

================================================================================
345_layers.21.post_attention_layernorm: Gemma3RMSNorm (layers.21.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.21.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.028547, Std: 0.551426
     First 10: [-0.03071139007806778, -0.04881244897842407, 0.017889641225337982, 0.08466877043247223, 0.21650660037994385, 0.14434614777565002, -0.1616826355457306, 0.02618226408958435, -0.12065969407558441, -0.008144095540046692]
     Last 10:  [0.007482957094907761, -0.0610712394118309, 0.1595326066017151, -0.14421889185905457, 0.002379700541496277, 0.07041843980550766, -0.1985519677400589, 0.20562228560447693, 0.18276390433311462, 0.15772560238838196]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006765, Std: 70.276169
     First 10: [-5.2237653732299805, -36.63751220703125, 4.6811347007751465, 23.34031105041504, 93.01683807373047, 70.55953216552734, -54.95275115966797, 6.9258503913879395, -64.39913940429688, -5.358387470245361]
     Last 10:  [1.0138288736343384, -4.7995076179504395, 32.515220642089844, -48.0018424987793, 0.6005383729934692, 29.345741271972656, -84.22147369384766, 23.73798370361328, 42.91338348388672, 67.24455261230469]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 188.242004
     First 10: [80.3981704711914, 358.1912841796875, 124.2218017578125, 130.92095947265625, 204.59893798828125, 232.92730712890625, 161.65090942382812, 125.58910369873047, 254.41612243652344, 313.8630676269531]
     Last 10:  [87.58534240722656, 50.38429260253906, 132.26242065429688, 216.62371826171875, 164.00189208984375, 271.4765625, 276.3442077636719, 74.48211669921875, 152.52276611328125, 277.7567443847656]

================================================================================
346_layers.21.pre_feedforward_layernorm: Gemma3RMSNorm (layers.21.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.21.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 21.278267, Std: 686.779907
     First 10: [249.52842712402344, 424.9617004394531, 152.95559692382812, 232.1474151611328, -108.04438018798828, 445.9153137207031, 281.3010559082031, -54.271663665771484, -161.11834716796875, 453.93646240234375]
     Last 10:  [-75.14190673828125, -31.908123016357422, -206.39825439453125, 32.95815658569336, 714.5280151367188, -243.57882690429688, -52.508934020996094, -58.11945343017578, 42.987056732177734, -46.35603332519531]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006975, Std: 0.463371
     First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
     Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.539170
     First 10: [1.4397141933441162, -0.5401094555854797, 0.5810002684593201, 0.4063321053981781, -0.03900078684091568, -0.18732291460037231, 0.2526835799217224, 0.5381686091423035, -0.1938457190990448, -0.36629170179367065]
     Last 10:  [1.0647069215774536, 2.0762782096862793, 0.4757876396179199, -0.005024031735956669, 0.023959392681717873, -0.33404237031936646, -0.2573551833629608, 1.450721025466919, 0.21045631170272827, -0.3072388768196106]

================================================================================
347_layers.21.mlp.gate_proj: Linear (layers.21.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.21.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006975, Std: 0.463371
     First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
     Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.014042, Std: 0.083661
     First 10: [-0.03226380795240402, -0.04939660429954529, -0.1958286315202713, 0.2221851646900177, 0.07295292615890503, 0.02665148675441742, -0.02239326760172844, 0.13844145834445953, -0.03876672312617302, -0.0346284843981266]
     Last 10:  [0.18315473198890686, 0.027935346588492393, -0.08284022659063339, 0.048996515572071075, 0.13530796766281128, -0.042232878506183624, 0.07718504965305328, 0.022640684619545937, 0.013000254519283772, 0.010271226987242699]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000016
     First 10: [0.0028428188525140285, 0.004765255842357874, 0.00643567182123661, 0.0008277519955299795, -0.0008068925235420465, 0.007130479905754328, 0.007758913561701775, 0.006108623929321766, 0.001978970132768154, -0.004385531414300203]
     Last 10:  [0.006640584208071232, 0.002319879597052932, 0.0003475389094091952, 0.0007861745543777943, -0.0005150026408955455, -0.012250707484781742, -0.00478405924513936, 0.007740495726466179, -0.00687545258551836, -0.00037248461740091443]

================================================================================
348_layers.21.mlp.act_fn: PytorchGELUTanh (layers.21.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.21.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.014042, Std: 0.083661
     First 10: [-0.03226380795240402, -0.04939660429954529, -0.1958286315202713, 0.2221851646900177, 0.07295292615890503, 0.02665148675441742, -0.02239326760172844, 0.13844145834445953, -0.03876672312617302, -0.0346284843981266]
     Last 10:  [0.18315473198890686, 0.027935346588492393, -0.08284022659063339, 0.048996515572071075, 0.13530796766281128, -0.042232878506183624, 0.07718504965305328, 0.022640684619545937, 0.013000254519283772, 0.010271226987242699]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.21.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.004166, Std: 0.041327
     First 10: [-0.01571669615805149, -0.023725271224975586, -0.08271303027868271, 0.13062524795532227, 0.03859779238700867, 0.013609078712761402, -0.010996597819030285, 0.07684239745140076, -0.01878395862877369, -0.016835954040288925]
     Last 10:  [0.10488533973693848, 0.014278961345553398, -0.03868551552295685, 0.025455597788095474, 0.07493558526039124, -0.02040509320795536, 0.04096686467528343, 0.011524822562932968, 0.006567548960447311, 0.005177700892090797]
     Zeros: 0, Total: 8064

================================================================================
349_layers.21.mlp.up_proj: Linear (layers.21.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.21.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006975, Std: 0.463371
     First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
     Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.002499, Std: 0.083128
     First 10: [0.038777295500040054, -0.059223420917987823, -0.07566986978054047, 0.023193221539258957, 0.005512133240699768, -0.035750798881053925, 0.08792135864496231, -0.020401477813720703, -0.033875707536935806, 0.04377712309360504]
     Last 10:  [0.19316941499710083, 0.017759615555405617, -0.016540395095944405, 0.04939170181751251, 0.16029660403728485, 0.03582299128174782, 0.06170757859945297, -0.03534972295165062, -0.05644694343209267, 0.09205536544322968]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000005
     First 10: [0.0020609628409147263, -0.002160273492336273, 0.009667756035923958, 0.000588006863836199, 0.0055515822023153305, -0.003930314909666777, 0.004390119109302759, -0.005880518816411495, 0.00013922888319939375, 0.006476806476712227]
     Last 10:  [-0.0012554263230413198, -0.00867832824587822, 0.0019945339299738407, -0.005413737613707781, 0.0018161458428949118, 0.0009635463356971741, 0.001995164668187499, -0.0006321180262602866, -0.0035475394688546658, 0.0034677612129598856]

================================================================================
350_layers.21.mlp.down_proj: Linear (layers.21.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.21.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000150, Std: 0.004593
     First 10: [-0.0006094509735703468, 0.0014050917234271765, 0.006258884444832802, 0.00302962027490139, 0.00021275617473293096, -0.00048653542762622237, -0.0009668358252383769, -0.0015676984330639243, 0.000636319862678647, -0.000737029651645571]
     Last 10:  [0.020260639488697052, 0.00025358886341564357, 0.0006398737314157188, 0.0012572952546179295, 0.012011920101940632, -0.0007309714565053582, 0.0025279659312218428, -0.00040739928954280913, -0.0003707180730998516, 0.0004766351485159248]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.21.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000068, Std: 0.001721
     First 10: [-0.0005158550338819623, -0.0004192159394733608, -0.0004108040011487901, 0.001043703523464501, -0.00043411084334366024, 3.03550623357296e-05, -0.0006948734517209232, 0.000522240181453526, 7.918966002762318e-05, -0.00033792047179304063]
     Last 10:  [0.00031575822504237294, -0.0016474274452775717, -0.0012615101877599955, 0.0014170357026159763, 0.0013975880574434996, -0.0007734567625448108, -0.002725002821534872, -0.0009682420641183853, 0.0014251329703256488, 0.0013294187374413013]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000012
     First 10: [0.004242517054080963, -0.005764346569776535, -0.0002950490452349186, 0.0039917160756886005, 0.009710648097097874, -0.0006154341390356421, 0.003985818009823561, -0.0015369242755696177, -0.0018184573855251074, 0.0013372849207371473]
     Last 10:  [0.007349750027060509, 0.004684749059379101, -0.0013021179474890232, -0.00012031633377773687, 0.004520024172961712, 0.01680419221520424, -0.0014717563753947616, 0.006092817522585392, 0.008604162372648716, 0.00035774678690358996]

================================================================================
351_layers.21.mlp: Gemma3MLP (layers.21.mlp)
================================================================================

  → INPUT[0]: layers.21.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.006975, Std: 0.463371
     First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
     Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000068, Std: 0.001721
     First 10: [-0.0005158550338819623, -0.0004192159394733608, -0.0004108040011487901, 0.001043703523464501, -0.00043411084334366024, 3.03550623357296e-05, -0.0006948734517209232, 0.000522240181453526, 7.918966002762318e-05, -0.00033792047179304063]
     Last 10:  [0.00031575822504237294, -0.0016474274452775717, -0.0012615101877599955, 0.0014170357026159763, 0.0013975880574434996, -0.0007734567625448108, -0.002725002821534872, -0.0009682420641183853, 0.0014251329703256488, 0.0013294187374413013]
     Zeros: 0, Total: 5376

================================================================================
352_layers.21.post_feedforward_layernorm: Gemma3RMSNorm (layers.21.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.21.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000068, Std: 0.001721
     First 10: [-0.0005158550338819623, -0.0004192159394733608, -0.0004108040011487901, 0.001043703523464501, -0.00043411084334366024, 3.03550623357296e-05, -0.0006948734517209232, 0.000522240181453526, 7.918966002762318e-05, -0.00033792047179304063]
     Last 10:  [0.00031575822504237294, -0.0016474274452775717, -0.0012615101877599955, 0.0014170357026159763, 0.0013975880574434996, -0.0007734567625448108, -0.002725002821534872, -0.0009682420641183853, 0.0014251329703256488, 0.0013294187374413013]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.21.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 8.731761, Std: 180.165359
     First 10: [-26.966638565063477, -113.93172454833984, -29.287843704223633, 77.6457748413086, -60.865108489990234, 4.468834400177002, -60.76070785522461, 36.93429946899414, 12.962908744812012, -80.67521667480469]
     Last 10:  [10.876729011535645, -33.80330276489258, -66.55987548828125, 158.05856323242188, 88.21133422851562, -93.23436737060547, -331.0540771484375, -44.697052001953125, 87.8104019165039, 168.56503295898438]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 256.011139
     First 10: [102.53248596191406, 537.2504272460938, 140.1985626220703, 146.33917236328125, 276.6804504394531, 290.56854248046875, 172.1787567138672, 139.06741333007812, 323.1988830566406, 471.8279724121094]
     Last 10:  [100.24085998535156, 59.30662536621094, 154.0721893310547, 326.83056640625, 184.50575256347656, 353.2845153808594, 356.0624694824219, 134.67727661132812, 180.0934600830078, 371.66436767578125]

================================================================================
353_layers.22.input_layernorm: Gemma3RMSNorm (layers.22.input_layernorm)
================================================================================

  → INPUT[0]: layers.22.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 30.010027, Std: 826.557312
     First 10: [222.56178283691406, 311.02996826171875, 123.66775512695312, 309.7931823730469, -168.90948486328125, 450.3841552734375, 220.54034423828125, -17.337364196777344, -148.1554412841797, 373.26123046875]
     Last 10:  [-64.26517486572266, -65.71142578125, -272.9581298828125, 191.0167236328125, 802.7393798828125, -336.8132019042969, -383.5630187988281, -102.8165054321289, 130.79745483398438, 122.20899963378906]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.119664, Std: 5.098887
     First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
     Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 16.440878
     First 10: [31.71990394592285, 3.050492763519287, 15.65216064453125, 15.713166236877441, 7.567743301391602, 7.306266784667969, 12.3092622756958, 17.7283878326416, 6.277831077575684, 4.265968322753906]
     Last 10:  [23.151037216186523, 34.75090789794922, 14.782796859741211, 7.5746259689331055, 11.089254379272461, 5.777628421783447, 5.671036720275879, 22.705408096313477, 10.556818962097168, 5.938177108764648]

================================================================================
354_layers.22.self_attn.q_proj: Linear (layers.22.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.22.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.119664, Std: 5.098887
     First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
     Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.085504, Std: 2.071075
     First 10: [-0.3606719970703125, 0.25113391876220703, 1.154634714126587, -1.1956827640533447, 0.8577898740768433, -0.2992662191390991, 0.10739541053771973, 0.5160561203956604, 1.010702133178711, 0.13838011026382446]
     Last 10:  [-4.100765705108643, 1.8266681432724, 0.6036360263824463, 0.8861453533172607, -0.4781343936920166, -0.09689527750015259, 0.8772269487380981, 1.7120635509490967, -0.4919315576553345, -1.5381542444229126]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000011
     First 10: [0.001726475777104497, 0.005286933854222298, -0.01984292082488537, -0.005673375446349382, 0.015752630308270454, 0.006296321749687195, 0.007244820706546307, 0.016539359465241432, -0.002260153880342841, 0.005269465036690235]
     Last 10:  [-0.001001103431917727, 0.003875802271068096, 0.0007492604199796915, 0.006654753349721432, -0.002650805748999119, 0.002098236232995987, 0.00237856013700366, 0.008087841793894768, -0.01569448970258236, 0.0009570606052875519]

================================================================================
355_layers.22.self_attn.k_proj: Linear (layers.22.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.22.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.119664, Std: 5.098887
     First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
     Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.014008, Std: 1.990108
     First 10: [0.9766206741333008, -0.5148115158081055, 0.6268669366836548, -1.2359373569488525, 1.1525217294692993, -0.6996595859527588, -0.9483623504638672, 1.3843380212783813, 0.42997777462005615, -0.4466647207736969]
     Last 10:  [-9.720972061157227, 3.4868927001953125, 0.6440816521644592, 2.1073660850524902, 2.507824182510376, 3.80507755279541, 4.631038188934326, 0.6810306310653687, -6.464661121368408, -0.8705835342407227]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000008
     First 10: [-0.007205790374428034, 0.0013913632137700915, -0.006251858547329903, -0.002838368993252516, 0.01685456559062004, -0.00219811056740582, -0.005453506484627724, 0.006713764742016792, 0.004758690483868122, 0.010519852861762047]
     Last 10:  [-0.0034919637255370617, -0.008710173889994621, -0.007565664127469063, 0.010218624025583267, -0.007783282548189163, 0.011762687005102634, 0.007122090086340904, -0.0035241306759417057, -0.006609452422708273, -0.008975725620985031]

================================================================================
356_layers.22.self_attn.v_proj: Linear (layers.22.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.22.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.119664, Std: 5.098887
     First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
     Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: 0.039747, Std: 1.127255
     First 10: [1.0966882705688477, 0.7812347412109375, 0.23234941065311432, 0.19118180871009827, -0.6556218862533569, 0.7667942047119141, -0.4091002941131592, 0.22289711236953735, 0.17747120559215546, 0.04030734300613403]
     Last 10:  [-0.8188996315002441, 0.08696593344211578, 1.791534423828125, 0.2542421519756317, -0.3360554873943329, -0.36960694193840027, -0.14066553115844727, -0.49565476179122925, -0.8397150039672852, -0.5054383277893066]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000009
     First 10: [-0.0023579734843224287, -0.002660835161805153, -0.007319741882383823, 0.012294631451368332, -0.016203319653868675, -0.007551136426627636, -0.00726336520165205, 0.0020951377227902412, -0.0028678246308118105, 0.005141856614500284]
     Last 10:  [-0.002593124285340309, 0.0029170154593884945, -0.0039732265286147594, -0.0045119463466107845, -0.006056978367269039, 0.023809216916561127, 0.016655512154102325, -0.014171618968248367, -0.0037284926511347294, 0.0018325228011235595]

================================================================================
357_layers.22.self_attn.q_norm: Gemma3RMSNorm (layers.22.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.22.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.085504, Std: 2.071075
     First 10: [-0.3606719970703125, 0.25113391876220703, 1.154634714126587, -1.1956827640533447, 0.8577898740768433, -0.2992662191390991, 0.10739541053771973, 0.5160561203956604, 1.010702133178711, 0.13838011026382446]
     Last 10:  [-4.100765705108643, 1.8266681432724, 0.6036360263824463, 0.8861453533172607, -0.4781343936920166, -0.09689527750015259, 0.8772269487380981, 1.7120635509490967, -0.4919315576553345, -1.5381542444229126]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: 0.003010, Std: 0.907564
     First 10: [-0.06539787352085114, 0.19391512870788574, 0.7777132391929626, -0.8633933067321777, 0.2865588068962097, -0.16905853152275085, 0.06798228621482849, 0.3256538510322571, 0.4177933633327484, 0.07708168029785156]
     Last 10:  [-0.31349673867225647, 0.3238573968410492, 0.2545357048511505, 0.43479204177856445, -0.2915246784687042, -0.05743566155433655, 0.33197465538978577, 0.8465550541877747, -0.31335288286209106, -0.5584181547164917]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.094064
     First 10: [-0.5809110999107361, 0.7846838235855103, 0.5567893981933594, 0.6689667701721191, -0.22787460684776306, 0.30567291378974915, 0.4630698263645172, 0.45852625370025635, -0.04458220303058624, 0.2874562442302704]
     Last 10:  [-0.819055438041687, -0.5803650617599487, -0.0019529322162270546, 0.16132579743862152, 0.4431212544441223, 0.4029961824417114, -0.10428383946418762, 0.17034213244915009, 0.5076705813407898, -0.14071524143218994]

================================================================================
358_layers.22.self_attn.k_norm: Gemma3RMSNorm (layers.22.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.22.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: 0.014008, Std: 1.990108
     First 10: [0.9766206741333008, -0.5148115158081055, 0.6268669366836548, -1.2359373569488525, 1.1525217294692993, -0.6996595859527588, -0.9483623504638672, 1.3843380212783813, 0.42997777462005615, -0.4466647207736969]
     Last 10:  [-9.720972061157227, 3.4868927001953125, 0.6440816521644592, 2.1073660850524902, 2.507824182510376, 3.80507755279541, 4.631038188934326, 0.6810306310653687, -6.464661121368408, -0.8705835342407227]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.22.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.070471, Std: 2.606749
     First 10: [0.6744826436042786, -0.3173788785934448, 0.4709046185016632, -0.520111620426178, 0.8953589200973511, -0.40938758850097656, -0.314823180437088, 0.6868636608123779, 0.25402072072029114, -0.18145418167114258]
     Last 10:  [-31.77065658569336, 4.397150039672852, 0.38686421513557434, 1.297036051750183, 1.2155823707580566, 1.6576658487319946, 3.1659507751464844, 0.35646507143974304, -2.803743839263916, -0.7436607480049133]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.524969
     First 10: [0.2587319612503052, 0.1236165314912796, 0.36913397908210754, -0.23301222920417786, 0.41591233015060425, 0.06643959134817123, -0.39496463537216187, -0.0956912711262703, 0.07674156874418259, -0.2595875859260559]
     Last 10:  [7.477418899536133, 2.2709949016571045, 0.5579902529716492, 0.5964642763137817, 0.25728708505630493, 0.13000555336475372, 0.7732621431350708, 0.35768020153045654, 0.12496684491634369, 1.215703010559082]

================================================================================
359_layers.22.self_attn.o_proj: Linear (layers.22.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.22.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.027073, Std: 0.894376
     First 10: [1.0966882705688477, 0.7812347412109375, 0.23234941065311432, 0.19118180871009827, -0.6556218862533569, 0.7667942047119141, -0.4091002941131592, 0.22289711236953735, 0.17747120559215546, 0.04030734300613403]
     Last 10:  [-0.39939725399017334, 0.21678102016448975, 0.5563833117485046, -0.29007530212402344, 0.29163143038749695, -0.217654287815094, 0.11650477349758148, 0.16673356294631958, -0.7178808450698853, -0.7067828178405762]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.018907, Std: 0.358094
     First 10: [-0.2199665904045105, 0.05313340574502945, -0.21738030016422272, 0.08784294128417969, -0.194219708442688, -0.04234836995601654, -0.06432276964187622, 0.02760402485728264, -0.1292407214641571, -0.08854381740093231]
     Last 10:  [-0.10702682286500931, 0.14953233301639557, 0.2191532850265503, 0.0015471316874027252, 0.03773049637675285, -0.19228309392929077, 0.11880626529455185, 0.007898246869444847, -0.007783878594636917, -0.05807621777057648]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: -0.000001
     First 10: [0.002244969131425023, 0.0018460133578628302, 0.004395393189042807, -0.0012758404482156038, -0.005221677012741566, -0.0013710259227082133, 0.007097206078469753, -0.008906519040465355, -0.004450384061783552, -0.006194964982569218]
     Last 10:  [0.0013902927748858929, 0.006014177575707436, 0.0017872157040983438, -0.0008251406834460795, -0.004898956045508385, -0.005312464199960232, 0.004503894597291946, -0.012448749504983425, 0.0014133569784462452, -0.009171860292553902]

================================================================================
360_layers.22.self_attn: Gemma3Attention (layers.22.self_attn)
================================================================================

  → OUTPUT[0]: layers.22.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.018907, Std: 0.358094
     First 10: [-0.2199665904045105, 0.05313340574502945, -0.21738030016422272, 0.08784294128417969, -0.194219708442688, -0.04234836995601654, -0.06432276964187622, 0.02760402485728264, -0.1292407214641571, -0.08854381740093231]
     Last 10:  [-0.10702682286500931, 0.14953233301639557, 0.2191532850265503, 0.0015471316874027252, 0.03773049637675285, -0.19228309392929077, 0.11880626529455185, 0.007898246869444847, -0.007783878594636917, -0.05807621777057648]
     Zeros: 0, Total: 5376

================================================================================
361_layers.22.post_attention_layernorm: Gemma3RMSNorm (layers.22.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.22.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.018907, Std: 0.358094
     First 10: [-0.2199665904045105, 0.05313340574502945, -0.21738030016422272, 0.08784294128417969, -0.194219708442688, -0.04234836995601654, -0.06432276964187622, 0.02760402485728264, -0.1292407214641571, -0.08854381740093231]
     Last 10:  [-0.10702682286500931, 0.14953233301639557, 0.2191532850265503, 0.0015471316874027252, 0.03773049637675285, -0.19228309392929077, 0.11880626529455185, 0.007898246869444847, -0.007783878594636917, -0.05807621777057648]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 2.420167, Std: 88.506355
     First 10: [-38.79816436767578, 55.42149353027344, -98.62366485595703, 45.88089370727539, -103.36785125732422, -24.60865020751953, -35.644195556640625, 12.461679458618164, -80.68533325195312, -74.39836120605469]
     Last 10:  [-27.200626373291016, 20.855510711669922, 102.9354248046875, 0.7872195243835449, 13.462584495544434, -128.01654052734375, 76.5503158569336, 1.4986056089401245, -2.5646157264709473, -38.56374740600586]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 203.962051
     First 10: [67.24137878417969, 402.55609130859375, 174.5312042236328, 201.0776824951172, 204.91384887695312, 223.82492065429688, 213.39637756347656, 173.66163635253906, 240.53973388671875, 324.086181640625]
     Last 10:  [113.13027954101562, 61.63258361816406, 209.92666625976562, 227.4984130859375, 159.2324676513672, 297.978271484375, 288.34918212890625, 84.20620727539062, 146.9588165283203, 297.1916809082031]

================================================================================
362_layers.22.pre_feedforward_layernorm: Gemma3RMSNorm (layers.22.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.22.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 32.430195, Std: 840.844421
     First 10: [183.76361083984375, 366.45147705078125, 25.044090270996094, 355.674072265625, -272.27734375, 425.7755126953125, 184.89614868164062, -4.87568473815918, -228.8407745361328, 298.86285400390625]
     Last 10:  [-91.46580505371094, -44.85591506958008, -170.022705078125, 191.80393981933594, 816.2019653320312, -464.8297424316406, -307.0126953125, -101.31790161132812, 128.2328338623047, 83.64524841308594]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012731, Std: 0.435994
     First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
     Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 0.332127
     First 10: [2.0594868659973145, -0.5800763368606567, 0.1913726031780243, 0.055725812911987305, -0.1126217395067215, -0.2909904718399048, 0.0031341565772891045, 0.1574852615594864, -0.38112807273864746, -0.45310133695602417]
     Last 10:  [0.679225504398346, 1.3945380449295044, 0.08230747282505035, -0.2362366020679474, -0.014367155730724335, -0.45775139331817627, -0.39314961433410645, 1.2495946884155273, 0.06436089426279068, -0.39721328020095825]

================================================================================
363_layers.22.mlp.gate_proj: Linear (layers.22.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.22.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012731, Std: 0.435994
     First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
     Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.005867, Std: 0.083245
     First 10: [0.050328709185123444, 0.004280753433704376, 0.049845267087221146, 0.0332026481628418, 0.03385660797357559, -0.367888480424881, 0.013333476148545742, -0.12108683586120605, -0.006789416074752808, 0.06070050597190857]
     Last 10:  [-0.11343406140804291, -0.07796841859817505, 0.7547639012336731, -0.06256610155105591, 0.023868225514888763, -0.02085898444056511, 0.02691822126507759, 0.0031635360792279243, -0.040290504693984985, -0.0030505936592817307]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000016
     First 10: [-0.007184543646872044, -0.001789214788004756, 0.0031402914319187403, -1.2113225238863379e-05, -0.010143992491066456, 0.009241101332008839, 0.009228934533894062, 0.0069653987884521484, -0.0016159664373844862, -0.0018734793411567807]
     Last 10:  [-0.00020722710178233683, 0.0008297608001157641, -0.006900321692228317, 0.015056867152452469, -0.006326531060039997, 0.005258149467408657, 0.0018615714507177472, 0.016294633969664574, 0.00828561745584011, -0.0014779584016650915]

================================================================================
364_layers.22.mlp.act_fn: PytorchGELUTanh (layers.22.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.22.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.005867, Std: 0.083245
     First 10: [0.050328709185123444, 0.004280753433704376, 0.049845267087221146, 0.0332026481628418, 0.03385660797357559, -0.367888480424881, 0.013333476148545742, -0.12108683586120605, -0.006789416074752808, 0.06070050597190857]
     Last 10:  [-0.11343406140804291, -0.07796841859817505, 0.7547639012336731, -0.06256610155105591, 0.023868225514888763, -0.02085898444056511, 0.02691822126507759, 0.0031635360792279243, -0.040290504693984985, -0.0030505936592817307]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.22.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000187, Std: 0.041290
     First 10: [0.026174437254667282, 0.002147687366232276, 0.025913415476679802, 0.01704104244709015, 0.017385512590408325, -0.13114970922470093, 0.006737660616636276, -0.05470845103263855, -0.003376318607479334, 0.03181926906108856]
     Last 10:  [-0.05159476771950722, -0.036561474204063416, 0.5847242474555969, -0.029722407460212708, 0.012161364778876305, -0.010255926288664341, 0.013748145662248135, 0.0015857606194913387, -0.019497815519571304, -0.0015215842286124825]
     Zeros: 0, Total: 8064

================================================================================
365_layers.22.mlp.up_proj: Linear (layers.22.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.22.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012731, Std: 0.435994
     First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
     Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000125, Std: 0.086457
     First 10: [-0.059474021196365356, 0.05188290774822235, -0.010762285441160202, -0.01627976819872856, -0.025735042989253998, -0.08914840221405029, 0.027703814208507538, 0.018703322857618332, 0.00683923065662384, 0.08297491073608398]
     Last 10:  [-0.22374555468559265, 0.07247208058834076, 0.23796246945858002, 0.020316364243626595, -0.024654977023601532, -0.09366852045059204, -0.01965862140059471, 0.16244667768478394, 0.044433265924453735, -0.03742983937263489]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: -0.000003
     First 10: [-0.0029535102657973766, -0.007610720582306385, 0.001026727957651019, -0.0023032529279589653, -0.009918713942170143, 0.0013160344678908587, -0.011509578675031662, -0.002186328172683716, 0.005047795828431845, -0.005742235109210014]
     Last 10:  [-0.003875351045280695, 0.0076936716213822365, 0.009434976615011692, 0.0065651158802211285, -0.005880077835172415, -0.0014312637504190207, -0.0007836964214220643, 0.0026954521890729666, -0.006963326595723629, -0.0011441856622695923]

================================================================================
366_layers.22.mlp.down_proj: Linear (layers.22.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.22.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000042, Std: 0.005932
     First 10: [-0.0015566990477964282, 0.00011142826406285167, -0.00027888757176697254, -0.00027742423117160797, -0.0004474169109016657, 0.011691787280142307, 0.0001866589009296149, -0.0010232297936454415, -2.3091421098797582e-05, 0.002640201011672616]
     Last 10:  [0.011544100008904934, -0.0026496860664337873, 0.13914242386817932, -0.0006038512801751494, -0.0002998381678480655, 0.0009606574312783778, -0.0002702695783227682, 0.00025760155403986573, -0.0008663516491651535, 5.695265281246975e-05]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.22.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000013, Std: 0.002551
     First 10: [-0.00041726240306161344, 0.00015297502977773547, -0.0002851833705790341, 0.0008279255125671625, -0.0003054695844184607, 0.0006038003484718502, -5.667538789566606e-05, -0.0003777878009714186, 0.00041177315870299935, 0.0004111839225515723]
     Last 10:  [0.0012045789044350386, -0.001689740689471364, 0.0012449956266209483, -0.00023999845143407583, -0.00020690337987616658, -0.00043740763794630766, -0.0001059499045368284, -0.001861112890765071, -0.0022947844117879868, -0.000678480020724237]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: 0.000005
     First 10: [-0.006971784867346287, 0.005135323852300644, -0.005072112660855055, 0.005397645290941, -0.005253474228084087, -0.002653685864061117, -0.0025662833359092474, 0.00012149959366070107, 0.006190866231918335, -0.00635948870331049]
     Last 10:  [0.003455781377851963, 0.009371541440486908, 0.003068838268518448, -0.0004330539086367935, -0.0036614197306334972, -0.004726378247141838, -0.009204437956213951, 0.006876996718347073, -0.00470391009002924, -0.0008310319390147924]

================================================================================
367_layers.22.mlp: Gemma3MLP (layers.22.mlp)
================================================================================

  → INPUT[0]: layers.22.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012731, Std: 0.435994
     First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
     Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000013, Std: 0.002551
     First 10: [-0.00041726240306161344, 0.00015297502977773547, -0.0002851833705790341, 0.0008279255125671625, -0.0003054695844184607, 0.0006038003484718502, -5.667538789566606e-05, -0.0003777878009714186, 0.00041177315870299935, 0.0004111839225515723]
     Last 10:  [0.0012045789044350386, -0.001689740689471364, 0.0012449956266209483, -0.00023999845143407583, -0.00020690337987616658, -0.00043740763794630766, -0.0001059499045368284, -0.001861112890765071, -0.0022947844117879868, -0.000678480020724237]
     Zeros: 0, Total: 5376

================================================================================
368_layers.22.post_feedforward_layernorm: Gemma3RMSNorm (layers.22.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.22.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.000013, Std: 0.002551
     First 10: [-0.00041726240306161344, 0.00015297502977773547, -0.0002851833705790341, 0.0008279255125671625, -0.0003054695844184607, 0.0006038003484718502, -5.667538789566606e-05, -0.0003777878009714186, 0.00041177315870299935, 0.0004111839225515723]
     Last 10:  [0.0012045789044350386, -0.001689740689471364, 0.0012449956266209483, -0.00023999845143407583, -0.00020690337987616658, -0.00043740763794630766, -0.0001059499045368284, -0.001861112890765071, -0.0022947844117879868, -0.000678480020724237]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.22.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 40.129307, Std: 1295.566284
     First 10: [-28.188135147094727, 57.61558532714844, -28.908397674560547, 86.90762329101562, -63.00331497192383, 123.92156982421875, -6.685600280761719, -35.70066452026367, 93.79269409179688, 135.3519287109375]
     Last 10:  [23.96026611328125, -20.615041732788086, 38.43105697631836, -16.062400817871094, -7.503787994384766, -30.752761840820312, -7.0132155418396, -48.217960357666016, -80.36627960205078, -47.288516998291016]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 306.657318
     First 10: [114.88185119628906, 645.0672607421875, 172.88340759277344, 179.0631866455078, 352.79669189453125, 351.05609130859375, 201.3504638671875, 161.1013641357422, 389.7232666015625, 563.6594848632812]
     Last 10:  [119.82865142822266, 73.11015319824219, 186.51156616210938, 405.551513671875, 219.3061065673828, 426.08203125, 401.09637451171875, 156.3800506591797, 211.7382354736328, 422.3818054199219]

================================================================================
369_layers.23.input_layernorm: Gemma3RMSNorm (layers.23.input_layernorm)
================================================================================

  → INPUT[0]: layers.23.input_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 72.559509, Std: 1928.775146
     First 10: [155.57546997070312, 424.06707763671875, -3.864307403564453, 442.5816955566406, -335.2806701660156, 549.6970825195312, 178.21054077148438, -40.57634735107422, -135.04808044433594, 434.21478271484375]
     Last 10:  [-67.50553894042969, -65.47095489501953, -131.59164428710938, 175.74154663085938, 808.6981811523438, -495.58251953125, -314.0259094238281, -149.53585815429688, 47.866554260253906, 36.35673141479492]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.input_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016988, Std: 1.770467
     First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
     Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 6.491487
     First 10: [12.184938430786133, 1.4571740627288818, 4.638324737548828, 3.0654406547546387, 3.0080971717834473, 2.7087440490722656, 3.7550601959228516, 3.867457389831543, 2.0697059631347656, 1.2905311584472656]
     Last 10:  [8.857712745666504, 10.675094604492188, 3.70265531539917, 2.105666399002075, 4.11358642578125, 1.8846515417099, 1.891184687614441, 8.493928909301758, 3.8986597061157227, 1.5860300064086914]

================================================================================
370_layers.23.self_attn.q_proj: Linear (layers.23.self_attn.q_proj)
================================================================================

  → INPUT[0]: layers.23.self_attn.q_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016988, Std: 1.770467
     First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
     Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.self_attn.q_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.066113, Std: 0.965892
     First 10: [-0.5019404888153076, 3.267324447631836, 0.9382902383804321, -4.378557205200195, -1.6263254880905151, 1.8315285444259644, -0.6986075639724731, 1.5401923656463623, 0.03232799470424652, -4.216312885284424]
     Last 10:  [-0.3292371332645416, 0.4730690121650696, 0.6639103293418884, -1.3571791648864746, -1.1953482627868652, -0.8623377680778503, 1.0080392360687256, -0.15944062173366547, 1.4105380773544312, 0.7137588262557983]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000017
     First 10: [0.005736687686294317, 0.001094195293262601, -0.02747938223183155, -0.00869374442845583, -0.011318214237689972, -0.014857107773423195, 0.002262244699522853, -0.016287563368678093, 0.002260647714138031, -0.00254975538700819]
     Last 10:  [0.01095449086278677, -0.010744977742433548, -0.002158928429707885, 0.00418271217495203, 0.0019178732763975859, 0.0014032891485840082, 0.005518793128430843, 0.006980281323194504, -0.010681862011551857, 0.009888719767332077]

================================================================================
371_layers.23.self_attn.k_proj: Linear (layers.23.self_attn.k_proj)
================================================================================

  → INPUT[0]: layers.23.self_attn.k_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016988, Std: 1.770467
     First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
     Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.self_attn.k_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.014699, Std: 0.683250
     First 10: [-0.035623274743556976, -0.5003649592399597, -0.6913220286369324, -0.5560872554779053, 0.5266618132591248, -0.674839198589325, -0.22738128900527954, -0.5199233889579773, -0.5867617130279541, 0.21602745354175568]
     Last 10:  [2.399643898010254, 3.239105463027954, 2.177467107772827, -0.5970985889434814, 1.1158716678619385, -0.3703809976577759, 5.396165370941162, 0.2536398470401764, 3.2775368690490723, -0.33081382513046265]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000012
     First 10: [-0.007145208306610584, 0.009686765260994434, -7.604456914123148e-05, -3.279850716353394e-05, -0.008062557317316532, -0.0032822901848703623, -0.0177463311702013, -0.011220007203519344, -0.0035245148465037346, -0.009469344280660152]
     Last 10:  [0.014103755354881287, 0.0023711840622127056, 0.001708928495645523, 0.001946749398484826, -0.007635163143277168, -0.0063829561695456505, 0.010679824277758598, -0.002503171795979142, -0.011955688707530499, 0.004226323217153549]

================================================================================
372_layers.23.self_attn.v_proj: Linear (layers.23.self_attn.v_proj)
================================================================================

  → INPUT[0]: layers.23.self_attn.v_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.016988, Std: 1.770467
     First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
     Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.self_attn.v_proj_output
     Shape: [1, 7, 256]
     Dtype: torch.float32
     Mean: -0.002767, Std: 0.433900
     First 10: [0.18057888746261597, 0.10078537464141846, 0.5773279666900635, 0.39569172263145447, -0.06049492955207825, 0.3637787401676178, 0.2827119529247284, 0.6494826078414917, -0.15422837436199188, -0.2906862497329712]
     Last 10:  [-0.3941286504268646, 0.44312334060668945, 0.08729101717472076, 0.33791521191596985, -1.408284306526184, 0.387949675321579, -0.6129022836685181, 0.7450695037841797, 0.5986040830612183, 0.78910231590271]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256, 768]
     Mean: 0.000024
     First 10: [-0.0005500229308381677, 0.021277906373143196, 0.0047966898418962955, -0.002247609430924058, -0.00449473038315773, -0.004259899258613586, 0.0016099284403026104, -0.006777489557862282, -0.010847263969480991, -0.013811267912387848]
     Last 10:  [-0.0006756020011380315, -0.013818595558404922, -0.009155903942883015, -0.0014644393231719732, -0.015395872294902802, -0.014436035417020321, 0.010805107653141022, 0.0005703300121240318, -0.0034569972194731236, -0.013174092397093773]

================================================================================
373_layers.23.self_attn.q_norm: Gemma3RMSNorm (layers.23.self_attn.q_norm)
================================================================================

  → INPUT[0]: layers.23.self_attn.q_norm_input_0
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.066113, Std: 0.965892
     First 10: [-0.5019404888153076, 3.267324447631836, 0.9382902383804321, -4.378557205200195, -1.6263254880905151, 1.8315285444259644, -0.6986075639724731, 1.5401923656463623, 0.03232799470424652, -4.216312885284424]
     Last 10:  [-0.3292371332645416, 0.4730690121650696, 0.6639103293418884, -1.3571791648864746, -1.1953482627868652, -0.8623377680778503, 1.0080392360687256, -0.15944062173366547, 1.4105380773544312, 0.7137588262557983]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.self_attn.q_norm_output
     Shape: [1, 3, 7, 256]
     Dtype: torch.float32
     Mean: -0.025536, Std: 0.878382
     First 10: [-0.2403334230184555, -0.0022922917269170284, -1.032644510269165, -2.5529251098632812, 0.01627814583480358, -1.5146085023880005, 0.7634945511817932, 1.4874383211135864, -0.01454649493098259, 0.022197827696800232]
     Last 10:  [-0.050226546823978424, 0.19520524144172668, 0.22679750621318817, -0.45152172446250916, -0.22718971967697144, -0.23443470895290375, 0.12096568197011948, -0.026906533166766167, 0.394452303647995, 0.27729979157447815]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.469170
     First 10: [-0.5068144798278809, -1.0007226467132568, -2.133605718612671, -0.39944136142730713, -1.0103096961975098, -1.851794958114624, -2.1256957054138184, -0.005253586918115616, -1.4634767770767212, -1.005422830581665]
     Last 10:  [-0.6610577702522278, -0.08321371674537659, -0.24102053046226501, -0.26083284616470337, -0.5777249932289124, -0.395987868309021, -0.7333841919898987, -0.625061571598053, -0.37868642807006836, -0.13682429492473602]

================================================================================
374_layers.23.self_attn.k_norm: Gemma3RMSNorm (layers.23.self_attn.k_norm)
================================================================================

  → INPUT[0]: layers.23.self_attn.k_norm_input_0
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.014699, Std: 0.683250
     First 10: [-0.035623274743556976, -0.5003649592399597, -0.6913220286369324, -0.5560872554779053, 0.5266618132591248, -0.674839198589325, -0.22738128900527954, -0.5199233889579773, -0.5867617130279541, 0.21602745354175568]
     Last 10:  [2.399643898010254, 3.239105463027954, 2.177467107772827, -0.5970985889434814, 1.1158716678619385, -0.3703809976577759, 5.396165370941162, 0.2536398470401764, 3.2775368690490723, -0.33081382513046265]
     Zeros: 0, Total: 1792

  → OUTPUT[0]: layers.23.self_attn.k_norm_output
     Shape: [1, 1, 7, 256]
     Dtype: torch.float32
     Mean: -0.040708, Std: 3.154028
     First 10: [-0.00044170464389026165, -0.012608443386852741, 1.7572158575057983, 0.6053315997123718, -0.07268968969583511, 1.3084105253219604, -0.21574939787387848, -0.998650312423706, -0.014400137588381767, -0.017188720405101776]
     Last 10:  [9.812729835510254, 4.772675037384033, 4.241828441619873, -1.528754472732544, 5.684643745422363, -1.2181940078735352, 27.801761627197266, 1.267327904701233, 7.393815040588379, -0.7430755496025085]
     Zeros: 0, Total: 1792

  → PARAMETER: weight
     Shape: [256]
     Mean: 0.754886
     First 10: [-0.9934936761856079, -0.9867775440216064, -2.3337740898132324, -1.571199655532837, -1.0724233388900757, -2.0173754692077637, -0.5021111369132996, 0.007886538282036781, -0.9871221780776978, -1.041751503944397]
     Last 10:  [5.544090747833252, 1.3579957485198975, 2.117509126663208, 3.097301959991455, 7.152584075927734, 4.263492584228516, 7.245050430297852, 6.996091842651367, 2.6101670265197754, 2.59464168548584]

================================================================================
375_layers.23.self_attn.o_proj: Linear (layers.23.self_attn.o_proj)
================================================================================

  → INPUT[0]: layers.23.self_attn.o_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.001016, Std: 0.225265
     First 10: [0.18057888746261597, 0.10078537464141846, 0.5773279666900635, 0.39569172263145447, -0.06049492955207825, 0.3637787401676178, 0.2827119529247284, 0.6494826078414917, -0.15422837436199188, -0.2906862497329712]
     Last 10:  [-0.04445837065577507, -0.106530100107193, -0.03558943420648575, -0.04302895814180374, -0.0926256775856018, 0.1158161386847496, -0.05509444698691368, 0.07242661714553833, -0.03410325199365616, 0.22681641578674316]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.self_attn.o_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.002948, Std: 0.135374
     First 10: [-0.08060356229543686, -0.03412829339504242, -0.03302070498466492, -0.029198644682765007, 0.0558071993291378, -0.08552975207567215, 0.00853467732667923, -0.028378888964653015, 0.03082314506173134, -0.015844620764255524]
     Last 10:  [0.042154934257268906, 0.03602764010429382, -0.00597868487238884, 0.02808588370680809, -0.0717778354883194, 0.03321591764688492, -0.013857553713023663, 0.0379830077290535, -0.029481563717126846, 0.0010167928412556648]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 768]
     Mean: 0.000002
     First 10: [0.010930648073554039, 0.004906164947897196, -0.002527083968743682, -0.009685561060905457, -0.011720249429345131, -0.0028758097905665636, -0.0029655885882675648, 0.011155259795486927, 0.001121786772273481, -0.011011909693479538]
     Last 10:  [0.01191921066492796, 0.015756715089082718, 0.010444211773574352, 0.0012161111226305366, -0.010626006871461868, 0.013540659099817276, -0.007109189406037331, -0.003039613366127014, -0.007348277606070042, 0.0014056176878511906]

================================================================================
376_layers.23.self_attn: Gemma3Attention (layers.23.self_attn)
================================================================================

  → OUTPUT[0]: layers.23.self_attn_output_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.002948, Std: 0.135374
     First 10: [-0.08060356229543686, -0.03412829339504242, -0.03302070498466492, -0.029198644682765007, 0.0558071993291378, -0.08552975207567215, 0.00853467732667923, -0.028378888964653015, 0.03082314506173134, -0.015844620764255524]
     Last 10:  [0.042154934257268906, 0.03602764010429382, -0.00597868487238884, 0.02808588370680809, -0.0717778354883194, 0.03321591764688492, -0.013857553713023663, 0.0379830077290535, -0.029481563717126846, 0.0010167928412556648]
     Zeros: 0, Total: 5376

================================================================================
377_layers.23.post_attention_layernorm: Gemma3RMSNorm (layers.23.post_attention_layernorm)
================================================================================

  → INPUT[0]: layers.23.post_attention_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.002948, Std: 0.135374
     First 10: [-0.08060356229543686, -0.03412829339504242, -0.03302070498466492, -0.029198644682765007, 0.0558071993291378, -0.08552975207567215, 0.00853467732667923, -0.028378888964653015, 0.03082314506173134, -0.015844620764255524]
     Last 10:  [0.042154934257268906, 0.03602764010429382, -0.00597868487238884, 0.02808588370680809, -0.0717778354883194, 0.03321591764688492, -0.013857553713023663, 0.0379830077290535, -0.029481563717126846, 0.0010167928412556648]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.post_attention_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 13.232907, Std: 331.626190
     First 10: [-33.60166931152344, -85.44408416748047, -19.16473388671875, -18.60396957397461, 71.15177154541016, -122.20758056640625, 6.340312480926514, -15.008856773376465, 45.54396438598633, -33.05653381347656]
     Last 10:  [22.34293556213379, 10.73908519744873, -4.434736728668213, 43.20695495605469, -74.09333038330078, 69.53937530517578, -23.06243896484375, 21.458480834960938, -28.96901512145996, 1.8043187856674194]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 243.108200
     First 10: [79.86325073242188, 484.6372985839844, 111.5799560546875, 122.5911865234375, 246.30911254882812, 276.15679931640625, 143.10137939453125, 101.58805847167969, 285.6147155761719, 403.687744140625]
     Last 10:  [91.6067123413086, 51.081336975097656, 128.6023406982422, 267.79193115234375, 179.35968017578125, 364.7928466796875, 289.783203125, 97.70980834960938, 170.68560791015625, 309.0498046875]

================================================================================
378_layers.23.pre_feedforward_layernorm: Gemma3RMSNorm (layers.23.pre_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.23.pre_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 85.792412, Std: 2236.355713
     First 10: [121.97380065917969, 338.62298583984375, -23.029041290283203, 423.97772216796875, -264.12890625, 427.489501953125, 184.5508575439453, -55.585205078125, -89.50411987304688, 401.15826416015625]
     Last 10:  [-45.16260528564453, -54.731868743896484, -136.02638244628906, 218.94850158691406, 734.6048583984375, -426.04315185546875, -337.0883483886719, -128.07737731933594, 18.897539138793945, 38.161048889160156]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.pre_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012118, Std: 0.588893
     First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
     Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 2.299745
     First 10: [6.945194244384766, -0.08098087459802628, 1.8713798522949219, 1.547544240951538, 0.971116304397583, 0.6731096506118774, 1.3835909366607666, 1.9542016983032227, 0.4101477861404419, 0.1664436012506485]
     Last 10:  [2.9624123573303223, 4.2360687255859375, 1.639979600906372, 0.8172942399978638, 1.2401576042175293, 0.24750040471553802, 0.4958897829055786, 7.6116156578063965, 1.4745073318481445, 0.38909026980400085]

================================================================================
379_layers.23.mlp.gate_proj: Linear (layers.23.mlp.gate_proj)
================================================================================

  → INPUT[0]: layers.23.mlp.gate_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012118, Std: 0.588893
     First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
     Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.mlp.gate_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.009133, Std: 0.127814
     First 10: [0.013385389000177383, -0.03814718499779701, -0.19594824314117432, -0.20470348000526428, 0.013659888878464699, 0.07857532054185867, 0.43904343247413635, -0.023601919412612915, -0.17886635661125183, -0.020931705832481384]
     Last 10:  [-0.5184257626533508, 0.09926365315914154, 0.26727116107940674, -0.714452862739563, -0.01524563878774643, 0.026633061468601227, -0.0894288420677185, 0.5458469390869141, -0.2703744173049927, -0.11396177858114243]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000005
     First 10: [-0.006619514897465706, 0.001599389361217618, -0.00041585485450923443, -0.008246047422289848, -0.0070463428273797035, 0.002556256949901581, -0.0077001722529530525, 0.007912381552159786, 0.0038331937976181507, -0.000668105436488986]
     Last 10:  [-0.00044777008588425815, -0.001339098671451211, 0.0044809686951339245, 0.005675017833709717, 0.002495822263881564, 0.003688738215714693, 0.005179557483643293, -0.0032151020132005215, -0.0024905449245125055, 0.0024532286915928125]

================================================================================
380_layers.23.mlp.act_fn: PytorchGELUTanh (layers.23.mlp.act_fn)
================================================================================

  → INPUT[0]: layers.23.mlp.act_fn_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.009133, Std: 0.127814
     First 10: [0.013385389000177383, -0.03814718499779701, -0.19594824314117432, -0.20470348000526428, 0.013659888878464699, 0.07857532054185867, 0.43904343247413635, -0.023601919412612915, -0.17886635661125183, -0.020931705832481384]
     Last 10:  [-0.5184257626533508, 0.09926365315914154, 0.26727116107940674, -0.714452862739563, -0.01524563878774643, 0.026633061468601227, -0.0894288420677185, 0.5458469390869141, -0.2703744173049927, -0.11396177858114243]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.23.mlp.act_fn_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.001662, Std: 0.060468
     First 10: [0.006764170713722706, -0.01849319040775299, -0.08275438100099564, -0.0857512354850769, 0.0069043817929923534, 0.04174821451306343, 0.29401013255119324, -0.011578749865293503, -0.07673780620098114, -0.010291074402630329]
     Last 10:  [-0.15662600100040436, 0.05355623736977577, 0.16179630160331726, -0.1697227656841278, -0.007530097384005785, 0.013599475845694542, -0.04152814298868179, 0.3861163854598999, -0.10637672245502472, -0.05181095749139786]
     Zeros: 0, Total: 8064

================================================================================
381_layers.23.mlp.up_proj: Linear (layers.23.mlp.up_proj)
================================================================================

  → INPUT[0]: layers.23.mlp.up_proj_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012118, Std: 0.588893
     First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
     Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.mlp.up_proj_output
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: -0.000164, Std: 0.145596
     First 10: [0.01934933476150036, 0.03202500566840172, -0.048482246696949005, 0.171466663479805, -0.08870480954647064, 0.2702706456184387, -0.08358319848775864, 0.31863975524902344, -0.25187334418296814, -0.0422697439789772]
     Last 10:  [-0.3087368607521057, -0.055336885154247284, 0.6487718820571899, 2.1040916442871094, 0.2937208116054535, -0.10384551435709, -0.6375556588172913, 0.04321000725030899, 0.029359988868236542, -0.07044504582881927]
     Zeros: 0, Total: 8064

  → PARAMETER: weight
     Shape: [1152, 768]
     Mean: 0.000002
     First 10: [-0.004209074191749096, 0.00025024794740602374, -0.009029907174408436, -0.0009208996780216694, 0.00035895133623853326, -0.0023924759589135647, 0.005625997204333544, -0.0007448712713085115, -0.010620685294270515, 0.0014794043963775039]
     Last 10:  [0.0010194458300247788, 0.008623381145298481, 0.0027566575445234776, -0.0027538458816707134, -0.001835700822994113, 0.006967035587877035, 0.00580932293087244, 0.00196055113337934, 0.011085523292422295, 0.003251994727179408]

================================================================================
382_layers.23.mlp.down_proj: Linear (layers.23.mlp.down_proj)
================================================================================

  → INPUT[0]: layers.23.mlp.down_proj_input_0
     Shape: [1, 7, 1152]
     Dtype: torch.float32
     Mean: 0.000295, Std: 0.028018
     First 10: [0.00013088221021462232, -0.0005922445561736822, 0.0040121180936694145, -0.014703478664159775, -0.0006124518695287406, 0.011283316649496555, -0.02457430772483349, -0.003689449978992343, 0.01932820864021778, 0.0004350010713096708]
     Last 10:  [0.04835622012615204, -0.0029636353719979525, 0.10496889054775238, -0.35711225867271423, -0.0022117462940514088, -0.001412244513630867, 0.026476502418518066, 0.016684092581272125, -0.003123219357803464, 0.003649825230240822]
     Zeros: 0, Total: 8064

  → OUTPUT[0]: layers.23.mlp.down_proj_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000003, Std: 0.007013
     First 10: [0.0012564724311232567, -0.00041205191519111395, -0.003087694989517331, -0.0004482174990698695, -0.0008019140223041177, -0.0013704855227842927, -0.002324463566765189, 0.0021277498453855515, -7.806951180100441e-05, 0.00023313546262215823]
     Last 10:  [0.01264757476747036, -0.0054664406925439835, -0.00577447609975934, 0.007187287788838148, -0.01551779080182314, -0.009138539433479309, -0.0025247656740248203, 0.005036311224102974, -0.015160895884037018, -0.007592188194394112]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768, 1152]
     Mean: -0.000004
     First 10: [0.0061723534017801285, -0.0022696133237332106, -0.0013929621782153845, -0.002562027657404542, -0.00018058264686260372, 0.005527716130018234, 0.0015264393296092749, -0.0025726202875375748, 0.013699417002499104, -0.002115969080477953]
     Last 10:  [-0.005424580071121454, -0.0012112949043512344, -0.005898043047636747, 0.0033184518106281757, 0.007405060343444347, -0.007318858057260513, 0.005879099015146494, -0.0011707213707268238, -0.004874801263213158, 0.006631152704358101]

================================================================================
383_layers.23.mlp: Gemma3MLP (layers.23.mlp)
================================================================================

  → INPUT[0]: layers.23.mlp_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 0.012118, Std: 0.588893
     First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
     Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.mlp_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000003, Std: 0.007013
     First 10: [0.0012564724311232567, -0.00041205191519111395, -0.003087694989517331, -0.0004482174990698695, -0.0008019140223041177, -0.0013704855227842927, -0.002324463566765189, 0.0021277498453855515, -7.806951180100441e-05, 0.00023313546262215823]
     Last 10:  [0.01264757476747036, -0.0054664406925439835, -0.00577447609975934, 0.007187287788838148, -0.01551779080182314, -0.009138539433479309, -0.0025247656740248203, 0.005036311224102974, -0.015160895884037018, -0.007592188194394112]
     Zeros: 0, Total: 5376

================================================================================
384_layers.23.post_feedforward_layernorm: Gemma3RMSNorm (layers.23.post_feedforward_layernorm)
================================================================================

  → INPUT[0]: layers.23.post_feedforward_layernorm_input_0
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: -0.000003, Std: 0.007013
     First 10: [0.0012564724311232567, -0.00041205191519111395, -0.003087694989517331, -0.0004482174990698695, -0.0008019140223041177, -0.0013704855227842927, -0.002324463566765189, 0.0021277498453855515, -7.806951180100441e-05, 0.00023313546262215823]
     Last 10:  [0.01264757476747036, -0.0054664406925439835, -0.00577447609975934, 0.007187287788838148, -0.01551779080182314, -0.009138539433479309, -0.0025247656740248203, 0.005036311224102974, -0.015160895884037018, -0.007592188194394112]
     Zeros: 0, Total: 5376

  → OUTPUT[0]: layers.23.post_feedforward_layernorm_output
     Shape: [1, 7, 768]
     Dtype: torch.float32
     Mean: 15.959156, Std: 765.469299
     First 10: [28.176244735717773, -33.85921859741211, -101.64606475830078, -18.55021095275879, -35.45656967163086, -84.20851135253906, -92.92117309570312, 75.3086929321289, -4.63818883895874, 18.471643447875977]
     Last 10:  [83.44525909423828, -19.312490463256836, -84.33599853515625, 122.01461791992188, -192.36846923828125, -196.8218536376953, -45.513999938964844, 63.81926345825195, -167.50921630859375, -159.90078735351562]
     Zeros: 0, Total: 5376

  → PARAMETER: weight
     Shape: [768]
     Mean: 282.086700
     First 10: [128.57861328125, 473.819091796875, 189.2213897705078, 238.14605712890625, 254.48892211914062, 354.04608154296875, 229.99102783203125, 203.51620483398438, 342.297119140625, 456.8259582519531]
     Last 10:  [114.558837890625, 60.878875732421875, 254.80508422851562, 296.341552734375, 216.12646484375, 376.22918701171875, 314.74224853515625, 220.94635009765625, 192.5185546875, 367.8861999511719]

Forward pass completed. Tracked 385 operations.

================================================================================
OPERATION SUMMARY (385 operations)
================================================================================

000_embed_tokens: embed_tokens (Gemma3TextScaledWordEmbedding)
  IN[0]:  [1, 7] | min=1 max=88108 | torch.int64
    First 10: [2, 88108, 564, 1461, 1070, 19406, 1]
    Last 10:  [2, 88108, 564, 1461, 1070, 19406, 1]
  OUT[0]: [1, 7, 768] | μ=-0.013574 σ=1.632227
    First 10: [-2.477302312850952, -1.2636504173278809, 0.3826928734779358, 0.06365708261728287, -0.820263147354126, -0.9725850224494934, 0.4710817039012909, -0.11057573556900024, 1.1160361766815186, 0.26941946148872375]
    Last 10:  [-2.1493282318115234, -0.6306940913200378, -1.1066092252731323, -2.5482146739959717, 1.7686560153961182, 1.0899485349655151, -0.6922177672386169, 5.721008777618408, 3.196016550064087, -1.2484151124954224]
  WEIGHT: [262144, 768] | μ=-0.000163

001_layers.0.input_layernorm: layers.0.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.013574 σ=1.632227
    First 10: [-2.477302312850952, -1.2636504173278809, 0.3826928734779358, 0.06365708261728287, -0.820263147354126, -0.9725850224494934, 0.4710817039012909, -0.11057573556900024, 1.1160361766815186, 0.26941946148872375]
    Last 10:  [-2.1493282318115234, -0.6306940913200378, -1.1066092252731323, -2.5482146739959717, 1.7686560153961182, 1.0899485349655151, -0.6922177672386169, 5.721008777618408, 3.196016550064087, -1.2484151124954224]
  OUT[0]: [1, 7, 768] | μ=-0.166489 σ=16.408581
    First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
    Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
  WEIGHT: [768] | μ=13.211769

002_layers.0.self_attn.q_proj: layers.0.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.166489 σ=16.408581
    First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
    Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
  OUT[0]: [1, 7, 768] | μ=0.187788 σ=7.018822
    First 10: [0.3887830376625061, 3.351538896560669, -3.1458942890167236, 0.48394227027893066, -5.401116371154785, 3.701035976409912, -4.790302276611328, 0.42496490478515625, -6.131454944610596, 2.385254144668579]
    Last 10:  [2.4578323364257812, -7.078050136566162, 1.9613218307495117, -0.4571880102157593, -0.6431244611740112, -2.448065757751465, -1.3958616256713867, 1.229301929473877, -0.23432433605194092, -0.2790461778640747]
  WEIGHT: [768, 768] | μ=0.000009

003_layers.0.self_attn.k_proj: layers.0.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.166489 σ=16.408581
    First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
    Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
  OUT[0]: [1, 7, 256] | μ=0.228117 σ=6.326502
    First 10: [0.9482555389404297, 0.5784203410148621, 0.15434527397155762, 0.14805006980895996, 0.32564619183540344, 0.821070671081543, -0.9551006555557251, 0.05978959798812866, -9.037637710571289, 0.3974881172180176]
    Last 10:  [3.4061479568481445, 18.547565460205078, -5.63254976272583, -0.6382596492767334, -2.370680809020996, 2.5257697105407715, -2.741736650466919, 3.1282882690429688, -1.7282251119613647, 2.643249034881592]
  WEIGHT: [256, 768] | μ=0.000009

004_layers.0.self_attn.v_proj: layers.0.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.166489 σ=16.408581
    First 10: [-30.318098068237305, -13.217909812927246, 3.8043212890625, 0.63350909948349, -7.917629718780518, -13.831581115722656, 4.474942684173584, -0.9933174848556519, 11.816372871398926, 2.664897918701172]
    Last 10:  [-13.23598861694336, -5.045870304107666, -7.587230682373047, -15.341130256652832, 12.761270523071289, 7.231410980224609, -4.46995735168457, 87.9295425415039, 21.287275314331055, -8.23403549194336]
  OUT[0]: [1, 7, 256] | μ=0.099511 σ=2.979395
    First 10: [-0.19047972559928894, 0.631655216217041, -2.821593761444092, -0.5566350221633911, -0.6524765491485596, 1.4340227842330933, 0.9365267157554626, 0.07686394453048706, -2.8396809101104736, -1.2724430561065674]
    Last 10:  [1.3050856590270996, 0.10212904214859009, -4.919314384460449, 2.1930313110351562, -0.542229175567627, -1.5569565296173096, 2.8126730918884277, -1.5750327110290527, 3.4985499382019043, -0.08559703826904297]
  WEIGHT: [256, 768] | μ=-0.000003

005_layers.0.self_attn.q_norm: layers.0.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.187788 σ=7.018822
    First 10: [0.3887830376625061, 3.351538896560669, -3.1458942890167236, 0.48394227027893066, -5.401116371154785, 3.701035976409912, -4.790302276611328, 0.42496490478515625, -6.131454944610596, 2.385254144668579]
    Last 10:  [2.4578323364257812, -7.078050136566162, 1.9613218307495117, -0.4571880102157593, -0.6431244611740112, -2.448065757751465, -1.3958616256713867, 1.229301929473877, -0.23432433605194092, -0.2790461778640747]
  OUT[0]: [1, 3, 7, 256] | μ=0.017637 σ=1.106099
    First 10: [0.1519453227519989, 1.6530735492706299, 0.4565025568008423, 0.0987328514456749, -1.367156982421875, 0.6147310137748718, -1.534438967704773, 0.1036820039153099, -1.1722685098648071, 0.7755711674690247]
    Last 10:  [0.8841097354888916, -3.1796979904174805, 0.7111338973045349, -0.09806857258081436, -0.17871248722076416, -0.9386019110679626, -0.5666730999946594, 0.382217139005661, -0.10534459352493286, -0.10174508392810822]
  WEIGHT: [256] | μ=0.449255

006_layers.0.self_attn.k_norm: layers.0.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.228117 σ=6.326502
    First 10: [0.9482555389404297, 0.5784203410148621, 0.15434527397155762, 0.14805006980895996, 0.32564619183540344, 0.821070671081543, -0.9551006555557251, 0.05978959798812866, -9.037637710571289, 0.3974881172180176]
    Last 10:  [3.4061479568481445, 18.547565460205078, -5.63254976272583, -0.6382596492767334, -2.370680809020996, 2.5257697105407715, -2.741736650466919, 3.1282882690429688, -1.7282251119613647, 2.643249034881592]
  OUT[0]: [1, 1, 7, 256] | μ=0.062646 σ=1.004581
    First 10: [0.2459360957145691, 0.11071343719959259, 0.018123731017112732, 0.020769385620951653, 0.07968343049287796, 0.07294320315122604, -0.20613667368888855, 0.009935260750353336, -0.04140132665634155, 0.07572239637374878]
    Last 10:  [0.7992237210273743, 5.201683044433594, -1.4005458354949951, -0.2580697536468506, -0.7257094979286194, 0.5870898365974426, -0.5776166319847107, 0.8694612979888916, -0.32367414236068726, 0.7755516767501831]
  WEIGHT: [256] | μ=0.437071

007_layers.0.self_attn.o_proj: layers.0.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.148220 σ=1.928052
    First 10: [-0.19047972559928894, 0.631655216217041, -2.821593761444092, -0.5566350221633911, -0.6524765491485596, 1.4340227842330933, 0.9365267157554626, 0.07686394453048706, -2.8396809101104736, -1.2724430561065674]
    Last 10:  [-2.088566541671753, -0.025558926165103912, -0.9876888990402222, 1.3683289289474487, -0.5881507396697998, 0.16551503539085388, 0.809123158454895, -0.6462826728820801, 2.007369041442871, -0.2429787814617157]
  OUT[0]: [1, 7, 768] | μ=-0.022564 σ=0.581956
    First 10: [-0.3779955506324768, -0.14444078505039215, 0.3628699779510498, -0.035884685814380646, -0.06462811678647995, -0.6456531882286072, -0.8867893815040588, -0.12370826303958893, 0.012052223086357117, 0.39969393610954285]
    Last 10:  [-0.3356463611125946, -0.028985433280467987, 0.8986057043075562, 1.1091954708099365, 0.5758756399154663, 0.5815268754959106, -1.0386407375335693, 0.07800734043121338, -0.16813135147094727, -0.5977584719657898]
  WEIGHT: [768, 768] | μ=-0.000001

008_layers.0.self_attn: layers.0.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.022564 σ=0.581956
    First 10: [-0.3779955506324768, -0.14444078505039215, 0.3628699779510498, -0.035884685814380646, -0.06462811678647995, -0.6456531882286072, -0.8867893815040588, -0.12370826303958893, 0.012052223086357117, 0.39969393610954285]
    Last 10:  [-0.3356463611125946, -0.028985433280467987, 0.8986057043075562, 1.1091954708099365, 0.5758756399154663, 0.5815268754959106, -1.0386407375335693, 0.07800734043121338, -0.16813135147094727, -0.5977584719657898]

009_layers.0.post_attention_layernorm: layers.0.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.022564 σ=0.581956
    First 10: [-0.3779955506324768, -0.14444078505039215, 0.3628699779510498, -0.035884685814380646, -0.06462811678647995, -0.6456531882286072, -0.8867893815040588, -0.12370826303958893, 0.012052223086357117, 0.39969393610954285]
    Last 10:  [-0.3356463611125946, -0.028985433280467987, 0.8986057043075562, 1.1091954708099365, 0.5758756399154663, 0.5815268754959106, -1.0386407375335693, 0.07800734043121338, -0.16813135147094727, -0.5977584719657898]
  OUT[0]: [1, 7, 768] | μ=-0.106367 σ=1.716240
    First 10: [-3.0801680088043213, -0.05903661996126175, 0.06795834004878998, -0.006062098778784275, -0.038303155452013016, -0.5212643146514893, -0.1841287463903427, -0.028685597702860832, 0.005756846629083157, 0.2436545342206955]
    Last 10:  [-0.08132490515708923, -0.00605315575376153, 0.13139201700687408, 0.0034704909194260836, 0.20731592178344727, 0.2177962213754654, -0.4465637505054474, 0.06332460790872574, -0.06968610733747482, -0.18223796784877777]
  WEIGHT: [768] | μ=-0.424272

010_layers.0.pre_feedforward_layernorm: layers.0.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.119942 σ=2.299109
    First 10: [-5.557470321655273, -1.322687029838562, 0.45065122842788696, 0.05759498476982117, -0.8585662841796875, -1.493849277496338, 0.2869529724121094, -0.13926133513450623, 1.1217930316925049, 0.5130739808082581]
    Last 10:  [-2.2306530475616455, -0.6367472410202026, -0.9752172231674194, -2.5447442531585693, 1.9759719371795654, 1.3077447414398193, -1.1387815475463867, 5.784333229064941, 3.1263303756713867, -1.4306530952453613]
  OUT[0]: [1, 7, 768] | μ=-0.178554 σ=4.892603
    First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
    Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
  WEIGHT: [768] | μ=4.554407

011_layers.0.mlp.gate_proj: layers.0.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.178554 σ=4.892603
    First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
    Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
  OUT[0]: [1, 7, 1152] | μ=-0.641182 σ=0.874306
    First 10: [-0.20775730907917023, 0.6305413246154785, -1.6627393960952759, -1.5643736124038696, -0.1845763921737671, -0.018746018409729004, 0.29749056696891785, -0.5662631392478943, -0.34384840726852417, -0.7666267156600952]
    Last 10:  [-0.5577700734138489, -1.3794704675674438, -0.034723371267318726, -0.1392453908920288, -0.854925274848938, -1.9765441417694092, -0.6656848788261414, -1.0517432689666748, -1.5457125902175903, 0.3487890362739563]
  WEIGHT: [1152, 768] | μ=0.000054

012_layers.0.mlp.act_fn: layers.0.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.641182 σ=0.874306
    First 10: [-0.20775730907917023, 0.6305413246154785, -1.6627393960952759, -1.5643736124038696, -0.1845763921737671, -0.018746018409729004, 0.29749056696891785, -0.5662631392478943, -0.34384840726852417, -0.7666267156600952]
    Last 10:  [-0.5577700734138489, -1.3794704675674438, -0.034723371267318726, -0.1392453908920288, -0.854925274848938, -1.9765441417694092, -0.6656848788261414, -1.0517432689666748, -1.5457125902175903, 0.3487890362739563]
  OUT[0]: [1, 7, 1152] | μ=-0.001562 σ=0.350151
    First 10: [-0.08678273856639862, 0.4639320373535156, -0.08026853948831558, -0.09228496253490448, -0.07877400517463684, -0.009232823736965656, 0.18353557586669922, -0.16175587475299835, -0.12567399442195892, -0.1699979305267334]
    Last 10:  [-0.16094255447387695, -0.11593639105558395, -0.01688077300786972, -0.06191253662109375, -0.16792051494121552, -0.04745147004723549, -0.1683361679315567, -0.1542075127363205, -0.09462754428386688, 0.2219565510749817]

013_layers.0.mlp.up_proj: layers.0.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.178554 σ=4.892603
    First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
    Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
  OUT[0]: [1, 7, 1152] | μ=-0.000245 σ=0.801804
    First 10: [-0.6215949654579163, -0.34889891743659973, 0.2935008704662323, -0.8074559569358826, 0.8279687762260437, 0.13126586377620697, -0.5818911194801331, -0.6940755844116211, -0.09826682507991791, 0.0732971802353859]
    Last 10:  [-0.43286415934562683, 0.47943422198295593, -0.3986634612083435, 0.926375687122345, -0.6728918552398682, 0.4082828760147095, -0.20388725399971008, -2.3840243816375732, -0.6635693311691284, -0.15048916637897491]
  WEIGHT: [1152, 768] | μ=0.000011

014_layers.0.mlp.down_proj: layers.0.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.001395 σ=0.744998
    First 10: [0.05394371226429939, -0.16186538338661194, -0.023558886721730232, 0.07451604306697845, -0.06522241979837418, -0.0012119546299800277, -0.1067977249622345, 0.11227080225944519, 0.012349584139883518, -0.012460368685424328]
    Last 10:  [0.06966626644134521, -0.05558387190103531, 0.0067297471687197685, -0.057354267686605453, 0.11299234628677368, -0.01937362179160118, 0.03432159870862961, 0.36763447523117065, 0.06279193609952927, -0.033402055501937866]
  OUT[0]: [1, 7, 768] | μ=-0.001042 σ=0.169039
    First 10: [-0.04582834243774414, -0.017291147261857986, -0.055749066174030304, -0.044060878455638885, 0.09626876562833786, 0.03131965175271034, -0.008971783332526684, 0.05209774896502495, -0.08086703717708588, -0.05818032845854759]
    Last 10:  [-0.10964630544185638, -0.07410191744565964, -0.2569091022014618, 0.3055190443992615, 0.3751865327358246, 0.41724711656570435, -0.6931462287902832, -0.25841009616851807, -0.44807684421539307, 0.22264385223388672]
  WEIGHT: [768, 1152] | μ=0.000000

015_layers.0.mlp: layers.0.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=-0.178554 σ=4.892603
    First 10: [-13.582653045654297, -3.7471764087677, 0.8863352537155151, 0.11444022506475449, -2.1995797157287598, -6.0359907150268555, 0.5376847386360168, -0.24647492170333862, 2.9889302253723145, 1.4126075506210327]
    Last 10:  [-3.3817355632781982, -1.2170051336288452, -1.5296337604522705, -5.592211723327637, 4.124910831451416, 2.755112886428833, -2.4754908084869385, 40.453468322753906, 6.582738876342773, -3.1498632431030273]
  OUT[0]: [1, 7, 768] | μ=-0.001042 σ=0.169039
    First 10: [-0.04582834243774414, -0.017291147261857986, -0.055749066174030304, -0.044060878455638885, 0.09626876562833786, 0.03131965175271034, -0.008971783332526684, 0.05209774896502495, -0.08086703717708588, -0.05818032845854759]
    Last 10:  [-0.10964630544185638, -0.07410191744565964, -0.2569091022014618, 0.3055190443992615, 0.3751865327358246, 0.41724711656570435, -0.6931462287902832, -0.25841009616851807, -0.44807684421539307, 0.22264385223388672]

016_layers.0.post_feedforward_layernorm: layers.0.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.001042 σ=0.169039
    First 10: [-0.04582834243774414, -0.017291147261857986, -0.055749066174030304, -0.044060878455638885, 0.09626876562833786, 0.03131965175271034, -0.008971783332526684, 0.05209774896502495, -0.08086703717708588, -0.05818032845854759]
    Last 10:  [-0.10964630544185638, -0.07410191744565964, -0.2569091022014618, 0.3055190443992615, 0.3751865327358246, 0.41724711656570435, -0.6931462287902832, -0.25841009616851807, -0.44807684421539307, 0.22264385223388672]
  OUT[0]: [1, 7, 768] | μ=-0.366480 σ=14.647358
    First 10: [-5.018401145935059, -0.09892900288105011, -0.2165645807981491, -0.12747548520565033, 0.7080104351043701, 0.24819548428058624, -0.03779777139425278, 0.19746749103069305, -0.46800848841667175, -0.4165009558200836]
    Last 10:  [-0.12543471157550812, -0.08793212473392487, -0.21500946581363678, 0.5422981381416321, 0.6047890782356262, 0.7310860753059387, -1.208717703819275, -1.027296543121338, -0.7602019906044006, 0.3011569380760193]
  WEIGHT: [768] | μ=0.256210

017_layers.1.input_layernorm: layers.1.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.486422 σ=15.329423
    First 10: [-10.575871467590332, -1.4216160774230957, 0.23408664762973785, -0.06988050043582916, -0.15055584907531738, -1.245653748512268, 0.249155193567276, 0.05820615589618683, 0.6537845134735107, 0.09657302498817444]
    Last 10:  [-2.3560876846313477, -0.7246793508529663, -1.190226674079895, -2.002446174621582, 2.580760955810547, 2.0388307571411133, -2.347499370574951, 4.7570366859436035, 2.366128444671631, -1.1294960975646973]
  OUT[0]: [1, 7, 768] | μ=-0.240247 σ=8.536188
    First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
    Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
  WEIGHT: [768] | μ=22.233313

018_layers.1.self_attn.q_proj: layers.1.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.240247 σ=8.536188
    First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
    Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
  OUT[0]: [1, 7, 768] | μ=0.227430 σ=3.527764
    First 10: [0.6124878525733948, 0.5231271982192993, -0.31129342317581177, 0.8081249594688416, 0.3285582363605499, 0.8916200995445251, 0.4114353060722351, 0.42764490842819214, 0.2689150869846344, 0.05157384276390076]
    Last 10:  [0.29172056913375854, 0.4805294871330261, -0.021477773785591125, 0.33477264642715454, -0.3854120969772339, -0.2016754150390625, 0.24495382606983185, 0.2473474144935608, 0.3586224913597107, 0.09955033659934998]
  WEIGHT: [768, 768] | μ=-0.000026

019_layers.1.self_attn.k_proj: layers.1.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.240247 σ=8.536188
    First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
    Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
  OUT[0]: [1, 7, 256] | μ=0.177580 σ=2.952570
    First 10: [-0.029512323439121246, 0.0036770999431610107, -0.022987838834524155, -0.07440949976444244, 0.0337701290845871, -0.13090761005878448, -0.05024230480194092, -0.02097412943840027, -0.03171498700976372, 0.03588118404150009]
    Last 10:  [0.4185788333415985, -0.1796785295009613, 0.4933841824531555, 1.1130009889602661, 0.5604655146598816, 0.1016218364238739, 0.12205003201961517, 0.5053402781486511, 0.5786342620849609, -0.15862073004245758]
  WEIGHT: [256, 768] | μ=-0.000025

020_layers.1.self_attn.v_proj: layers.1.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.240247 σ=8.536188
    First 10: [-0.8995006084442139, -1.1330710649490356, 0.20203420519828796, -0.06938213855028152, -0.09476179629564285, -0.9704149961471558, 0.21648553013801575, 0.050379183143377304, 0.5012192130088806, 0.0650838315486908]
    Last 10:  [-2.8999993801116943, -0.7886595726013184, -1.8072237968444824, -2.0880017280578613, 2.9290380477905273, 2.214716672897339, -2.6158199310302734, 4.374491214752197, 2.361835479736328, -1.3024003505706787]
  OUT[0]: [1, 7, 256] | μ=-0.021767 σ=1.959199
    First 10: [-0.00632987916469574, -0.13523229956626892, -0.05910938233137131, 0.06699798256158829, -0.06367265433073044, -0.018030205741524696, 0.2024754285812378, -0.005681876093149185, -0.03216393291950226, 0.30808958411216736]
    Last 10:  [0.024603724479675293, 0.07117131352424622, -0.1273249089717865, 0.1884080022573471, 0.24171674251556396, -1.0228400230407715, 0.45299115777015686, -0.27653610706329346, 0.24216628074645996, -0.010611675679683685]
  WEIGHT: [256, 768] | μ=0.000007

021_layers.1.self_attn.q_norm: layers.1.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.227430 σ=3.527764
    First 10: [0.6124878525733948, 0.5231271982192993, -0.31129342317581177, 0.8081249594688416, 0.3285582363605499, 0.8916200995445251, 0.4114353060722351, 0.42764490842819214, 0.2689150869846344, 0.05157384276390076]
    Last 10:  [0.29172056913375854, 0.4805294871330261, -0.021477773785591125, 0.33477264642715454, -0.3854120969772339, -0.2016754150390625, 0.24495382606983185, 0.2473474144935608, 0.3586224913597107, 0.09955033659934998]
  OUT[0]: [1, 3, 7, 256] | μ=0.165219 σ=1.677917
    First 10: [4.009385108947754, 2.043389081954956, -1.5297473669052124, 3.0244038105010986, 1.783223271369934, 2.8866612911224365, 1.9713298082351685, 1.7137842178344727, 1.295831561088562, 0.25581657886505127]
    Last 10:  [0.9689206480979919, 1.732717752456665, -0.08676992356777191, 1.0620428323745728, -1.5582120418548584, -0.7226658463478088, 0.9391295909881592, 0.9531855583190918, 1.277065396308899, 0.35076236724853516]
  WEIGHT: [256] | μ=1.303981

022_layers.1.self_attn.k_norm: layers.1.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.177580 σ=2.952570
    First 10: [-0.029512323439121246, 0.0036770999431610107, -0.022987838834524155, -0.07440949976444244, 0.0337701290845871, -0.13090761005878448, -0.05024230480194092, -0.02097412943840027, -0.03171498700976372, 0.03588118404150009]
    Last 10:  [0.4185788333415985, -0.1796785295009613, 0.4933841824531555, 1.1130009889602661, 0.5604655146598816, 0.1016218364238739, 0.12205003201961517, 0.5053402781486511, 0.5786342620849609, -0.15862073004245758]
  OUT[0]: [1, 1, 7, 256] | μ=0.156810 σ=1.957492
    First 10: [-0.028727121651172638, 0.006577483378350735, -0.0449017733335495, -0.1285410076379776, 0.06847850233316422, -0.16799931228160858, -0.1169901117682457, -0.033375561237335205, -0.07938093692064285, 0.07487687468528748]
    Last 10:  [0.7815216779708862, -0.29819104075431824, 0.7150827646255493, 2.049163341522217, 0.8346467018127441, 0.17153921723365784, 0.18646255135536194, 0.8000037670135498, 0.956226110458374, -0.27630114555358887]
  WEIGHT: [256] | μ=1.409485

023_layers.1.self_attn.o_proj: layers.1.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.027622 σ=0.815454
    First 10: [-0.00632987916469574, -0.13523229956626892, -0.05910938233137131, 0.06699798256158829, -0.06367265433073044, -0.018030205741524696, 0.2024754285812378, -0.005681876093149185, -0.03216393291950226, 0.30808958411216736]
    Last 10:  [0.04616662114858627, -0.007932167500257492, -0.03748765215277672, 0.035884931683540344, 0.038612913340330124, -0.6513183116912842, 0.10659945011138916, -0.09423140436410904, 0.4220597743988037, 0.03893042355775833]
  OUT[0]: [1, 7, 768] | μ=0.015939 σ=0.414087
    First 10: [-0.03845176845788956, -0.06503398716449738, 0.2212992012500763, 0.12925636768341064, -0.055878646671772, -0.13894006609916687, -0.16007213294506073, -0.280428022146225, -0.06990984082221985, 0.16293013095855713]
    Last 10:  [0.4090411365032196, -0.05258294194936752, 0.2331312894821167, -0.14305217564105988, -0.0436706505715847, -0.2093750536441803, -0.203327476978302, -0.1739659309387207, -0.05422750487923622, -0.5052568912506104]
  WEIGHT: [768, 768] | μ=-0.000012

024_layers.1.self_attn: layers.1.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.015939 σ=0.414087
    First 10: [-0.03845176845788956, -0.06503398716449738, 0.2212992012500763, 0.12925636768341064, -0.055878646671772, -0.13894006609916687, -0.16007213294506073, -0.280428022146225, -0.06990984082221985, 0.16293013095855713]
    Last 10:  [0.4090411365032196, -0.05258294194936752, 0.2331312894821167, -0.14305217564105988, -0.0436706505715847, -0.2093750536441803, -0.203327476978302, -0.1739659309387207, -0.05422750487923622, -0.5052568912506104]

025_layers.1.post_attention_layernorm: layers.1.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.015939 σ=0.414087
    First 10: [-0.03845176845788956, -0.06503398716449738, 0.2212992012500763, 0.12925636768341064, -0.055878646671772, -0.13894006609916687, -0.16007213294506073, -0.280428022146225, -0.06990984082221985, 0.16293013095855713]
    Last 10:  [0.4090411365032196, -0.05258294194936752, 0.2331312894821167, -0.14305217564105988, -0.0436706505715847, -0.2093750536441803, -0.203327476978302, -0.1739659309387207, -0.05422750487923622, -0.5052568912506104]
  OUT[0]: [1, 7, 768] | μ=-0.187307 σ=8.121754
    First 10: [-1.273963451385498, -0.15359070897102356, 0.3613540232181549, 0.20257557928562164, -0.14524546265602112, -0.27656200528144836, -0.21255281567573547, -0.45935818552970886, -0.15347011387348175, 0.4855777621269226]
    Last 10:  [0.3562525510787964, -0.041807252913713455, 0.1714819371700287, -0.26884692907333374, -0.04543168470263481, -0.3040570318698883, -0.2657511532306671, -0.546119213104248, -0.06792004406452179, -0.5033805966377258]
  WEIGHT: [768] | μ=0.720134

026_layers.1.pre_feedforward_layernorm: layers.1.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.673729 σ=19.897224
    First 10: [-11.849834442138672, -1.5752067565917969, 0.595440685749054, 0.13269507884979248, -0.2958013117313385, -1.522215723991394, 0.03660237789154053, -0.40115201473236084, 0.5003144145011902, 0.5821508169174194]
    Last 10:  [-1.9998351335525513, -0.7664865851402283, -1.018744707107544, -2.2712931632995605, 2.5353293418884277, 1.7347737550735474, -2.613250494003296, 4.2109174728393555, 2.298208475112915, -1.6328766345977783]
  OUT[0]: [1, 7, 768] | μ=-0.020971 σ=2.015995
    First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
    Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
  WEIGHT: [768] | μ=13.716516

027_layers.1.mlp.gate_proj: layers.1.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.020971 σ=2.015995
    First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
    Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
  OUT[0]: [1, 7, 1152] | μ=-0.120275 σ=0.335553
    First 10: [-0.07127414643764496, 0.01362256146967411, -0.048374563455581665, -0.0974014475941658, -0.11092638224363327, -0.05410915985703468, 0.06660674512386322, -0.054953113198280334, 0.20188869535923004, 0.04545402526855469]
    Last 10:  [-0.12045767903327942, -0.39974474906921387, 0.2644624710083008, -0.19441068172454834, -0.2604334056377411, -0.21609994769096375, 0.16585807502269745, -0.24325817823410034, -0.1319679468870163, -0.12777209281921387]
  WEIGHT: [1152, 768] | μ=0.000007

028_layers.1.mlp.act_fn: layers.1.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.120275 σ=0.335553
    First 10: [-0.07127414643764496, 0.01362256146967411, -0.048374563455581665, -0.0974014475941658, -0.11092638224363327, -0.05410915985703468, 0.06660674512386322, -0.054953113198280334, 0.20188869535923004, 0.04545402526855469]
    Last 10:  [-0.12045767903327942, -0.39974474906921387, 0.2644624710083008, -0.19441068172454834, -0.2604334056377411, -0.21609994769096375, 0.16585807502269745, -0.24325817823410034, -0.1319679468870163, -0.12777209281921387]
  OUT[0]: [1, 7, 1152] | μ=-0.013192 σ=0.154458
    First 10: [-0.03361216560006142, 0.006885312031954527, -0.02325408346951008, -0.04492194950580597, -0.05056443810462952, -0.025887129828333855, 0.03507194668054581, -0.026272421702742577, 0.11709453910589218, 0.023550970479846]
    Last 10:  [-0.05445420369505882, -0.13778842985630035, 0.15981002151966095, -0.08222201466560364, -0.10346245020627975, -0.08956438302993774, 0.09385314583778381, -0.09825374186038971, -0.05905639007687569, -0.05739079788327217]

029_layers.1.mlp.up_proj: layers.1.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.020971 σ=2.015995
    First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
    Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
  OUT[0]: [1, 7, 1152] | μ=-0.004129 σ=0.317843
    First 10: [0.13341844081878662, -0.004517419263720512, 0.03417050465941429, 0.0684620663523674, 0.06160465627908707, -0.015334632247686386, 0.027129750698804855, -0.01175076887011528, 0.029869310557842255, 0.1294068843126297]
    Last 10:  [0.8832411766052246, 0.21826523542404175, 0.07913633435964584, -0.1096477210521698, 0.1508164405822754, 0.3041124641895294, 0.21505028009414673, -0.056547652930021286, 0.07689377665519714, 0.2263047993183136]
  WEIGHT: [1152, 768] | μ=0.000000

030_layers.1.mlp.down_proj: layers.1.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000062 σ=0.081873
    First 10: [-0.004484482575207949, -3.110384204774164e-05, -0.0007946037803776562, -0.0030754494946449995, -0.0031150048598647118, 0.0003969696117565036, 0.0009514931589365005, 0.0003087211516685784, 0.003497533267363906, 0.0030476576648652554]
    Last 10:  [-0.0480961948633194, -0.03007442317903042, 0.012646779417991638, 0.009015456773340702, -0.015603838488459587, -0.02723764441907406, 0.020183145999908447, 0.005556018557399511, -0.0045410688035190105, -0.012987812981009483]
  OUT[0]: [1, 7, 768] | μ=-0.000136 σ=0.026268
    First 10: [0.002910963026806712, 0.0003085295029450208, 0.0006314038764685392, -0.0020582801662385464, -0.002385294297710061, 0.004201765637844801, 0.0012363921850919724, -0.0008050656761042774, -0.0007019420154392719, 0.0021230403799563646]
    Last 10:  [0.005400285590440035, -0.0010172133333981037, 0.0052062030881643295, -0.00724160997197032, 0.0010461467318236828, -0.0027242195792496204, -0.009691147133708, -0.0179337989538908, -0.0040361955761909485, 0.0022561131045222282]
  WEIGHT: [768, 1152] | μ=-0.000001

031_layers.1.mlp: layers.1.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=-0.020971 σ=2.015995
    First 10: [-0.7466881275177002, -0.6794275641441345, 0.16748155653476715, 0.03856533020734787, -0.11932671815156937, -0.7656273245811462, 0.009348885156214237, -0.11248935014009476, 0.22293013334274292, 0.2472446709871292]
    Last 10:  [-0.9212725162506104, -0.39411190152168274, -0.4617830216884613, -1.415812611579895, 1.6921372413635254, 1.1308547258377075, -1.628305435180664, 3.2818429470062256, 1.4289218187332153, -1.1005653142929077]
  OUT[0]: [1, 7, 768] | μ=-0.000136 σ=0.026268
    First 10: [0.002910963026806712, 0.0003085295029450208, 0.0006314038764685392, -0.0020582801662385464, -0.002385294297710061, 0.004201765637844801, 0.0012363921850919724, -0.0008050656761042774, -0.0007019420154392719, 0.0021230403799563646]
    Last 10:  [0.005400285590440035, -0.0010172133333981037, 0.0052062030881643295, -0.00724160997197032, 0.0010461467318236828, -0.0027242195792496204, -0.009691147133708, -0.0179337989538908, -0.0040361955761909485, 0.0022561131045222282]

032_layers.1.post_feedforward_layernorm: layers.1.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000136 σ=0.026268
    First 10: [0.002910963026806712, 0.0003085295029450208, 0.0006314038764685392, -0.0020582801662385464, -0.002385294297710061, 0.004201765637844801, 0.0012363921850919724, -0.0008050656761042774, -0.0007019420154392719, 0.0021230403799563646]
    Last 10:  [0.005400285590440035, -0.0010172133333981037, 0.0052062030881643295, -0.00724160997197032, 0.0010461467318236828, -0.0027242195792496204, -0.009691147133708, -0.0179337989538908, -0.0040361955761909485, 0.0022561131045222282]
  OUT[0]: [1, 7, 768] | μ=0.031468 σ=4.030575
    First 10: [11.874693870544434, 0.09452100843191147, 0.11465039104223251, -0.3292507231235504, -0.9207574129104614, 1.1562845706939697, 0.21611712872982025, -0.1344224363565445, -0.22409769892692566, 0.7729232907295227]
    Last 10:  [0.27437031269073486, -0.06021535396575928, 0.18261933326721191, -0.7792431712150574, 0.07369881868362427, -0.20097064971923828, -0.7667845487594604, -1.6380910873413086, -0.33648356795310974, 0.14867855608463287]
  WEIGHT: [768] | μ=0.708472

033_layers.2.input_layernorm: layers.2.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.642261 σ=20.243124
    First 10: [0.02485942840576172, -1.4806857109069824, 0.7100910544395447, -0.19655564427375793, -1.2165586948394775, -0.3659311532974243, 0.252719521522522, -0.5355744361877441, 0.2762167155742645, 1.355074167251587]
    Last 10:  [-1.7254648208618164, -0.8267019391059875, -0.836125373840332, -3.0505363941192627, 2.6090281009674072, 1.533803105354309, -3.380034923553467, 2.572826385498047, 1.961724877357483, -1.4841980934143066]
  OUT[0]: [1, 7, 768] | μ=-0.026103 σ=4.754027
    First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
    Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
  WEIGHT: [768] | μ=26.423407

034_layers.2.self_attn.q_proj: layers.2.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.026103 σ=4.754027
    First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
    Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
  OUT[0]: [1, 7, 768] | μ=0.046460 σ=1.801459
    First 10: [-0.36334437131881714, 0.017857879400253296, -0.021441936492919922, -0.5530362725257874, -0.38796016573905945, 1.274657130241394, 0.29073214530944824, -0.487531453371048, 0.5537347793579102, 0.33335721492767334]
    Last 10:  [0.29533475637435913, 0.41967833042144775, 1.1354382038116455, 0.3936917185783386, -0.5400428771972656, -0.6574865579605103, 0.26659446954727173, -0.022056810557842255, 0.2536875605583191, -1.0901076793670654]
  WEIGHT: [768, 768] | μ=-0.000003

035_layers.2.self_attn.k_proj: layers.2.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.026103 σ=4.754027
    First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
    Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
  OUT[0]: [1, 7, 256] | μ=0.094431 σ=1.859646
    First 10: [-1.0551759004592896, -1.948734164237976, -0.4912123382091522, -1.1269705295562744, -1.3528980016708374, 0.7888169288635254, -0.11417031288146973, -1.213828206062317, 0.6067166924476624, 1.5700477361679077]
    Last 10:  [3.677457571029663, 2.713850975036621, 7.206689834594727, 2.639547348022461, -3.0033864974975586, -2.7033843994140625, 3.2159948348999023, 3.167816162109375, 0.792203426361084, 0.20938019454479218]
  WEIGHT: [256, 768] | μ=-0.000009

036_layers.2.self_attn.v_proj: layers.2.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.026103 σ=4.754027
    First 10: [0.002700293902307749, -1.132821798324585, 0.6278751492500305, -0.17412054538726807, -0.7262515425682068, -0.3081706166267395, 0.21050363779067993, -0.41721901297569275, 0.22126582264900208, 0.933429479598999]
    Last 10:  [-2.0468599796295166, -1.075150728225708, -1.0829135179519653, -2.457232713699341, 2.9285342693328857, 1.5251924991607666, -3.4243860244750977, 1.9569770097732544, 1.955761432647705, -1.7268152236938477]
  OUT[0]: [1, 7, 256] | μ=0.005879 σ=0.904993
    First 10: [0.09928067028522491, -0.016716446727514267, -0.20497094094753265, -0.10366927832365036, 0.025770358741283417, -0.10563710331916809, -0.20119136571884155, 0.04089313745498657, 0.19365032017230988, 0.17264938354492188]
    Last 10:  [-1.121331810951233, -0.38518744707107544, -0.4193658232688904, 0.18737810850143433, -0.3953475058078766, 0.10543012619018555, 0.08753445744514465, 0.27651330828666687, -0.23474937677383423, 1.9442005157470703]
  WEIGHT: [256, 768] | μ=0.000033

037_layers.2.self_attn.q_norm: layers.2.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.046460 σ=1.801459
    First 10: [-0.36334437131881714, 0.017857879400253296, -0.021441936492919922, -0.5530362725257874, -0.38796016573905945, 1.274657130241394, 0.29073214530944824, -0.487531453371048, 0.5537347793579102, 0.33335721492767334]
    Last 10:  [0.29533475637435913, 0.41967833042144775, 1.1354382038116455, 0.3936917185783386, -0.5400428771972656, -0.6574865579605103, 0.26659446954727173, -0.022056810557842255, 0.2536875605583191, -1.0901076793670654]
  OUT[0]: [1, 3, 7, 256] | μ=0.042880 σ=1.479561
    First 10: [-1.9673094749450684, 0.020288221538066864, -0.14283299446105957, -2.768562078475952, -2.0828802585601807, 4.021634578704834, 1.2630131244659424, -1.4972803592681885, 2.1579360961914062, 1.621669888496399]
    Last 10:  [0.5908542275428772, 0.4938216507434845, 1.5157097578048706, 0.5722675323486328, -0.9914202094078064, -0.8356114625930786, 0.41073930263519287, -0.040680814534425735, 0.4229012131690979, -1.8225127458572388]
  WEIGHT: [256] | μ=0.639680

038_layers.2.self_attn.k_norm: layers.2.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.094431 σ=1.859646
    First 10: [-1.0551759004592896, -1.948734164237976, -0.4912123382091522, -1.1269705295562744, -1.3528980016708374, 0.7888169288635254, -0.11417031288146973, -1.213828206062317, 0.6067166924476624, 1.5700477361679077]
    Last 10:  [3.677457571029663, 2.713850975036621, 7.206689834594727, 2.639547348022461, -3.0033864974975586, -2.7033843994140625, 3.2159948348999023, 3.167816162109375, 0.792203426361084, 0.20938019454479218]
  OUT[0]: [1, 1, 7, 256] | μ=0.088166 σ=3.102985
    First 10: [-2.8802244663238525, -3.157100200653076, -0.8592400550842285, -1.6301077604293823, -1.8473399877548218, 1.1344377994537354, -0.23634913563728333, -2.120568037033081, 0.6022592782974243, 1.115332007408142]
    Last 10:  [4.155835151672363, 5.0257954597473145, 10.735418319702148, 3.897294044494629, -3.4731411933898926, -4.453522682189941, 4.465592384338379, 3.75076961517334, 1.0371109247207642, 0.3067752718925476]
  WEIGHT: [256] | μ=1.011649

039_layers.2.self_attn.o_proj: layers.2.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.001366 σ=0.682374
    First 10: [0.09928067028522491, -0.016716446727514267, -0.20497094094753265, -0.10366927832365036, 0.025770358741283417, -0.10563710331916809, -0.20119136571884155, 0.04089313745498657, 0.19365032017230988, 0.17264938354492188]
    Last 10:  [-0.0854857861995697, -1.1065808534622192, -0.4098498523235321, 0.1805793046951294, 0.2039640247821808, -0.6879286170005798, -0.4501395523548126, 0.09166073054075241, 0.05141796916723251, -4.75787878036499]
  OUT[0]: [1, 7, 768] | μ=-0.005249 σ=0.274977
    First 10: [0.02823609486222267, 0.03672467917203903, -0.00804198533296585, 0.09384729713201523, -0.05652657896280289, -0.07385166734457016, -0.011170231737196445, -0.04899873211979866, -0.02543088234961033, -0.004873378202319145]
    Last 10:  [-0.21234281361103058, 0.04082677513360977, 0.5334573984146118, -0.12419344484806061, -0.00542566180229187, -0.3276468515396118, 0.2406778484582901, -0.42357438802719116, -0.06206699460744858, -0.11366133391857147]
  WEIGHT: [768, 768] | μ=-0.000006

040_layers.2.self_attn: layers.2.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.005249 σ=0.274977
    First 10: [0.02823609486222267, 0.03672467917203903, -0.00804198533296585, 0.09384729713201523, -0.05652657896280289, -0.07385166734457016, -0.011170231737196445, -0.04899873211979866, -0.02543088234961033, -0.004873378202319145]
    Last 10:  [-0.21234281361103058, 0.04082677513360977, 0.5334573984146118, -0.12419344484806061, -0.00542566180229187, -0.3276468515396118, 0.2406778484582901, -0.42357438802719116, -0.06206699460744858, -0.11366133391857147]

041_layers.2.post_attention_layernorm: layers.2.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.005249 σ=0.274977
    First 10: [0.02823609486222267, 0.03672467917203903, -0.00804198533296585, 0.09384729713201523, -0.05652657896280289, -0.07385166734457016, -0.011170231737196445, -0.04899873211979866, -0.02543088234961033, -0.004873378202319145]
    Last 10:  [-0.21234281361103058, 0.04082677513360977, 0.5334573984146118, -0.12419344484806061, -0.00542566180229187, -0.3276468515396118, 0.2406778484582901, -0.42357438802719116, -0.06206699460744858, -0.11366133391857147]
  OUT[0]: [1, 7, 768] | μ=-0.012212 σ=9.402136
    First 10: [2.6012983322143555, 0.15047016739845276, -0.018052563071250916, 0.16019277274608612, -0.21596364676952362, -0.2862200438976288, -0.024880945682525635, -0.10637471079826355, -0.12475689500570297, -0.02494468353688717]
    Last 10:  [-0.2245132476091385, 0.041580505669116974, 0.34282591938972473, -0.5356549620628357, -0.010441051796078682, -0.45830848813056946, 0.33245083689689636, -2.0652337074279785, -0.10623007267713547, -0.23491325974464417]
  WEIGHT: [768] | μ=0.918192

042_layers.2.pre_feedforward_layernorm: layers.2.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.654473 σ=17.171438
    First 10: [2.626157760620117, -1.330215573310852, 0.6920384764671326, -0.036362871527671814, -1.4325222969055176, -0.6521512269973755, 0.22783857583999634, -0.6419491767883301, 0.15145981311798096, 1.3301295042037964]
    Last 10:  [-1.9499781131744385, -0.7851214408874512, -0.4932994544506073, -3.586191415786743, 2.5985870361328125, 1.075494647026062, -3.047584056854248, 0.5075926780700684, 1.8554948568344116, -1.7191113233566284]
  OUT[0]: [1, 7, 768] | μ=-0.052867 σ=3.134514
    First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
    Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
  WEIGHT: [768] | μ=23.098120

043_layers.2.mlp.gate_proj: layers.2.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.052867 σ=3.134514
    First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
    Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
  OUT[0]: [1, 7, 1152] | μ=-0.390194 σ=0.568921
    First 10: [-0.032689712941646576, -0.049942102283239365, 0.06258758902549744, -0.15238383412361145, -0.018055252730846405, 0.099705271422863, -0.2726435661315918, 0.20162516832351685, -0.1838446855545044, -0.0074073150753974915]
    Last 10:  [-0.8337905406951904, -0.314787358045578, -0.28080546855926514, -0.2970106899738312, -0.0792415589094162, -0.6461949944496155, -0.11522801220417023, -0.9790428876876831, -0.3196631073951721, -0.6443208456039429]
  WEIGHT: [1152, 768] | μ=0.000061

044_layers.2.mlp.act_fn: layers.2.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.390194 σ=0.568921
    First 10: [-0.032689712941646576, -0.049942102283239365, 0.06258758902549744, -0.15238383412361145, -0.018055252730846405, 0.099705271422863, -0.2726435661315918, 0.20162516832351685, -0.1838446855545044, -0.0074073150753974915]
    Last 10:  [-0.8337905406951904, -0.314787358045578, -0.28080546855926514, -0.2970106899738312, -0.0792415589094162, -0.6461949944496155, -0.11522801220417023, -0.9790428876876831, -0.3196631073951721, -0.6443208456039429]
  OUT[0]: [1, 7, 1152] | μ=-0.042223 σ=0.206244
    First 10: [-0.015918616205453873, -0.023976419121026993, 0.03285551071166992, -0.0669640451669693, -0.00889758113771677, 0.05381198227405548, -0.10703166574239731, 0.11692092567682266, -0.0785144791007042, -0.003681768663227558]
    Last 10:  [-0.1686868965625763, -0.11850835382938385, -0.10935595631599426, -0.11382556706666946, -0.03711836412549019, -0.16745640337467194, -0.05232881009578705, -0.160492405295372, -0.11975278705358505, -0.16736163198947906]

045_layers.2.mlp.up_proj: layers.2.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.052867 σ=3.134514
    First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
    Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
  OUT[0]: [1, 7, 1152] | μ=-0.001235 σ=0.535849
    First 10: [-0.010250693187117577, -0.3237747848033905, 0.02593904733657837, -0.035400088876485825, 0.151950865983963, -0.20820970833301544, 0.16876435279846191, -0.29318922758102417, 0.2106885313987732, 0.12538564205169678]
    Last 10:  [-0.029880091547966003, -0.2194540798664093, 0.08097942173480988, -0.2075425386428833, 0.23828892409801483, -0.04915416240692139, -0.2174989879131317, 0.0808962732553482, -1.2447271347045898, 0.1727088987827301]
  WEIGHT: [1152, 768] | μ=0.000012

046_layers.2.mlp.down_proj: layers.2.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.001651 σ=0.166671
    First 10: [0.00016317685367539525, 0.007762960158288479, 0.0008522406569682062, 0.0023705330677330494, -0.0013519951608031988, -0.011204177513718605, -0.018063129857182503, -0.0342799574136734, -0.01654209941625595, -0.0004616409132722765]
    Last 10:  [0.005040379706770182, 0.026007141917943954, -0.00885558221489191, 0.023623647168278694, -0.008844895288348198, 0.008231178857386112, 0.011381463147699833, -0.012983237393200397, 0.14905954897403717, -0.02890484407544136]
  OUT[0]: [1, 7, 768] | μ=0.001058 σ=0.078724
    First 10: [0.012004838325083256, -0.006629047449678183, -0.006676972843706608, 0.002998131327331066, -0.0020404274109750986, 0.005859403870999813, -0.0017380919307470322, -0.003668359015136957, -0.004967392422258854, -0.001908790203742683]
    Last 10:  [0.010193292051553726, 0.01077516470104456, 0.014597687870264053, 0.030868591740727425, 0.005632299464195967, -0.03513884171843529, 0.025990480557084084, -0.02402442879974842, 0.017063895240426064, 0.003353796899318695]
  WEIGHT: [768, 1152] | μ=-0.000001

047_layers.2.mlp: layers.2.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=-0.052867 σ=3.134514
    First 10: [0.1942491978406906, -1.3864109516143799, 0.5397331714630127, -0.0270340908318758, -1.2036945819854736, -0.7250807881355286, 0.15017583966255188, -0.4614020884037018, 0.1490674614906311, 1.2182656526565552]
    Last 10:  [-2.0410070419311523, -0.8848969340324402, -0.4963706433773041, -4.031074523925781, 3.470853328704834, 1.434057593345642, -4.057227611541748, 0.5243053436279297, 2.223024606704712, -2.466458320617676]
  OUT[0]: [1, 7, 768] | μ=0.001058 σ=0.078724
    First 10: [0.012004838325083256, -0.006629047449678183, -0.006676972843706608, 0.002998131327331066, -0.0020404274109750986, 0.005859403870999813, -0.0017380919307470322, -0.003668359015136957, -0.004967392422258854, -0.001908790203742683]
    Last 10:  [0.010193292051553726, 0.01077516470104456, 0.014597687870264053, 0.030868591740727425, 0.005632299464195967, -0.03513884171843529, 0.025990480557084084, -0.02402442879974842, 0.017063895240426064, 0.003353796899318695]

048_layers.2.post_feedforward_layernorm: layers.2.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.001058 σ=0.078724
    First 10: [0.012004838325083256, -0.006629047449678183, -0.006676972843706608, 0.002998131327331066, -0.0020404274109750986, 0.005859403870999813, -0.0017380919307470322, -0.003668359015136957, -0.004967392422258854, -0.001908790203742683]
    Last 10:  [0.010193292051553726, 0.01077516470104456, 0.014597687870264053, 0.030868591740727425, 0.005632299464195967, -0.03513884171843529, 0.025990480557084084, -0.02402442879974842, 0.017063895240426064, 0.003353796899318695]
  OUT[0]: [1, 7, 768] | μ=-0.156588 σ=7.204574
    First 10: [12.67269515991211, -0.6051055192947388, -0.32405057549476624, 0.10981320589780807, -0.22105488181114197, 0.49228745698928833, -0.09195002913475037, -0.18093745410442352, -0.4969541132450104, -0.21979975700378418]
    Last 10:  [0.3182140290737152, 0.3240564465522766, 0.3106733560562134, 2.793078660964966, 0.2573801577091217, -1.5145682096481323, 1.424516201019287, -1.6110018491744995, 0.8563956022262573, 0.16673821210861206]
  WEIGHT: [768] | μ=1.490947

049_layers.3.input_layernorm: layers.3.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.811061 σ=21.139889
    First 10: [15.298852920532227, -1.9353210926055908, 0.36798790097236633, 0.07345033437013626, -1.653577208518982, -0.15986377000808716, 0.13588854670524597, -0.8228866457939148, -0.3454943001270294, 1.1103297472000122]
    Last 10:  [-1.6317640542984009, -0.46106499433517456, -0.18262609839439392, -0.7931127548217773, 2.8559672832489014, -0.4390735626220703, -1.623067855834961, -1.1034091711044312, 2.711890459060669, -1.5523731708526611]
  OUT[0]: [1, 7, 768] | μ=-0.059826 σ=4.460990
    First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
    Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
  WEIGHT: [768] | μ=30.287369

050_layers.3.self_attn.q_proj: layers.3.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.059826 σ=4.460990
    First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
    Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
  OUT[0]: [1, 7, 768] | μ=-0.075081 σ=1.795474
    First 10: [5.27870512008667, 0.9697731137275696, -0.023747868835926056, -0.33054471015930176, 0.19091086089611053, 0.19677618145942688, 0.6259857416152954, 0.8535281419754028, -0.09705960005521774, 0.34126782417297363]
    Last 10:  [0.39680060744285583, -0.5330816507339478, 0.5797348618507385, -0.12298648059368134, 0.25590670108795166, -0.6416741609573364, -0.5962934494018555, -0.445017546415329, -1.0649075508117676, 0.4235389828681946]
  WEIGHT: [768, 768] | μ=0.000012

051_layers.3.self_attn.k_proj: layers.3.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.059826 σ=4.460990
    First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
    Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
  OUT[0]: [1, 7, 256] | μ=-0.069509 σ=1.955774
    First 10: [1.3439936637878418, -0.32221704721450806, 0.05881437659263611, -0.16233588755130768, -0.3924422264099121, 2.4740941524505615, 0.6671534776687622, 0.4409787356853485, 0.008452504873275757, 0.5024046897888184]
    Last 10:  [0.2524745464324951, -0.8102883696556091, 0.698316216468811, 0.09909147024154663, -1.4675397872924805, 1.4179701805114746, -0.3621646463871002, 0.6354324221611023, -0.4580196142196655, 1.356261968612671]
  WEIGHT: [256, 768] | μ=0.000001

052_layers.3.self_attn.v_proj: layers.3.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.059826 σ=4.460990
    First 10: [2.550663471221924, -2.321545362472534, 0.4334876537322998, 0.0792025551199913, -1.52183198928833, -0.1884797215461731, 0.13804568350315094, -0.8314339518547058, -0.384589284658432, 1.1203356981277466]
    Last 10:  [-1.7164626121520996, -0.5725439786911011, -0.1931837499141693, -0.6284022927284241, 3.0878732204437256, -0.49686697125434875, -1.7737966775894165, -0.7682948112487793, 2.774280548095703, -2.0288033485412598]
  OUT[0]: [1, 7, 256] | μ=0.030189 σ=0.942193
    First 10: [0.6075347661972046, -0.42021098732948303, 0.4340025782585144, 0.023828014731407166, 0.07199177145957947, 0.17016369104385376, 0.503790557384491, -0.2691144645214081, -0.2737869620323181, 0.48845216631889343]
    Last 10:  [0.7529522180557251, -0.06331443786621094, -0.14544378221035004, -0.15088340640068054, -0.5530520677566528, -0.37817004323005676, -0.07560047507286072, 0.40298786759376526, -0.2962351441383362, -0.4666005074977875]
  WEIGHT: [256, 768] | μ=0.000004

053_layers.3.self_attn.q_norm: layers.3.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.075081 σ=1.795474
    First 10: [5.27870512008667, 0.9697731137275696, -0.023747868835926056, -0.33054471015930176, 0.19091086089611053, 0.19677618145942688, 0.6259857416152954, 0.8535281419754028, -0.09705960005521774, 0.34126782417297363]
    Last 10:  [0.39680060744285583, -0.5330816507339478, 0.5797348618507385, -0.12298648059368134, 0.25590670108795166, -0.6416741609573364, -0.5962934494018555, -0.445017546415329, -1.0649075508117676, 0.4235389828681946]
  OUT[0]: [1, 3, 7, 256] | μ=0.030101 σ=1.334758
    First 10: [14.881897926330566, 1.8810877799987793, -0.04842377454042435, -0.7044716477394104, 0.37411898374557495, 0.14404939115047455, 0.9528961181640625, 2.0417819023132324, -0.21162833273410797, 0.5745779871940613]
    Last 10:  [0.41022682189941406, -0.31897205114364624, 0.4335772693157196, -0.12138792127370834, 0.2090539187192917, -0.6446216106414795, -0.5271077752113342, -0.5089263916015625, -0.7899011373519897, 0.44846752285957336]
  WEIGHT: [256] | μ=0.262050

054_layers.3.self_attn.k_norm: layers.3.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.069509 σ=1.955774
    First 10: [1.3439936637878418, -0.32221704721450806, 0.05881437659263611, -0.16233588755130768, -0.3924422264099121, 2.4740941524505615, 0.6671534776687622, 0.4409787356853485, 0.008452504873275757, 0.5024046897888184]
    Last 10:  [0.2524745464324951, -0.8102883696556091, 0.698316216468811, 0.09909147024154663, -1.4675397872924805, 1.4179701805114746, -0.3621646463871002, 0.6354324221611023, -0.4580196142196655, 1.356261968612671]
  OUT[0]: [1, 1, 7, 256] | μ=-0.093442 σ=1.536873
    First 10: [1.2437915802001953, -0.42851004004478455, 0.0775265321135521, -0.1494944840669632, -0.47322511672973633, 1.7534525394439697, 0.42483702301979065, 0.4671519994735718, 0.010844283737242222, 0.019883062690496445]
    Last 10:  [0.20633482933044434, -0.900826096534729, 0.7094592452049255, 0.0872325599193573, -1.3293918371200562, 1.133787989616394, -0.34825578331947327, 0.5455424189567566, -0.4419648051261902, 1.0593016147613525]
  WEIGHT: [256] | μ=0.535987

055_layers.3.self_attn.o_proj: layers.3.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.023787 σ=0.711618
    First 10: [0.6075347661972046, -0.42021098732948303, 0.4340025782585144, 0.023828014731407166, 0.07199177145957947, 0.17016369104385376, 0.503790557384491, -0.2691144645214081, -0.2737869620323181, 0.48845216631889343]
    Last 10:  [-0.3799763321876526, -0.2270483374595642, -0.21431121230125427, 0.01856204867362976, 0.5147045850753784, 0.07324805855751038, 0.2661823034286499, 0.14580003917217255, 0.06988730281591415, 0.1202896311879158]
  OUT[0]: [1, 7, 768] | μ=-0.005366 σ=0.325539
    First 10: [0.07736073434352875, -0.13666430115699768, 0.022870009765028954, -1.4198710918426514, -0.25494304299354553, -0.01596187800168991, -0.005810592323541641, -0.05218188464641571, -0.09109882265329361, 0.12817645072937012]
    Last 10:  [0.3095112442970276, -0.15470106899738312, -0.13348500430583954, 0.27271005511283875, 0.2615244388580322, 0.1882404386997223, -0.20827709138393402, -0.2415952980518341, 0.053962528705596924, 0.029189620167016983]
  WEIGHT: [768, 768] | μ=0.000000

056_layers.3.self_attn: layers.3.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.005366 σ=0.325539
    First 10: [0.07736073434352875, -0.13666430115699768, 0.022870009765028954, -1.4198710918426514, -0.25494304299354553, -0.01596187800168991, -0.005810592323541641, -0.05218188464641571, -0.09109882265329361, 0.12817645072937012]
    Last 10:  [0.3095112442970276, -0.15470106899738312, -0.13348500430583954, 0.27271005511283875, 0.2615244388580322, 0.1882404386997223, -0.20827709138393402, -0.2415952980518341, 0.053962528705596924, 0.029189620167016983]

057_layers.3.post_attention_layernorm: layers.3.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.005366 σ=0.325539
    First 10: [0.07736073434352875, -0.13666430115699768, 0.022870009765028954, -1.4198710918426514, -0.25494304299354553, -0.01596187800168991, -0.005810592323541641, -0.05218188464641571, -0.09109882265329361, 0.12817645072937012]
    Last 10:  [0.3095112442970276, -0.15470106899738312, -0.13348500430583954, 0.27271005511283875, 0.2615244388580322, 0.1882404386997223, -0.20827709138393402, -0.2415952980518341, 0.053962528705596924, 0.029189620167016983]
  OUT[0]: [1, 7, 768] | μ=0.449305 σ=10.823559
    First 10: [2.5858347415924072, -0.4077173173427582, 0.019658956676721573, -0.05586138367652893, -0.9262765645980835, -0.05996449291706085, -0.007037626579403877, -0.04921206831932068, -0.33035343885421753, 0.5727789998054504]
    Last 10:  [0.12477358430624008, -0.057168830186128616, -0.08541831374168396, 1.4020951986312866, 0.5478277802467346, 0.3417673110961914, -0.41895878314971924, -1.185265064239502, 0.10198970884084702, 0.08589426428079605]
  WEIGHT: [768] | μ=0.784519

058_layers.3.pre_feedforward_layernorm: layers.3.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.361756 σ=18.592110
    First 10: [17.884687423706055, -2.343038320541382, 0.3876468539237976, 0.01758895069360733, -2.5798537731170654, -0.219828262925148, 0.12885092198848724, -0.8720986843109131, -0.6758477687835693, 1.6831088066101074]
    Last 10:  [-1.5069904327392578, -0.5182338356971741, -0.2680444121360779, 0.6089824438095093, 3.403795003890991, -0.0973062515258789, -2.0420265197753906, -2.2886743545532227, 2.813880205154419, -1.466478943824768]
  OUT[0]: [1, 7, 768] | μ=-0.043312 σ=2.849301
    First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
    Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
  WEIGHT: [768] | μ=17.232321

059_layers.3.mlp.gate_proj: layers.3.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.043312 σ=2.849301
    First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
    Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
  OUT[0]: [1, 7, 1152] | μ=-0.352430 σ=0.544698
    First 10: [-0.07084888964891434, -0.18283990025520325, -0.22277596592903137, 0.21060164272785187, 0.01612473465502262, 0.007492784410715103, 0.07497682422399521, -0.14284296333789825, 0.012564491480588913, -0.13575641810894012]
    Last 10:  [-0.26270657777786255, -0.40185970067977905, -0.48565801978111267, -0.1234157606959343, 0.05971186235547066, -0.04699007794260979, -0.2791433036327362, 0.12028338760137558, 0.24023769795894623, 0.048303112387657166]
  WEIGHT: [1152, 768] | μ=0.000063

060_layers.3.mlp.act_fn: layers.3.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.352430 σ=0.544698
    First 10: [-0.07084888964891434, -0.18283990025520325, -0.22277596592903137, 0.21060164272785187, 0.01612473465502262, 0.007492784410715103, 0.07497682422399521, -0.14284296333789825, 0.012564491480588913, -0.13575641810894012]
    Last 10:  [-0.26270657777786255, -0.40185970067977905, -0.48565801978111267, -0.1234157606959343, 0.05971186235547066, -0.04699007794260979, -0.2791433036327362, 0.12028338760137558, 0.24023769795894623, 0.048303112387657166]
  OUT[0]: [1, 7, 1152] | μ=-0.040765 σ=0.196113
    First 10: [-0.03342361003160477, -0.07815743237733841, -0.09175216406583786, 0.12286457419395447, 0.008166090585291386, 0.0037687893491238356, 0.03972896561026573, -0.06330914795398712, 0.006345224101096392, -0.060548409819602966]
    Last 10:  [-0.10413532704114914, -0.1382046490907669, -0.15232019126415253, -0.055646877735853195, 0.03127751126885414, -0.02261447347700596, -0.10888659954071045, 0.06589967012405396, 0.14292283356189728, 0.025081999599933624]

061_layers.3.mlp.up_proj: layers.3.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.043312 σ=2.849301
    First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
    Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
  OUT[0]: [1, 7, 1152] | μ=-0.005127 σ=0.477205
    First 10: [-0.11400371044874191, -0.18644334375858307, -0.0863964706659317, 0.0509701669216156, -0.09478780627250671, 0.03514707833528519, -0.019085437059402466, -0.21105001866817474, -0.2080688178539276, -0.23981821537017822]
    Last 10:  [0.23056812584400177, -0.23218762874603271, -0.06676831096410751, 0.27007389068603516, -0.10065621137619019, -0.3287680745124817, 0.21089354157447815, 0.23527228832244873, -0.22566327452659607, -0.10350172966718674]
  WEIGHT: [1152, 768] | μ=0.000003

062_layers.3.mlp.down_proj: layers.3.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.000333 σ=0.149697
    First 10: [0.0038104155100882053, 0.014571933075785637, 0.007927062921226025, 0.006262427661567926, -0.0007740458240732551, 0.00013246193702798337, -0.0007582446560263634, 0.013361397199332714, -0.0013202432310208678, 0.014520611613988876]
    Last 10:  [-0.02401028759777546, 0.03208940848708153, 0.010170161724090576, -0.01502876915037632, -0.0031482758931815624, 0.00743491668254137, -0.02296348102390766, 0.015504365786910057, -0.03225243464112282, -0.002596030244603753]
  OUT[0]: [1, 7, 768] | μ=0.001876 σ=0.047310
    First 10: [0.00988748949021101, -0.0016319871647283435, -0.002810006495565176, 0.00253739720210433, -0.0021906206384301186, -0.00230024429038167, 3.4377328120172024e-05, -0.002132640453055501, -0.0010078410850837827, -0.007609821856021881]
    Last 10:  [0.013000523671507835, -0.01447188388556242, 0.0038546277210116386, 0.003431163029745221, 0.00859474204480648, 0.00100653525441885, -0.007862483151257038, -0.0091759217903018, 0.007515238597989082, 0.008473170921206474]
  WEIGHT: [768, 1152] | μ=0.000005

063_layers.3.mlp: layers.3.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=-0.043312 σ=2.849301
    First 10: [0.9975376129150391, -1.7517386674880981, 0.25042539834976196, 0.01089455746114254, -1.5437740087509155, -0.1656026840209961, 0.07661867886781693, -0.5084198713302612, -0.4676489531993866, 1.0390793085098267]
    Last 10:  [-1.1077098846435547, -0.4092414677143097, -0.18448734283447266, 0.30786260962486267, 2.5189812183380127, -0.07360126078128815, -1.478574514389038, -1.1106336116790771, 1.8832433223724365, -1.12771737575531]
  OUT[0]: [1, 7, 768] | μ=0.001876 σ=0.047310
    First 10: [0.00988748949021101, -0.0016319871647283435, -0.002810006495565176, 0.00253739720210433, -0.0021906206384301186, -0.00230024429038167, 3.4377328120172024e-05, -0.002132640453055501, -0.0010078410850837827, -0.007609821856021881]
    Last 10:  [0.013000523671507835, -0.01447188388556242, 0.0038546277210116386, 0.003431163029745221, 0.00859474204480648, 0.00100653525441885, -0.007862483151257038, -0.0091759217903018, 0.007515238597989082, 0.008473170921206474]

064_layers.3.post_feedforward_layernorm: layers.3.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.001876 σ=0.047310
    First 10: [0.00988748949021101, -0.0016319871647283435, -0.002810006495565176, 0.00253739720210433, -0.0021906206384301186, -0.00230024429038167, 3.4377328120172024e-05, -0.002132640453055501, -0.0010078410850837827, -0.007609821856021881]
    Last 10:  [0.013000523671507835, -0.01447188388556242, 0.0038546277210116386, 0.003431163029745221, 0.00859474204480648, 0.00100653525441885, -0.007862483151257038, -0.0091759217903018, 0.007515238597989082, 0.008473170921206474]
  OUT[0]: [1, 7, 768] | μ=0.333951 σ=14.892618
    First 10: [15.690444946289062, -0.19420620799064636, -0.16625581681728363, 0.11464894562959671, -0.3918304145336151, -0.3535054326057434, 0.002100064419209957, -0.11386733502149582, -0.16140559315681458, -1.2639120817184448]
    Last 10:  [0.49900510907173157, -0.6048781275749207, 0.0936402827501297, 0.6753284335136414, 0.7552799582481384, 0.08121141791343689, -0.7302577495574951, -1.358172059059143, 0.6901171803474426, 0.8474723696708679]
  WEIGHT: [768] | μ=2.698411

065_layers.4.input_layernorm: layers.4.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.027805 σ=25.062201
    First 10: [33.57513427734375, -2.5372445583343506, 0.22139103710651398, 0.13223789632320404, -2.971684217453003, -0.5733336806297302, 0.13095098733901978, -0.9859660267829895, -0.8372533321380615, 0.4191967248916626]
    Last 10:  [-1.0079853534698486, -1.1231119632720947, -0.17440412938594818, 1.2843108177185059, 4.159074783325195, -0.016094833612442017, -2.7722842693328857, -3.646846294403076, 3.503997325897217, -0.6190065741539001]
  OUT[0]: [1, 7, 768] | μ=-0.054486 σ=6.085320
    First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
    Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
  WEIGHT: [768] | μ=30.053549

066_layers.4.self_attn.q_proj: layers.4.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.054486 σ=6.085320
    First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
    Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
  OUT[0]: [1, 7, 768] | μ=-0.128718 σ=2.056209
    First 10: [-1.3003647327423096, 0.2258465588092804, 0.18628384172916412, 0.10066002607345581, -0.38012808561325073, -0.5542322397232056, -1.250847339630127, 0.5661227703094482, -0.515535831451416, 0.11348970234394073]
    Last 10:  [-0.11105728149414062, 0.32519063353538513, 0.29016372561454773, -0.8885889053344727, 0.04653879255056381, -0.22440002858638763, -0.4166398048400879, -0.19353613257408142, -0.029963389039039612, -0.00011694245040416718]
  WEIGHT: [768, 768] | μ=0.000012

067_layers.4.self_attn.k_proj: layers.4.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.054486 σ=6.085320
    First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
    Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
  OUT[0]: [1, 7, 256] | μ=-0.252606 σ=2.220254
    First 10: [0.1747579127550125, 0.03840899467468262, -0.5019262433052063, -0.08137509971857071, 0.1490200012922287, -0.4019699990749359, 0.2811308801174164, 0.3252238631248474, -0.1669502556324005, 0.003788955509662628]
    Last 10:  [-0.09925991296768188, 1.2903430461883545, -1.269709825515747, -0.5569393634796143, -0.46465837955474854, -1.7159514427185059, 0.7715805768966675, 0.4556434154510498, 0.043789297342300415, 0.7574905753135681]
  WEIGHT: [256, 768] | μ=0.000026

068_layers.4.self_attn.v_proj: layers.4.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.054486 σ=6.085320
    First 10: [4.035336971282959, -2.3738059997558594, 0.2638205289840698, 0.1618194729089737, -2.093550682067871, -0.5342796444892883, 0.1322597861289978, -1.0641852617263794, -0.7283433675765991, 0.32008132338523865]
    Last 10:  [-0.8204545974731445, -0.9805105924606323, -0.16312284767627716, 0.5961924195289612, 2.6703298091888428, -0.010940315201878548, -1.813201665878296, -1.6088236570358276, 2.0943615436553955, -0.4713234007358551]
  OUT[0]: [1, 7, 256] | μ=0.018024 σ=1.299405
    First 10: [0.35552769899368286, 0.07439523935317993, -0.26891568303108215, -0.04349346458911896, 0.19978776574134827, -0.006230875849723816, -0.42201948165893555, 0.29892539978027344, 0.09775888919830322, 0.26005351543426514]
    Last 10:  [0.22149068117141724, -0.2593604624271393, 0.3115338683128357, -0.07205217331647873, -0.0030505768954753876, -0.23764684796333313, 0.16726790368556976, -0.14450547099113464, 0.1104220300912857, -0.08823485672473907]
  WEIGHT: [256, 768] | μ=0.000003

069_layers.4.self_attn.q_norm: layers.4.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.128718 σ=2.056209
    First 10: [-1.3003647327423096, 0.2258465588092804, 0.18628384172916412, 0.10066002607345581, -0.38012808561325073, -0.5542322397232056, -1.250847339630127, 0.5661227703094482, -0.515535831451416, 0.11348970234394073]
    Last 10:  [-0.11105728149414062, 0.32519063353538513, 0.29016372561454773, -0.8885889053344727, 0.04653879255056381, -0.22440002858638763, -0.4166398048400879, -0.19353613257408142, -0.029963389039039612, -0.00011694245040416718]
  OUT[0]: [1, 3, 7, 256] | μ=-0.070463 σ=1.395111
    First 10: [-4.0822343826293945, 0.6525353789329529, 0.5451899170875549, 0.2914077937602997, -1.097116231918335, -0.9762637615203857, -3.485938787460327, 1.4749176502227783, -1.3194186687469482, 0.23538611829280853]
    Last 10:  [-0.2757661044597626, 1.2404624223709106, 0.9970362782478333, -2.7414257526397705, 0.13000279664993286, -0.7447633743286133, -1.5398623943328857, -0.7079785466194153, -0.08108490705490112, -0.0002886266738642007]
  WEIGHT: [256] | μ=0.362248

070_layers.4.self_attn.k_norm: layers.4.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.252606 σ=2.220254
    First 10: [0.1747579127550125, 0.03840899467468262, -0.5019262433052063, -0.08137509971857071, 0.1490200012922287, -0.4019699990749359, 0.2811308801174164, 0.3252238631248474, -0.1669502556324005, 0.003788955509662628]
    Last 10:  [-0.09925991296768188, 1.2903430461883545, -1.269709825515747, -0.5569393634796143, -0.46465837955474854, -1.7159514427185059, 0.7715805768966675, 0.4556434154510498, 0.043789297342300415, 0.7574905753135681]
  OUT[0]: [1, 1, 7, 256] | μ=-0.057136 σ=1.377365
    First 10: [0.1737399697303772, 0.05580642446875572, -0.8446398377418518, -0.09585341066122055, 0.15438324213027954, -0.4901633858680725, 0.2758810520172119, 0.4866156280040741, -0.18139946460723877, 0.005308731459081173]
    Last 10:  [-0.111277274787426, 1.2815203666687012, -1.3333845138549805, -0.5321565270423889, -0.5818893909454346, -1.6759469509124756, 0.797446608543396, 0.3600291609764099, 0.05690978094935417, 1.0351741313934326]
  WEIGHT: [256] | μ=0.445765

071_layers.4.self_attn.o_proj: layers.4.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.010674 σ=0.744312
    First 10: [0.35552769899368286, 0.07439523935317993, -0.26891568303108215, -0.04349346458911896, 0.19978776574134827, -0.006230875849723816, -0.42201948165893555, 0.29892539978027344, 0.09775888919830322, 0.26005351543426514]
    Last 10:  [0.12048257142305374, -0.15959219634532928, 0.2263602465391159, -0.04229557141661644, 0.04798565059900284, -0.28840941190719604, 0.0410408079624176, -0.1332937777042389, 0.005188792943954468, -0.0297364704310894]
  OUT[0]: [1, 7, 768] | μ=0.008274 σ=0.264323
    First 10: [0.07013438642024994, -0.02277786284685135, 0.035652726888656616, -0.07001519203186035, 0.0020276717841625214, -0.06461795419454575, -0.062479034066200256, 0.022180359810590744, -0.09435208886861801, 0.027010587975382805]
    Last 10:  [-0.14023488759994507, 0.07838107645511627, -0.10736659169197083, 0.00969766452908516, -0.1169893816113472, 0.05185773968696594, -0.011285662651062012, -0.17035627365112305, -0.12618526816368103, -0.05198054388165474]
  WEIGHT: [768, 768] | μ=0.000012

072_layers.4.self_attn: layers.4.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.008274 σ=0.264323
    First 10: [0.07013438642024994, -0.02277786284685135, 0.035652726888656616, -0.07001519203186035, 0.0020276717841625214, -0.06461795419454575, -0.062479034066200256, 0.022180359810590744, -0.09435208886861801, 0.027010587975382805]
    Last 10:  [-0.14023488759994507, 0.07838107645511627, -0.10736659169197083, 0.00969766452908516, -0.1169893816113472, 0.05185773968696594, -0.011285662651062012, -0.17035627365112305, -0.12618526816368103, -0.05198054388165474]

073_layers.4.post_attention_layernorm: layers.4.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.008274 σ=0.264323
    First 10: [0.07013438642024994, -0.02277786284685135, 0.035652726888656616, -0.07001519203186035, 0.0020276717841625214, -0.06461795419454575, -0.062479034066200256, 0.022180359810590744, -0.09435208886861801, 0.027010587975382805]
    Last 10:  [-0.14023488759994507, 0.07838107645511627, -0.10736659169197083, 0.00969766452908516, -0.1169893816113472, 0.05185773968696594, -0.011285662651062012, -0.17035627365112305, -0.12618526816368103, -0.05198054388165474]
  OUT[0]: [1, 7, 768] | μ=0.203157 σ=4.951511
    First 10: [2.811494827270508, -0.11620846390724182, 0.030258726328611374, -0.061204202473163605, 0.012642545625567436, -0.45691394805908203, -0.07427477836608887, 0.018411392346024513, -0.643004298210144, 0.22905509173870087]
    Last 10:  [-0.11435713618993759, 0.058000970631837845, -0.07437372952699661, 0.13958856463432312, -0.874189019203186, 0.3526437282562256, -0.07218769937753677, -1.9812443256378174, -0.7202491164207458, -0.6112315058708191]
  WEIGHT: [768] | μ=1.568858

074_layers.4.pre_feedforward_layernorm: layers.4.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.175352 σ=23.267481
    First 10: [36.386627197265625, -2.6534531116485596, 0.25164976716041565, 0.07103369385004044, -2.9590415954589844, -1.030247688293457, 0.05667620897293091, -0.9675546288490295, -1.4802576303482056, 0.6482518315315247]
    Last 10:  [-1.1223424673080444, -1.0651110410690308, -0.2487778663635254, 1.4238994121551514, 3.284885883331299, 0.33654889464378357, -2.8444719314575195, -5.628090858459473, 2.783748149871826, -1.2302380800247192]
  OUT[0]: [1, 7, 768] | μ=0.008037 σ=3.812306
    First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
    Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
  WEIGHT: [768] | μ=18.926020

075_layers.4.mlp.gate_proj: layers.4.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.008037 σ=3.812306
    First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
    Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
  OUT[0]: [1, 7, 1152] | μ=-0.532002 σ=0.776529
    First 10: [-0.2433040291070938, -0.2199590653181076, -0.025291763246059418, -0.22469228506088257, -0.6570779085159302, -0.2255728840827942, -0.22156882286071777, -0.04523707926273346, -0.05315668135881424, -0.1563359797000885]
    Last 10:  [0.4588277339935303, 0.10540883988142014, -0.06063370779156685, -0.13590772449970245, -0.2392680048942566, 0.06479018926620483, 0.025217141956090927, 0.8626278638839722, 0.14050805568695068, -0.12124986201524734]
  WEIGHT: [1152, 768] | μ=0.000059

076_layers.4.mlp.act_fn: layers.4.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.532002 σ=0.776529
    First 10: [-0.2433040291070938, -0.2199590653181076, -0.025291763246059418, -0.22469228506088257, -0.6570779085159302, -0.2255728840827942, -0.22156882286071777, -0.04523707926273346, -0.05315668135881424, -0.1563359797000885]
    Last 10:  [0.4588277339935303, 0.10540883988142014, -0.06063370779156685, -0.13590772449970245, -0.2392680048942566, 0.06479018926620483, 0.025217141956090927, 0.8626278638839722, 0.14050805568695068, -0.12124986201524734]
  OUT[0]: [1, 7, 1152] | μ=-0.022440 σ=0.248153
    First 10: [-0.09826793521642685, -0.09083317220211029, -0.012390716932713985, -0.09237390756607056, -0.16797126829624176, -0.09265868365764618, -0.09135908633470535, -0.021802425384521484, -0.02545160986483097, -0.06845723092556]
    Last 10:  [0.31053170561790466, 0.057128846645355225, -0.028851067647337914, -0.06060776486992836, -0.0970119759440422, 0.03406858444213867, 0.012862233445048332, 0.6950259804725647, 0.07810419052839279, -0.05477428063750267]

077_layers.4.mlp.up_proj: layers.4.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.008037 σ=3.812306
    First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
    Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
  OUT[0]: [1, 7, 1152] | μ=0.018667 σ=0.656962
    First 10: [-0.07482915371656418, 0.20824719965457916, -0.1833893060684204, -0.026981636881828308, -0.04808507114648819, -0.23260554671287537, -0.17104984819889069, 0.32192689180374146, 0.3443179130554199, 0.2210167944431305]
    Last 10:  [-0.1666335016489029, -0.08376934379339218, 0.21405565738677979, -0.09443143010139465, -0.42135483026504517, -0.3598727285861969, 0.17925535142421722, -0.23852309584617615, 0.22429916262626648, 0.18247124552726746]
  WEIGHT: [1152, 768] | μ=-0.000001

078_layers.4.mlp.down_proj: layers.4.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.003881 σ=0.238542
    First 10: [0.007353306282311678, -0.018915753811597824, 0.0022723248694092035, 0.002492399187758565, 0.008076909929513931, 0.021552924066781998, 0.015626957640051842, -0.007018786855041981, -0.008763445541262627, -0.015130197629332542]
    Last 10:  [-0.051744986325502396, -0.004785646218806505, -0.006175734102725983, 0.005723278038203716, 0.04087646305561066, -0.01226035412400961, 0.0023056240752339363, -0.16577975451946259, 0.017518704757094383, -0.009994731284677982]
  OUT[0]: [1, 7, 768] | μ=0.000898 σ=0.064236
    First 10: [0.016506865620613098, 0.012730066664516926, 0.004437127150595188, -0.00526181748136878, -0.0026479382067918777, 0.0001356686552753672, 0.008064948953688145, -0.008999384939670563, -0.0007766254129819572, 0.002039021346718073]
    Last 10:  [0.004823110997676849, 0.00025620352244004607, -0.0014824876561760902, 0.002598237944766879, 0.00329629541374743, 0.005703882314264774, 0.0011940994299948215, 0.0003665557596832514, 0.0006752926856279373, -0.0019562644883990288]
  WEIGHT: [768, 1152] | μ=0.000001

079_layers.4.mlp: layers.4.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.008037 σ=3.812306
    First 10: [1.9352421760559082, -1.9702104330062866, 0.18646706640720367, 0.051742617040872574, -1.7876861095428467, -0.7228826880455017, 0.03819458559155464, -0.715308666229248, -0.9395695328712463, 0.37408843636512756]
    Last 10:  [-0.6615992784500122, -0.7469133734703064, -0.1508733332157135, 0.4032302796840668, 1.6649904251098633, 0.17754381895065308, -1.3994044065475464, -1.7387750148773193, 1.3346937894821167, -0.5207018256187439]
  OUT[0]: [1, 7, 768] | μ=0.000898 σ=0.064236
    First 10: [0.016506865620613098, 0.012730066664516926, 0.004437127150595188, -0.00526181748136878, -0.0026479382067918777, 0.0001356686552753672, 0.008064948953688145, -0.008999384939670563, -0.0007766254129819572, 0.002039021346718073]
    Last 10:  [0.004823110997676849, 0.00025620352244004607, -0.0014824876561760902, 0.002598237944766879, 0.00329629541374743, 0.005703882314264774, 0.0011940994299948215, 0.0003665557596832514, 0.0006752926856279373, -0.0019562644883990288]

080_layers.4.post_feedforward_layernorm: layers.4.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000898 σ=0.064236
    First 10: [0.016506865620613098, 0.012730066664516926, 0.004437127150595188, -0.00526181748136878, -0.0026479382067918777, 0.0001356686552753672, 0.008064948953688145, -0.008999384939670563, -0.0007766254129819572, 0.002039021346718073]
    Last 10:  [0.004823110997676849, 0.00025620352244004607, -0.0014824876561760902, 0.002598237944766879, 0.00329629541374743, 0.005703882314264774, 0.0011940994299948215, 0.0003665557596832514, 0.0006752926856279373, -0.0019562644883990288]
  OUT[0]: [1, 7, 768] | μ=0.123660 σ=14.204190
    First 10: [13.617456436157227, 1.2953903675079346, 0.1348228007555008, -0.13247188925743103, -0.3941936790943146, 0.017186861485242844, 0.29084891080856323, -0.24068281054496765, -0.11646171659231186, 0.3421156108379364]
    Last 10:  [0.3306266963481903, 0.020900847390294075, -0.05535745993256569, 1.2262427806854248, 0.8037211894989014, 1.2321528196334839, 0.30467066168785095, 0.12004515528678894, 0.163411945104599, -0.529354453086853]
  WEIGHT: [768] | μ=2.749710

081_layers.5.input_layernorm: layers.5.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.299011 σ=28.675858
    First 10: [50.00408172607422, -1.358062744140625, 0.38647258281707764, -0.061438195407390594, -3.3532352447509766, -1.0130608081817627, 0.34752511978149414, -1.2082374095916748, -1.5967193841934204, 0.9903674125671387]
    Last 10:  [-0.7917157411575317, -1.0442101955413818, -0.3041353225708008, 2.650142192840576, 4.088606834411621, 1.5687017440795898, -2.5398013591766357, -5.508045673370361, 2.947160005569458, -1.7595925331115723]
  OUT[0]: [1, 7, 768] | μ=-0.017976 σ=3.510119
    First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
    Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
  WEIGHT: [768] | μ=14.830829

082_layers.5.self_attn.q_proj: layers.5.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.017976 σ=3.510119
    First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
    Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
  OUT[0]: [1, 7, 768] | μ=-0.003083 σ=1.959772
    First 10: [0.3435963988304138, -0.8238925337791443, -0.5850796699523926, 0.5215917825698853, 0.833429217338562, 1.023348331451416, -0.6344496607780457, -1.1658132076263428, 0.6053445339202881, -0.9074148535728455]
    Last 10:  [-0.17620936036109924, 0.04484046995639801, 0.0753069594502449, 0.6970285177230835, 0.09042491763830185, -0.15865793824195862, -0.109433114528656, 0.13280242681503296, -0.207976832985878, 0.08010171353816986]
  WEIGHT: [768, 768] | μ=-0.000011

083_layers.5.self_attn.k_proj: layers.5.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.017976 σ=3.510119
    First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
    Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
  OUT[0]: [1, 7, 256] | μ=-0.032304 σ=1.118277
    First 10: [-0.32856476306915283, 0.4253772795200348, 0.5012852549552917, -0.23478823900222778, -0.6292316317558289, -0.6332000494003296, 0.5806336402893066, 0.7183332443237305, -0.350685715675354, 0.43357163667678833]
    Last 10:  [-1.2204737663269043, 0.2628942131996155, -0.5726051926612854, 1.5888240337371826, 1.0807337760925293, -0.5544968843460083, -0.8628553748130798, -0.05456794798374176, -0.7803530693054199, 0.4297964572906494]
  WEIGHT: [256, 768] | μ=-0.000011

084_layers.5.self_attn.v_proj: layers.5.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.017976 σ=3.510119
    First 10: [7.124884128570557, -1.240091323852539, 0.9947600960731506, -0.2406749427318573, -1.9054161310195923, -0.7982738614082336, 0.7203129529953003, -3.675464391708374, -1.063263177871704, 0.622174859046936]
    Last 10:  [-0.2904086112976074, -0.3451426923274994, -0.2562764585018158, 0.27179858088493347, 0.6871599555015564, 0.2708766758441925, -0.4070959687232971, -0.6696759462356567, 0.4528987407684326, -0.2965461015701294]
  OUT[0]: [1, 7, 256] | μ=-0.023424 σ=0.701207
    First 10: [-0.18729406595230103, -0.6642611026763916, -0.6630067825317383, 0.1364155113697052, 0.03617032989859581, 0.15833841264247894, 0.3766028881072998, 0.10187871754169464, 0.0008386000990867615, 0.7521985769271851]
    Last 10:  [-0.22159415483474731, 0.20331120491027832, -0.11347837746143341, -0.3656628429889679, -0.022672876715660095, 0.07251614332199097, 0.09820893406867981, 0.11884456872940063, -0.0043951719999313354, -0.19001463055610657]
  WEIGHT: [256, 768] | μ=-0.000024

085_layers.5.self_attn.q_norm: layers.5.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.003083 σ=1.959772
    First 10: [0.3435963988304138, -0.8238925337791443, -0.5850796699523926, 0.5215917825698853, 0.833429217338562, 1.023348331451416, -0.6344496607780457, -1.1658132076263428, 0.6053445339202881, -0.9074148535728455]
    Last 10:  [-0.17620936036109924, 0.04484046995639801, 0.0753069594502449, 0.6970285177230835, 0.09042491763830185, -0.15865793824195862, -0.109433114528656, 0.13280242681503296, -0.207976832985878, 0.08010171353816986]
  OUT[0]: [1, 3, 7, 256] | μ=-0.034788 σ=1.330069
    First 10: [0.7491567730903625, -1.0988593101501465, -0.5799961686134338, 0.6482558846473694, 0.7619922161102295, 1.1293338537216187, -0.6823820471763611, -1.2502248287200928, 0.6221124529838562, -1.2545554637908936]
    Last 10:  [-0.4889146089553833, 0.10989035665988922, 0.17953625321388245, 1.8139169216156006, 0.2425702065229416, -0.4021260738372803, -0.2881060838699341, 0.25207382440567017, -0.5073937773704529, 0.21538400650024414]
  WEIGHT: [256] | μ=0.938661

086_layers.5.self_attn.k_norm: layers.5.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.032304 σ=1.118277
    First 10: [-0.32856476306915283, 0.4253772795200348, 0.5012852549552917, -0.23478823900222778, -0.6292316317558289, -0.6332000494003296, 0.5806336402893066, 0.7183332443237305, -0.350685715675354, 0.43357163667678833]
    Last 10:  [-1.2204737663269043, 0.2628942131996155, -0.5726051926612854, 1.5888240337371826, 1.0807337760925293, -0.5544968843460083, -0.8628553748130798, -0.05456794798374176, -0.7803530693054199, 0.4297964572906494]
  OUT[0]: [1, 1, 7, 256] | μ=-0.050333 σ=2.715901
    First 10: [-0.5265185236930847, 0.4871973991394043, 1.4220259189605713, -0.2873842418193817, -1.9846969842910767, -1.7208930253982544, 1.7191245555877686, 1.9557185173034668, -0.3138028383255005, 0.3583470582962036]
    Last 10:  [-8.504571914672852, 1.8737486600875854, -4.18779993057251, 11.032317161560059, 8.001799583435059, -3.92203688621521, -6.254220008850098, -0.4947076737880707, -5.4822540283203125, 2.8989500999450684]
  WEIGHT: [256] | μ=0.861877

087_layers.5.self_attn.o_proj: layers.5.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.017123 σ=0.504531
    First 10: [-0.18729406595230103, -0.6642611026763916, -0.6630067825317383, 0.1364155113697052, 0.03617032989859581, 0.15833841264247894, 0.3766028881072998, 0.10187871754169464, 0.0008386000990867615, 0.7521985769271851]
    Last 10:  [-0.21994152665138245, 0.2003229707479477, -0.11402162164449692, -0.3645123243331909, -0.027654623612761497, 0.07523023337125778, 0.09487675875425339, 0.1152477040886879, -0.006584251765161753, -0.19205912947654724]
  OUT[0]: [1, 7, 768] | μ=-0.004213 σ=0.243797
    First 10: [0.3297337293624878, -0.026250962167978287, -0.019959639757871628, 0.3316638767719269, 0.000552251935005188, -0.2645221948623657, 0.4683080315589905, 0.5044411420822144, 0.10519514232873917, -0.06506234407424927]
    Last 10:  [0.10227788239717484, -0.00046186894178390503, -0.003080049529671669, 0.07474000751972198, -0.08899757266044617, 0.04381008446216583, -0.16858626902103424, -0.08501040190458298, 0.013002429157495499, 0.08716219663619995]
  WEIGHT: [768, 768] | μ=0.000013

088_layers.5.self_attn: layers.5.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.004213 σ=0.243797
    First 10: [0.3297337293624878, -0.026250962167978287, -0.019959639757871628, 0.3316638767719269, 0.000552251935005188, -0.2645221948623657, 0.4683080315589905, 0.5044411420822144, 0.10519514232873917, -0.06506234407424927]
    Last 10:  [0.10227788239717484, -0.00046186894178390503, -0.003080049529671669, 0.07474000751972198, -0.08899757266044617, 0.04381008446216583, -0.16858626902103424, -0.08501040190458298, 0.013002429157495499, 0.08716219663619995]

089_layers.5.post_attention_layernorm: layers.5.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.004213 σ=0.243797
    First 10: [0.3297337293624878, -0.026250962167978287, -0.019959639757871628, 0.3316638767719269, 0.000552251935005188, -0.2645221948623657, 0.4683080315589905, 0.5044411420822144, 0.10519514232873917, -0.06506234407424927]
    Last 10:  [0.10227788239717484, -0.00046186894178390503, -0.003080049529671669, 0.07474000751972198, -0.08899757266044617, 0.04381008446216583, -0.16858626902103424, -0.08501040190458298, 0.013002429157495499, 0.08716219663619995]
  OUT[0]: [1, 7, 768] | μ=-0.546489 σ=10.290910
    First 10: [13.371333122253418, -0.14551414549350739, -0.009859991259872913, 0.03625224158167839, 0.003768774913623929, -2.0020790100097656, 0.2959776818752289, 0.19209809601306915, 0.6666984558105469, -0.6306414008140564]
    Last 10:  [0.08635198324918747, 3.0255745514295995e-05, -0.003566921688616276, 4.2407355308532715, -1.9975206851959229, 0.6813219785690308, -2.750837802886963, -3.8418102264404297, 0.15440253913402557, 2.6208882331848145]
  WEIGHT: [768] | μ=2.037554

090_layers.5.pre_feedforward_layernorm: layers.5.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.247478 σ=24.092289
    First 10: [63.37541580200195, -1.5035768747329712, 0.3766126036643982, -0.025185953825712204, -3.349466562271118, -3.0151398181915283, 0.6435028314590454, -1.016139268875122, -0.9300209283828735, 0.3597260117530823]
    Last 10:  [-0.7053637504577637, -1.044179916381836, -0.3077022433280945, 6.890877723693848, 2.0910861492156982, 2.25002384185791, -5.2906389236450195, -9.349855422973633, 3.1015625, 0.8612957000732422]
  OUT[0]: [1, 7, 768] | μ=0.038860 σ=3.106304
    First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
    Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
  WEIGHT: [768] | μ=15.136345

091_layers.5.mlp.gate_proj: layers.5.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.038860 σ=3.106304
    First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
    Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
  OUT[0]: [1, 7, 1152] | μ=-0.391299 σ=0.629577
    First 10: [0.02877137064933777, -0.6331754922866821, -0.26515066623687744, 0.28761565685272217, -0.7272838950157166, 0.5175226926803589, 0.03199346363544464, -0.09256668388843536, -0.060559168457984924, -0.22323153913021088]
    Last 10:  [0.009463325142860413, -0.17048652470111847, 0.014853917062282562, 0.044093020260334015, -0.1398654580116272, -0.15750913321971893, -0.20382940769195557, -0.8908457159996033, -0.04318623244762421, -0.19850178062915802]
  WEIGHT: [1152, 768] | μ=0.000041

092_layers.5.mlp.act_fn: layers.5.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.391299 σ=0.629577
    First 10: [0.02877137064933777, -0.6331754922866821, -0.26515066623687744, 0.28761565685272217, -0.7272838950157166, 0.5175226926803589, 0.03199346363544464, -0.09256668388843536, -0.060559168457984924, -0.22323153913021088]
    Last 10:  [0.009463325142860413, -0.17048652470111847, 0.014853917062282562, 0.044093020260334015, -0.1398654580116272, -0.15750913321971893, -0.20382940769195557, -0.8908457159996033, -0.04318623244762421, -0.19850178062915802]
  OUT[0]: [1, 7, 1152] | μ=-0.029117 σ=0.209296
    First 10: [0.014715880155563354, -0.16676074266433716, -0.1048545092344284, 0.17635789513587952, -0.1699022650718689, 0.36100655794143677, 0.01640501245856285, -0.04286986589431763, -0.028817396610975266, -0.09190022200345993]
    Last 10:  [0.004767389036715031, -0.07370394468307495, 0.00751497782766819, 0.022821879014372826, -0.062153976410627365, -0.06889812648296356, -0.08545468747615814, -0.16626223921775818, -0.020849300548434258, -0.08363451063632965]

093_layers.5.mlp.up_proj: layers.5.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.038860 σ=3.106304
    First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
    Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
  OUT[0]: [1, 7, 1152] | μ=-0.008198 σ=0.552294
    First 10: [-0.22471049427986145, -0.04140250384807587, -0.18849781155586243, -0.2998359203338623, 1.6828224658966064, 0.015173113904893398, -0.003897935152053833, -0.021450629457831383, -0.037054598331451416, -0.24090734124183655]
    Last 10:  [0.15915650129318237, 0.000818789005279541, 0.03584031015634537, -1.0316874980926514, -0.041844867169857025, 0.23295414447784424, -0.09408757090568542, -0.6292651295661926, 0.09948500990867615, 0.2083302140235901]
  WEIGHT: [1152, 768] | μ=0.000003

094_layers.5.mlp.down_proj: layers.5.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.002147 σ=0.166352
    First 10: [-0.003306812606751919, 0.006904312409460545, 0.019764846190810204, -0.05287843197584152, -0.285915344953537, 0.005477593746036291, -6.394567753886804e-05, 0.000919585581868887, 0.0010678170947358012, 0.02213943749666214]
    Last 10:  [0.0007587609579786658, -6.0347978433128446e-05, 0.00026933912886306643, -0.023545047268271446, 0.0026008249260485172, -0.016050104051828384, 0.008040224201977253, 0.10462302714586258, -0.00207419297657907, -0.0174235962331295]
  OUT[0]: [1, 7, 768] | μ=-0.002165 σ=0.054250
    First 10: [-0.0009648120030760765, 0.003008507192134857, -0.01828138716518879, -0.24516165256500244, 0.0015844423323869705, -0.013097355142235756, -0.002461325842887163, 0.0009445161558687687, -0.00655019748955965, 0.026850104331970215]
    Last 10:  [0.003286368679255247, 0.005061447620391846, 0.00836451631039381, -0.003524386091157794, -0.0015884670428931713, 0.001512336079031229, -0.001298633636906743, -0.0005852117319591343, -0.0014101224951446056, -0.006745236460119486]
  WEIGHT: [768, 1152] | μ=0.000001

095_layers.5.mlp: layers.5.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.038860 σ=3.106304
    First 10: [7.344599723815918, -2.047506093978882, 0.5023669004440308, -0.03192931413650513, -3.256387948989868, -3.4885683059692383, 0.8103163838386536, -1.2967281341552734, -0.9585423469543457, 0.332263708114624]
    Last 10:  [-0.3066747486591339, -0.5235657095909119, -0.1225433424115181, 1.076202154159546, 0.6449078321456909, 0.7433299422264099, -1.7017263174057007, -1.8413337469100952, 0.9972212314605713, 0.22075806558132172]
  OUT[0]: [1, 7, 768] | μ=-0.002165 σ=0.054250
    First 10: [-0.0009648120030760765, 0.003008507192134857, -0.01828138716518879, -0.24516165256500244, 0.0015844423323869705, -0.013097355142235756, -0.002461325842887163, 0.0009445161558687687, -0.00655019748955965, 0.026850104331970215]
    Last 10:  [0.003286368679255247, 0.005061447620391846, 0.00836451631039381, -0.003524386091157794, -0.0015884670428931713, 0.001512336079031229, -0.001298633636906743, -0.0005852117319591343, -0.0014101224951446056, -0.006745236460119486]

096_layers.5.post_feedforward_layernorm: layers.5.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.002165 σ=0.054250
    First 10: [-0.0009648120030760765, 0.003008507192134857, -0.01828138716518879, -0.24516165256500244, 0.0015844423323869705, -0.013097355142235756, -0.002461325842887163, 0.0009445161558687687, -0.00655019748955965, 0.026850104331970215]
    Last 10:  [0.003286368679255247, 0.005061447620391846, 0.00836451631039381, -0.003524386091157794, -0.0015884670428931713, 0.001512336079031229, -0.001298633636906743, -0.0005852117319591343, -0.0014101224951446056, -0.006745236460119486]
  OUT[0]: [1, 7, 768] | μ=0.399568 σ=16.089525
    First 10: [-0.3506588339805603, 0.1745542734861374, -0.2329130470752716, -0.33557093143463135, 0.13900311291217804, -1.120367169380188, -0.0309966541826725, 0.010442123748362064, -0.604693591594696, 2.7555291652679443]
    Last 10:  [0.18887940049171448, 0.34358248114585876, 0.24204234778881073, -2.2528860569000244, -0.6064938902854919, 0.40758800506591797, -0.4978914260864258, -0.32810476422309875, -0.45444566011428833, -3.18894100189209]
  WEIGHT: [768] | μ=4.636819

097_layers.6.input_layernorm: layers.6.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.152090 σ=35.324909
    First 10: [63.024757385253906, -1.3290226459503174, 0.1436995565891266, -0.36075687408447266, -3.210463523864746, -4.135507106781006, 0.6125061511993408, -1.0056971311569214, -1.5347144603729248, 3.115255117416382]
    Last 10:  [-0.5164843797683716, -0.7005974054336548, -0.06565989553928375, 4.637991905212402, 1.4845921993255615, 2.657611846923828, -5.788530349731445, -9.677960395812988, 2.6471168994903564, -2.3276453018188477]
  OUT[0]: [1, 7, 768] | μ=-0.008112 σ=4.792890
    First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
    Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
  WEIGHT: [768] | μ=23.848883

098_layers.6.self_attn.q_proj: layers.6.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.008112 σ=4.792890
    First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
    Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
  OUT[0]: [1, 7, 768] | μ=0.042702 σ=1.918274
    First 10: [0.14327573776245117, 0.2968392074108124, -0.17443940043449402, -0.5721753239631653, -0.05072745680809021, -1.0570058822631836, -0.1343490481376648, -0.7743239998817444, -0.21355396509170532, -1.1742801666259766]
    Last 10:  [0.04512564092874527, -0.29525813460350037, -0.5819755792617798, -0.5884723663330078, -0.1443282663822174, -0.3701057434082031, -0.016013965010643005, -0.20694798231124878, -0.4433669447898865, 0.10566351562738419]
  WEIGHT: [768, 768] | μ=0.000020

099_layers.6.self_attn.k_proj: layers.6.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.008112 σ=4.792890
    First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
    Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
  OUT[0]: [1, 7, 256] | μ=0.097255 σ=1.984499
    First 10: [-0.30353057384490967, 0.6019998788833618, 0.3208559453487396, -0.23235483467578888, 0.5574093461036682, 0.899836540222168, 0.8410823345184326, -1.0979262590408325, 2.678884506225586, 0.6798723936080933]
    Last 10:  [1.4125584363937378, 0.9977766275405884, -0.9503301382064819, -1.7522881031036377, 0.47577667236328125, -1.057414174079895, 0.8809548020362854, -1.448569416999817, -0.7725968360900879, 0.6956427693367004]
  WEIGHT: [256, 768] | μ=-0.000004

100_layers.6.self_attn.v_proj: layers.6.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.008112 σ=4.792890
    First 10: [9.461089134216309, -1.8649003505706787, 0.20794548094272614, -0.4733513295650482, -3.129227876663208, -4.120837688446045, 0.7593151330947876, -1.2893636226654053, -1.5914177894592285, 2.829976797103882]
    Last 10:  [-0.2194434255361557, -0.4446757435798645, -0.02406752109527588, 0.7199561595916748, 0.3993394374847412, 0.8520820736885071, -1.5729140043258667, -1.4483065605163574, 0.8093404769897461, -0.5207423567771912]
  OUT[0]: [1, 7, 256] | μ=-0.041952 σ=1.106261
    First 10: [0.19194035232067108, -0.2043537199497223, -0.8504716157913208, 0.022621557116508484, -0.42504599690437317, 0.31335774064064026, 0.488045334815979, -0.21698057651519775, 0.49385786056518555, -0.12780530750751495]
    Last 10:  [0.19130395352840424, 0.3566189408302307, 0.06716808676719666, -0.230184406042099, 0.05417200177907944, 0.031561143696308136, 0.19935011863708496, 0.16878502070903778, 0.45267194509506226, -0.3658459186553955]
  WEIGHT: [256, 768] | μ=0.000021

101_layers.6.self_attn.q_norm: layers.6.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.042702 σ=1.918274
    First 10: [0.14327573776245117, 0.2968392074108124, -0.17443940043449402, -0.5721753239631653, -0.05072745680809021, -1.0570058822631836, -0.1343490481376648, -0.7743239998817444, -0.21355396509170532, -1.1742801666259766]
    Last 10:  [0.04512564092874527, -0.29525813460350037, -0.5819755792617798, -0.5884723663330078, -0.1443282663822174, -0.3701057434082031, -0.016013965010643005, -0.20694798231124878, -0.4433669447898865, 0.10566351562738419]
  OUT[0]: [1, 3, 7, 256] | μ=-0.023853 σ=1.078872
    First 10: [0.17996715009212494, 0.330476313829422, -0.19148372113704681, -0.3485027849674225, -0.05959152430295944, -0.7692082524299622, -0.12068133056163788, -0.5305924415588379, -0.13892462849617004, -1.9361149072647095]
    Last 10:  [0.1073635071516037, -0.3989931046962738, -5.6870646476745605, -1.7756233215332031, -0.1529327630996704, -0.5279085636138916, -0.041021011769771576, -0.25063636898994446, -0.7693237066268921, 0.11961238831281662]
  WEIGHT: [256] | μ=0.320920

102_layers.6.self_attn.k_norm: layers.6.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.097255 σ=1.984499
    First 10: [-0.30353057384490967, 0.6019998788833618, 0.3208559453487396, -0.23235483467578888, 0.5574093461036682, 0.899836540222168, 0.8410823345184326, -1.0979262590408325, 2.678884506225586, 0.6798723936080933]
    Last 10:  [1.4125584363937378, 0.9977766275405884, -0.9503301382064819, -1.7522881031036377, 0.47577667236328125, -1.057414174079895, 0.8809548020362854, -1.448569416999817, -0.7725968360900879, 0.6956427693367004]
  OUT[0]: [1, 1, 7, 256] | μ=0.024105 σ=1.612834
    First 10: [-0.25837022066116333, 0.464072048664093, 0.36655372381210327, -0.26156994700431824, 0.4507996737957001, 0.5224059820175171, 0.6693564057350159, 0.012522566132247448, 1.0097755193710327, 0.5100921988487244]
    Last 10:  [3.0650718212127686, 3.6916518211364746, -0.4654194116592407, -3.075366973876953, 2.28810453414917, -3.9262754917144775, 1.8397516012191772, -5.629446506500244, -2.266714334487915, 3.0263850688934326]
  WEIGHT: [256] | μ=0.673052

103_layers.6.self_attn.o_proj: layers.6.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.022864 σ=0.617378
    First 10: [0.19194035232067108, -0.2043537199497223, -0.8504716157913208, 0.022621557116508484, -0.42504599690437317, 0.31335774064064026, 0.488045334815979, -0.21698057651519775, 0.49385786056518555, -0.12780530750751495]
    Last 10:  [-0.5958857536315918, 0.34729546308517456, -0.4479677081108093, -0.20617568492889404, -0.15168073773384094, 0.11476361006498337, 0.2084617018699646, -0.018320254981517792, 0.25284168124198914, -0.034005120396614075]
  OUT[0]: [1, 7, 768] | μ=0.012906 σ=0.202212
    First 10: [0.05031392350792885, 0.03156943619251251, -0.10082419961690903, 0.4057666063308716, -0.08210524171590805, 0.011960698291659355, -0.8786852955818176, 0.516616702079773, -0.11017249524593353, -0.002619369886815548]
    Last 10:  [-0.08533892780542374, -0.011552748270332813, -0.009593963623046875, -0.09305529296398163, 0.02681528776884079, -0.007388741243630648, -0.0746922492980957, -0.03289960324764252, -0.09478618949651718, -0.09884050488471985]
  WEIGHT: [768, 768] | μ=0.000024

104_layers.6.self_attn: layers.6.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.012906 σ=0.202212
    First 10: [0.05031392350792885, 0.03156943619251251, -0.10082419961690903, 0.4057666063308716, -0.08210524171590805, 0.011960698291659355, -0.8786852955818176, 0.516616702079773, -0.11017249524593353, -0.002619369886815548]
    Last 10:  [-0.08533892780542374, -0.011552748270332813, -0.009593963623046875, -0.09305529296398163, 0.02681528776884079, -0.007388741243630648, -0.0746922492980957, -0.03289960324764252, -0.09478618949651718, -0.09884050488471985]

105_layers.6.post_attention_layernorm: layers.6.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.012906 σ=0.202212
    First 10: [0.05031392350792885, 0.03156943619251251, -0.10082419961690903, 0.4057666063308716, -0.08210524171590805, 0.011960698291659355, -0.8786852955818176, 0.516616702079773, -0.11017249524593353, -0.002619369886815548]
    Last 10:  [-0.08533892780542374, -0.011552748270332813, -0.009593963623046875, -0.09305529296398163, 0.02681528776884079, -0.007388741243630648, -0.0746922492980957, -0.03289960324764252, -0.09478618949651718, -0.09884050488471985]
  OUT[0]: [1, 7, 768] | μ=-0.363730 σ=11.079844
    First 10: [1.1099894046783447, 0.3342331349849701, -0.03848286718130112, 0.022486235946416855, -0.9552391171455383, 0.17584216594696045, -0.09741358458995819, 0.13770562410354614, -1.7967027425765991, -0.04564639925956726]
    Last 10:  [-0.14492326974868774, -0.029406988993287086, -0.0005356306792236865, -3.5251638889312744, 1.110536813735962, -0.2057226002216339, -2.465404987335205, -0.8607967495918274, -2.4174249172210693, -3.8764822483062744]
  WEIGHT: [768] | μ=2.562892

106_layers.6.pre_feedforward_layernorm: layers.6.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.211640 σ=28.749672
    First 10: [64.13475036621094, -0.9947894811630249, 0.10521668940782547, -0.3382706344127655, -4.165702819824219, -3.959664821624756, 0.5150925517082214, -0.8679915070533752, -3.3314170837402344, 3.069608688354492]
    Last 10:  [-0.6614076495170593, -0.7300043702125549, -0.0661955252289772, 1.112828016281128, 2.5951290130615234, 2.4518892765045166, -8.253934860229492, -10.53875732421875, 0.2296919822692871, -6.204127311706543]
  OUT[0]: [1, 7, 768] | μ=0.034622 σ=3.463174
    First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
    Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
  WEIGHT: [768] | μ=14.992329

107_layers.6.mlp.gate_proj: layers.6.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.034622 σ=3.463174
    First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
    Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
  OUT[0]: [1, 7, 1152] | μ=-0.592478 σ=0.745965
    First 10: [-0.5440196990966797, -0.6878746747970581, -0.8888449668884277, -0.35568535327911377, -0.1946469098329544, -0.201930433511734, -0.8482429385185242, -0.12103144079446793, -0.3996831774711609, -0.4813653826713562]
    Last 10:  [0.20294269919395447, 0.02571805566549301, -0.2132638394832611, 0.041842199862003326, 0.00018084794282913208, -0.1005886048078537, -0.18988926708698273, -0.13068997859954834, -0.1406102329492569, 0.028667893260717392]
  WEIGHT: [1152, 768] | μ=0.000055

108_layers.6.mlp.act_fn: layers.6.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.592478 σ=0.745965
    First 10: [-0.5440196990966797, -0.6878746747970581, -0.8888449668884277, -0.35568535327911377, -0.1946469098329544, -0.201930433511734, -0.8482429385185242, -0.12103144079446793, -0.3996831774711609, -0.4813653826713562]
    Last 10:  [0.20294269919395447, 0.02571805566549301, -0.2132638394832611, 0.041842199862003326, 0.00018084794282913208, -0.1005886048078537, -0.18988926708698273, -0.13068997859954834, -0.1406102329492569, 0.028667893260717392]
  OUT[0]: [1, 7, 1152] | μ=-0.043078 σ=0.212399
    First 10: [-0.15953750908374786, -0.1691083461046219, -0.16636590659618378, -0.12842079997062683, -0.08230392634868622, -0.08480839431285858, -0.16818013787269592, -0.05468607693910599, -0.13777627050876617, -0.15170690417289734]
    Last 10:  [0.11778945475816727, 0.013122866861522198, -0.08862470090389252, 0.02161935158073902, 9.043701720656827e-05, -0.04626460745930672, -0.08064600080251694, -0.05855054780840874, -0.0624435730278492, 0.014661772176623344]

109_layers.6.mlp.up_proj: layers.6.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.034622 σ=3.463174
    First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
    Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
  OUT[0]: [1, 7, 1152] | μ=0.006085 σ=0.615140
    First 10: [0.030279632657766342, -0.30094286799430847, 0.22125594317913055, 0.20676761865615845, 0.027686983346939087, 0.3134256899356842, -0.13073188066482544, -0.09233465045690536, -0.05976252257823944, -0.03421647846698761]
    Last 10:  [-0.1983657330274582, -0.0359877347946167, 0.11531883478164673, 0.010895349085330963, -0.0684266984462738, -0.1353670060634613, -0.08209416270256042, 0.014871313236653805, 0.14535276591777802, -0.002670787274837494]
  WEIGHT: [1152, 768] | μ=-0.000007

110_layers.6.mlp.down_proj: layers.6.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.004063 σ=0.210955
    First 10: [-0.004830737132579088, 0.050891950726509094, -0.036809444427490234, -0.026553263887763023, -0.0022787475027143955, -0.02658112905919552, 0.021986505016684532, 0.005049419589340687, 0.008233857341110706, 0.005190875846892595]
    Last 10:  [-0.023365391418337822, -0.00047226223978213966, -0.010220097377896309, 0.00023555038205813617, -6.188306542753708e-06, 0.006262701470404863, 0.0066205658949911594, -0.0008707235101610422, -0.009076345711946487, -3.915847628377378e-05]
  OUT[0]: [1, 7, 768] | μ=-0.000629 σ=0.057071
    First 10: [0.00634501688182354, 0.004376271273940802, 0.0012677377089858055, 0.035662345588207245, -0.0008410429581999779, -0.022754300385713577, -0.026448791846632957, -0.013995904475450516, -0.0022758401464670897, -0.013856747187674046]
    Last 10:  [0.0028572631999850273, -7.190450560301542e-06, -0.025598108768463135, 0.002208554185926914, 0.004026091191917658, 3.731984179466963e-06, 0.000786306569352746, -0.00026517288642935455, -0.000956143019720912, -0.00013687252067029476]
  WEIGHT: [768, 1152] | μ=-0.000010

111_layers.6.mlp: layers.6.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.034622 σ=3.463174
    First 10: [6.335306644439697, -1.2191983461380005, 0.19111695885658264, -0.6245304942131042, -3.5758559703826904, -3.412169933319092, 0.8097769618034363, -1.4809818267822266, -2.6800763607025146, 2.2008230686187744]
    Last 10:  [-0.2907072603702545, -0.3628469705581665, -0.030519932508468628, 0.11293632537126541, 0.46893978118896484, 0.5486366152763367, -1.6361842155456543, -1.174567461013794, 0.04772033542394638, -0.8848674893379211]
  OUT[0]: [1, 7, 768] | μ=-0.000629 σ=0.057071
    First 10: [0.00634501688182354, 0.004376271273940802, 0.0012677377089858055, 0.035662345588207245, -0.0008410429581999779, -0.022754300385713577, -0.026448791846632957, -0.013995904475450516, -0.0022758401464670897, -0.013856747187674046]
    Last 10:  [0.0028572631999850273, -7.190450560301542e-06, -0.025598108768463135, 0.002208554185926914, 0.004026091191917658, 3.731984179466963e-06, 0.000786306569352746, -0.00026517288642935455, -0.000956143019720912, -0.00013687252067029476]

112_layers.6.post_feedforward_layernorm: layers.6.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000629 σ=0.057071
    First 10: [0.00634501688182354, 0.004376271273940802, 0.0012677377089858055, 0.035662345588207245, -0.0008410429581999779, -0.022754300385713577, -0.026448791846632957, -0.013995904475450516, -0.0022758401464670897, -0.013856747187674046]
    Last 10:  [0.0028572631999850273, -7.190450560301542e-06, -0.025598108768463135, 0.002208554185926914, 0.004026091191917658, 3.731984179466963e-06, 0.000786306569352746, -0.00026517288642935455, -0.000956143019720912, -0.00013687252067029476]
  OUT[0]: [1, 7, 768] | μ=-0.216741 σ=24.623375
    First 10: [2.419426679611206, 0.5197418332099915, 0.02015558071434498, 0.32179951667785645, -0.16849274933338165, -4.366389751434326, -0.36000385880470276, -0.17356623709201813, -0.4994187653064728, -3.1046905517578125]
    Last 10:  [0.4658999741077423, -0.0014572901418432593, -0.4041871726512909, 4.263004779815674, 7.978884696960449, 0.004802596289664507, 1.3551628589630127, -0.3614208698272705, -1.2833293676376343, -0.24761907756328583]
  WEIGHT: [768] | μ=4.815946

113_layers.7.input_layernorm: layers.7.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.428381 σ=20.526878
    First 10: [66.5541763305664, -0.47504764795303345, 0.1253722757101059, -0.016471117734909058, -4.334195613861084, -8.326054573059082, 0.15508869290351868, -1.041557788848877, -3.8308358192443848, -0.03508186340332031]
    Last 10:  [-0.19550767540931702, -0.7314616441726685, -0.4703826904296875, 5.375832557678223, 10.574013710021973, 2.4566919803619385, -6.898772239685059, -10.900177955627441, -1.0536373853683472, -6.451746463775635]
  OUT[0]: [1, 7, 768] | μ=-0.133090 σ=7.411880
    First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
    Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
  WEIGHT: [768] | μ=28.588394

114_layers.7.self_attn.q_proj: layers.7.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.133090 σ=7.411880
    First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
    Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
  OUT[0]: [1, 7, 768] | μ=0.003301 σ=2.606306
    First 10: [-4.223196029663086, -0.5169938206672668, 3.632781505584717, 2.9991183280944824, -2.431966781616211, -2.573936700820923, -6.604992866516113, -3.9174771308898926, -0.954897940158844, -2.7613744735717773]
    Last 10:  [0.6811474561691284, -1.5387005805969238, 0.057238832116127014, 1.8257091045379639, -0.1769227385520935, 0.88812255859375, 0.38037705421447754, -0.8882836103439331, 0.27367228269577026, 0.24918851256370544]
  WEIGHT: [768, 768] | μ=-0.000019

115_layers.7.self_attn.k_proj: layers.7.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.133090 σ=7.411880
    First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
    Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
  OUT[0]: [1, 7, 256] | μ=-0.146019 σ=3.185627
    First 10: [-3.815772533416748, -0.7051448225975037, 0.1709478497505188, 0.5272495746612549, -0.05298486351966858, -5.23608922958374, -2.343763589859009, -0.5868213772773743, -2.9956228733062744, 1.9162503480911255]
    Last 10:  [-0.7095701098442078, 3.136915683746338, -0.07073283195495605, 3.576366901397705, 0.6303370594978333, -4.247355937957764, 0.9756876826286316, 1.5503613948822021, -0.0047494471073150635, 5.394392490386963]
  WEIGHT: [256, 768] | μ=0.000031

116_layers.7.self_attn.v_proj: layers.7.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.133090 σ=7.411880
    First 10: [18.515033721923828, -0.6753665804862976, 0.33255743980407715, -0.036425452679395676, -4.024686336517334, -6.901650428771973, 0.3619687259197235, -2.5901646614074707, -2.8638815879821777, -0.026763714849948883]
    Last 10:  [-0.6167663931846619, -2.2459304332733154, -1.0387873649597168, 3.1819064617156982, 7.367425441741943, 2.0479018688201904, -4.832546234130859, -7.024925708770752, -0.8707630038261414, -4.6910810470581055]
  OUT[0]: [1, 7, 256] | μ=-0.053327 σ=1.597128
    First 10: [0.4400979280471802, -0.5012692213058472, -0.14221903681755066, 0.387668639421463, 0.194087415933609, -0.8690145015716553, -0.13597248494625092, -0.7789811491966248, -0.6410876512527466, -0.627556562423706]
    Last 10:  [-0.07089030742645264, -1.3574899435043335, -2.1258625984191895, 1.5627870559692383, 0.5206422805786133, 0.8376187682151794, 1.5522445440292358, -1.0755716562271118, -0.5039283037185669, -2.0208306312561035]
  WEIGHT: [256, 768] | μ=-0.000015

117_layers.7.self_attn.q_norm: layers.7.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.003301 σ=2.606306
    First 10: [-4.223196029663086, -0.5169938206672668, 3.632781505584717, 2.9991183280944824, -2.431966781616211, -2.573936700820923, -6.604992866516113, -3.9174771308898926, -0.954897940158844, -2.7613744735717773]
    Last 10:  [0.6811474561691284, -1.5387005805969238, 0.057238832116127014, 1.8257091045379639, -0.1769227385520935, 0.88812255859375, 0.38037705421447754, -0.8882836103439331, 0.27367228269577026, 0.24918851256370544]
  OUT[0]: [1, 3, 7, 256] | μ=-0.010468 σ=0.992830
    First 10: [-0.848550021648407, 0.011364876292645931, 2.426466226577759, 1.6333039999008179, -2.545416831970215, -0.6489803194999695, -1.028720736503601, -2.387176513671875, -0.4872666895389557, -1.3402745723724365]
    Last 10:  [0.35203149914741516, -0.8567473292350769, 0.024089345708489418, 1.2759817838668823, -0.11965087801218033, 0.6047213077545166, 0.3154619634151459, -0.5101438760757446, 0.1904856413602829, 0.11584224551916122]
  WEIGHT: [256] | μ=0.195412

118_layers.7.self_attn.k_norm: layers.7.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.146019 σ=3.185627
    First 10: [-3.815772533416748, -0.7051448225975037, 0.1709478497505188, 0.5272495746612549, -0.05298486351966858, -5.23608922958374, -2.343763589859009, -0.5868213772773743, -2.9956228733062744, 1.9162503480911255]
    Last 10:  [-0.7095701098442078, 3.136915683746338, -0.07073283195495605, 3.576366901397705, 0.6303370594978333, -4.247355937957764, 0.9756876826286316, 1.5503613948822021, -0.0047494471073150635, 5.394392490386963]
  OUT[0]: [1, 1, 7, 256] | μ=-0.050059 σ=1.533870
    First 10: [-1.7176523208618164, -0.16750359535217285, 0.0704079419374466, 0.22107620537281036, -0.030606655403971672, -1.5295729637145996, -1.2169368267059326, -0.3119720220565796, -1.052018404006958, 0.7318155765533447]
    Last 10:  [-0.35902321338653564, 1.1994738578796387, -0.045408234000205994, 1.1816037893295288, 0.2743886113166809, -1.1580835580825806, 0.32961520552635193, 0.725878119468689, -0.0019792956300079823, 2.4584474563598633]
  WEIGHT: [256] | μ=0.555092

119_layers.7.self_attn.o_proj: layers.7.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.016267 σ=0.974338
    First 10: [0.4400979280471802, -0.5012692213058472, -0.14221903681755066, 0.387668639421463, 0.194087415933609, -0.8690145015716553, -0.13597248494625092, -0.7789811491966248, -0.6410876512527466, -0.627556562423706]
    Last 10:  [-0.5475466847419739, -0.3356672525405884, -0.2727785110473633, -1.240326166152954, -0.569685161113739, 1.0148969888687134, -0.43601930141448975, -0.7802430391311646, 0.5486963391304016, 0.5103546380996704]
  OUT[0]: [1, 7, 768] | μ=0.006377 σ=0.361557
    First 10: [0.4419093430042267, -0.11456971615552902, -0.7630380392074585, 0.34656599164009094, 0.14343559741973877, 0.24089360237121582, 0.2682955861091614, 0.4884958565235138, 0.36980965733528137, 0.5119692087173462]
    Last 10:  [-0.42560476064682007, 0.29745689034461975, -0.291105180978775, -0.12519881129264832, -0.25898289680480957, -0.26777029037475586, -0.024022243916988373, 0.5190296769142151, -0.31364119052886963, -0.12858785688877106]
  WEIGHT: [768, 768] | μ=0.000007

120_layers.7.self_attn: layers.7.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.006377 σ=0.361557
    First 10: [0.4419093430042267, -0.11456971615552902, -0.7630380392074585, 0.34656599164009094, 0.14343559741973877, 0.24089360237121582, 0.2682955861091614, 0.4884958565235138, 0.36980965733528137, 0.5119692087173462]
    Last 10:  [-0.42560476064682007, 0.29745689034461975, -0.291105180978775, -0.12519881129264832, -0.25898289680480957, -0.26777029037475586, -0.024022243916988373, 0.5190296769142151, -0.31364119052886963, -0.12858785688877106]

121_layers.7.post_attention_layernorm: layers.7.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.006377 σ=0.361557
    First 10: [0.4419093430042267, -0.11456971615552902, -0.7630380392074585, 0.34656599164009094, 0.14343559741973877, 0.24089360237121582, 0.2682955861091614, 0.4884958565235138, 0.36980965733528137, 0.5119692087173462]
    Last 10:  [-0.42560476064682007, 0.29745689034461975, -0.291105180978775, -0.12519881129264832, -0.25898289680480957, -0.26777029037475586, -0.024022243916988373, 0.5190296769142151, -0.31364119052886963, -0.12858785688877106]
  OUT[0]: [1, 7, 768] | μ=-0.260268 σ=6.522995
    First 10: [7.117562770843506, -1.9654557704925537, -0.15486136078834534, 0.03231007978320122, 1.258903980255127, 3.1706888675689697, 0.03701484203338623, 0.05386624485254288, 4.810990333557129, 8.88559627532959]
    Last 10:  [-0.06615622341632843, 0.08324179798364639, -0.036571159958839417, -1.768336534500122, -4.6586198806762695, -3.3745169639587402, -0.3030528128147125, 5.51243257522583, -2.350674867630005, -2.2881431579589844]
  WEIGHT: [768] | μ=3.568632

122_layers.7.pre_feedforward_layernorm: layers.7.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.688649 σ=22.778650
    First 10: [73.67173767089844, -2.4405033588409424, -0.02948908507823944, 0.01583896204829216, -3.075291633605957, -5.155365943908691, 0.1921035349369049, -0.9876915216445923, 0.9801545143127441, 8.85051441192627]
    Last 10:  [-0.26166391372680664, -0.6482198238372803, -0.5069538354873657, 3.6074960231781006, 5.915393829345703, -0.9178249835968018, -7.201825141906738, -5.387745380401611, -3.4043121337890625, -8.739889144897461]
  OUT[0]: [1, 7, 768] | μ=-0.019878 σ=2.871474
    First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
    Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
  WEIGHT: [768] | μ=12.227965

123_layers.7.mlp.gate_proj: layers.7.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.019878 σ=2.871474
    First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
    Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
  OUT[0]: [1, 7, 1152] | μ=-0.251895 σ=0.531517
    First 10: [0.15232856571674347, -0.25741755962371826, 0.3169572949409485, 0.254840224981308, 0.27500417828559875, 0.3429062068462372, 0.07665270566940308, -0.13700029253959656, -0.30639809370040894, 0.2957385182380676]
    Last 10:  [-0.15574222803115845, -0.11063674092292786, -0.043479375541210175, -0.41014349460601807, 0.11076068878173828, -0.02211076393723488, 0.05155554413795471, -0.25060707330703735, -0.13173255324363708, 0.5366371870040894]
  WEIGHT: [1152, 768] | μ=0.000047

124_layers.7.mlp.act_fn: layers.7.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.251895 σ=0.531517
    First 10: [0.15232856571674347, -0.25741755962371826, 0.3169572949409485, 0.254840224981308, 0.27500417828559875, 0.3429062068462372, 0.07665270566940308, -0.13700029253959656, -0.30639809370040894, 0.2957385182380676]
    Last 10:  [-0.15574222803115845, -0.11063674092292786, -0.043479375541210175, -0.41014349460601807, 0.11076068878173828, -0.02211076393723488, 0.05155554413795471, -0.25060707330703735, -0.13173255324363708, 0.5366371870040894]
  OUT[0]: [1, 7, 1152] | μ=-0.010971 σ=0.225540
    First 10: [0.08538548648357391, -0.10256379842758179, 0.19789299368858337, 0.1530497968196869, 0.16729521751403809, 0.21745508909225464, 0.04066808894276619, -0.06103583797812462, -0.11632699519395828, 0.18225687742233276]
    Last 10:  [-0.0682336762547493, -0.05044511333107948, -0.020985743030905724, -0.13980582356452942, 0.06026449799537659, -0.010860360227525234, 0.026837678626179695, -0.10050945729017258, -0.058963313698768616, 0.3778996169567108]

125_layers.7.mlp.up_proj: layers.7.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.019878 σ=2.871474
    First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
    Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
  OUT[0]: [1, 7, 1152] | μ=-0.014265 σ=0.505875
    First 10: [-0.24799680709838867, 0.6161417365074158, 0.34367406368255615, -0.001232176087796688, -0.125099316239357, 0.1914304494857788, -0.2307918816804886, 0.09608514606952667, 0.17156316339969635, 0.23690165579319]
    Last 10:  [-0.24736300110816956, 0.18767327070236206, 0.1535607874393463, -1.0377447605133057, 0.31615838408470154, 0.3575296700000763, -0.5684059262275696, -0.09489428251981735, -0.24996069073677063, 0.1050192266702652]
  WEIGHT: [1152, 768] | μ=0.000001

126_layers.7.mlp.down_proj: layers.7.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000538 σ=0.136891
    First 10: [-0.021175328642129898, -0.06319383531808853, 0.06801068782806396, -0.00018858429393731058, -0.0209285169839859, 0.04162752628326416, -0.009385865181684494, -0.005864637438207865, -0.01995742693543434, 0.043176956474781036]
    Last 10:  [0.016878487542271614, -0.009467199444770813, -0.0032225872855633497, 0.1450827568769455, 0.019053125753998756, -0.003882901044562459, -0.015254695899784565, 0.009537773206830025, 0.014738510362803936, 0.03968672454357147]
  OUT[0]: [1, 7, 768] | μ=0.000575 σ=0.037296
    First 10: [0.05536491051316261, 0.01840168610215187, 0.008803915232419968, -0.12111048400402069, -0.017574012279510498, -0.005831789691001177, -0.022392939776182175, 0.052352067083120346, 0.026740672066807747, -0.006215983536094427]
    Last 10:  [-0.0012983432970941067, -0.023360606282949448, -0.00026936037465929985, 0.016890205442905426, 0.018106434494256973, 0.007753157988190651, -0.005200939252972603, 0.0007503838278353214, -0.009557616896927357, -0.02597605623304844]
  WEIGHT: [768, 1152] | μ=-0.000001

127_layers.7.mlp: layers.7.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=-0.019878 σ=2.871474
    First 10: [5.967108726501465, -1.359557032585144, -0.03249392658472061, 0.01640396937727928, -1.5030566453933716, -2.4563517570495605, 0.19502107799053192, -1.0604265928268433, 0.424932062625885, 3.4093024730682373]
    Last 10:  [-0.25698012113571167, -0.7100740671157837, -0.47563204169273376, 0.8371800184249878, 1.7164908647537231, -0.3766673803329468, -2.5490689277648926, -1.4917054176330566, -1.447738766670227, -2.46610951423645]
  OUT[0]: [1, 7, 768] | μ=0.000575 σ=0.037296
    First 10: [0.05536491051316261, 0.01840168610215187, 0.008803915232419968, -0.12111048400402069, -0.017574012279510498, -0.005831789691001177, -0.022392939776182175, 0.052352067083120346, 0.026740672066807747, -0.006215983536094427]
    Last 10:  [-0.0012983432970941067, -0.023360606282949448, -0.00026936037465929985, 0.016890205442905426, 0.018106434494256973, 0.007753157988190651, -0.005200939252972603, 0.0007503838278353214, -0.009557616896927357, -0.02597605623304844]

128_layers.7.post_feedforward_layernorm: layers.7.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000575 σ=0.037296
    First 10: [0.05536491051316261, 0.01840168610215187, 0.008803915232419968, -0.12111048400402069, -0.017574012279510498, -0.005831789691001177, -0.022392939776182175, 0.052352067083120346, 0.026740672066807747, -0.006215983536094427]
    Last 10:  [-0.0012983432970941067, -0.023360606282949448, -0.00026936037465929985, 0.016890205442905426, 0.018106434494256973, 0.007753157988190651, -0.005200939252972603, 0.0007503838278353214, -0.009557616896927357, -0.02597605623304844]
  OUT[0]: [1, 7, 768] | μ=1.086789 σ=40.632660
    First 10: [17.59507942199707, 2.7183680534362793, 0.10772810131311417, -0.5726056098937988, -4.0927300453186035, -1.405979037284851, -0.2877838611602783, 0.5575938820838928, 7.603008270263672, -1.7671234607696533]
    Last 10:  [-0.03336841240525246, -0.7911984324455261, -0.0035207299515604973, 7.47305965423584, 8.904891967773438, 2.6661040782928467, -2.3462138175964355, 0.21614669263362885, -2.9964587688446045, -12.301118850708008]
  WEIGHT: [768] | μ=6.747643

129_layers.8.input_layernorm: layers.8.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.398140 σ=49.361523
    First 10: [91.26681518554688, 0.2778646945953369, 0.07823901623487473, -0.5567666292190552, -7.1680216789245605, -6.561345100402832, -0.09568032622337341, -0.43009763956069946, 8.583162307739258, 7.083391189575195]
    Last 10:  [-0.2950323224067688, -1.4394183158874512, -0.5104745626449585, 11.08055591583252, 14.82028579711914, 1.748279094696045, -9.548038482666016, -5.1715989112854, -6.400771141052246, -21.04100799560547]
  OUT[0]: [1, 7, 768] | μ=-0.070726 σ=6.093462
    First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
    Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
  WEIGHT: [768] | μ=25.392935

130_layers.8.self_attn.q_proj: layers.8.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.070726 σ=6.093462
    First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
    Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
  OUT[0]: [1, 7, 768] | μ=0.135690 σ=2.320163
    First 10: [0.23136797547340393, 0.9997062683105469, 0.6384376287460327, -0.3165666162967682, 0.8686844110488892, 0.2633551359176636, -0.7059409022331238, 0.4156378507614136, 0.10963167250156403, -2.074816942214966]
    Last 10:  [-0.4906226396560669, 0.42897266149520874, -0.7689382433891296, 0.019621163606643677, -0.44520220160484314, 0.8766031265258789, 0.3753315806388855, -0.8456871509552002, -0.32136431336402893, -0.6847308874130249]
  WEIGHT: [768, 768] | μ=-0.000036

131_layers.8.self_attn.k_proj: layers.8.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.070726 σ=6.093462
    First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
    Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
  OUT[0]: [1, 7, 256] | μ=0.091760 σ=2.586420
    First 10: [0.2132103443145752, -1.0478852987289429, -0.01173257827758789, 0.5306379795074463, -1.1320075988769531, -0.018470972776412964, 0.002465352416038513, -1.2199022769927979, 0.6086537837982178, -0.1363930106163025]
    Last 10:  [2.486532211303711, 1.8488750457763672, -2.639826774597168, 1.7773514986038208, -0.9401611685752869, 2.1703412532806396, -0.44885122776031494, -2.9708292484283447, -2.3916609287261963, -2.927790641784668]
  WEIGHT: [256, 768] | μ=-0.000025

132_layers.8.self_attn.v_proj: layers.8.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.070726 σ=6.093462
    First 10: [6.030961513519287, 0.11089356988668442, 0.03892610967159271, -0.2919674813747406, -1.6033321619033813, -1.4132435321807861, -0.0447801910340786, -0.19068843126296997, 1.6892589330673218, 1.412129521369934]
    Last 10:  [-0.19873034954071045, -0.9972404837608337, -0.4018235206604004, 2.393507242202759, 3.203411817550659, 0.610568106174469, -2.275845766067505, -1.384764552116394, -2.012239456176758, -5.242753505706787]
  OUT[0]: [1, 7, 256] | μ=0.021070 σ=1.393743
    First 10: [-0.11598235368728638, -0.2668547034263611, -0.6445173621177673, 0.4491630494594574, 0.7806375622749329, 0.30412137508392334, 1.5936214923858643, 0.2586211562156677, 0.2932492196559906, 0.4429655075073242]
    Last 10:  [-0.3856288194656372, -0.10197493433952332, 0.3624061942100525, 0.4622375965118408, -0.0023049991577863693, 0.12164025008678436, -0.20833665132522583, -0.2916319668292999, -0.2909829616546631, -0.23868553340435028]
  WEIGHT: [256, 768] | μ=0.000021

133_layers.8.self_attn.q_norm: layers.8.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.135690 σ=2.320163
    First 10: [0.23136797547340393, 0.9997062683105469, 0.6384376287460327, -0.3165666162967682, 0.8686844110488892, 0.2633551359176636, -0.7059409022331238, 0.4156378507614136, 0.10963167250156403, -2.074816942214966]
    Last 10:  [-0.4906226396560669, 0.42897266149520874, -0.7689382433891296, 0.019621163606643677, -0.44520220160484314, 0.8766031265258789, 0.3753315806388855, -0.8456871509552002, -0.32136431336402893, -0.6847308874130249]
  OUT[0]: [1, 3, 7, 256] | μ=0.052719 σ=1.183598
    First 10: [0.6027870774269104, 1.0836869478225708, 2.5114634037017822, -1.1668769121170044, 0.5611018538475037, 0.6127721667289734, -2.596522808074951, 0.22389104962348938, 0.1934043914079666, -0.9943795800209045]
    Last 10:  [-0.3928007483482361, 0.3771650791168213, -1.1457568407058716, 0.021717574447393417, -0.6592866778373718, 1.3039953708648682, 0.9249271154403687, -0.9633112549781799, -0.5093561410903931, -0.5180079936981201]
  WEIGHT: [256] | μ=0.157315

134_layers.8.self_attn.k_norm: layers.8.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.091760 σ=2.586420
    First 10: [0.2132103443145752, -1.0478852987289429, -0.01173257827758789, 0.5306379795074463, -1.1320075988769531, -0.018470972776412964, 0.002465352416038513, -1.2199022769927979, 0.6086537837982178, -0.1363930106163025]
    Last 10:  [2.486532211303711, 1.8488750457763672, -2.639826774597168, 1.7773514986038208, -0.9401611685752869, 2.1703412532806396, -0.44885122776031494, -2.9708292484283447, -2.3916609287261963, -2.927790641784668]
  OUT[0]: [1, 1, 7, 256] | μ=0.008510 σ=1.761029
    First 10: [0.3069399893283844, -0.48919203877449036, -0.008260846138000488, 0.3655574321746826, -1.212753176689148, -0.020853709429502487, 0.0016939332708716393, -1.7175416946411133, 0.9070112705230713, 0.07263458520174026]
    Last 10:  [2.968484878540039, 2.1207633018493652, -1.700260877609253, 1.2637357711791992, -0.5362961292266846, 0.8655752539634705, -0.17810387909412384, -2.472322702407837, -1.1833361387252808, -2.9109697341918945]
  WEIGHT: [256] | μ=0.589800

135_layers.8.self_attn.o_proj: layers.8.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.014153 σ=0.752103
    First 10: [-0.11598235368728638, -0.2668547034263611, -0.6445173621177673, 0.4491630494594574, 0.7806375622749329, 0.30412137508392334, 1.5936214923858643, 0.2586211562156677, 0.2932492196559906, 0.4429655075073242]
    Last 10:  [-0.002783447504043579, 0.19933781027793884, 0.0705631822347641, 0.4776221215724945, 0.1944543719291687, 0.21020391583442688, 0.19536617398262024, -0.29081830382347107, -0.42075246572494507, -0.4283957779407501]
  OUT[0]: [1, 7, 768] | μ=-0.018979 σ=0.514229
    First 10: [0.1325911581516266, -0.032845638692379, 0.7288525104522705, -1.267212986946106, 0.04053500294685364, 0.038502126932144165, -0.5962883234024048, -1.3378788232803345, -0.26437169313430786, 0.12909261882305145]
    Last 10:  [-1.1305373907089233, 0.034707214683294296, 0.30106058716773987, 0.028965860605239868, -0.29058778285980225, 0.0314028337597847, -0.17769712209701538, 0.04128396138548851, 0.017154958099126816, 0.1695108711719513]
  WEIGHT: [768, 768] | μ=0.000003

136_layers.8.self_attn: layers.8.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.018979 σ=0.514229
    First 10: [0.1325911581516266, -0.032845638692379, 0.7288525104522705, -1.267212986946106, 0.04053500294685364, 0.038502126932144165, -0.5962883234024048, -1.3378788232803345, -0.26437169313430786, 0.12909261882305145]
    Last 10:  [-1.1305373907089233, 0.034707214683294296, 0.30106058716773987, 0.028965860605239868, -0.29058778285980225, 0.0314028337597847, -0.17769712209701538, 0.04128396138548851, 0.017154958099126816, 0.1695108711719513]

137_layers.8.post_attention_layernorm: layers.8.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.018979 σ=0.514229
    First 10: [0.1325911581516266, -0.032845638692379, 0.7288525104522705, -1.267212986946106, 0.04053500294685364, 0.038502126932144165, -0.5962883234024048, -1.3378788232803345, -0.26437169313430786, 0.12909261882305145]
    Last 10:  [-1.1305373907089233, 0.034707214683294296, 0.30106058716773987, 0.028965860605239868, -0.29058778285980225, 0.0314028337597847, -0.17769712209701538, 0.04128396138548851, 0.017154958099126816, 0.1695108711719513]
  OUT[0]: [1, 7, 768] | μ=-1.793263 σ=37.577015
    First 10: [3.828481435775757, -1.5720540285110474, 0.05414615571498871, -0.1097029522061348, 0.9283417463302612, 1.4297144412994385, -0.01246384996920824, 0.011519843712449074, -11.284200668334961, 5.658708095550537]
    Last 10:  [-0.1407741904258728, 0.014473839662969112, 0.058324821293354034, 0.8305338025093079, -12.759029388427734, 1.1014902591705322, -6.195261001586914, 0.8631356954574585, 0.32565122842788696, 7.903704643249512]
  WEIGHT: [768] | μ=11.670672

138_layers.8.pre_feedforward_layernorm: layers.8.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-1.395123 σ=46.813889
    First 10: [95.09529876708984, -1.2941893339157104, 0.13238516449928284, -0.6664695739746094, -6.23967981338501, -5.131630897521973, -0.10814417898654938, -0.41857779026031494, -2.701038360595703, 12.74209976196289]
    Last 10:  [-0.4358065128326416, -1.424944519996643, -0.45214974880218506, 11.911089897155762, 2.0612564086914062, 2.849769353866577, -15.74329948425293, -4.308463096618652, -6.075119972229004, -13.137303352355957]
  OUT[0]: [1, 7, 768] | μ=-0.020318 σ=3.774287
    First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
    Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
  WEIGHT: [768] | μ=25.906479

139_layers.8.mlp.gate_proj: layers.8.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.020318 σ=3.774287
    First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
    Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
  OUT[0]: [1, 7, 1152] | μ=-0.514568 σ=0.835373
    First 10: [0.5354303121566772, -0.04544266685843468, -0.2574884295463562, 0.06807553023099899, -1.2819278240203857, -0.19579574465751648, -0.2545359432697296, 0.6520605087280273, -0.23293167352676392, 0.17520317435264587]
    Last 10:  [-0.5340793132781982, 0.27043259143829346, -0.32156652212142944, -0.021483495831489563, -0.36139512062072754, -0.206824392080307, -0.6822670698165894, -0.6076549887657166, -0.2342354953289032, -0.5878432989120483]
  WEIGHT: [1152, 768] | μ=0.000066

140_layers.8.mlp.act_fn: layers.8.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.514568 σ=0.835373
    First 10: [0.5354303121566772, -0.04544266685843468, -0.2574884295463562, 0.06807553023099899, -1.2819278240203857, -0.19579574465751648, -0.2545359432697296, 0.6520605087280273, -0.23293167352676392, 0.17520317435264587]
    Last 10:  [-0.5340793132781982, 0.27043259143829346, -0.32156652212142944, -0.021483495831489563, -0.36139512062072754, -0.206824392080307, -0.6822670698165894, -0.6076549887657166, -0.2342354953289032, -0.5878432989120483]
  OUT[0]: [1, 7, 1152] | μ=0.001210 σ=0.301526
    First 10: [0.37682658433914185, -0.02189778722822666, -0.10258499532938004, 0.03588514029979706, -0.12833645939826965, -0.0827016606926918, -0.10169880837202072, 0.48431915044784546, -0.09501545131206512, 0.09978491812944412]
    Last 10:  [-0.15845291316509247, 0.1640390157699585, -0.12023395299911499, -0.010557633824646473, -0.12971056997776031, -0.08646838366985321, -0.1689358651638031, -0.16513922810554504, -0.09542874246835709, -0.16363847255706787]

141_layers.8.mlp.up_proj: layers.8.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.020318 σ=3.774287
    First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
    Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
  OUT[0]: [1, 7, 1152] | μ=0.011300 σ=0.768343
    First 10: [-0.17938682436943054, -0.10357041656970978, 0.19779498875141144, -0.19597384333610535, -0.8540266156196594, -0.05134892836213112, -0.2166343629360199, -0.04228357970714569, 0.37728285789489746, -0.41750502586364746]
    Last 10:  [0.4832491874694824, 0.43068334460258484, -0.6291753053665161, -0.04431915283203125, 0.13948316872119904, -0.23257678747177124, 0.14517760276794434, -0.19196799397468567, -0.03350755572319031, -0.542410135269165]
  WEIGHT: [1152, 768] | μ=-0.000000

142_layers.8.mlp.down_proj: layers.8.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.003476 σ=0.259300
    First 10: [-0.06759772449731827, 0.002267963020130992, -0.02029079757630825, -0.007032549008727074, 0.10960274934768677, 0.004246641881763935, 0.022031456232070923, -0.0204787477850914, -0.035847701132297516, -0.04166070371866226]
    Last 10:  [-0.0765722393989563, 0.07064887136220932, 0.075648233294487, 0.0004679053963627666, -0.0180924404412508, 0.020110538229346275, -0.024525703862309456, 0.03170144557952881, 0.0031975838355720043, 0.0887591689825058]
  OUT[0]: [1, 7, 768] | μ=0.000403 σ=0.067837
    First 10: [0.02686716988682747, -0.0061106919310987, 0.024766908958554268, 0.20575492084026337, 0.00869075022637844, -0.014572693966329098, 0.05624259263277054, -0.22964581847190857, 0.012694557197391987, -0.003785832319408655]
    Last 10:  [0.003454180434346199, 0.01679644174873829, 0.015389577485620975, -0.006853911560028791, -0.04134400188922882, 0.03915342688560486, 0.016812633723020554, -0.056042205542325974, 0.000387740321457386, 0.009278018958866596]
  WEIGHT: [768, 1152] | μ=-0.000007

143_layers.8.mlp: layers.8.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=-0.020318 σ=3.774287
    First 10: [8.204497337341309, -0.33019405603408813, 0.12760476768016815, -0.5927627086639404, -1.8904364109039307, -1.365344762802124, -0.08934927731752396, -0.38221853971481323, -0.637097179889679, 2.64886736869812]
    Last 10:  [-0.5153451561927795, -1.8759243488311768, -0.5221496224403381, 2.782146453857422, 0.5063446164131165, 0.88980633020401, -4.441524982452393, -1.213296890258789, -2.425774335861206, -2.8765869140625]
  OUT[0]: [1, 7, 768] | μ=0.000403 σ=0.067837
    First 10: [0.02686716988682747, -0.0061106919310987, 0.024766908958554268, 0.20575492084026337, 0.00869075022637844, -0.014572693966329098, 0.05624259263277054, -0.22964581847190857, 0.012694557197391987, -0.003785832319408655]
    Last 10:  [0.003454180434346199, 0.01679644174873829, 0.015389577485620975, -0.006853911560028791, -0.04134400188922882, 0.03915342688560486, 0.016812633723020554, -0.056042205542325974, 0.000387740321457386, 0.009278018958866596]

144_layers.8.post_feedforward_layernorm: layers.8.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000403 σ=0.067837
    First 10: [0.02686716988682747, -0.0061106919310987, 0.024766908958554268, 0.20575492084026337, 0.00869075022637844, -0.014572693966329098, 0.05624259263277054, -0.22964581847190857, 0.012694557197391987, -0.003785832319408655]
    Last 10:  [0.003454180434346199, 0.01679644174873829, 0.015389577485620975, -0.006853911560028791, -0.04134400188922882, 0.03915342688560486, 0.016812633723020554, -0.056042205542325974, 0.000387740321457386, 0.009278018958866596]
  OUT[0]: [1, 7, 768] | μ=1.279546 σ=31.713074
    First 10: [8.972832679748535, -1.3591588735580444, 0.22021204233169556, 0.2870769202709198, 2.297525644302368, -5.088879585266113, 0.44379329681396484, -0.14892078936100006, 5.111526966094971, -1.518528938293457]
    Last 10:  [0.047995563596487045, 0.3520873486995697, 0.08506133407354355, -2.120387315750122, -16.283430099487305, 12.435527801513672, 6.111661434173584, -11.430350303649902, 0.09647952020168304, 3.720930814743042]
  WEIGHT: [768] | μ=9.239451

145_layers.9.input_layernorm: layers.9.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.115576 σ=59.861839
    First 10: [104.06813049316406, -2.653348207473755, 0.3525972068309784, -0.3793926537036896, -3.9421541690826416, -10.220510482788086, 0.33564913272857666, -0.5674985647201538, 2.4104886054992676, 11.223570823669434]
    Last 10:  [-0.38781094551086426, -1.072857141494751, -0.3670884072780609, 9.790702819824219, -14.222173690795898, 15.285297393798828, -9.631637573242188, -15.738813400268555, -5.978640556335449, -9.416372299194336]
  OUT[0]: [1, 7, 768] | μ=-0.010411 σ=3.120684
    First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
    Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
  WEIGHT: [768] | μ=22.355370

146_layers.9.self_attn.q_proj: layers.9.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.010411 σ=3.120684
    First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
    Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
  OUT[0]: [1, 7, 768] | μ=-0.036152 σ=1.286699
    First 10: [-0.6003598570823669, -0.196706622838974, 0.48577195405960083, -0.1411602795124054, 0.8894214630126953, 1.031860113143921, -0.44488590955734253, 0.22515203058719635, -0.2262679785490036, -0.3262194097042084]
    Last 10:  [-1.1671102046966553, 0.09605583548545837, -0.4668017029762268, 0.22229382395744324, 0.8088752031326294, -0.010314390063285828, -0.5170165300369263, 0.10669933259487152, -0.8704776763916016, -0.29626885056495667]
  WEIGHT: [768, 768] | μ=0.000010

147_layers.9.self_attn.k_proj: layers.9.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.010411 σ=3.120684
    First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
    Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
  OUT[0]: [1, 7, 256] | μ=-0.111561 σ=1.204171
    First 10: [0.07614259421825409, -0.02898043394088745, -1.4051761627197266, -1.140845775604248, 0.0358443483710289, -2.461568832397461, 0.14244864881038666, -0.02645450457930565, -0.22181349992752075, 1.5721005201339722]
    Last 10:  [-2.6710867881774902, -0.45008936524391174, -4.620720863342285, 1.9184460639953613, 5.037489414215088, -3.9948513507843018, -6.398279666900635, -0.45327794551849365, -1.1527889966964722, -1.1172962188720703]
  WEIGHT: [256, 768] | μ=0.000003

148_layers.9.self_attn.v_proj: layers.9.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.010411 σ=3.120684
    First 10: [5.225019931793213, -0.49572840332984924, 0.2400832325220108, -0.22984439134597778, -0.5363993644714355, -1.1266438961029053, 0.15429484844207764, -0.31094133853912354, 0.23951518535614014, 1.1059528589248657]
    Last 10:  [-0.2755195200443268, -1.0067334175109863, -0.21830566227436066, 1.0710899829864502, -1.3551884889602661, 1.8731131553649902, -1.0506439208984375, -2.0473310947418213, -0.9445829391479492, -0.9031105041503906]
  OUT[0]: [1, 7, 256] | μ=-0.027820 σ=0.715945
    First 10: [-0.1266833394765854, 0.5651862621307373, -0.21170511841773987, 0.21897965669631958, 0.04614535719156265, -0.1431199014186859, -0.16944749653339386, -0.11720070242881775, 0.11196364462375641, -0.5168630480766296]
    Last 10:  [0.33685001730918884, -0.04175226390361786, -0.20378762483596802, -0.12236517667770386, 0.43034905195236206, 0.6150254607200623, -0.09351329505443573, -0.1274517923593521, -0.47873109579086304, 0.1678474098443985]
  WEIGHT: [256, 768] | μ=-0.000001

149_layers.9.self_attn.q_norm: layers.9.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.036152 σ=1.286699
    First 10: [-0.6003598570823669, -0.196706622838974, 0.48577195405960083, -0.1411602795124054, 0.8894214630126953, 1.031860113143921, -0.44488590955734253, 0.22515203058719635, -0.2262679785490036, -0.3262194097042084]
    Last 10:  [-1.1671102046966553, 0.09605583548545837, -0.4668017029762268, 0.22229382395744324, 0.8088752031326294, -0.010314390063285828, -0.5170165300369263, 0.10669933259487152, -0.8704776763916016, -0.29626885056495667]
  OUT[0]: [1, 3, 7, 256] | μ=0.021759 σ=1.114739
    First 10: [-0.9820979237556458, -0.38740137219429016, 0.5120255947113037, -0.1884961724281311, 1.1480494737625122, 0.7934421896934509, -0.5135412812232971, 0.4102477431297302, -0.22454996407032013, -0.2853083312511444]
    Last 10:  [-4.042196273803711, 0.19195783138275146, -1.2350518703460693, 1.2575076818466187, 2.2929725646972656, -0.0381360799074173, -1.7126706838607788, 0.35286861658096313, -1.445129156112671, -0.7262293100357056]
  WEIGHT: [256] | μ=0.335935

150_layers.9.self_attn.k_norm: layers.9.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.111561 σ=1.204171
    First 10: [0.07614259421825409, -0.02898043394088745, -1.4051761627197266, -1.140845775604248, 0.0358443483710289, -2.461568832397461, 0.14244864881038666, -0.02645450457930565, -0.22181349992752075, 1.5721005201339722]
    Last 10:  [-2.6710867881774902, -0.45008936524391174, -4.620720863342285, 1.9184460639953613, 5.037489414215088, -3.9948513507843018, -6.398279666900635, -0.45327794551849365, -1.1527889966964722, -1.1172962188720703]
  OUT[0]: [1, 1, 7, 256] | μ=-0.070423 σ=1.604714
    First 10: [0.1284542828798294, -0.04800771176815033, 0.018999001011252403, -0.036068856716156006, 0.04730023443698883, -0.13668940961360931, 0.358690083026886, -0.028695106506347656, -0.5920730233192444, -0.047596827149391174]
    Last 10:  [-2.781630754470825, -0.7288652062416077, -5.126715183258057, 1.350743293762207, 6.757702827453613, -4.069862365722656, -5.858631610870361, -0.5248639583587646, -2.4637506008148193, -1.4181329011917114]
  WEIGHT: [256] | μ=0.429340

151_layers.9.self_attn.o_proj: layers.9.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.041313 σ=0.412007
    First 10: [-0.1266833394765854, 0.5651862621307373, -0.21170511841773987, 0.21897965669631958, 0.04614535719156265, -0.1431199014186859, -0.16944749653339386, -0.11720070242881775, 0.11196364462375641, -0.5168630480766296]
    Last 10:  [0.054611459374427795, 0.14244839549064636, 0.14476999640464783, 0.041322555392980576, 0.2782055139541626, 0.29791146516799927, 0.028671905398368835, -0.01952143758535385, -0.3747113347053528, -0.18747276067733765]
  OUT[0]: [1, 7, 768] | μ=0.000796 σ=0.135285
    First 10: [0.059194568544626236, -0.01699569821357727, 0.2064433991909027, 0.1933930218219757, 0.057044900953769684, 0.07737097144126892, -0.016686849296092987, -0.07431036978960037, 0.02882661670446396, -0.12376612424850464]
    Last 10:  [-0.014843176119029522, -0.0040070172399282455, -0.05649123340845108, 0.09446848928928375, -0.03461406007409096, -0.04676936939358711, 0.0864887535572052, -0.1023760661482811, 0.05060172826051712, 0.04279104620218277]
  WEIGHT: [768, 768] | μ=0.000018

152_layers.9.self_attn: layers.9.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.000796 σ=0.135285
    First 10: [0.059194568544626236, -0.01699569821357727, 0.2064433991909027, 0.1933930218219757, 0.057044900953769684, 0.07737097144126892, -0.016686849296092987, -0.07431036978960037, 0.02882661670446396, -0.12376612424850464]
    Last 10:  [-0.014843176119029522, -0.0040070172399282455, -0.05649123340845108, 0.09446848928928375, -0.03461406007409096, -0.04676936939358711, 0.0864887535572052, -0.1023760661482811, 0.05060172826051712, 0.04279104620218277]

153_layers.9.post_attention_layernorm: layers.9.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000796 σ=0.135285
    First 10: [0.059194568544626236, -0.01699569821357727, 0.2064433991909027, 0.1933930218219757, 0.057044900953769684, 0.07737097144126892, -0.016686849296092987, -0.07431036978960037, 0.02882661670446396, -0.12376612424850464]
    Last 10:  [-0.014843176119029522, -0.0040070172399282455, -0.05649123340845108, 0.09446848928928375, -0.03461406007409096, -0.04676936939358711, 0.0864887535572052, -0.1023760661482811, 0.05060172826051712, 0.04279104620218277]
  OUT[0]: [1, 7, 768] | μ=-0.697687 σ=19.210552
    First 10: [2.941415548324585, -1.8931573629379272, 0.012385942041873932, 0.026006704196333885, 3.3404765129089355, 8.214856147766113, 0.0065179974772036076, -0.02010747231543064, 3.2961103916168213, -16.82527732849121]
    Last 10:  [-0.010513320565223694, -0.0022820960730314255, -0.014650694094598293, 4.835803985595703, -2.7875514030456543, -4.283390522003174, 6.498577117919922, -3.404336929321289, 2.0345542430877686, 4.377447605133057]
  WEIGHT: [768] | μ=8.098214

154_layers.9.pre_feedforward_layernorm: layers.9.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.813263 σ=55.374264
    First 10: [107.0095443725586, -4.546505451202393, 0.36498314142227173, -0.35338595509529114, -0.601677656173706, -2.0056543350219727, 0.3421671390533447, -0.5876060128211975, 5.706599235534668, -5.601706504821777]
    Last 10:  [-0.39832425117492676, -1.0751392841339111, -0.3817391097545624, 14.626506805419922, -17.00972557067871, 11.001907348632812, -3.1330604553222656, -19.143150329589844, -3.9440863132476807, -5.038924694061279]
  OUT[0]: [1, 7, 768] | μ=0.027625 σ=3.104226
    First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
    Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
  WEIGHT: [768] | μ=17.059443

155_layers.9.mlp.gate_proj: layers.9.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.027625 σ=3.104226
    First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
    Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
  OUT[0]: [1, 7, 1152] | μ=-0.316449 σ=0.660543
    First 10: [-0.4384632706642151, -0.6396448016166687, -0.16982899606227875, -0.022782035171985626, -0.03662486374378204, 0.2186051309108734, -0.1946832239627838, -0.6165542602539062, -0.12686212360858917, -0.11507278680801392]
    Last 10:  [0.13568086922168732, 0.6883193850517273, -0.12580080330371857, -0.37565386295318604, -0.39662647247314453, 0.4005763530731201, -0.6241196393966675, -0.027682073414325714, -0.15641900897026062, -0.2170560657978058]
  WEIGHT: [1152, 768] | μ=0.000031

156_layers.9.mlp.act_fn: layers.9.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.316449 σ=0.660543
    First 10: [-0.4384632706642151, -0.6396448016166687, -0.16982899606227875, -0.022782035171985626, -0.03662486374378204, 0.2186051309108734, -0.1946832239627838, -0.6165542602539062, -0.12686212360858917, -0.11507278680801392]
    Last 10:  [0.13568086922168732, 0.6883193850517273, -0.12580080330371857, -0.37565386295318604, -0.39662647247314453, 0.4005763530731201, -0.6241196393966675, -0.027682073414325714, -0.15641900897026062, -0.2170560657978058]
  OUT[0]: [1, 7, 1152] | μ=0.002183 σ=0.246616
    First 10: [-0.1449338048696518, -0.16711735725402832, -0.07346358895301819, -0.01118397619575262, -0.017777418717741966, 0.12821581959724426, -0.08231651037931442, -0.16574397683143616, -0.057027749717235565, -0.05226539447903633]
    Last 10:  [0.07516209781169891, 0.5191980004310608, -0.05660349875688553, -0.13283230364322662, -0.1371692419052124, 0.2626239061355591, -0.16622485220432281, -0.013535368256270885, -0.0684884712100029, -0.08987978100776672]

157_layers.9.mlp.up_proj: layers.9.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.027625 σ=3.104226
    First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
    Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
  OUT[0]: [1, 7, 1152] | μ=-0.008001 σ=0.574858
    First 10: [-0.2237587422132492, 0.34771716594696045, -0.28441405296325684, -0.2070593535900116, 0.09408167749643326, -0.061830081045627594, 0.09338714182376862, -0.40350228548049927, -0.2476229965686798, -0.14350809156894684]
    Last 10:  [0.1811629831790924, -0.24391087889671326, -0.6161313056945801, -0.06923380494117737, -0.08539508283138275, -0.5772427320480347, -0.18432283401489258, 0.15946602821350098, -0.006444871425628662, -0.5001517534255981]
  WEIGHT: [1152, 768] | μ=-0.000011

158_layers.9.mlp.down_proj: layers.9.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.001411 σ=0.156758
    First 10: [0.03243020549416542, -0.058109574019908905, 0.02089407667517662, 0.0023157468531280756, -0.0016725293826311827, -0.00792759470641613, -0.007687303703278303, 0.0668780729174614, 0.014121382497251034, 0.007500506937503815]
    Last 10:  [0.013616589829325676, -0.1266380399465561, 0.034875188022851944, 0.00919648539274931, 0.01171357836574316, -0.1515977382659912, 0.030639035627245903, -0.0021584313362836838, 0.0004413994029164314, 0.04495352879166603]
  OUT[0]: [1, 7, 768] | μ=0.001575 σ=0.039374
    First 10: [0.045741356909275055, 0.010571747086942196, 0.016032230108976364, -0.014087729156017303, -0.01987428590655327, -0.0010112444870173931, 0.026660192757844925, 0.05390277877449989, -0.0020642774179577827, 0.003971022553741932]
    Last 10:  [0.014186738058924675, 0.005833907052874565, 0.006155320908874273, 0.00930024590343237, 0.010828102938830853, 0.008878645487129688, 0.002906620502471924, 0.0022366580087691545, 0.016298720613121986, 0.008661651983857155]
  WEIGHT: [768, 1152] | μ=0.000002

159_layers.9.mlp: layers.9.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.027625 σ=3.104226
    First 10: [7.218198776245117, -0.6133948564529419, 0.20979398488998413, -0.18259437382221222, -0.10072112828493118, -0.26914462447166443, 0.17969243228435516, -0.29222723841667175, 0.6833451390266418, -0.5888895988464355]
    Last 10:  [-0.24467137455940247, -0.6904118061065674, -0.2129317820072174, 1.8019087314605713, -1.7208194732666016, 1.4282748699188232, -0.3917103707790375, -3.015045642852783, -0.682235836982727, -0.5066076517105103]
  OUT[0]: [1, 7, 768] | μ=0.001575 σ=0.039374
    First 10: [0.045741356909275055, 0.010571747086942196, 0.016032230108976364, -0.014087729156017303, -0.01987428590655327, -0.0010112444870173931, 0.026660192757844925, 0.05390277877449989, -0.0020642774179577827, 0.003971022553741932]
    Last 10:  [0.014186738058924675, 0.005833907052874565, 0.006155320908874273, 0.00930024590343237, 0.010828102938830853, 0.008878645487129688, 0.002906620502471924, 0.0022366580087691545, 0.016298720613121986, 0.008661651983857155]

160_layers.9.post_feedforward_layernorm: layers.9.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.001575 σ=0.039374
    First 10: [0.045741356909275055, 0.010571747086942196, 0.016032230108976364, -0.014087729156017303, -0.01987428590655327, -0.0010112444870173931, 0.026660192757844925, 0.05390277877449989, -0.0020642774179577827, 0.003971022553741932]
    Last 10:  [0.014186738058924675, 0.005833907052874565, 0.006155320908874273, 0.00930024590343237, 0.010828102938830853, 0.008878645487129688, 0.002906620502471924, 0.0022366580087691545, 0.016298720613121986, 0.008661651983857155]
  OUT[0]: [1, 7, 768] | μ=1.487013 σ=38.032009
    First 10: [28.49126434326172, 8.671907424926758, 0.16775557398796082, -0.061303965747356415, -13.13699722290039, -1.1041773557662964, 0.14295276999473572, 0.10914087295532227, -2.3340344429016113, 5.011218070983887]
    Last 10:  [0.20864500105381012, 0.1285853236913681, 0.04285602644085884, 6.248290061950684, 10.558403015136719, 9.18568229675293, 2.8715615272521973, 0.9648259878158569, 9.390739440917969, 9.8519868850708]
  WEIGHT: [768] | μ=12.372260

161_layers.10.input_layernorm: layers.10.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.673750 σ=78.747818
    First 10: [135.5008087158203, 4.125401973724365, 0.5327386856079102, -0.41468992829322815, -13.738675117492676, -3.1098318099975586, 0.48511990904808044, -0.47846513986587524, 3.3725647926330566, -0.5904884338378906]
    Last 10:  [-0.18967925012111664, -0.9465539455413818, -0.33888307213783264, 20.874797821044922, -6.451322555541992, 20.187589645385742, -0.26149892807006836, -18.17832374572754, 5.446653366088867, 4.8130621910095215]
  OUT[0]: [1, 7, 768] | μ=0.032235 σ=4.787254
    First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
    Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
  WEIGHT: [768] | μ=26.779985

162_layers.10.self_attn.q_proj: layers.10.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.032235 σ=4.787254
    First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
    Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
  OUT[0]: [1, 7, 768] | μ=-0.018493 σ=1.657976
    First 10: [-1.0678211450576782, -0.0728258490562439, 0.2084197998046875, -0.5983860492706299, -0.40541839599609375, 0.8403134942054749, 0.176253080368042, 0.6481025815010071, -0.6037862300872803, -2.895703077316284]
    Last 10:  [0.47437429428100586, -0.7743321061134338, 0.18208062648773193, -0.43556734919548035, -0.10939088463783264, -0.34626132249832153, -0.005111187696456909, 0.42120182514190674, -0.26664215326309204, -0.3194923400878906]
  WEIGHT: [768, 768] | μ=0.000011

163_layers.10.self_attn.k_proj: layers.10.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.032235 σ=4.787254
    First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
    Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
  OUT[0]: [1, 7, 256] | μ=-0.008436 σ=2.068873
    First 10: [0.5706704258918762, 0.15423715114593506, 0.4762849509716034, 0.536907970905304, -0.32628747820854187, 0.17519299685955048, 0.8784173727035522, 0.6061020493507385, -1.8863917589187622, 0.39095327258110046]
    Last 10:  [1.0912690162658691, 0.3328990042209625, 1.3697811365127563, -0.9509172439575195, -0.9190304279327393, -1.8802253007888794, 0.9496269226074219, -0.019326239824295044, 0.2780712842941284, 2.5585649013519287]
  WEIGHT: [256, 768] | μ=0.000014

164_layers.10.self_attn.v_proj: layers.10.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.032235 σ=4.787254
    First 10: [8.839815139770508, 0.4481425881385803, 0.4173068106174469, -0.49339571595191956, -1.738417625427246, -0.27897027134895325, 0.3306654691696167, -0.33460208773612976, 0.2636586129665375, -0.044576290994882584]
    Last 10:  [-0.09065646678209305, -0.45614495873451233, -0.36000341176986694, 1.7950009107589722, -0.4329400360584259, 1.7454429864883423, -0.020330760627985, -2.0308403968811035, 0.6330615878105164, 0.3481471538543701]
  OUT[0]: [1, 7, 256] | μ=0.008511 σ=1.147287
    First 10: [-0.6150282025337219, 1.076550006866455, -0.5600451231002808, -0.01631423830986023, -0.0039937421679496765, 0.7776657342910767, 1.303105354309082, 0.24787095189094543, -0.17604845762252808, -0.26193928718566895]
    Last 10:  [0.04848024621605873, 0.0865318775177002, -0.20355474948883057, 0.32468870282173157, -0.022418759763240814, -0.4204830527305603, -0.026636749505996704, -0.14448118209838867, -0.17191867530345917, -0.0009204372763633728]
  WEIGHT: [256, 768] | μ=-0.000001

165_layers.10.self_attn.q_norm: layers.10.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.018493 σ=1.657976
    First 10: [-1.0678211450576782, -0.0728258490562439, 0.2084197998046875, -0.5983860492706299, -0.40541839599609375, 0.8403134942054749, 0.176253080368042, 0.6481025815010071, -0.6037862300872803, -2.895703077316284]
    Last 10:  [0.47437429428100586, -0.7743321061134338, 0.18208062648773193, -0.43556734919548035, -0.10939088463783264, -0.34626132249832153, -0.005111187696456909, 0.42120182514190674, -0.26664215326309204, -0.3194923400878906]
  OUT[0]: [1, 3, 7, 256] | μ=0.025527 σ=1.441827
    First 10: [-2.7014760971069336, -0.1867826133966446, 0.4201945662498474, -1.0601913928985596, -0.7861958742141724, 1.4781757593154907, 0.12446189671754837, 0.9691815972328186, -0.41361117362976074, 0.21886485815048218]
    Last 10:  [0.41678810119628906, -0.48910075426101685, 0.10557984560728073, -0.2644821107387543, -0.11311029642820358, -0.13131028413772583, -0.004373955074697733, 0.30115199089050293, -0.22703143954277039, -0.17774012684822083]
  WEIGHT: [256] | μ=0.297345

166_layers.10.self_attn.k_norm: layers.10.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.008436 σ=2.068873
    First 10: [0.5706704258918762, 0.15423715114593506, 0.4762849509716034, 0.536907970905304, -0.32628747820854187, 0.17519299685955048, 0.8784173727035522, 0.6061020493507385, -1.8863917589187622, 0.39095327258110046]
    Last 10:  [1.0912690162658691, 0.3328990042209625, 1.3697811365127563, -0.9509172439575195, -0.9190304279327393, -1.8802253007888794, 0.9496269226074219, -0.019326239824295044, 0.2780712842941284, 2.5585649013519287]
  OUT[0]: [1, 1, 7, 256] | μ=0.039321 σ=2.487803
    First 10: [0.22347848117351532, 0.10667050629854202, 0.328497976064682, 0.303237646818161, -0.17876030504703522, 0.1927831768989563, 1.4777112007141113, 0.4528779983520508, -0.7190179228782654, 0.16522181034088135]
    Last 10:  [1.5787482261657715, 0.7135182619094849, 3.0485377311706543, -2.0072104930877686, -1.1388312578201294, -6.211282253265381, 1.4778177738189697, -0.029452254995703697, 0.37079107761383057, 5.3479790687561035]
  WEIGHT: [256] | μ=1.076180

167_layers.10.self_attn.o_proj: layers.10.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.005636 σ=0.639963
    First 10: [-0.6150282025337219, 1.076550006866455, -0.5600451231002808, -0.01631423830986023, -0.0039937421679496765, 0.7776657342910767, 1.303105354309082, 0.24787095189094543, -0.17604845762252808, -0.26193928718566895]
    Last 10:  [-0.22523105144500732, 0.18859215080738068, 0.21379142999649048, 0.019026361405849457, -0.1339663863182068, -0.06691275537014008, -0.15701518952846527, -0.09413884580135345, 0.18972241878509521, -0.028892191126942635]
  OUT[0]: [1, 7, 768] | μ=0.003449 σ=0.323051
    First 10: [-0.01422254741191864, -0.2069137990474701, -0.23555901646614075, -0.3846706748008728, 0.0008076075464487076, 0.05993238463997841, 0.8263041973114014, 0.6470094919204712, -0.2453005611896515, 0.03419297933578491]
    Last 10:  [-0.04648622125387192, 0.07606767117977142, 0.03814473748207092, 0.04050071910023689, -0.05014830827713013, 0.13038089871406555, 0.0059653595089912415, -0.12078195810317993, -0.19959163665771484, 0.11028923094272614]
  WEIGHT: [768, 768] | μ=-0.000006

168_layers.10.self_attn: layers.10.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.003449 σ=0.323051
    First 10: [-0.01422254741191864, -0.2069137990474701, -0.23555901646614075, -0.3846706748008728, 0.0008076075464487076, 0.05993238463997841, 0.8263041973114014, 0.6470094919204712, -0.2453005611896515, 0.03419297933578491]
    Last 10:  [-0.04648622125387192, 0.07606767117977142, 0.03814473748207092, 0.04050071910023689, -0.05014830827713013, 0.13038089871406555, 0.0059653595089912415, -0.12078195810317993, -0.19959163665771484, 0.11028923094272614]

169_layers.10.post_attention_layernorm: layers.10.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.003449 σ=0.323051
    First 10: [-0.01422254741191864, -0.2069137990474701, -0.23555901646614075, -0.3846706748008728, 0.0008076075464487076, 0.05993238463997841, 0.8263041973114014, 0.6470094919204712, -0.2453005611896515, 0.03419297933578491]
    Last 10:  [-0.04648622125387192, 0.07606767117977142, 0.03814473748207092, 0.04050071910023689, -0.05014830827713013, 0.13038089871406555, 0.0059653595089912415, -0.12078195810317993, -0.19959163665771484, 0.11028923094272614]
  OUT[0]: [1, 7, 768] | μ=-0.646258 σ=22.548883
    First 10: [-0.3770410418510437, -43.31430435180664, 0.062326934188604355, -0.06573646515607834, 0.03056534379720688, 4.2708740234375, -0.1401454210281372, 0.06057007983326912, -17.10334587097168, 3.1395158767700195]
    Last 10:  [-0.010127308778464794, 0.03528875857591629, -0.01420315820723772, 1.891629934310913, -5.118750095367432, 19.320446014404297, 0.5046502351760864, -3.964210033416748, -8.750176429748535, 11.845114707946777]
  WEIGHT: [768] | μ=18.129446

170_layers.10.pre_feedforward_layernorm: layers.10.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.027492 σ=69.936043
    First 10: [135.12376403808594, -39.18890380859375, 0.5950655937194824, -0.4804264008998871, -13.708109855651855, 1.1610422134399414, 0.34497448801994324, -0.41789504885673523, -13.730781555175781, 2.549027442932129]
    Last 10:  [-0.1998065561056137, -0.9112651944160461, -0.3530862331390381, 22.766427993774414, -11.570072174072266, 39.508033752441406, 0.24315130710601807, -22.142534255981445, -3.303523063659668, 16.65817642211914]
  OUT[0]: [1, 7, 768] | μ=0.022425 σ=1.806885
    First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
    Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
  WEIGHT: [768] | μ=10.723625

171_layers.10.mlp.gate_proj: layers.10.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.022425 σ=1.806885
    First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
    Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
  OUT[0]: [1, 7, 1152] | μ=-0.142018 σ=0.405221
    First 10: [0.08816401660442352, -0.0607757605612278, -0.10053574293851852, -0.14158545434474945, 0.08552953600883484, -0.216712087392807, -0.06933435052633286, -0.017048589885234833, -0.14203928411006927, -0.14726318418979645]
    Last 10:  [-0.08458366990089417, 0.08225631713867188, 0.3171066343784332, -0.2373175472021103, -0.298464834690094, 0.057482603937387466, 0.015380747616291046, -0.2755654454231262, -0.3339303135871887, -0.20978350937366486]
  WEIGHT: [1152, 768] | μ=0.000031

172_layers.10.mlp.act_fn: layers.10.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.142018 σ=0.405221
    First 10: [0.08816401660442352, -0.0607757605612278, -0.10053574293851852, -0.14158545434474945, 0.08552953600883484, -0.216712087392807, -0.06933435052633286, -0.017048589885234833, -0.14203928411006927, -0.14726318418979645]
    Last 10:  [-0.08458366990089417, 0.08225631713867188, 0.3171066343784332, -0.2373175472021103, -0.298464834690094, 0.057482603937387466, 0.015380747616291046, -0.2755654454231262, -0.3339303135871887, -0.20978350937366486]
  OUT[0]: [1, 7, 1152] | μ=-0.011080 σ=0.139327
    First 10: [0.04717891290783882, -0.028915222734212875, -0.046242404729127884, -0.062822125852108, 0.04567958042025566, -0.08976639807224274, -0.03275090456008911, -0.008408346213400364, -0.06299803406000137, -0.06501127034425735]
    Last 10:  [-0.0394410602748394, 0.04382438585162163, 0.19800420105457306, -0.09640063345432281, -0.11421724408864975, 0.03005877695977688, 0.007784746587276459, -0.10786939412355423, -0.12329622358083725, -0.08746320754289627]

173_layers.10.mlp.up_proj: layers.10.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.022425 σ=1.806885
    First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
    Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
  OUT[0]: [1, 7, 1152] | μ=0.003523 σ=0.297430
    First 10: [-0.07381104677915573, -0.20803222060203552, 0.21475844085216522, -0.12599027156829834, -0.07823003828525543, -0.008628346025943756, -0.14163535833358765, 0.01524711400270462, -0.07757746428251266, -0.007031451910734177]
    Last 10:  [-0.02409861423075199, -0.22197870910167694, 0.34128910303115845, -0.2067723423242569, -0.2064887434244156, -0.06914513558149338, -0.10537631809711456, -0.07425980269908905, -0.038289640098810196, -0.1352376639842987]
  WEIGHT: [1152, 768] | μ=-0.000006

174_layers.10.mlp.down_proj: layers.10.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.000449 σ=0.048832
    First 10: [-0.003482325002551079, 0.006015297956764698, -0.009930946864187717, 0.00791497714817524, -0.0035735152196139097, 0.0007745355251245201, 0.0046386863104999065, -0.000128203013446182, 0.004887227900326252, 0.0004571236204355955]
    Last 10:  [0.0009504748741164804, -0.009728080593049526, 0.06757667660713196, 0.019932985305786133, 0.023584574460983276, -0.002078418154269457, -0.0008203279576264322, 0.008010359480977058, 0.004720968194305897, 0.011828320100903511]
  OUT[0]: [1, 7, 768] | μ=0.000543 σ=0.013593
    First 10: [0.010458292439579964, 0.000565237132832408, -0.001533660339191556, 0.010764668695628643, -0.0020619195420295, 0.0011394532630220056, 0.006673688068985939, 0.004166203085333109, 0.006167241837829351, 0.0011687192600220442]
    Last 10:  [0.0003994796425104141, 0.0008639742154628038, -0.004224345553666353, 0.0021077936980873346, -0.002784663811326027, 0.001395173603668809, 0.0002562707522884011, -0.0025051215197890997, 0.0015519093722105026, -0.0022064035292714834]
  WEIGHT: [768, 1152] | μ=0.000000

175_layers.10.mlp: layers.10.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.022425 σ=1.806885
    First 10: [4.137228965759277, -0.9052891135215759, 0.1936635822057724, -0.1719788759946823, -0.7593662738800049, 0.04277887940406799, 0.09837104380130768, -0.11751110106706619, -0.47928979992866516, 0.08048207312822342]
    Last 10:  [-0.0652768686413765, -0.28229403495788574, -0.13560228049755096, 0.8954299092292786, -0.37547338008880615, 1.2572715282440186, 0.008261208422482014, -1.2631416320800781, -0.17223134636878967, 0.4815542995929718]
  OUT[0]: [1, 7, 768] | μ=0.000543 σ=0.013593
    First 10: [0.010458292439579964, 0.000565237132832408, -0.001533660339191556, 0.010764668695628643, -0.0020619195420295, 0.0011394532630220056, 0.006673688068985939, 0.004166203085333109, 0.006167241837829351, 0.0011687192600220442]
    Last 10:  [0.0003994796425104141, 0.0008639742154628038, -0.004224345553666353, 0.0021077936980873346, -0.002784663811326027, 0.001395173603668809, 0.0002562707522884011, -0.0025051215197890997, 0.0015519093722105026, -0.0022064035292714834]

176_layers.10.post_feedforward_layernorm: layers.10.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000543 σ=0.013593
    First 10: [0.010458292439579964, 0.000565237132832408, -0.001533660339191556, 0.010764668695628643, -0.0020619195420295, 0.0011394532630220056, 0.006673688068985939, 0.004166203085333109, 0.006167241837829351, 0.0011687192600220442]
    Last 10:  [0.0003994796425104141, 0.0008639742154628038, -0.004224345553666353, 0.0021077936980873346, -0.002784663811326027, 0.001395173603668809, 0.0002562707522884011, -0.0025051215197890997, 0.0015519093722105026, -0.0022064035292714834]
  OUT[0]: [1, 7, 768] | μ=0.328299 σ=37.294270
    First 10: [34.12296676635742, 3.6017274856567383, -0.04993508756160736, -0.012380721047520638, -7.4208784103393555, 7.338292598724365, 0.2408878058195114, 0.09581567347049713, 39.18910217285156, 8.297354698181152]
    Last 10:  [0.04290032386779785, 0.14453132450580597, -0.21473000943660736, 12.157130241394043, -27.347509384155273, 17.710033416748047, 2.6461753845214844, -10.201940536499023, 8.61826229095459, -26.83121681213379]
  WEIGHT: [768] | μ=18.728531

177_layers.11.input_layernorm: layers.11.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.355791 σ=82.082832
    First 10: [169.24673461914062, -35.58717727661133, 0.5451304912567139, -0.4928071200847626, -21.12898826599121, 8.499334335327148, 0.5858622789382935, -0.3220793604850769, 25.45832061767578, 10.846382141113281]
    Last 10:  [-0.15690623223781586, -0.7667338848114014, -0.5678162574768066, 34.92355728149414, -38.917579650878906, 57.21806716918945, 2.889326572418213, -32.34447479248047, 5.314739227294922, -10.173040390014648]
  OUT[0]: [1, 7, 768] | μ=-0.006655 σ=1.573720
    First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
    Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
  WEIGHT: [768] | μ=18.237368

178_layers.11.self_attn.q_proj: layers.11.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.006655 σ=1.573720
    First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
    Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
  OUT[0]: [1, 7, 768] | μ=0.001039 σ=0.611310
    First 10: [-0.09156732261180878, 0.3459119200706482, 0.19846586883068085, -0.48402148485183716, -0.23424744606018066, 0.19631995260715485, 0.04110550880432129, 0.23962023854255676, -0.30840134620666504, 0.15131571888923645]
    Last 10:  [0.26486700773239136, 0.24146471917629242, -0.4796066880226135, 0.42644205689430237, 0.43191808462142944, -0.3650445342063904, -0.37736809253692627, 0.23516127467155457, 0.2788996696472168, 0.1399633288383484]
  WEIGHT: [768, 768] | μ=0.000003

179_layers.11.self_attn.k_proj: layers.11.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.006655 σ=1.573720
    First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
    Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
  OUT[0]: [1, 7, 256] | μ=0.027585 σ=0.472891
    First 10: [0.046045608818531036, 0.1744554191827774, 0.012274806387722492, 0.2555646300315857, 0.1650231033563614, 0.09937448799610138, 0.10243315994739532, 0.15716998279094696, -0.03965344280004501, -0.03249487280845642]
    Last 10:  [0.19297710061073303, -0.05566868185997009, -1.6119849681854248, 1.1931569576263428, 1.0026549100875854, -1.2613270282745361, -1.1065199375152588, 0.5563743114471436, 1.1152448654174805, 0.9930656552314758]
  WEIGHT: [256, 768] | μ=0.000011

180_layers.11.self_attn.v_proj: layers.11.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.006655 σ=1.573720
    First 10: [1.8347408771514893, -0.374031662940979, 0.24103686213493347, -0.2637021243572235, -0.18145005404949188, 0.05340665578842163, 0.2633401155471802, -0.14052537083625793, 0.14432500302791595, 0.06402083486318588]
    Last 10:  [-0.13659825921058655, -0.5171864628791809, -0.6519793272018433, 0.7310874462127686, -0.8594019412994385, 0.947557270526886, 0.0321175679564476, -1.1887410879135132, 0.10344541817903519, -0.12487587332725525]
  OUT[0]: [1, 7, 256] | μ=0.001210 σ=0.330970
    First 10: [-0.15349380671977997, 0.00564942229539156, -0.005607791244983673, 0.0222473181784153, 0.05821211263537407, -0.056732892990112305, -0.18139448761940002, -0.012423541396856308, 0.08332851529121399, 0.06380753964185715]
    Last 10:  [-0.3696819543838501, 0.11895468831062317, 0.1926790177822113, 0.2663939297199249, -0.2067018449306488, -0.058590829372406006, 0.03164631128311157, 0.1266070455312729, 0.14239056408405304, -0.2026577591896057]
  WEIGHT: [256, 768] | μ=-0.000010

181_layers.11.self_attn.q_norm: layers.11.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.001039 σ=0.611310
    First 10: [-0.09156732261180878, 0.3459119200706482, 0.19846586883068085, -0.48402148485183716, -0.23424744606018066, 0.19631995260715485, 0.04110550880432129, 0.23962023854255676, -0.30840134620666504, 0.15131571888923645]
    Last 10:  [0.26486700773239136, 0.24146471917629242, -0.4796066880226135, 0.42644205689430237, 0.43191808462142944, -0.3650445342063904, -0.37736809253692627, 0.23516127467155457, 0.2788996696472168, 0.1399633288383484]
  OUT[0]: [1, 3, 7, 256] | μ=0.022283 σ=1.210421
    First 10: [-0.8192920088768005, -0.04526694118976593, 4.827511787414551, 0.056779589504003525, 0.04163285717368126, 2.775134563446045, 0.9300568103790283, 3.391101598739624, -0.04886486008763313, 0.041965629905462265]
    Last 10:  [0.3099839985370636, 0.3441033363342285, -0.760554313659668, 4.6932291984558105, 0.45289933681488037, -0.49922868609428406, -0.40257394313812256, 0.22047704458236694, 0.4309048354625702, 0.20892184972763062]
  WEIGHT: [256] | μ=0.380387

182_layers.11.self_attn.k_norm: layers.11.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.027585 σ=0.472891
    First 10: [0.046045608818531036, 0.1744554191827774, 0.012274806387722492, 0.2555646300315857, 0.1650231033563614, 0.09937448799610138, 0.10243315994739532, 0.15716998279094696, -0.03965344280004501, -0.03249487280845642]
    Last 10:  [0.19297710061073303, -0.05566868185997009, -1.6119849681854248, 1.1931569576263428, 1.0026549100875854, -1.2613270282745361, -1.1065199375152588, 0.5563743114471436, 1.1152448654174805, 0.9930656552314758]
  OUT[0]: [1, 1, 7, 256] | μ=0.401193 σ=6.568158
    First 10: [0.2812678813934326, 0.003122471971437335, 0.05148325860500336, 0.09161295741796494, 0.017753679305315018, 0.37447667121887207, 0.38712987303733826, 0.5596069693565369, -0.0033908409532159567, 0.007323098368942738]
    Last 10:  [4.315730094909668, -1.1337100267410278, -30.22579574584961, 5.5522966384887695, 24.085351943969727, -25.227201461791992, -29.137876510620117, 13.677152633666992, 20.990201950073242, 18.690034866333008]
  WEIGHT: [256] | μ=1.479310

183_layers.11.self_attn.o_proj: layers.11.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.000596 σ=0.264628
    First 10: [-0.15349380671977997, 0.00564942229539156, -0.005607791244983673, 0.0222473181784153, 0.05821211263537407, -0.056732892990112305, -0.18139448761940002, -0.012423541396856308, 0.08332851529121399, 0.06380753964185715]
    Last 10:  [-0.3667054772377014, 0.11834569275379181, 0.18895280361175537, 0.2649455964565277, -0.20332516729831696, -0.05846085026860237, 0.031943388283252716, 0.12683136761188507, 0.14136430621147156, -0.20110945403575897]
  OUT[0]: [1, 7, 768] | μ=0.000446 σ=0.098691
    First 10: [-0.02052891254425049, -0.004613460972905159, 0.040831632912158966, -0.16776414215564728, -0.00996142253279686, -0.008936421945691109, -0.030869871377944946, -0.004106689244508743, 0.00041606929153203964, -0.027991265058517456]
    Last 10:  [-0.04314298927783966, -0.0048136040568351746, 0.43728044629096985, -0.027412191033363342, 0.09565167129039764, -0.04336071014404297, -0.023723481222987175, 0.0534840002655983, 0.025535201653838158, 0.02990374155342579]
  WEIGHT: [768, 768] | μ=0.000035

184_layers.11.self_attn: layers.11.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.000446 σ=0.098691
    First 10: [-0.02052891254425049, -0.004613460972905159, 0.040831632912158966, -0.16776414215564728, -0.00996142253279686, -0.008936421945691109, -0.030869871377944946, -0.004106689244508743, 0.00041606929153203964, -0.027991265058517456]
    Last 10:  [-0.04314298927783966, -0.0048136040568351746, 0.43728044629096985, -0.027412191033363342, 0.09565167129039764, -0.04336071014404297, -0.023723481222987175, 0.0534840002655983, 0.025535201653838158, 0.02990374155342579]

185_layers.11.post_attention_layernorm: layers.11.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000446 σ=0.098691
    First 10: [-0.02052891254425049, -0.004613460972905159, 0.040831632912158966, -0.16776414215564728, -0.00996142253279686, -0.008936421945691109, -0.030869871377944946, -0.004106689244508743, 0.00041606929153203964, -0.027991265058517456]
    Last 10:  [-0.04314298927783966, -0.0048136040568351746, 0.43728044629096985, -0.027412191033363342, 0.09565167129039764, -0.04336071014404297, -0.023723481222987175, 0.0534840002655983, 0.025535201653838158, 0.02990374155342579]
  OUT[0]: [1, 7, 768] | μ=0.689809 σ=33.282619
    First 10: [-9.178921699523926, -6.560518264770508, 0.0027526868507266045, 0.11581756919622421, -3.2563059329986572, -6.331864833831787, -0.00954048614948988, -0.004173110239207745, 0.2813100516796112, -21.94794273376465]
    Last 10:  [-0.4141189157962799, -0.09490440785884857, -0.048198848962783813, -3.7988693714141846, 44.4823112487793, -20.178651809692383, -4.809895992279053, 7.430749416351318, 3.15907883644104, 10.2652006149292]
  WEIGHT: [768] | μ=25.808859

186_layers.11.pre_feedforward_layernorm: layers.11.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=1.045600 σ=88.690735
    First 10: [160.06781005859375, -42.14769744873047, 0.547883152961731, -0.37698954343795776, -24.38529396057129, 2.1674695014953613, 0.5763217806816101, -0.32625246047973633, 25.7396297454834, -11.101560592651367]
    Last 10:  [-0.5710251331329346, -0.8616383075714111, -0.6160150766372681, 31.12468719482422, 5.564731597900391, 37.03941345214844, -1.9205694198608398, -24.913724899291992, 8.473817825317383, 0.09216022491455078]
  OUT[0]: [1, 7, 768] | μ=0.029638 σ=1.885465
    First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
    Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
  WEIGHT: [768] | μ=20.641964

187_layers.11.mlp.gate_proj: layers.11.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.029638 σ=1.885465
    First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
    Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
  OUT[0]: [1, 7, 1152] | μ=-0.022888 σ=0.415940
    First 10: [0.03617463633418083, -0.10488053411245346, 0.24704128503799438, 0.0035113394260406494, 0.10809838771820068, 0.19250638782978058, -0.13973060250282288, -0.03689698129892349, 0.07491662353277206, -0.10153275728225708]
    Last 10:  [-0.10446126013994217, -0.061193808913230896, 0.3088166117668152, -0.19580431282520294, -0.1983404904603958, -0.015726163983345032, 0.12720420956611633, 0.15382327139377594, 0.039929959923028946, -0.34532269835472107]
  WEIGHT: [1152, 768] | μ=0.000004

188_layers.11.mlp.act_fn: layers.11.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.022888 σ=0.415940
    First 10: [0.03617463633418083, -0.10488053411245346, 0.24704128503799438, 0.0035113394260406494, 0.10809838771820068, 0.19250638782978058, -0.13973060250282288, -0.03689698129892349, 0.07491662353277206, -0.10153275728225708]
    Last 10:  [-0.10446126013994217, -0.061193808913230896, 0.3088166117668152, -0.19580431282520294, -0.1983404904603958, -0.015726163983345032, 0.12720420956611633, 0.15382327139377594, 0.039929959923028946, -0.34532269835472107]
  OUT[0]: [1, 7, 1152] | μ=0.049827 σ=0.236241
    First 10: [0.018609261140227318, -0.04806000366806984, 0.1476212739944458, 0.0017605884931981564, 0.05870182812213898, 0.11094623059034348, -0.062101490795612335, -0.017905499786138535, 0.03969527408480644, -0.046660810708999634]
    Last 10:  [-0.04788525402545929, -0.029103929176926613, 0.1918555349111557, -0.08270462602376938, -0.08357906341552734, -0.0077644228003919125, 0.07003990560770035, 0.08631397038698196, 0.020600885152816772, -0.12602148950099945]

189_layers.11.mlp.up_proj: layers.11.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.029638 σ=1.885465
    First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
    Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
  OUT[0]: [1, 7, 1152] | μ=-0.000341 σ=0.319445
    First 10: [0.1178276538848877, -0.1282694935798645, 0.10161206871271133, -0.06015774607658386, 0.03943557292222977, 0.11978377401828766, 0.06380180269479752, 0.0325949490070343, -0.07597626000642776, 0.20454417169094086]
    Last 10:  [-0.08025982975959778, 0.14978045225143433, -0.14887215197086334, -0.19248171150684357, -0.09445177763700485, 0.3154454231262207, -0.288366436958313, -0.004110246896743774, 0.017934367060661316, 0.2301751673221588]
  WEIGHT: [1152, 768] | μ=-0.000008

190_layers.11.mlp.down_proj: layers.11.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000679 σ=0.082805
    First 10: [0.0021926856134086847, 0.006164632271975279, 0.015000103041529655, -0.00010591303725959733, 0.0023149403277784586, 0.0132895577698946, -0.003962187096476555, -0.0005836288328282535, -0.0030158984009176493, -0.009544196538627148]
    Last 10:  [0.0038432623259723186, -0.004359199665486813, -0.028561946004629135, 0.01591912843286991, 0.007894190959632397, -0.002449251711368561, -0.020197158679366112, -0.00035477173514664173, 0.00036946384352631867, -0.029007017612457275]
  OUT[0]: [1, 7, 768] | μ=0.000539 σ=0.020795
    First 10: [0.0018350998871028423, 7.917040056781843e-05, 0.0012390915071591735, -0.002071141032502055, -0.0012225244427099824, 0.003739813808351755, -0.0016483452636748552, -0.0019259187392890453, -0.003110730554908514, 0.0020603295415639877]
    Last 10:  [-0.0008136935066431761, -0.0024531472008675337, -0.010591590777039528, -7.204432040452957e-05, 0.0062161823734641075, 0.003502915147691965, 0.004403927829116583, 0.005129925906658173, -0.004834230989217758, -0.005289529450237751]
  WEIGHT: [768, 1152] | μ=-0.000009

191_layers.11.mlp: layers.11.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.029638 σ=1.885465
    First 10: [3.2803268432617188, -0.3809269666671753, 0.27320608496665955, -0.20443472266197205, -0.7741731405258179, 0.034608520567417145, 0.2749420404434204, -0.1481848955154419, 0.41081246733665466, -0.16353543102741241]
    Last 10:  [-0.4742642343044281, -0.6510483026504517, -0.6660211682319641, 1.4841387271881104, 0.06726130098104477, 0.6440465450286865, -0.07090839743614197, -1.5996392965316772, 0.5469518303871155, 0.0023829531855881214]
  OUT[0]: [1, 7, 768] | μ=0.000539 σ=0.020795
    First 10: [0.0018350998871028423, 7.917040056781843e-05, 0.0012390915071591735, -0.002071141032502055, -0.0012225244427099824, 0.003739813808351755, -0.0016483452636748552, -0.0019259187392890453, -0.003110730554908514, 0.0020603295415639877]
    Last 10:  [-0.0008136935066431761, -0.0024531472008675337, -0.010591590777039528, -7.204432040452957e-05, 0.0062161823734641075, 0.003502915147691965, 0.004403927829116583, 0.005129925906658173, -0.004834230989217758, -0.005289529450237751]

192_layers.11.post_feedforward_layernorm: layers.11.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000539 σ=0.020795
    First 10: [0.0018350998871028423, 7.917040056781843e-05, 0.0012390915071591735, -0.002071141032502055, -0.0012225244427099824, 0.003739813808351755, -0.0016483452636748552, -0.0019259187392890453, -0.003110730554908514, 0.0020603295415639877]
    Last 10:  [-0.0008136935066431761, -0.0024531472008675337, -0.010591590777039528, -7.204432040452957e-05, 0.0062161823734641075, 0.003502915147691965, 0.004403927829116583, 0.005129925906658173, -0.004834230989217758, -0.005289529450237751]
  OUT[0]: [1, 7, 768] | μ=2.304401 σ=74.105316
    First 10: [10.505766868591309, 0.9498871564865112, 1.3887830972671509, -2.1586830615997314, -5.487325668334961, 29.72430419921875, -2.0400543212890625, -2.12039852142334, -24.925981521606445, 17.8207950592041]
    Last 10:  [-0.5759255886077881, -1.8118822574615479, -7.454408168792725, -0.21545833349227905, 39.34021759033203, 27.131750106811523, 22.58598518371582, 12.515430450439453, -13.679925918579102, -33.960350036621094]
  WEIGHT: [768] | μ=28.846571

193_layers.12.input_layernorm: layers.12.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=3.350000 σ=135.506973
    First 10: [170.57357788085938, -41.197811126708984, 1.9366662502288818, -2.535672664642334, -29.87261962890625, 31.891773223876953, -1.4637324810028076, -2.446650981903076, 0.8136482238769531, 6.719234466552734]
    Last 10:  [-1.1469507217407227, -2.673520565032959, -8.070423126220703, 30.909229278564453, 44.90494918823242, 64.1711654663086, 20.665416717529297, -12.398294448852539, -5.206108093261719, -33.86819076538086]
  OUT[0]: [1, 7, 768] | μ=0.047915 σ=3.885965
    First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
    Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
  WEIGHT: [768] | μ=26.468756

194_layers.12.self_attn.q_proj: layers.12.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.047915 σ=3.885965
    First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
    Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
  OUT[0]: [1, 7, 768] | μ=0.012480 σ=1.535521
    First 10: [-0.804032564163208, 0.37707000970840454, -0.8528565764427185, -0.40152794122695923, 3.8703808784484863, 0.5866332054138184, -2.3382296562194824, 0.747713565826416, 0.298966646194458, 3.5231122970581055]
    Last 10:  [-1.9151663780212402, 0.5873419642448425, 0.12516561150550842, 0.03597442805767059, -0.00978928804397583, -0.42343395948410034, -0.42343905568122864, 0.2664339244365692, 0.9900935292243958, -1.9853806495666504]
  WEIGHT: [768, 768] | μ=-0.000000

195_layers.12.self_attn.k_proj: layers.12.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.047915 σ=3.885965
    First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
    Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
  OUT[0]: [1, 7, 256] | μ=-0.007322 σ=1.416668
    First 10: [0.2104572355747223, -0.019714832305908203, 0.3573058843612671, 0.12048636376857758, -0.6234138011932373, -0.08012927323579788, -3.7463607788085938, -0.5013067126274109, 0.05337300896644592, 1.600102424621582]
    Last 10:  [-5.884676933288574, 2.2959229946136475, 1.233973503112793, -1.0790659189224243, -1.9169360399246216, -0.6775946021080017, -0.9330291152000427, 2.7042794227600098, 1.749098777770996, -0.5477821826934814]
  WEIGHT: [256, 768] | μ=-0.000015

196_layers.12.self_attn.v_proj: layers.12.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.047915 σ=3.885965
    First 10: [5.862751007080078, -1.4678936004638672, 0.608935534954071, -0.9166908264160156, -1.9905316829681396, 1.235032320022583, -0.44769829511642456, -0.7454348206520081, 0.03146858513355255, 0.2436176985502243]
    Last 10:  [-0.4832143783569336, -1.505737066268921, -3.758566379547119, 2.4710323810577393, 1.4779233932495117, 1.944830298423767, 1.2216086387634277, -1.14332914352417, -0.5137605667114258, -1.5583224296569824]
  OUT[0]: [1, 7, 256] | μ=0.013955 σ=0.862566
    First 10: [0.02118532359600067, -0.34404104948043823, -0.04512466490268707, -0.03596951812505722, 0.062094204127788544, 0.47610732913017273, 0.3312092423439026, -0.41256383061408997, 0.008246857672929764, -0.3073456287384033]
    Last 10:  [0.4186096787452698, -0.6452377438545227, 0.014433741569519043, 0.6810883283615112, 0.5483975410461426, 0.8453601598739624, 0.36293888092041016, -0.016039013862609863, 0.17271602153778076, -1.2644233703613281]
  WEIGHT: [256, 768] | μ=-0.000019

197_layers.12.self_attn.q_norm: layers.12.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.012480 σ=1.535521
    First 10: [-0.804032564163208, 0.37707000970840454, -0.8528565764427185, -0.40152794122695923, 3.8703808784484863, 0.5866332054138184, -2.3382296562194824, 0.747713565826416, 0.298966646194458, 3.5231122970581055]
    Last 10:  [-1.9151663780212402, 0.5873419642448425, 0.12516561150550842, 0.03597442805767059, -0.00978928804397583, -0.42343395948410034, -0.42343905568122864, 0.2664339244365692, 0.9900935292243958, -1.9853806495666504]
  OUT[0]: [1, 3, 7, 256] | μ=-0.053893 σ=1.026035
    First 10: [-0.9810542464256287, 0.35052061080932617, -2.1246585845947266, -0.3041011691093445, -0.4188075661659241, 0.7541762590408325, -0.01668388769030571, 0.49581456184387207, 0.584750771522522, -1.097120761871338]
    Last 10:  [-13.123527526855469, 0.36365312337875366, 0.128529891371727, 0.01234135590493679, -0.010364540852606297, -0.7878853678703308, -0.31607967615127563, 0.15702155232429504, 1.3470075130462646, -9.620278358459473]
  WEIGHT: [256] | μ=0.269653

198_layers.12.self_attn.k_norm: layers.12.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.007322 σ=1.416668
    First 10: [0.2104572355747223, -0.019714832305908203, 0.3573058843612671, 0.12048636376857758, -0.6234138011932373, -0.08012927323579788, -3.7463607788085938, -0.5013067126274109, 0.05337300896644592, 1.600102424621582]
    Last 10:  [-5.884676933288574, 2.2959229946136475, 1.233973503112793, -1.0790659189224243, -1.9169360399246216, -0.6775946021080017, -0.9330291152000427, 2.7042794227600098, 1.749098777770996, -0.5477821826934814]
  OUT[0]: [1, 1, 7, 256] | μ=0.058824 σ=1.837179
    First 10: [0.13420966267585754, -0.024540286511182785, 0.20930597186088562, 0.26599448919296265, -0.004592957906424999, -0.10389760136604309, -0.03927338495850563, -0.0648767501115799, 0.05853899568319321, 0.0023185608442872763]
    Last 10:  [-2.392063856124878, 8.450733184814453, 2.749326467514038, -7.1906657218933105, -4.214174747467041, -0.7789255380630493, -2.922283172607422, 10.981688499450684, 3.0672366619110107, -0.5333201885223389]
  WEIGHT: [256] | μ=0.641884

199_layers.12.self_attn.o_proj: layers.12.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.017142 σ=0.461440
    First 10: [0.02118532359600067, -0.34404104948043823, -0.04512466490268707, -0.03596951812505722, 0.062094204127788544, 0.47610732913017273, 0.3312092423439026, -0.41256383061408997, 0.008246857672929764, -0.3073456287384033]
    Last 10:  [0.22768241167068481, -0.31409764289855957, -0.1116405501961708, 0.6132321953773499, 0.22976411879062653, 0.530254602432251, 0.19460050761699677, -0.03244711831212044, -0.06575445085763931, -1.019191026687622]
  OUT[0]: [1, 7, 768] | μ=0.001088 σ=0.166376
    First 10: [-0.04107115417718887, -0.06875456869602203, 0.2451094388961792, -0.037204355001449585, -0.02468542940914631, -0.02276606112718582, -0.12125665694475174, -0.11597006767988205, -0.02610476128757, 0.05870819091796875]
    Last 10:  [0.012472093105316162, -0.34136953949928284, -0.11113515496253967, 0.00604768842458725, 0.07735893130302429, -0.02525918558239937, 0.24240943789482117, 0.013309326022863388, -0.07271507382392883, 0.07985234260559082]
  WEIGHT: [768, 768] | μ=0.000010

200_layers.12.self_attn: layers.12.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.001088 σ=0.166376
    First 10: [-0.04107115417718887, -0.06875456869602203, 0.2451094388961792, -0.037204355001449585, -0.02468542940914631, -0.02276606112718582, -0.12125665694475174, -0.11597006767988205, -0.02610476128757, 0.05870819091796875]
    Last 10:  [0.012472093105316162, -0.34136953949928284, -0.11113515496253967, 0.00604768842458725, 0.07735893130302429, -0.02525918558239937, 0.24240943789482117, 0.013309326022863388, -0.07271507382392883, 0.07985234260559082]

201_layers.12.post_attention_layernorm: layers.12.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.001088 σ=0.166376
    First 10: [-0.04107115417718887, -0.06875456869602203, 0.2451094388961792, -0.037204355001449585, -0.02468542940914631, -0.02276606112718582, -0.12125665694475174, -0.11597006767988205, -0.02610476128757, 0.05870819091796875]
    Last 10:  [0.012472093105316162, -0.34136953949928284, -0.11113515496253967, 0.00604768842458725, 0.07735893130302429, -0.02525918558239937, 0.24240943789482117, 0.013309326022863388, -0.07271507382392883, 0.07985234260559082]
  OUT[0]: [1, 7, 768] | μ=-0.178083 σ=16.829136
    First 10: [-1.8329373598098755, -18.78799057006836, 5.436163902282715, -1.0219370126724243, -2.152355670928955, -3.0890607833862305, -3.6098432540893555, -2.8711442947387695, -3.4299378395080566, 9.84205436706543]
    Last 10:  [0.2913830578327179, -4.157111644744873, -2.520211696624756, 0.46962836384773254, 10.500821113586426, -4.822738170623779, 32.78165054321289, 0.7129244208335876, -6.708139896392822, 14.69610595703125]
  WEIGHT: [768] | μ=16.643095

202_layers.12.pre_feedforward_layernorm: layers.12.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=3.171916 σ=127.510208
    First 10: [168.7406463623047, -59.985801696777344, 7.372830390930176, -3.5576095581054688, -32.02497482299805, 28.802711486816406, -5.073575973510742, -5.317795276641846, -2.6162896156311035, 16.561288833618164]
    Last 10:  [-0.8555676937103271, -6.830632209777832, -10.590635299682617, 31.37885856628418, 55.40576934814453, 59.348426818847656, 53.44706726074219, -11.685370445251465, -11.914247512817383, -19.17208480834961]
  OUT[0]: [1, 7, 768] | μ=0.058533 σ=1.650225
    First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
    Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
  WEIGHT: [768] | μ=10.990865

203_layers.12.mlp.gate_proj: layers.12.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.058533 σ=1.650225
    First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
    Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
  OUT[0]: [1, 7, 1152] | μ=-0.104813 σ=0.300468
    First 10: [-0.022982895374298096, -0.20530149340629578, -0.08957429230213165, -0.12830787897109985, -0.0981706827878952, -0.15481024980545044, -0.1020633727312088, -0.1902666985988617, 0.13335318863391876, -0.04614615812897682]
    Last 10:  [-0.1434941589832306, 0.19373413920402527, -0.26234978437423706, -0.8278949856758118, 0.07833276689052582, -0.07045590877532959, -0.1476972997188568, -0.31951433420181274, -0.20305182039737701, -0.6358994841575623]
  WEIGHT: [1152, 768] | μ=0.000012

204_layers.12.mlp.act_fn: layers.12.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.104813 σ=0.300468
    First 10: [-0.022982895374298096, -0.20530149340629578, -0.08957429230213165, -0.12830787897109985, -0.0981706827878952, -0.15481024980545044, -0.1020633727312088, -0.1902666985988617, 0.13335318863391876, -0.04614615812897682]
    Last 10:  [-0.1434941589832306, 0.19373413920402527, -0.26234978437423706, -0.8278949856758118, 0.07833276689052582, -0.07045590877532959, -0.1476972997188568, -0.31951433420181274, -0.20305182039737701, -0.6358994841575623]
  OUT[0]: [1, 7, 1152] | μ=-0.014765 σ=0.134785
    First 10: [-0.011280739679932594, -0.08595378696918488, -0.041590508073568344, -0.05760425329208374, -0.04524673894047737, -0.0678822249174118, -0.04688316956162453, -0.08077815920114517, 0.07374993711709976, -0.02222384698688984]
    Last 10:  [-0.0635608658194542, 0.11174694448709488, -0.10402996838092804, -0.16887173056602478, 0.04161179065704346, -0.03324923664331436, -0.06517761945724487, -0.11971507221460342, -0.08519037812948227, -0.16691353917121887]

205_layers.12.mlp.up_proj: layers.12.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.058533 σ=1.650225
    First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
    Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
  OUT[0]: [1, 7, 1152] | μ=0.000586 σ=0.293478
    First 10: [0.02123599499464035, 0.07039011269807816, 0.06042609363794327, -0.05637071281671524, -0.08315056562423706, 0.16270342469215393, 0.11544345319271088, 0.11698631197214127, -0.12754835188388824, -0.07499265670776367]
    Last 10:  [-0.2852236330509186, -0.17267188429832458, -0.14019858837127686, 0.644933819770813, 0.23454919457435608, -0.010507181286811829, 0.14551949501037598, 0.12502118945121765, -0.257402628660202, 0.12464164197444916]
  WEIGHT: [1152, 768] | μ=-0.000001

206_layers.12.mlp.down_proj: layers.12.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000070 σ=0.053040
    First 10: [-0.00023955773212946951, -0.00605029659345746, -0.0025131518486887217, 0.0032471928279846907, 0.0037622919771820307, -0.011044670827686787, -0.005412355065345764, -0.009449939243495464, -0.009406683035194874, 0.0016666253795847297]
    Last 10:  [0.01812906190752983, -0.019295554608106613, 0.014584855176508427, -0.10891108959913254, 0.009760011918842793, 0.00034935574512928724, -0.009484614245593548, -0.01496692094951868, 0.021928226575255394, -0.020804377272725105]
  OUT[0]: [1, 7, 768] | μ=-0.000482 σ=0.017125
    First 10: [0.0020637139678001404, -0.00023306722869165242, -0.0020020543597638607, 0.00027065069298259914, 0.0009393703076057136, -0.0005907444283366203, 0.0006556111620739102, 0.0017650971421971917, -6.506458157673478e-05, -0.0013531404547393322]
    Last 10:  [-0.007020239718258381, -0.007523358799517155, -0.0034375921823084354, 0.003751582931727171, 0.005033687688410282, 0.0005947427125647664, -0.0023683509789407253, -0.00093159603420645, -0.0014653141843155026, 0.0028231372125446796]
  WEIGHT: [768, 1152] | μ=-0.000009

207_layers.12.mlp: layers.12.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.058533 σ=1.650225
    First 10: [3.1254405975341797, -0.5100337266921997, 1.1215983629226685, -0.5822058916091919, -0.9440978169441223, 0.46173423528671265, -0.7053480744361877, -0.8316826820373535, -0.044826339930295944, 0.263200581073761]
    Last 10:  [-0.19259266555309296, -1.603816270828247, -2.6633176803588867, 1.1604979038238525, 0.6602644324302673, 0.8036152720451355, 1.5054106712341309, -0.5353468656539917, -0.534945011138916, -0.39037227630615234]
  OUT[0]: [1, 7, 768] | μ=-0.000482 σ=0.017125
    First 10: [0.0020637139678001404, -0.00023306722869165242, -0.0020020543597638607, 0.00027065069298259914, 0.0009393703076057136, -0.0005907444283366203, 0.0006556111620739102, 0.0017650971421971917, -6.506458157673478e-05, -0.0013531404547393322]
    Last 10:  [-0.007020239718258381, -0.007523358799517155, -0.0034375921823084354, 0.003751582931727171, 0.005033687688410282, 0.0005947427125647664, -0.0023683509789407253, -0.00093159603420645, -0.0014653141843155026, 0.0028231372125446796]

208_layers.12.post_feedforward_layernorm: layers.12.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000482 σ=0.017125
    First 10: [0.0020637139678001404, -0.00023306722869165242, -0.0020020543597638607, 0.00027065069298259914, 0.0009393703076057136, -0.0005907444283366203, 0.0006556111620739102, 0.0017650971421971917, -6.506458157673478e-05, -0.0013531404547393322]
    Last 10:  [-0.007020239718258381, -0.007523358799517155, -0.0034375921823084354, 0.003751582931727171, 0.005033687688410282, 0.0005947427125647664, -0.0023683509789407253, -0.00093159603420645, -0.0014653141843155026, 0.0028231372125446796]
  OUT[0]: [1, 7, 768] | μ=2.770514 σ=116.501724
    First 10: [8.000317573547363, -2.435619592666626, -3.0871739387512207, 0.46263647079467773, 4.762817859649658, -4.873488426208496, 1.2409080266952515, 2.6048433780670166, -0.5370645523071289, -11.960341453552246]
    Last 10:  [-10.02040958404541, -6.7268195152282715, -4.912494659423828, 16.25006675720215, 36.858985900878906, 6.057577610015869, -19.51620864868164, -2.851673126220703, -6.811434268951416, 26.02605628967285]
  WEIGHT: [768] | μ=29.933502

209_layers.13.input_layernorm: layers.13.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=5.942430 σ=212.997604
    First 10: [176.740966796875, -62.42142105102539, 4.285656452178955, -3.094973087310791, -27.262157440185547, 23.929222106933594, -3.832667827606201, -2.712951898574829, -3.1533541679382324, 4.600947380065918]
    Last 10:  [-10.875977516174316, -13.557451248168945, -15.503129959106445, 47.62892532348633, 92.26475524902344, 65.406005859375, 33.93085861206055, -14.537043571472168, -18.72568130493164, 6.853971481323242]
  OUT[0]: [1, 7, 768] | μ=0.054176 σ=5.218561
    First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
    Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
  WEIGHT: [768] | μ=25.962729

210_layers.13.self_attn.q_proj: layers.13.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.054176 σ=5.218561
    First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
    Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
  OUT[0]: [1, 7, 768] | μ=-0.071761 σ=1.772350
    First 10: [0.8364247679710388, -0.4532351493835449, 0.7776120901107788, -0.47673994302749634, 0.9883427619934082, 0.24520409107208252, 2.4637582302093506, -1.2464847564697266, -0.29622364044189453, -0.30926695466041565]
    Last 10:  [-0.3050664961338043, 1.0661121606826782, 0.23267847299575806, -0.5322763323783875, -0.41054007411003113, 0.5130617618560791, 0.45901283621788025, -0.18490785360336304, 0.15671074390411377, 1.076202392578125]
  WEIGHT: [768, 768] | μ=-0.000000

211_layers.13.self_attn.k_proj: layers.13.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.054176 σ=5.218561
    First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
    Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
  OUT[0]: [1, 7, 256] | μ=-0.027784 σ=2.013980
    First 10: [0.007019702345132828, 0.11941589415073395, 0.7390118837356567, 0.1345953643321991, 0.9551467299461365, -0.07838650792837143, -0.6739803552627563, -0.6394873857498169, 0.14342156052589417, -0.39992213249206543]
    Last 10:  [-1.3505351543426514, 1.8229715824127197, 0.05259718745946884, -0.018563412129878998, -0.8138828873634338, 2.008383274078369, 1.163895845413208, -1.538025975227356, 0.6274494528770447, 2.1304666996002197]
  WEIGHT: [256, 768] | μ=0.000031

212_layers.13.self_attn.v_proj: layers.13.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.054176 σ=5.218561
    First 10: [7.684293270111084, -0.8150748014450073, 0.9144554734230042, -0.6581206917762756, -1.3583489656448364, 0.6733653545379639, -0.6853163838386536, -0.6034366488456726, -0.09593736380338669, 0.12533383071422577]
    Last 10:  [-1.613237977027893, -2.498838424682617, -2.8385283946990967, 1.7001827955245972, 1.2224775552749634, 0.8108631372451782, 0.7590326070785522, -0.6522057056427002, -0.65494304895401, 0.11215680092573166]
  OUT[0]: [1, 7, 256] | μ=0.006436 σ=1.005554
    First 10: [0.45034146308898926, -0.4081689119338989, 0.24878141283988953, -0.49970880150794983, -0.051942989230155945, -0.3459335267543793, -0.5095895528793335, -0.25714099407196045, 0.6120578050613403, -0.3974817991256714]
    Last 10:  [-0.21557466685771942, -0.022943012416362762, -0.6692516207695007, 0.4855843484401703, -0.10301446914672852, -0.259247362613678, -0.09954842925071716, -0.16998042166233063, -0.670846164226532, -0.08857104182243347]
  WEIGHT: [256, 768] | μ=0.000040

213_layers.13.self_attn.q_norm: layers.13.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.071761 σ=1.772350
    First 10: [0.8364247679710388, -0.4532351493835449, 0.7776120901107788, -0.47673994302749634, 0.9883427619934082, 0.24520409107208252, 2.4637582302093506, -1.2464847564697266, -0.29622364044189453, -0.30926695466041565]
    Last 10:  [-0.3050664961338043, 1.0661121606826782, 0.23267847299575806, -0.5322763323783875, -0.41054007411003113, 0.5130617618560791, 0.45901283621788025, -0.18490785360336304, 0.15671074390411377, 1.076202392578125]
  OUT[0]: [1, 3, 7, 256] | μ=-0.034570 σ=1.282260
    First 10: [1.7442165613174438, -1.104560136795044, 1.1223775148391724, -1.0668585300445557, 1.7916052341461182, 0.34625256061553955, -0.3750143349170685, -2.5772624015808105, -0.5066099762916565, -0.5889802575111389]
    Last 10:  [-0.40384751558303833, 2.0955889225006104, 0.3443293571472168, -0.4951009750366211, -0.9615939259529114, 0.5001615881919861, 0.5896702408790588, -0.2578638195991516, 0.1713263988494873, 1.2032439708709717]
  WEIGHT: [256] | μ=0.335631

214_layers.13.self_attn.k_norm: layers.13.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.027784 σ=2.013980
    First 10: [0.007019702345132828, 0.11941589415073395, 0.7390118837356567, 0.1345953643321991, 0.9551467299461365, -0.07838650792837143, -0.6739803552627563, -0.6394873857498169, 0.14342156052589417, -0.39992213249206543]
    Last 10:  [-1.3505351543426514, 1.8229715824127197, 0.05259718745946884, -0.018563412129878998, -0.8138828873634338, 2.008383274078369, 1.163895845413208, -1.538025975227356, 0.6274494528770447, 2.1304666996002197]
  OUT[0]: [1, 1, 7, 256] | μ=0.053946 σ=2.089630
    First 10: [0.004087395034730434, 0.13581787049770355, 0.8140512704849243, 0.22478584945201874, 1.160390019416809, -0.23296472430229187, -0.39481431245803833, -0.8376200199127197, 0.1146681159734726, -0.4332643449306488]
    Last 10:  [-3.073794364929199, 2.5395915508270264, 0.11110297590494156, -0.05622228980064392, -1.1022379398345947, 4.935131072998047, 2.521240711212158, -3.4987099170684814, 1.5758628845214844, 6.105504989624023]
  WEIGHT: [256] | μ=1.190099

215_layers.13.self_attn.o_proj: layers.13.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.017604 σ=0.724271
    First 10: [0.45034146308898926, -0.4081689119338989, 0.24878141283988953, -0.49970880150794983, -0.051942989230155945, -0.3459335267543793, -0.5095895528793335, -0.25714099407196045, 0.6120578050613403, -0.3974817991256714]
    Last 10:  [-0.18219275772571564, 0.07211694866418839, -0.5332483649253845, 0.4648361802101135, -0.09327122569084167, -0.17683327198028564, -0.03819107264280319, -0.16252046823501587, -0.5181922912597656, -0.08235093206167221]
  OUT[0]: [1, 7, 768] | μ=0.014945 σ=0.265551
    First 10: [-0.15213292837142944, -0.015081462450325489, -0.022870853543281555, -0.01687520556151867, -0.007552599534392357, -0.058719463646411896, 0.049116626381874084, -0.08975470066070557, -0.17323821783065796, 0.22528076171875]
    Last 10:  [-0.003948226571083069, 0.005071710795164108, 0.04794684052467346, -0.06946811825037003, -0.04805656149983406, -0.023258188739418983, 0.07940039038658142, 0.07642364501953125, -0.11784300953149796, -0.029977921396493912]
  WEIGHT: [768, 768] | μ=-0.000003

216_layers.13.self_attn: layers.13.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.014945 σ=0.265551
    First 10: [-0.15213292837142944, -0.015081462450325489, -0.022870853543281555, -0.01687520556151867, -0.007552599534392357, -0.058719463646411896, 0.049116626381874084, -0.08975470066070557, -0.17323821783065796, 0.22528076171875]
    Last 10:  [-0.003948226571083069, 0.005071710795164108, 0.04794684052467346, -0.06946811825037003, -0.04805656149983406, -0.023258188739418983, 0.07940039038658142, 0.07642364501953125, -0.11784300953149796, -0.029977921396493912]

217_layers.13.post_attention_layernorm: layers.13.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.014945 σ=0.265551
    First 10: [-0.15213292837142944, -0.015081462450325489, -0.022870853543281555, -0.01687520556151867, -0.007552599534392357, -0.058719463646411896, 0.049116626381874084, -0.08975470066070557, -0.17323821783065796, 0.22528076171875]
    Last 10:  [-0.003948226571083069, 0.005071710795164108, 0.04794684052467346, -0.06946811825037003, -0.04805656149983406, -0.023258188739418983, 0.07940039038658142, 0.07642364501953125, -0.11784300953149796, -0.029977921396493912]
  OUT[0]: [1, 7, 768] | μ=-2.197792 σ=62.527351
    First 10: [-10.064956665039062, -4.032870769500732, -0.791649580001831, -0.755563497543335, -0.7226142883300781, -9.659396171569824, 2.478848934173584, -3.038947105407715, -28.351734161376953, 40.1602668762207]
    Last 10:  [-0.20532387495040894, 0.10868159681558609, 2.529832601547241, -9.388433456420898, -12.188921928405762, -8.446057319641113, 20.02294158935547, 7.456014156341553, -15.894796371459961, -9.30518627166748]
  WEIGHT: [768] | μ=25.952833

218_layers.13.pre_feedforward_layernorm: layers.13.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=3.744637 σ=164.024460
    First 10: [166.67601013183594, -66.45429229736328, 3.494006872177124, -3.850536584854126, -27.984771728515625, 14.26982593536377, -1.3538188934326172, -5.751898765563965, -31.505088806152344, 44.76121520996094]
    Last 10:  [-11.08130168914795, -13.448769569396973, -12.973297119140625, 38.24049377441406, 80.07583618164062, 56.9599494934082, 53.953800201416016, -7.081029415130615, -34.62047576904297, -2.4512147903442383]
  OUT[0]: [1, 7, 768] | μ=0.058432 σ=1.746081
    First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
    Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
  WEIGHT: [768] | μ=7.262858

219_layers.13.mlp.gate_proj: layers.13.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.058432 σ=1.746081
    First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
    Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
  OUT[0]: [1, 7, 1152] | μ=-0.104752 σ=0.329033
    First 10: [0.006748717278242111, -0.09960862994194031, 0.07397498935461044, -0.09028328955173492, 0.017488647252321243, 0.18890106678009033, -0.17671608924865723, 0.039600953459739685, -0.2648722529411316, -0.4570804238319397]
    Last 10:  [-0.17768847942352295, 0.18994814157485962, -0.031693316996097565, -0.004064023494720459, -0.00039180368185043335, 0.03942228481173515, 0.03157612681388855, 0.04819710925221443, -0.11810573935508728, -0.15407778322696686]
  WEIGHT: [1152, 768] | μ=0.000002

220_layers.13.mlp.act_fn: layers.13.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.104752 σ=0.329033
    First 10: [0.006748717278242111, -0.09960862994194031, 0.07397498935461044, -0.09028328955173492, 0.017488647252321243, 0.18890106678009033, -0.17671608924865723, 0.039600953459739685, -0.2648722529411316, -0.4570804238319397]
    Last 10:  [-0.17768847942352295, 0.18994814157485962, -0.031693316996097565, -0.004064023494720459, -0.00039180368185043335, 0.03942228481173515, 0.03157612681388855, 0.04819710925221443, -0.11810573935508728, -0.15407778322696686]
  OUT[0]: [1, 7, 1152] | μ=-0.009111 σ=0.142765
    First 10: [0.00339252850972116, -0.045852623879909515, 0.03916862979531288, -0.04189427196979523, 0.008866335265338421, 0.10860161483287811, -0.07596450299024582, 0.02042594738304615, -0.10477280616760254, -0.14801806211471558]
    Last 10:  [-0.07631464302539825, 0.1092815175652504, -0.015446001663804054, -0.002025422640144825, -0.00019584059191402048, 0.02033098414540291, 0.016185762360692024, 0.02502492256462574, -0.053501009941101074, -0.06760554015636444]

221_layers.13.mlp.up_proj: layers.13.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.058432 σ=1.746081
    First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
    Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
  OUT[0]: [1, 7, 1152] | μ=-0.001263 σ=0.310816
    First 10: [-0.07227173447608948, 0.0660347044467926, -0.07152324914932251, 0.012200601398944855, -0.16272211074829102, -0.26572757959365845, -0.013649238273501396, 0.07763451337814331, -0.004814311861991882, 0.1388780176639557]
    Last 10:  [-0.2902665138244629, 0.012585415504872799, -0.1292167603969574, 0.07026379555463791, -0.04178517311811447, -0.28114619851112366, 0.04783618822693825, 0.11752069741487503, -0.20859655737876892, -0.10907648503780365]
  WEIGHT: [1152, 768] | μ=-0.000011

222_layers.13.mlp.down_proj: layers.13.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.000258 σ=0.053467
    First 10: [-0.00024518391001038253, -0.0030278644990175962, -0.002801467664539814, -0.0005111353239044547, -0.0014427488204091787, -0.028858443722128868, 0.0010368576040491462, 0.0015857585240155458, 0.0005044089630246162, -0.020556455478072166]
    Last 10:  [0.022151585668325424, 0.0013753533130511642, 0.0019958822522312403, -0.00014231388922780752, 8.183233148884028e-06, -0.0057159787975251675, 0.000774265150539577, 0.0029409462586045265, 0.011160126887261868, 0.007374174892902374]
  OUT[0]: [1, 7, 768] | μ=0.000603 σ=0.017372
    First 10: [0.004211364313960075, -0.0019049250986427069, -0.00040013561374507844, -0.00012071029050275683, 0.0010902953799813986, 0.0025013103149831295, 0.0009798873215913773, -0.0009930059313774109, 0.0011830583680421114, 0.005010321270674467]
    Last 10:  [-0.0004615726647898555, -0.00014996170648373663, 0.007172790355980396, 0.003221483901143074, 0.000838735606521368, 0.003366317367181182, 0.00033169661764986813, -0.0036381478421390057, -0.0014558428665623069, 0.0021559761371463537]
  WEIGHT: [768, 1152] | μ=-0.000011

223_layers.13.mlp: layers.13.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.058432 σ=1.746081
    First 10: [2.9443588256835938, -0.3831539452075958, 0.3363678455352783, -0.33110475540161133, -0.6566616296768188, 0.19487294554710388, -0.10149349272251129, -0.5617879033088684, -0.41452157497406006, 0.5627065896987915]
    Last 10:  [-0.7203790545463562, -1.0151113271713257, -0.8557134866714478, 0.5471727252006531, 0.34048476815223694, 0.29490363597869873, 0.535789430141449, -0.13697543740272522, -0.5657199621200562, -0.017023194581270218]
  OUT[0]: [1, 7, 768] | μ=0.000603 σ=0.017372
    First 10: [0.004211364313960075, -0.0019049250986427069, -0.00040013561374507844, -0.00012071029050275683, 0.0010902953799813986, 0.0025013103149831295, 0.0009798873215913773, -0.0009930059313774109, 0.0011830583680421114, 0.005010321270674467]
    Last 10:  [-0.0004615726647898555, -0.00014996170648373663, 0.007172790355980396, 0.003221483901143074, 0.000838735606521368, 0.003366317367181182, 0.00033169661764986813, -0.0036381478421390057, -0.0014558428665623069, 0.0021559761371463537]

224_layers.13.post_feedforward_layernorm: layers.13.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000603 σ=0.017372
    First 10: [0.004211364313960075, -0.0019049250986427069, -0.00040013561374507844, -0.00012071029050275683, 0.0010902953799813986, 0.0025013103149831295, 0.0009798873215913773, -0.0009930059313774109, 0.0011830583680421114, 0.005010321270674467]
    Last 10:  [-0.0004615726647898555, -0.00014996170648373663, 0.007172790355980396, 0.003221483901143074, 0.000838735606521368, 0.003366317367181182, 0.00033169661764986813, -0.0036381478421390057, -0.0014558428665623069, 0.0021559761371463537]
  OUT[0]: [1, 7, 768] | μ=2.410892 σ=88.031578
    First 10: [17.05410385131836, -20.200931549072266, -0.9720085263252258, -0.3194139301776886, 6.542749404907227, 23.45691680908203, 3.0530779361724854, -2.1220381259918213, 11.596570014953613, 51.478458404541016]
    Last 10:  [-1.6369478702545166, -0.23135975003242493, 25.6538028717041, 27.850204467773438, 10.738801956176758, 68.50335693359375, 5.220648288726807, -21.50417709350586, -13.386789321899414, 39.7132682800293]
  WEIGHT: [768] | μ=35.164944

225_layers.14.input_layernorm: layers.14.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=6.155529 σ=239.607086
    First 10: [183.73011779785156, -86.65522766113281, 2.521998405456543, -4.169950485229492, -21.4420223236084, 37.726741790771484, 1.6992590427398682, -7.873936653137207, -19.908519744873047, 96.23966979980469]
    Last 10:  [-12.718249320983887, -13.680129051208496, 12.680505752563477, 66.0906982421875, 90.81463623046875, 125.46330261230469, 59.1744499206543, -28.585206985473633, -48.00726318359375, 37.262054443359375]
  OUT[0]: [1, 7, 768] | μ=0.056472 σ=5.685355
    First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
    Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
  WEIGHT: [768] | μ=21.306219

226_layers.14.self_attn.q_proj: layers.14.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.056472 σ=5.685355
    First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
    Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
  OUT[0]: [1, 7, 768] | μ=0.032740 σ=1.906701
    First 10: [0.028124824166297913, 0.44571512937545776, 0.25772935152053833, 0.9772237539291382, 2.3116519451141357, -0.22039569914340973, 0.6215305328369141, 0.047316014766693115, -1.471388816833496, -0.21935640275478363]
    Last 10:  [-0.1737244874238968, 0.27111536264419556, 0.39346277713775635, -0.28846055269241333, -0.2518097460269928, -0.27236616611480713, 1.0081894397735596, 0.617536723613739, 0.13530395925045013, 0.34730425477027893]
  WEIGHT: [768, 768] | μ=-0.000003

227_layers.14.self_attn.k_proj: layers.14.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.056472 σ=5.685355
    First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
    Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
  OUT[0]: [1, 7, 256] | μ=-0.111514 σ=1.932355
    First 10: [-0.2207908034324646, -0.04775351285934448, -0.07402798533439636, 0.11566570401191711, -0.29033151268959045, 2.072566032409668, -0.5297539234161377, 0.5046263933181763, -0.10775488615036011, 0.6581724882125854]
    Last 10:  [-0.05878379940986633, 1.723232388496399, 1.3115403652191162, -0.6094167828559875, -1.9947216510772705, 1.8402093648910522, 2.0767550468444824, 2.681412935256958, -4.059468746185303, 0.4617413282394409]
  WEIGHT: [256, 768] | μ=0.000004

228_layers.14.self_attn.v_proj: layers.14.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.056472 σ=5.685355
    First 10: [7.530344009399414, -1.5655806064605713, 0.4032381474971771, -0.527524471282959, -1.039053201675415, 1.1030391454696655, 0.20922300219535828, -1.3420393466949463, -0.609518826007843, 2.7390921115875244]
    Last 10:  [-1.1619235277175903, -1.803166151046753, 1.28843355178833, 1.8953903913497925, 0.9587252736091614, 1.2921949625015259, 1.0242164134979248, -0.9521566033363342, -1.3971601724624634, 0.501461386680603]
  OUT[0]: [1, 7, 256] | μ=-0.004478 σ=1.178115
    First 10: [-0.501308798789978, 0.9232020378112793, 0.4883410930633545, -0.25761279463768005, 0.37365052103996277, 0.2523801326751709, -0.11057871580123901, -0.1554214507341385, 0.6825931668281555, -0.13478206098079681]
    Last 10:  [-0.28715601563453674, -0.11343425512313843, 0.16109225153923035, 0.7588263154029846, -0.47793760895729065, -0.22729337215423584, -0.170091450214386, 0.11519107222557068, -0.8462551832199097, -0.10331271588802338]
  WEIGHT: [256, 768] | μ=-0.000002

229_layers.14.self_attn.q_norm: layers.14.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.032740 σ=1.906701
    First 10: [0.028124824166297913, 0.44571512937545776, 0.25772935152053833, 0.9772237539291382, 2.3116519451141357, -0.22039569914340973, 0.6215305328369141, 0.047316014766693115, -1.471388816833496, -0.21935640275478363]
    Last 10:  [-0.1737244874238968, 0.27111536264419556, 0.39346277713775635, -0.28846055269241333, -0.2518097460269928, -0.27236616611480713, 1.0081894397735596, 0.617536723613739, 0.13530395925045013, 0.34730425477027893]
  OUT[0]: [1, 3, 7, 256] | μ=-0.022471 σ=1.213354
    First 10: [0.1003028079867363, 1.0526059865951538, 0.8727142214775085, 1.641601324081421, -0.27390366792678833, -0.35076388716697693, 0.8005458116531372, 0.061382513493299484, -0.009351968765258789, -0.7046124339103699]
    Last 10:  [-0.5762138366699219, 0.3556777536869049, 1.2215381860733032, -0.5598868131637573, -0.43046385049819946, -0.6195335388183594, 1.3909661769866943, 0.6647266745567322, 0.2153312712907791, 0.5164086818695068]
  WEIGHT: [256] | μ=0.461721

230_layers.14.self_attn.k_norm: layers.14.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.111514 σ=1.932355
    First 10: [-0.2207908034324646, -0.04775351285934448, -0.07402798533439636, 0.11566570401191711, -0.29033151268959045, 2.072566032409668, -0.5297539234161377, 0.5046263933181763, -0.10775488615036011, 0.6581724882125854]
    Last 10:  [-0.05878379940986633, 1.723232388496399, 1.3115403652191162, -0.6094167828559875, -1.9947216510772705, 1.8402093648910522, 2.0767550468444824, 2.681412935256958, -4.059468746185303, 0.4617413282394409]
  OUT[0]: [1, 1, 7, 256] | μ=-0.046633 σ=1.880148
    First 10: [-0.2256920039653778, -0.05131816864013672, -0.059695590287446976, 0.03600867837667465, -0.0014628918142989278, 0.07795681804418564, -0.9856333136558533, 0.9465233683586121, -0.00020775220764335245, 0.4418083727359772]
    Last 10:  [-0.044420741498470306, 3.232144355773926, 1.1971092224121094, -0.77071613073349, -3.1295506954193115, 2.1062538623809814, 3.7301809787750244, 5.796924591064453, -5.381000995635986, 0.7690918445587158]
  WEIGHT: [256] | μ=0.657235

231_layers.14.self_attn.o_proj: layers.14.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.009665 σ=0.508602
    First 10: [-0.501308798789978, 0.9232020378112793, 0.4883410930633545, -0.25761279463768005, 0.37365052103996277, 0.2523801326751709, -0.11057871580123901, -0.1554214507341385, 0.6825931668281555, -0.13478206098079681]
    Last 10:  [0.039655208587646484, 0.15596690773963928, -0.03644498437643051, 0.5815441012382507, -0.3286437392234802, 0.028827853500843048, -0.11520837247371674, -0.03017500787973404, -0.43303704261779785, 0.4345278739929199]
  OUT[0]: [1, 7, 768] | μ=-0.008653 σ=0.217847
    First 10: [0.12269598990678787, -0.022870689630508423, -0.013895757496356964, 0.07412634789943695, -0.08660323917865753, -0.002777267247438431, -0.03183448314666748, -0.031418878585100174, -0.08178964257240295, -0.09039819985628128]
    Last 10:  [-0.029067542403936386, -0.047225676476955414, 0.05217019468545914, -0.056367505341768265, -0.0705995187163353, 0.07758945971727371, 0.036799684166908264, 0.10514664649963379, -0.16595499217510223, -0.05093392729759216]
  WEIGHT: [768, 768] | μ=0.000005

232_layers.14.self_attn: layers.14.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.008653 σ=0.217847
    First 10: [0.12269598990678787, -0.022870689630508423, -0.013895757496356964, 0.07412634789943695, -0.08660323917865753, -0.002777267247438431, -0.03183448314666748, -0.031418878585100174, -0.08178964257240295, -0.09039819985628128]
    Last 10:  [-0.029067542403936386, -0.047225676476955414, 0.05217019468545914, -0.056367505341768265, -0.0705995187163353, 0.07758945971727371, 0.036799684166908264, 0.10514664649963379, -0.16595499217510223, -0.05093392729759216]

233_layers.14.post_attention_layernorm: layers.14.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.008653 σ=0.217847
    First 10: [0.12269598990678787, -0.022870689630508423, -0.013895757496356964, 0.07412634789943695, -0.08660323917865753, -0.002777267247438431, -0.03183448314666748, -0.031418878585100174, -0.08178964257240295, -0.09039819985628128]
    Last 10:  [-0.029067542403936386, -0.047225676476955414, 0.05217019468545914, -0.056367505341768265, -0.0705995187163353, 0.07758945971727371, 0.036799684166908264, 0.10514664649963379, -0.16595499217510223, -0.05093392729759216]
  OUT[0]: [1, 7, 768] | μ=0.144088 σ=16.890066
    First 10: [8.62802791595459, -7.865265846252441, -0.869902491569519, 5.292575836181641, -15.408013343811035, -0.7929950952529907, -3.161799430847168, -1.860727310180664, -21.920698165893555, -26.63882827758789]
    Last 10:  [-1.671074390411377, -1.072404384613037, 3.0777504444122314, -7.039388656616211, -13.41563892364502, 23.908565521240234, 8.664802551269531, 8.241847038269043, -23.259517669677734, -14.986763000488281]
  WEIGHT: [768] | μ=30.738136

234_layers.14.pre_feedforward_layernorm: layers.14.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=6.299619 σ=239.912643
    First 10: [192.35813903808594, -94.52049255371094, 1.652095913887024, 1.1226253509521484, -36.85003662109375, 36.933746337890625, -1.4625403881072998, -9.734663963317871, -41.82921600341797, 69.60084533691406]
    Last 10:  [-14.389324188232422, -14.752532958984375, 15.758255958557129, 59.051307678222656, 77.39899444580078, 149.3718719482422, 67.83924865722656, -20.343360900878906, -71.26678466796875, 22.275291442871094]
  OUT[0]: [1, 7, 768] | μ=0.016894 σ=1.438832
    First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
    Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
  WEIGHT: [768] | μ=5.706133

235_layers.14.mlp.gate_proj: layers.14.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.016894 σ=1.438832
    First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
    Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
  OUT[0]: [1, 7, 1152] | μ=-0.078370 σ=0.261370
    First 10: [0.14834237098693848, 0.12829217314720154, -0.02011808753013611, 0.024282237514853477, -0.04086781293153763, 0.07456660270690918, -0.041377656161785126, 0.08108655363321304, -0.0006834724918007851, -0.010279660113155842]
    Last 10:  [-0.021879808977246284, 0.1496003419160843, -0.09056642651557922, -0.048916224390268326, -0.17876023054122925, 0.00806389469653368, -0.10356353223323822, -0.016077920794487, -0.005521934479475021, -0.08705978095531464]
  WEIGHT: [1152, 768] | μ=0.000013

236_layers.14.mlp.act_fn: layers.14.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.078370 σ=0.261370
    First 10: [0.14834237098693848, 0.12829217314720154, -0.02011808753013611, 0.024282237514853477, -0.04086781293153763, 0.07456660270690918, -0.041377656161785126, 0.08108655363321304, -0.0006834724918007851, -0.010279660113155842]
    Last 10:  [-0.021879808977246284, 0.1496003419160843, -0.09056642651557922, -0.048916224390268326, -0.17876023054122925, 0.00806389469653368, -0.10356353223323822, -0.016077920794487, -0.005521934479475021, -0.08705978095531464]
  OUT[0]: [1, 7, 1152] | μ=-0.011250 σ=0.120153
    First 10: [0.08291784673929214, 0.07069417089223862, -0.009897587820887566, 0.012376322411000729, -0.01976778730750084, 0.039499424397945404, -0.02000599168241024, 0.043163448572158813, -0.00034154989407397807, -0.005097674205899239]
    Last 10:  [-0.010748935863375664, 0.08369525521993637, -0.04201546683907509, -0.023503907024860382, -0.07669972628355026, 0.004057888872921467, -0.047510623931884766, -0.007935838773846626, -0.0027488027699291706, -0.04050998017191887]

237_layers.14.mlp.up_proj: layers.14.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.016894 σ=1.438832
    First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
    Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
  OUT[0]: [1, 7, 1152] | μ=0.002904 σ=0.249255
    First 10: [0.05705193430185318, -0.0037382543087005615, -0.1112263947725296, -0.009159233421087265, -0.08151492476463318, 0.07436574995517731, 0.06018946319818497, -0.12019287049770355, 0.03315173462033272, -0.021319936960935593]
    Last 10:  [-0.06220266968011856, -0.25173962116241455, 0.039261288940906525, -0.08635926246643066, -0.3211487829685211, -0.028728969395160675, 0.00495245773345232, 0.04333190619945526, 0.11583015322685242, -0.0386919304728508]
  WEIGHT: [1152, 768] | μ=-0.000004

238_layers.14.mlp.down_proj: layers.14.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.001301 σ=0.037125
    First 10: [0.004730623681098223, -0.00026427279226481915, 0.0011008729925379157, -0.00011335762246744707, 0.0016113696619868279, 0.00293740420602262, -0.0012041499139741063, -0.005187938921153545, -1.1322971658955794e-05, 0.0001086820921045728]
    Last 10:  [0.0006686124834232032, -0.02106941118836403, -0.0016495813615620136, 0.002029780065640807, 0.02463202364742756, -0.00011657896538963541, -0.00023529435566160828, -0.000343875028192997, -0.0003183942462783307, 0.001567409373819828]
  OUT[0]: [1, 7, 768] | μ=0.000614 σ=0.013653
    First 10: [-0.0012987230438739061, -0.0008989650523290038, 0.0002725987578742206, -0.0004307625931687653, -0.0011674187844619155, 0.0006288615404628217, 0.0023097058292478323, 0.0008910225005820394, 0.00055984704522416, 0.00244341604411602]
    Last 10:  [0.00018927021301351488, 0.0009197206818498671, -0.0004020448250230402, 0.0005610291846096516, -8.46427064971067e-05, -0.0002974697854369879, 0.00014032510807737708, -0.0022252541966736317, 0.0006255374755710363, -0.00010594178456813097]
  WEIGHT: [768, 1152] | μ=-0.000009

239_layers.14.mlp: layers.14.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.016894 σ=1.438832
    First 10: [2.3697452545166016, -0.3636484444141388, 0.08298101276159286, 0.04697032645344734, -0.5297067761421204, 0.3147691488265991, -0.05289096757769585, -0.4889148473739624, -0.36060017347335815, 0.5416711568832397]
    Last 10:  [-0.41872718930244446, -0.6063752770423889, 0.46793532371520996, 0.5063270330429077, 0.21640726923942566, 0.45393654704093933, 0.34355247020721436, -0.2263667732477188, -0.6177079677581787, 0.0889405608177185]
  OUT[0]: [1, 7, 768] | μ=0.000614 σ=0.013653
    First 10: [-0.0012987230438739061, -0.0008989650523290038, 0.0002725987578742206, -0.0004307625931687653, -0.0011674187844619155, 0.0006288615404628217, 0.0023097058292478323, 0.0008910225005820394, 0.00055984704522416, 0.00244341604411602]
    Last 10:  [0.00018927021301351488, 0.0009197206818498671, -0.0004020448250230402, 0.0005610291846096516, -8.46427064971067e-05, -0.0002974697854369879, 0.00014032510807737708, -0.0022252541966736317, 0.0006255374755710363, -0.00010594178456813097]

240_layers.14.post_feedforward_layernorm: layers.14.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000614 σ=0.013653
    First 10: [-0.0012987230438739061, -0.0008989650523290038, 0.0002725987578742206, -0.0004307625931687653, -0.0011674187844619155, 0.0006288615404628217, 0.0023097058292478323, 0.0008910225005820394, 0.00055984704522416, 0.00244341604411602]
    Last 10:  [0.00018927021301351488, 0.0009197206818498671, -0.0004020448250230402, 0.0005610291846096516, -8.46427064971067e-05, -0.0002974697854369879, 0.00014032510807737708, -0.0022252541966736317, 0.0006255374755710363, -0.00010594178456813097]
  OUT[0]: [1, 7, 768] | μ=2.251310 σ=99.498322
    First 10: [-14.931605339050293, -29.44227409362793, 2.950902223587036, -4.3199028968811035, -23.0322208404541, 19.5983829498291, 30.702062606811523, 7.305133819580078, 17.826879501342773, 83.95952606201172]
    Last 10:  [2.4454541206359863, 4.695501327514648, -5.409968852996826, 15.459521293640137, -3.167933702468872, -17.228734970092773, 6.611525535583496, -36.66097640991211, 17.946247100830078, -6.042235851287842]
  WEIGHT: [768] | μ=43.596607

241_layers.15.input_layernorm: layers.15.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=8.550929 σ=325.543243
    First 10: [177.42652893066406, -123.9627685546875, 4.60299825668335, -3.197277545928955, -59.88225555419922, 56.532127380371094, 29.23952293395996, -2.429530143737793, -24.002336502075195, 153.56036376953125]
    Last 10:  [-11.943870544433594, -10.057031631469727, 10.348287582397461, 74.51082611083984, 74.23106384277344, 132.1431427001953, 74.45077514648438, -57.004337310791016, -53.32053756713867, 16.233055114746094]
  OUT[0]: [1, 7, 768] | μ=0.084202 σ=5.634511
    First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
    Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
  WEIGHT: [768] | μ=18.555494

242_layers.15.self_attn.q_proj: layers.15.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.084202 σ=5.634511
    First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
    Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
  OUT[0]: [1, 7, 768] | μ=-0.015853 σ=2.089638
    First 10: [0.2750684320926666, -3.550524950027466, -0.6223995089530945, 0.0007455646991729736, 2.240058422088623, -2.499338150024414, 0.6067607402801514, -2.0542101860046387, 1.9696431159973145, -0.4023197293281555]
    Last 10:  [-0.13992273807525635, -0.39495664834976196, -1.2112736701965332, -0.30776703357696533, 0.10131454467773438, -0.6142350435256958, -0.520649790763855, 0.10828877985477448, -0.6732699871063232, -0.20795512199401855]
  WEIGHT: [768, 768] | μ=0.000012

243_layers.15.self_attn.k_proj: layers.15.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.084202 σ=5.634511
    First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
    Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
  OUT[0]: [1, 7, 256] | μ=-0.029994 σ=2.032853
    First 10: [-0.2951665222644806, 1.1768625974655151, 0.00848531723022461, 0.4255927801132202, -0.5154724717140198, 0.7189075946807861, 0.6592564582824707, -0.15552927553653717, 0.06901262700557709, 0.7627174854278564]
    Last 10:  [-1.0547300577163696, 0.5886194705963135, -1.7441225051879883, -1.9584755897521973, -0.6799696683883667, -2.0162978172302246, -1.9833217859268188, -0.803550660610199, 0.22215652465820312, 0.2984813451766968]
  WEIGHT: [256, 768] | μ=0.000002

244_layers.15.self_attn.v_proj: layers.15.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.084202 σ=5.634511
    First 10: [8.556805610656738, -1.676918387413025, 0.4971413314342499, -0.33047962188720703, -2.251556158065796, 1.315859079360962, 2.2749738693237305, -0.27451515197753906, -0.5509650111198425, 3.2251522541046143]
    Last 10:  [-0.5547336935997009, -0.7623677253723145, 0.5122208595275879, 1.3200371265411377, 0.5755926370620728, 0.8734925389289856, 0.7321434617042542, -1.4846563339233398, -0.8560788631439209, 0.128972128033638]
  OUT[0]: [1, 7, 256] | μ=0.021755 σ=1.233423
    First 10: [-0.47365522384643555, -0.18011385202407837, -0.41710925102233887, 0.0747750848531723, 0.35331273078918457, -0.6285364031791687, 0.3741227090358734, 0.125362828373909, -0.3014511466026306, -0.35354703664779663]
    Last 10:  [0.06338294595479965, -0.02208004891872406, -0.1949484497308731, 0.6693199872970581, 0.49223893880844116, -0.02726396918296814, 0.3623366951942444, 0.018864162266254425, 0.0516878142952919, -0.07165651768445969]
  WEIGHT: [256, 768] | μ=-0.000000

245_layers.15.self_attn.q_norm: layers.15.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.015853 σ=2.089638
    First 10: [0.2750684320926666, -3.550524950027466, -0.6223995089530945, 0.0007455646991729736, 2.240058422088623, -2.499338150024414, 0.6067607402801514, -2.0542101860046387, 1.9696431159973145, -0.4023197293281555]
    Last 10:  [-0.13992273807525635, -0.39495664834976196, -1.2112736701965332, -0.30776703357696533, 0.10131454467773438, -0.6142350435256958, -0.520649790763855, 0.10828877985477448, -0.6732699871063232, -0.20795512199401855]
  OUT[0]: [1, 3, 7, 256] | μ=0.016387 σ=0.960839
    First 10: [0.37651678919792175, 0.5727710723876953, -1.027632236480713, -0.0010312963277101517, -0.01267665158957243, -0.06652969121932983, 0.7271559834480286, -1.3628730773925781, 2.019571542739868, -0.0019715651869773865]
    Last 10:  [-0.20435841381549835, -1.2880555391311646, -2.292523145675659, -1.0783475637435913, 0.06972628831863403, -2.3719112873077393, -4.256363391876221, 0.14771999418735504, -1.6556353569030762, -0.20596683025360107]
  WEIGHT: [256] | μ=0.263356

246_layers.15.self_attn.k_norm: layers.15.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.029994 σ=2.032853
    First 10: [-0.2951665222644806, 1.1768625974655151, 0.00848531723022461, 0.4255927801132202, -0.5154724717140198, 0.7189075946807861, 0.6592564582824707, -0.15552927553653717, 0.06901262700557709, 0.7627174854278564]
    Last 10:  [-1.0547300577163696, 0.5886194705963135, -1.7441225051879883, -1.9584755897521973, -0.6799696683883667, -2.0162978172302246, -1.9833217859268188, -0.803550660610199, 0.22215652465820312, 0.2984813451766968]
  OUT[0]: [1, 1, 7, 256] | μ=-0.127516 σ=2.091496
    First 10: [-0.42723512649536133, -0.25166651606559753, 0.011462745256721973, 0.4264484941959381, 0.004845777992159128, 0.028305426239967346, -0.09319332242012024, -0.1508299708366394, -0.06413722038269043, -0.006630311720073223]
    Last 10:  [-5.52408504486084, 1.4959686994552612, -11.68722915649414, -4.993087291717529, -6.895844459533691, -5.663033485412598, -2.1530206203460693, -4.067312240600586, 0.6875457763671875, 2.209059953689575]
  WEIGHT: [256] | μ=0.850871

247_layers.15.self_attn.o_proj: layers.15.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.012734 σ=0.916316
    First 10: [-0.47365522384643555, -0.18011385202407837, -0.41710925102233887, 0.0747750848531723, 0.35331273078918457, -0.6285364031791687, 0.3741227090358734, 0.125362828373909, -0.3014511466026306, -0.35354703664779663]
    Last 10:  [0.11542350798845291, 0.018483111634850502, -0.2530986964702606, 0.5508170127868652, 0.48238977789878845, -0.050392165780067444, 0.37293508648872375, -0.028464723378419876, 0.026468340307474136, -0.014735020697116852]
  OUT[0]: [1, 7, 768] | μ=0.008606 σ=0.359760
    First 10: [-0.053457751870155334, 0.029016204178333282, 0.045305244624614716, 0.004770169034600258, 0.0320814810693264, -0.07723040878772736, 0.14569181203842163, -0.19514091312885284, 0.05640750005841255, -0.118842713534832]
    Last 10:  [-0.018760016188025475, 0.04383497312664986, -0.02402014099061489, -0.005228996276855469, -0.04460621625185013, -0.006841190159320831, -0.02014404907822609, -0.024293426424264908, -0.04879247024655342, 0.07000140845775604]
  WEIGHT: [768, 768] | μ=-0.000002

248_layers.15.self_attn: layers.15.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.008606 σ=0.359760
    First 10: [-0.053457751870155334, 0.029016204178333282, 0.045305244624614716, 0.004770169034600258, 0.0320814810693264, -0.07723040878772736, 0.14569181203842163, -0.19514091312885284, 0.05640750005841255, -0.118842713534832]
    Last 10:  [-0.018760016188025475, 0.04383497312664986, -0.02402014099061489, -0.005228996276855469, -0.04460621625185013, -0.006841190159320831, -0.02014404907822609, -0.024293426424264908, -0.04879247024655342, 0.07000140845775604]

249_layers.15.post_attention_layernorm: layers.15.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.008606 σ=0.359760
    First 10: [-0.053457751870155334, 0.029016204178333282, 0.045305244624614716, 0.004770169034600258, 0.0320814810693264, -0.07723040878772736, 0.14569181203842163, -0.19514091312885284, 0.05640750005841255, -0.118842713534832]
    Last 10:  [-0.018760016188025475, 0.04383497312664986, -0.02402014099061489, -0.005228996276855469, -0.04460621625185013, -0.006841190159320831, -0.02014404907822609, -0.024293426424264908, -0.04879247024655342, 0.07000140845775604]
  OUT[0]: [1, 7, 768] | μ=-0.773209 σ=36.193607
    First 10: [-5.056215763092041, 7.695061206817627, 4.610808372497559, 0.4491417407989502, 5.582060813903809, -21.32071304321289, 21.214231491088867, -15.011122703552246, 15.79201602935791, -36.598575592041016]
    Last 10:  [-3.0826714038848877, 2.7122812271118164, -4.06519889831543, -1.6947458982467651, -21.55784797668457, -4.944144248962402, -11.817981719970703, -5.600545406341553, -16.491689682006836, 48.40235137939453]
  WEIGHT: [768] | μ=53.921402

250_layers.15.pre_feedforward_layernorm: layers.15.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=7.777719 σ=308.289764
    First 10: [172.3703155517578, -116.26770782470703, 9.21380615234375, -2.748135805130005, -54.300193786621094, 35.2114143371582, 50.45375442504883, -17.44065284729004, -8.210320472717285, 116.9617919921875]
    Last 10:  [-15.026541709899902, -7.34475040435791, 6.283088684082031, 72.81607818603516, 52.6732177734375, 127.1989974975586, 62.63279342651367, -62.604881286621094, -69.81222534179688, 64.63540649414062]
  OUT[0]: [1, 7, 768] | μ=0.050048 σ=1.626903
    First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
    Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
  WEIGHT: [768] | μ=4.498001

251_layers.15.mlp.gate_proj: layers.15.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.050048 σ=1.626903
    First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
    Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
  OUT[0]: [1, 7, 1152] | μ=-0.108265 σ=0.316032
    First 10: [-0.018640421330928802, 0.3564620614051819, 0.1350024789571762, 0.09405145794153214, -0.4554407000541687, -0.2488454431295395, 0.018176045268774033, -0.025425981730222702, -0.17996057868003845, -0.2846835255622864]
    Last 10:  [-0.001682499423623085, -0.00948718748986721, 0.07520028203725815, -0.005328044295310974, -0.07463696599006653, 0.013049734756350517, -0.09310083836317062, -0.04099193960428238, 0.01904069259762764, -0.07473614066839218]
  WEIGHT: [1152, 768] | μ=0.000012

252_layers.15.mlp.act_fn: layers.15.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.108265 σ=0.316032
    First 10: [-0.018640421330928802, 0.3564620614051819, 0.1350024789571762, 0.09405145794153214, -0.4554407000541687, -0.2488454431295395, 0.018176045268774033, -0.025425981730222702, -0.17996057868003845, -0.2846835255622864]
    Last 10:  [-0.001682499423623085, -0.00948718748986721, 0.07520028203725815, -0.005328044295310974, -0.07463696599006653, 0.013049734756350517, -0.09310083836317062, -0.04099193960428238, 0.01904069259762764, -0.07473614066839218]
  OUT[0]: [1, 7, 1152] | μ=-0.013322 σ=0.137072
    First 10: [-0.00918160006403923, 0.22786447405815125, 0.07475009560585022, 0.05054942145943642, -0.14775541424751282, -0.09997241944074631, 0.009219813160598278, -0.012455110438168049, -0.07712996006011963, -0.1104431077837944]
    Last 10:  [-0.0008401204249821603, -0.004707687068730593, 0.039854057133197784, -0.002652697032317519, -0.03509817644953728, 0.006592803169041872, -0.043097496032714844, -0.019825801253318787, 0.009664973244071007, -0.03514186292886734]

253_layers.15.mlp.up_proj: layers.15.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.050048 σ=1.626903
    First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
    Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
  OUT[0]: [1, 7, 1152] | μ=0.003769 σ=0.294882
    First 10: [-0.037296112626791, -0.05797937512397766, -0.008805528283119202, -0.004578541032969952, -0.8381357192993164, -0.05140405148267746, -0.07439427822828293, 0.10267028212547302, 0.042106449604034424, 0.015454471111297607]
    Last 10:  [0.025219690054655075, -0.03763987123966217, 0.023936942219734192, -0.09901262819766998, 0.025497576221823692, 0.04697975516319275, 0.03548315167427063, -0.05359477177262306, -0.008468195796012878, 0.0915905311703682]
  WEIGHT: [1152, 768] | μ=-0.000016

254_layers.15.mlp.down_proj: layers.15.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000961 σ=0.054195
    First 10: [0.0003424379974603653, -0.013211439363658428, -0.0006582140922546387, -0.00023144259466789663, 0.12383908778429031, 0.005138987209647894, -0.0006859013228677213, -0.0012787696905434132, -0.003247668733820319, -0.0017068397719413042]
    Last 10:  [-2.118757583957631e-05, 0.00017719673633109778, 0.0009539842722006142, 0.00026265051565133035, -0.0008949184557422996, 0.00030972828972153366, -0.0015292350435629487, 0.0010625593131408095, -8.184488251572475e-05, -0.003218661993741989]
  OUT[0]: [1, 7, 768] | μ=-0.000275 σ=0.017983
    First 10: [0.0014592756051570177, 0.0008235244313254952, -6.071146344766021e-05, -0.0014057585503906012, -0.0023643700405955315, 0.001071389764547348, 0.0032004942186176777, 0.0012298669898882508, -0.002775343833491206, 0.004271045792847872]
    Last 10:  [2.489541657269001e-05, -0.00027085962938144803, 0.0011891688918694854, -0.0008950495976023376, 0.00040699378587305546, -0.00043553835712373257, -8.213924593292177e-05, -0.0005206878413446248, 0.0009753420599736273, -0.00046670835581608117]
  WEIGHT: [768, 1152] | μ=-0.000007

255_layers.15.mlp: layers.15.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.050048 σ=1.626903
    First 10: [2.4197628498077393, -0.4293610453605652, 0.26266154646873474, -0.07903781533241272, -0.6567347645759583, 0.2525060176849365, 1.120949625968933, -0.5925902128219604, -0.060142215341329575, 0.7665439248085022]
    Last 10:  [-0.20742329955101013, -0.1724436730146408, 0.08845976740121841, 0.3693433105945587, 0.1028003990650177, 0.2586786150932312, 0.19307972490787506, -0.4596957564353943, -0.3709299564361572, 0.1599522978067398]
  OUT[0]: [1, 7, 768] | μ=-0.000275 σ=0.017983
    First 10: [0.0014592756051570177, 0.0008235244313254952, -6.071146344766021e-05, -0.0014057585503906012, -0.0023643700405955315, 0.001071389764547348, 0.0032004942186176777, 0.0012298669898882508, -0.002775343833491206, 0.004271045792847872]
    Last 10:  [2.489541657269001e-05, -0.00027085962938144803, 0.0011891688918694854, -0.0008950495976023376, 0.00040699378587305546, -0.00043553835712373257, -8.213924593292177e-05, -0.0005206878413446248, 0.0009753420599736273, -0.00046670835581608117]

256_layers.15.post_feedforward_layernorm: layers.15.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000275 σ=0.017983
    First 10: [0.0014592756051570177, 0.0008235244313254952, -6.071146344766021e-05, -0.0014057585503906012, -0.0023643700405955315, 0.001071389764547348, 0.0032004942186176777, 0.0012298669898882508, -0.002775343833491206, 0.004271045792847872]
    Last 10:  [2.489541657269001e-05, -0.00027085962938144803, 0.0011891688918694854, -0.0008950495976023376, 0.00040699378587305546, -0.00043553835712373257, -8.213924593292177e-05, -0.0005206878413446248, 0.0009753420599736273, -0.00046670835581608117]
  OUT[0]: [1, 7, 768] | μ=2.256958 σ=72.825829
    First 10: [24.456777572631836, 33.42272186279297, -1.1520030498504639, -24.27264404296875, -61.76890182495117, 45.822906494140625, 76.6097412109375, 18.297256469726562, -118.28570556640625, 192.639404296875]
    Last 10:  [0.6493815779685974, -2.831252336502075, 39.51802062988281, -46.41456985473633, 27.377927780151367, -47.31842803955078, -7.534228801727295, -19.60750961303711, 51.0959587097168, -49.43213653564453]
  WEIGHT: [768] | μ=66.700554

257_layers.16.input_layernorm: layers.16.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=10.034679 σ=359.662079
    First 10: [196.82708740234375, -82.84498596191406, 8.061802864074707, -27.020780563354492, -116.069091796875, 81.03431701660156, 127.06349182128906, 0.8566036224365234, -126.49602508544922, 309.6011962890625]
    Last 10:  [-14.37716007232666, -10.176002502441406, 45.801109313964844, 26.401508331298828, 80.0511474609375, 79.88056945800781, 55.09856414794922, -82.21238708496094, -18.716266632080078, 15.203269958496094]
  OUT[0]: [1, 7, 768] | μ=0.133224 σ=4.723349
    First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
    Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
  WEIGHT: [768] | μ=15.383217

258_layers.16.self_attn.q_proj: layers.16.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.133224 σ=4.723349
    First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
    Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
  OUT[0]: [1, 7, 768] | μ=0.063896 σ=1.741342
    First 10: [0.0821181908249855, -0.038808032870292664, 0.16820573806762695, -0.5041741132736206, -0.36305880546569824, -0.04728120565414429, 0.1847488135099411, -0.6405004262924194, 5.011054992675781, 5.636178016662598]
    Last 10:  [0.2995896339416504, 0.23130901157855988, 0.6076662540435791, 0.2111247330904007, -0.08041355013847351, -0.12157659232616425, -0.3028453588485718, 0.42278003692626953, 0.09611747413873672, -0.27475106716156006]
  WEIGHT: [768, 768] | μ=-0.000000

259_layers.16.self_attn.k_proj: layers.16.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.133224 σ=4.723349
    First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
    Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
  OUT[0]: [1, 7, 256] | μ=0.014895 σ=1.599558
    First 10: [-1.0430543422698975, -0.6856472492218018, -0.1530994176864624, -1.6472887992858887, 0.6151814460754395, 0.764738917350769, -0.09283172339200974, 1.4227927923202515, -0.42275291681289673, 1.75962495803833]
    Last 10:  [0.7464443445205688, 0.23397743701934814, -0.16423195600509644, 2.158895254135132, 0.0933859720826149, 0.48242518305778503, -1.8387813568115234, 1.1323245763778687, 0.009632214903831482, -0.3971259891986847]
  WEIGHT: [256, 768] | μ=0.000002

260_layers.16.self_attn.v_proj: layers.16.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.133224 σ=4.723349
    First 10: [7.863559246063232, -1.8271019458770752, 0.4221085011959076, -1.5956130027770996, -3.6543490886688232, 1.4519388675689697, 4.685192584991455, 0.058359235525131226, -2.248634099960327, 5.233091831207275]
    Last 10:  [-0.33985674381256104, -0.5998784303665161, 0.996881902217865, 0.30300697684288025, 0.6206114888191223, 0.43534931540489197, 0.34542760252952576, -1.3966319561004639, -0.2164115458726883, 0.08657288551330566]
  OUT[0]: [1, 7, 256] | μ=-0.064398 σ=0.989014
    First 10: [-0.6418328285217285, -0.3928605020046234, 1.1151726245880127, -0.7391738891601562, -0.13036535680294037, -0.44117534160614014, 0.8351699113845825, -0.11296050250530243, -0.18013650178909302, 0.21958743035793304]
    Last 10:  [-0.1414574831724167, 0.22670885920524597, -0.15669219195842743, 0.193239226937294, -0.3128224313259125, -1.4500670433044434, 0.07908748835325241, 0.1181928813457489, 0.11801724135875702, -0.10641785711050034]
  WEIGHT: [256, 768] | μ=0.000008

261_layers.16.self_attn.q_norm: layers.16.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.063896 σ=1.741342
    First 10: [0.0821181908249855, -0.038808032870292664, 0.16820573806762695, -0.5041741132736206, -0.36305880546569824, -0.04728120565414429, 0.1847488135099411, -0.6405004262924194, 5.011054992675781, 5.636178016662598]
    Last 10:  [0.2995896339416504, 0.23130901157855988, 0.6076662540435791, 0.2111247330904007, -0.08041355013847351, -0.12157659232616425, -0.3028453588485718, 0.42278003692626953, 0.09611747413873672, -0.27475106716156006]
  OUT[0]: [1, 3, 7, 256] | μ=0.041700 σ=0.950639
    First 10: [0.14055228233337402, -0.05802807956933975, 0.0006027726922184229, 0.0023286594077944756, -0.4200732707977295, 0.000978846219368279, 0.1647787094116211, -0.000790201302152127, -0.06001173332333565, 0.047274816781282425]
    Last 10:  [0.5726515650749207, 0.4938984513282776, 1.3055063486099243, 1.413020133972168, -0.1483013927936554, -0.5105913877487183, -0.44439223408699036, 0.8231408596038818, 0.32543495297431946, -0.634926974773407]
  WEIGHT: [256] | μ=0.381455

262_layers.16.self_attn.k_norm: layers.16.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.014895 σ=1.599558
    First 10: [-1.0430543422698975, -0.6856472492218018, -0.1530994176864624, -1.6472887992858887, 0.6151814460754395, 0.764738917350769, -0.09283172339200974, 1.4227927923202515, -0.42275291681289673, 1.75962495803833]
    Last 10:  [0.7464443445205688, 0.23397743701934814, -0.16423195600509644, 2.158895254135132, 0.0933859720826149, 0.48242518305778503, -1.8387813568115234, 1.1323245763778687, 0.009632214903831482, -0.3971259891986847]
  OUT[0]: [1, 1, 7, 256] | μ=-0.059272 σ=2.079158
    First 10: [-2.3326237201690674, -1.2727173566818237, -0.0011803103843703866, -0.03670081868767738, 1.1186199188232422, 0.012451402842998505, -0.21789956092834473, -0.007450073026120663, -0.004296461585909128, 0.04469418153166771]
    Last 10:  [4.765768527984619, 1.1218132972717285, -0.9314966201782227, 3.3408353328704834, 0.4841102659702301, 1.3612786531448364, -12.182586669921875, 6.189958095550537, 0.03163532912731171, -1.8134199380874634]
  WEIGHT: [256] | μ=0.596661

263_layers.16.self_attn.o_proj: layers.16.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.068816 σ=0.837523
    First 10: [-0.6418328285217285, -0.3928605020046234, 1.1151726245880127, -0.7391738891601562, -0.13036535680294037, -0.44117534160614014, 0.8351699113845825, -0.11296050250530243, -0.18013650178909302, 0.21958743035793304]
    Last 10:  [-0.12814335525035858, 0.20896776020526886, -0.14638862013816833, 0.17789873480796814, -0.2821471691131592, -1.4830693006515503, 0.07140576094388962, 0.11675554513931274, 0.12407781183719635, -0.12927919626235962]
  OUT[0]: [1, 7, 768] | μ=0.000107 σ=0.198805
    First 10: [-0.04244951531291008, -0.009432187303900719, -0.058707095682621, -0.11231457442045212, 0.006897404789924622, 0.19240403175354004, 0.03562046214938164, 0.03662789240479469, -0.18526023626327515, -0.16735705733299255]
    Last 10:  [0.03406906872987747, 0.041274238377809525, 0.038944266736507416, 0.0525117963552475, 0.09039435535669327, -0.03989114984869957, 0.10661245137453079, 0.005829542875289917, 0.03841768205165863, 0.07806211709976196]
  WEIGHT: [768, 768] | μ=0.000006

264_layers.16.self_attn: layers.16.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.000107 σ=0.198805
    First 10: [-0.04244951531291008, -0.009432187303900719, -0.058707095682621, -0.11231457442045212, 0.006897404789924622, 0.19240403175354004, 0.03562046214938164, 0.03662789240479469, -0.18526023626327515, -0.16735705733299255]
    Last 10:  [0.03406906872987747, 0.041274238377809525, 0.038944266736507416, 0.0525117963552475, 0.09039435535669327, -0.03989114984869957, 0.10661245137453079, 0.005829542875289917, 0.03841768205165863, 0.07806211709976196]

265_layers.16.post_attention_layernorm: layers.16.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000107 σ=0.198805
    First 10: [-0.04244951531291008, -0.009432187303900719, -0.058707095682621, -0.11231457442045212, 0.006897404789924622, 0.19240403175354004, 0.03562046214938164, 0.03662789240479469, -0.18526023626327515, -0.16735705733299255]
    Last 10:  [0.03406906872987747, 0.041274238377809525, 0.038944266736507416, 0.0525117963552475, 0.09039435535669327, -0.03989114984869957, 0.10661245137453079, 0.005829542875289917, 0.03841768205165863, 0.07806211709976196]
  OUT[0]: [1, 7, 768] | μ=-2.825767 σ=91.664742
    First 10: [-6.544094562530518, -7.093411922454834, -14.343620300292969, -27.86068344116211, 2.336379051208496, 90.0130386352539, 10.417393684387207, 9.075632095336914, -90.48550415039062, -99.10968017578125]
    Last 10:  [9.018077850341797, 7.927422046661377, 12.122605323791504, 23.551931381225586, 48.905242919921875, -35.421607971191406, 67.46156311035156, 2.68066143989563, 17.377859115600586, 62.81224822998047]
  WEIGHT: [768] | μ=50.438297

266_layers.16.pre_feedforward_layernorm: layers.16.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=7.208912 σ=299.971649
    First 10: [190.28298950195312, -89.93840026855469, -6.281817436218262, -54.88146209716797, -113.73271179199219, 171.04736328125, 137.4808807373047, 9.932235717773438, -216.98153686523438, 210.49151611328125]
    Last 10:  [-5.359082221984863, -2.2485804557800293, 57.92371368408203, 49.95343780517578, 128.95639038085938, 44.458961486816406, 122.56012725830078, -79.53172302246094, -1.3384075164794922, 78.01551818847656]
  OUT[0]: [1, 7, 768] | μ=0.081439 σ=2.306295
    First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
    Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
  WEIGHT: [768] | μ=3.857414

267_layers.16.mlp.gate_proj: layers.16.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.081439 σ=2.306295
    First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
    Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
  OUT[0]: [1, 7, 1152] | μ=-0.310488 σ=0.553181
    First 10: [-0.1314050257205963, -0.16383230686187744, -0.6103329658508301, 0.5611538887023926, -0.3229793310165405, 0.17225991189479828, 0.006114445626735687, -0.048787087202072144, 0.5801162123680115, -0.11870715022087097]
    Last 10:  [-0.003261435776948929, 0.05744418501853943, -0.19689679145812988, 0.05362384766340256, -0.14796103537082672, 0.0010593235492706299, 0.02988205850124359, -0.03396691381931305, -0.09891755133867264, -0.020195968449115753]
  WEIGHT: [1152, 768] | μ=-0.000024

268_layers.16.mlp.act_fn: layers.16.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.310488 σ=0.553181
    First 10: [-0.1314050257205963, -0.16383230686187744, -0.6103329658508301, 0.5611538887023926, -0.3229793310165405, 0.17225991189479828, 0.006114445626735687, -0.048787087202072144, 0.5801162123680115, -0.11870715022087097]
    Last 10:  [-0.003261435776948929, 0.05744418501853943, -0.19689679145812988, 0.05362384766340256, -0.14796103537082672, 0.0010593235492706299, 0.02988205850124359, -0.03396691381931305, -0.09891755133867264, -0.020195968449115753]
  OUT[0]: [1, 7, 1152] | μ=-0.030285 σ=0.178546
    First 10: [-0.058833733201026917, -0.07125607877969742, -0.16532567143440247, 0.39988234639167786, -0.12058942019939423, 0.09790939837694168, 0.0030721379444003105, -0.023444367572665215, 0.4171217679977417, -0.05374516546726227]
    Last 10:  [-0.0016264744335785508, 0.030037809163331985, -0.08308190107345581, 0.02795853652060032, -0.06527860462665558, 0.0005301094497554004, 0.015297207050025463, -0.016523266211152077, -0.04556163772940636, -0.009935276582837105]

269_layers.16.mlp.up_proj: layers.16.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.081439 σ=2.306295
    First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
    Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
  OUT[0]: [1, 7, 1152] | μ=-0.012204 σ=0.447993
    First 10: [-0.09395742416381836, 0.04666103422641754, -0.364766001701355, 0.2615402936935425, -0.24587729573249817, 0.4023342728614807, -0.18297605216503143, 0.29130780696868896, -0.4948385953903198, 0.12745603919029236]
    Last 10:  [0.07557912170886993, -0.051932401955127716, -0.0135548897087574, -0.011789873242378235, -0.008807355538010597, 0.14916223287582397, -0.11478916555643082, -0.05917856842279434, -0.07885716110467911, -0.16659410297870636]
  WEIGHT: [1152, 768] | μ=-0.000005

270_layers.16.mlp.down_proj: layers.16.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.000321 σ=0.097267
    First 10: [0.005527866072952747, -0.003324882360175252, 0.06030518561601639, 0.10458534955978394, 0.02965020015835762, 0.03939230740070343, -0.0005621276795864105, -0.006829527206718922, -0.20640794932842255, -0.006850145757198334]
    Last 10:  [-0.00012292750761844218, -0.0015599356265738606, 0.0011261659674346447, -0.0003296275972388685, 0.0005749318515881896, 7.907230610726401e-05, -0.0017559536499902606, 0.0009778232779353857, 0.0035928613506257534, 0.0016551584703847766]
  OUT[0]: [1, 7, 768] | μ=-0.000706 σ=0.039395
    First 10: [0.018145309761166573, 0.005536272190511227, -0.00724404864013195, 0.0067577725276350975, 0.01675591431558132, 0.005521407816559076, 0.009664974175393581, 0.005731484387069941, -0.004609137773513794, -0.008363023400306702]
    Last 10:  [0.003607769962400198, 0.002256703795865178, 0.017945390194654465, 0.0009218337363563478, 0.003465424058958888, -0.0022044284269213676, -0.0004948796704411507, -0.0037707828450948, -0.000382079160772264, 0.0032334281131625175]
  WEIGHT: [768, 1152] | μ=0.000001

271_layers.16.mlp: layers.16.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.081439 σ=2.306295
    First 10: [4.546849727630615, -0.5173097252845764, -0.1701306402683258, -1.5144457817077637, -1.6949152946472168, 1.7231591939926147, 3.155412197113037, 0.3211117386817932, -2.160771369934082, 1.8247543573379517]
    Last 10:  [-0.05415840074419975, -0.034520093351602554, 0.6061869263648987, 0.24355754256248474, 0.414359986782074, 0.10349878668785095, 0.38291236758232117, -0.599600076675415, -0.007093378342688084, 0.1989544779062271]
  OUT[0]: [1, 7, 768] | μ=-0.000706 σ=0.039395
    First 10: [0.018145309761166573, 0.005536272190511227, -0.00724404864013195, 0.0067577725276350975, 0.01675591431558132, 0.005521407816559076, 0.009664974175393581, 0.005731484387069941, -0.004609137773513794, -0.008363023400306702]
    Last 10:  [0.003607769962400198, 0.002256703795865178, 0.017945390194654465, 0.0009218337363563478, 0.003465424058958888, -0.0022044284269213676, -0.0004948796704411507, -0.0037707828450948, -0.000382079160772264, 0.0032334281131625175]

272_layers.16.post_feedforward_layernorm: layers.16.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000706 σ=0.039395
    First 10: [0.018145309761166573, 0.005536272190511227, -0.00724404864013195, 0.0067577725276350975, 0.01675591431558132, 0.005521407816559076, 0.009664974175393581, 0.005731484387069941, -0.004609137773513794, -0.008363023400306702]
    Last 10:  [0.003607769962400198, 0.002256703795865178, 0.017945390194654465, 0.0009218337363563478, 0.003465424058958888, -0.0022044284269213676, -0.0004948796704411507, -0.0037707828450948, -0.000382079160772264, 0.0032334281131625175]
  OUT[0]: [1, 7, 768] | μ=2.744242 σ=111.346214
    First 10: [33.89567947387695, 32.76103210449219, -20.25352668762207, 18.3454532623291, 60.56814956665039, 28.947559356689453, 34.44989776611328, 13.414114952087402, -23.95740509033203, -51.58452606201172]
    Last 10:  [40.443458557128906, 14.429034233093262, 292.05535888671875, 21.065383911132812, 88.27689361572266, -90.2981948852539, -16.67511558532715, -61.03594970703125, -7.756007671356201, 127.9292984008789]
  WEIGHT: [768] | μ=114.082069

273_layers.17.input_layernorm: layers.17.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=9.953154 σ=331.399292
    First 10: [224.1786651611328, -57.1773681640625, -26.535343170166016, -36.5360107421875, -53.1645622253418, 199.9949188232422, 171.9307861328125, 23.346351623535156, -240.93893432617188, 158.906982421875]
    Last 10:  [35.08437728881836, 12.18045425415039, 349.97906494140625, 71.0188217163086, 217.2332763671875, -45.8392333984375, 105.885009765625, -140.5676727294922, -9.094415664672852, 205.94482421875]
  OUT[0]: [1, 7, 768] | μ=0.186234 σ=6.954648
    First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
    Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
  WEIGHT: [768] | μ=14.356262

274_layers.17.self_attn.q_proj: layers.17.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.186234 σ=6.954648
    First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
    Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
  OUT[0]: [1, 7, 768] | μ=0.311863 σ=4.017663
    First 10: [0.13857966661453247, -8.82702350616455, 0.0628214180469513, 9.121500968933105, 8.699965476989746, -0.6280006766319275, -8.965055465698242, 1.2241649627685547, 8.873095512390137, 9.276311874389648]
    Last 10:  [0.5574794411659241, 0.5186766982078552, 0.8274462223052979, 0.020087286829948425, -0.048790574073791504, 0.32204025983810425, -1.638026475906372, 1.2235217094421387, -0.40435969829559326, 2.126105308532715]
  WEIGHT: [768, 768] | μ=0.000005

275_layers.17.self_attn.k_proj: layers.17.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.186234 σ=6.954648
    First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
    Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
  OUT[0]: [1, 7, 256] | μ=0.271005 σ=3.168662
    First 10: [0.3505149781703949, -3.1803534030914307, 0.23355220258235931, -7.714994430541992, 1.7707030773162842, 0.9917514324188232, 2.9340968132019043, 0.035356372594833374, 0.2736923396587372, -0.8501555919647217]
    Last 10:  [3.3833799362182617, 5.165805816650391, 17.18344497680664, -7.588434219360352, -3.2140440940856934, 1.6651239395141602, -13.826639175415039, 9.17832088470459, -0.38373684883117676, 5.6469502449035645]
  WEIGHT: [256, 768] | μ=0.000010

276_layers.17.self_attn.v_proj: layers.17.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.186234 σ=6.954648
    First 10: [13.756919860839844, -1.4558823108673096, -1.109694242477417, -2.0699071884155273, -1.530617594718933, 4.137596607208252, 6.3860249519348145, 1.4884828329086304, -4.4943647384643555, 3.0307443141937256]
    Last 10:  [1.075668215751648, 0.5675175786018372, 11.379369735717773, 1.1422479152679443, 2.2706551551818848, -0.35488682985305786, 1.0330787897109985, -2.5710713863372803, -0.1347963511943817, 1.7329555749893188]
  OUT[0]: [1, 7, 256] | μ=0.096592 σ=1.676072
    First 10: [1.8853219747543335, -0.43604549765586853, -1.0771384239196777, -0.4341403543949127, -0.2480888068675995, -0.6475500464439392, -0.5702807903289795, -0.41407105326652527, 1.435836672782898, 0.03128881752490997]
    Last 10:  [1.235020637512207, -0.46707072854042053, 0.919693648815155, 1.6343183517456055, -0.6363921761512756, 0.06932976841926575, 0.3904760777950287, -0.47385191917419434, -0.32089585065841675, -0.9098753929138184]
  WEIGHT: [256, 768] | μ=-0.000005

277_layers.17.self_attn.q_norm: layers.17.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.311863 σ=4.017663
    First 10: [0.13857966661453247, -8.82702350616455, 0.0628214180469513, 9.121500968933105, 8.699965476989746, -0.6280006766319275, -8.965055465698242, 1.2241649627685547, 8.873095512390137, 9.276311874389648]
    Last 10:  [0.5574794411659241, 0.5186766982078552, 0.8274462223052979, 0.020087286829948425, -0.048790574073791504, 0.32204025983810425, -1.638026475906372, 1.2235217094421387, -0.40435969829559326, 2.126105308532715]
  OUT[0]: [1, 3, 7, 256] | μ=0.012446 σ=1.021709
    First 10: [0.18029747903347015, -0.027406344190239906, 0.13634973764419556, -0.007857843302190304, 0.1501828134059906, -1.0530449151992798, 0.033092644065618515, 2.246753692626953, 0.10806622356176376, -0.24445298314094543]
    Last 10:  [0.07680691033601761, 0.12066474556922913, 0.0834144577383995, 0.010885986499488354, -0.007186017464846373, 0.057424046099185944, -0.15672728419303894, 0.16698266565799713, -0.09048336744308472, 0.9270464181900024]
  WEIGHT: [256] | μ=0.695495

278_layers.17.self_attn.k_norm: layers.17.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.271005 σ=3.168662
    First 10: [0.3505149781703949, -3.1803534030914307, 0.23355220258235931, -7.714994430541992, 1.7707030773162842, 0.9917514324188232, 2.9340968132019043, 0.035356372594833374, 0.2736923396587372, -0.8501555919647217]
    Last 10:  [3.3833799362182617, 5.165805816650391, 17.18344497680664, -7.588434219360352, -3.2140440940856934, 1.6651239395141602, -13.826639175415039, 9.17832088470459, -0.38373684883117676, 5.6469502449035645]
  OUT[0]: [1, 1, 7, 256] | μ=0.683395 σ=7.308217
    First 10: [0.1348065882921219, -0.020096804946660995, 0.047977346926927567, 0.01766389235854149, 0.017619771882891655, 0.27841514348983765, -0.04389505088329315, 0.009516091085970402, 0.0020128744654357433, -0.0006479561561718583]
    Last 10:  [10.378642082214355, 9.963871002197266, 57.42681121826172, -7.017959117889404, -10.160416603088379, 4.68733549118042, -57.844722747802734, 28.779096603393555, -0.8765086531639099, 12.75533676147461]
  WEIGHT: [256] | μ=1.916614

279_layers.17.self_attn.o_proj: layers.17.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.103143 σ=1.320695
    First 10: [1.8853219747543335, -0.43604549765586853, -1.0771384239196777, -0.4341403543949127, -0.2480888068675995, -0.6475500464439392, -0.5702807903289795, -0.41407105326652527, 1.435836672782898, 0.03128881752490997]
    Last 10:  [0.859013557434082, -0.1789332926273346, 0.7977057099342346, 1.3088476657867432, -0.6629815101623535, 0.21104279160499573, 0.6292656660079956, -0.8145148754119873, -0.25235381722450256, -0.671532154083252]
  OUT[0]: [1, 7, 768] | μ=-0.005370 σ=0.829125
    First 10: [-0.13105419278144836, -0.03487660363316536, 0.045117706060409546, -0.04473287984728813, 0.3218005299568176, 0.23208868503570557, 0.1797301173210144, 0.03578261286020279, -0.1155415028333664, -0.1811402142047882]
    Last 10:  [-0.12785762548446655, -0.025170370936393738, -0.07504306733608246, -0.48003023862838745, 0.20806440711021423, -0.01342037320137024, 0.03906511515378952, 0.16481474041938782, -0.05493714660406113, 0.018011868000030518]
  WEIGHT: [768, 768] | μ=0.000004

280_layers.17.self_attn: layers.17.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.005370 σ=0.829125
    First 10: [-0.13105419278144836, -0.03487660363316536, 0.045117706060409546, -0.04473287984728813, 0.3218005299568176, 0.23208868503570557, 0.1797301173210144, 0.03578261286020279, -0.1155415028333664, -0.1811402142047882]
    Last 10:  [-0.12785762548446655, -0.025170370936393738, -0.07504306733608246, -0.48003023862838745, 0.20806440711021423, -0.01342037320137024, 0.03906511515378952, 0.16481474041938782, -0.05493714660406113, 0.018011868000030518]

281_layers.17.post_attention_layernorm: layers.17.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.005370 σ=0.829125
    First 10: [-0.13105419278144836, -0.03487660363316536, 0.045117706060409546, -0.04473287984728813, 0.3218005299568176, 0.23208868503570557, 0.1797301173210144, 0.03578261286020279, -0.1155415028333664, -0.1811402142047882]
    Last 10:  [-0.12785762548446655, -0.025170370936393738, -0.07504306733608246, -0.48003023862838745, 0.20806440711021423, -0.01342037320137024, 0.03906511515378952, 0.16481474041938782, -0.05493714660406113, 0.018011868000030518]
  OUT[0]: [1, 7, 768] | μ=-4.750216 σ=125.622726
    First 10: [-18.045936584472656, -32.569236755371094, 10.212577819824219, -10.507555961608887, 79.1751480102539, 90.41741180419922, 40.399658203125, 6.878398895263672, -46.547943115234375, -76.33650970458984]
    Last 10:  [-9.095890998840332, -1.0184733867645264, -7.68153715133667, -70.52977752685547, 21.238534927368164, -2.711376190185547, 5.9426984786987305, 7.45294713973999, -5.328487873077393, 3.3442492485046387]
  WEIGHT: [768] | μ=189.625793

282_layers.17.pre_feedforward_layernorm: layers.17.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=5.202938 σ=275.644623
    First 10: [206.13272094726562, -89.7466049194336, -16.322765350341797, -47.0435676574707, 26.01058578491211, 290.4123229980469, 212.3304443359375, 30.224750518798828, -287.48687744140625, 82.57047271728516]
    Last 10:  [25.988487243652344, 11.161980628967285, 342.2975158691406, 0.489044189453125, 238.47181701660156, -48.55060958862305, 111.82770538330078, -133.11473083496094, -14.422903060913086, 209.28907775878906]
  OUT[0]: [1, 7, 768] | μ=0.028222 σ=1.617025
    First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
    Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
  WEIGHT: [768] | μ=2.004896

283_layers.17.mlp.gate_proj: layers.17.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.028222 σ=1.617025
    First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
    Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
  OUT[0]: [1, 7, 1152] | μ=-0.171175 σ=0.350872
    First 10: [-0.020067356526851654, -0.25969627499580383, 0.0644199401140213, -0.07609587907791138, -0.24038158357143402, 0.1670592874288559, -0.06978140771389008, 0.048835840076208115, -0.0325770229101181, 0.027158107608556747]
    Last 10:  [-0.08080010116100311, -0.02211068570613861, -0.07788600027561188, 0.007301550358533859, -0.20040029287338257, -0.06233274191617966, -0.2712494432926178, -0.036856625229120255, 0.021736374124884605, -0.07884566485881805]
  WEIGHT: [1152, 768] | μ=-0.000052

284_layers.17.mlp.act_fn: layers.17.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.171175 σ=0.350872
    First 10: [-0.020067356526851654, -0.25969627499580383, 0.0644199401140213, -0.07609587907791138, -0.24038158357143402, 0.1670592874288559, -0.06978140771389008, 0.048835840076208115, -0.0325770229101181, 0.027158107608556747]
    Last 10:  [-0.08080010116100311, -0.02211068570613861, -0.07788600027561188, 0.007301550358533859, -0.20040029287338257, -0.06233274191617966, -0.2712494432926178, -0.036856625229120255, 0.021736374124884605, -0.07884566485881805]
  OUT[0]: [1, 7, 1152] | μ=-0.030967 σ=0.135489
    First 10: [-0.009873035363852978, -0.10324342548847198, 0.033864401280879974, -0.035740070044994354, -0.09735973179340363, 0.09461182355880737, -0.03294965997338295, 0.02536899410188198, -0.015865204855799675, 0.013873263262212276]
    Last 10:  [-0.03779834136366844, -0.01086032297462225, -0.03652537986636162, 0.0036720437929034233, -0.08428562432527542, -0.029617341235280037, -0.10662973672151566, -0.017886508256196976, 0.011056660674512386, -0.03694533184170723]

285_layers.17.mlp.up_proj: layers.17.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.028222 σ=1.617025
    First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
    Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
  OUT[0]: [1, 7, 1152] | μ=-0.006298 σ=0.308781
    First 10: [-0.019437983632087708, 0.15518909692764282, -0.61243736743927, -0.039641156792640686, 0.06762806326150894, -0.07792088389396667, 0.2095772922039032, -0.055818766355514526, 0.13642644882202148, -0.33568185567855835]
    Last 10:  [-0.012301240116357803, -0.09485477209091187, -0.07380126416683197, -0.03080572932958603, -0.0125289186835289, 0.07794427126646042, -0.22445155680179596, -0.013760721310973167, 0.06169222667813301, 0.009290918707847595]
  WEIGHT: [1152, 768] | μ=0.000003

286_layers.17.mlp.down_proj: layers.17.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.001078 σ=0.054392
    First 10: [0.00019191189494449645, -0.016022253781557083, -0.020739825442433357, 0.0014167777262628078, -0.0065842499025166035, -0.0073722368106245995, -0.006905500311404467, -0.001416065962985158, -0.002164433477446437, -0.004657002631574869]
    Last 10:  [0.0004649664624594152, 0.0010301534784957767, 0.0026956191286444664, -0.00011311998969176784, 0.0010560076916590333, -0.002308502094820142, 0.023933209478855133, 0.00024613126879557967, 0.0006821100250817835, -0.0003432560770306736]
  OUT[0]: [1, 7, 768] | μ=-0.000621 σ=0.017734
    First 10: [0.014830893836915493, -0.0022054282017052174, -0.020456654950976372, 0.010588185861706734, -0.006462601013481617, 0.014442737214267254, 0.001900000381283462, -0.004931164439767599, 0.0022836157586425543, -0.004706940148025751]
    Last 10:  [-0.0002853651822078973, 0.0007746431510895491, -0.005335040856152773, -0.002247826661914587, 0.0020703605841845274, 0.0005449880845844746, -2.3727596271783113e-05, 0.002417197683826089, 0.001982189482077956, -0.0009052392560988665]
  WEIGHT: [768, 1152] | μ=-0.000000

287_layers.17.mlp: layers.17.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.028222 σ=1.617025
    First 10: [3.164077043533325, -0.305874764919281, -0.20127791166305542, -0.5546880960464478, 0.19256067276000977, 1.4793609380722046, 2.21905779838562, 0.42553257942199707, -1.3846782445907593, 0.39279472827911377]
    Last 10:  [0.1787160336971283, 0.11721841990947723, 2.066188097000122, 0.0017405897378921509, 0.7369488477706909, -0.08719334751367569, 0.2505689859390259, -0.7598181962966919, -0.054388657212257385, 0.4345143139362335]
  OUT[0]: [1, 7, 768] | μ=-0.000621 σ=0.017734
    First 10: [0.014830893836915493, -0.0022054282017052174, -0.020456654950976372, 0.010588185861706734, -0.006462601013481617, 0.014442737214267254, 0.001900000381283462, -0.004931164439767599, 0.0022836157586425543, -0.004706940148025751]
    Last 10:  [-0.0002853651822078973, 0.0007746431510895491, -0.005335040856152773, -0.002247826661914587, 0.0020703605841845274, 0.0005449880845844746, -2.3727596271783113e-05, 0.002417197683826089, 0.001982189482077956, -0.0009052392560988665]

288_layers.17.post_feedforward_layernorm: layers.17.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000621 σ=0.017734
    First 10: [0.014830893836915493, -0.0022054282017052174, -0.020456654950976372, 0.010588185861706734, -0.006462601013481617, 0.014442737214267254, 0.001900000381283462, -0.004931164439767599, 0.0022836157586425543, -0.004706940148025751]
    Last 10:  [-0.0002853651822078973, 0.0007746431510895491, -0.005335040856152773, -0.002247826661914587, 0.0020703605841845274, 0.0005449880845844746, -2.3727596271783113e-05, 0.002417197683826089, 0.001982189482077956, -0.0009052392560988665]
  OUT[0]: [1, 7, 768] | μ=4.056320 σ=248.259827
    First 10: [53.58515930175781, -35.57484436035156, -133.1756134033203, 78.62606811523438, -55.07909393310547, 148.32968139648438, 14.99479866027832, -32.27436065673828, 23.399826049804688, -62.352054595947266]
    Last 10:  [-4.5850138664245605, 7.166935443878174, -149.34461975097656, -69.96112060546875, 58.469444274902344, 27.1387939453125, -1.0460755825042725, 41.42734146118164, 47.9119873046875, -43.08349609375]
  WEIGHT: [768] | μ=140.947922

289_layers.18.input_layernorm: layers.18.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=9.259257 σ=477.690765
    First 10: [259.7178955078125, -125.32144927978516, -149.49838256835938, 31.582500457763672, -29.06850814819336, 438.74200439453125, 227.3252410888672, -2.049610137939453, -264.0870361328125, 20.21841812133789]
    Last 10:  [21.403472900390625, 18.328916549682617, 192.95289611816406, -69.47207641601562, 296.9412536621094, -21.411815643310547, 110.78163146972656, -91.68739318847656, 33.48908233642578, 166.20558166503906]
  OUT[0]: [1, 7, 768] | μ=0.068529 σ=6.911074
    First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
    Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
  WEIGHT: [768] | μ=14.610023

290_layers.18.self_attn.q_proj: layers.18.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.068529 σ=6.911074
    First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
    Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
  OUT[0]: [1, 7, 768] | μ=0.062047 σ=2.425930
    First 10: [-2.1774837970733643, -0.042265474796295166, 8.275694847106934, 1.1739144325256348, -9.493600845336914, -3.261657476425171, 0.8537642359733582, -0.01603122055530548, 0.9513674974441528, -0.4123399257659912]
    Last 10:  [-0.5237553715705872, 0.1617172360420227, 0.38433629274368286, 0.1967179924249649, -0.2654699385166168, -0.9831024408340454, -0.4114379286766052, -2.561054229736328, 0.35436972975730896, -0.37237581610679626]
  WEIGHT: [768, 768] | μ=0.000005

291_layers.18.self_attn.k_proj: layers.18.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.068529 σ=6.911074
    First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
    Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
  OUT[0]: [1, 7, 256] | μ=-0.104629 σ=2.658833
    First 10: [0.162762850522995, 0.2684285640716553, -0.5371240377426147, -1.3025097846984863, -2.5659079551696777, -5.457845687866211, -2.5228047370910645, 3.0173192024230957, -7.311702728271484, -0.3233160972595215]
    Last 10:  [-2.0583090782165527, -5.3989667892456055, -3.754859447479248, -4.582265377044678, -2.5288443565368652, -1.9453688859939575, 2.989722728729248, -2.247180461883545, 4.377954959869385, -0.1701778918504715]
  WEIGHT: [256, 768] | μ=-0.000046

292_layers.18.self_attn.v_proj: layers.18.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.068529 σ=6.911074
    First 10: [14.321464538574219, -1.569189190864563, -4.182168960571289, 0.7067245841026306, -0.8052279353141785, 8.76447868347168, 5.33723783493042, -0.053804751485586166, -5.22993803024292, 0.35448595881462097]
    Last 10:  [0.37093886733055115, 0.5356781482696533, 1.7565304040908813, -0.7367857098579407, 2.484002113342285, -0.11872757971286774, 0.8137179613113403, -2.026787757873535, 0.40987464785575867, 1.0709468126296997]
  OUT[0]: [1, 7, 256] | μ=-0.118032 σ=1.525934
    First 10: [-2.6649892330169678, 1.796452283859253, -0.13894771039485931, 1.1040825843811035, 0.0843687355518341, -0.4004369080066681, -0.44738176465034485, -0.22352451086044312, 1.222933292388916, -0.6613889932632446]
    Last 10:  [-0.054093584418296814, -0.5611344575881958, -0.17963440716266632, -0.3368476629257202, 0.164906844496727, 0.16659802198410034, 0.20967981219291687, 0.9458404183387756, 0.32866865396499634, -0.2231229543685913]
  WEIGHT: [256, 768] | μ=0.000026

293_layers.18.self_attn.q_norm: layers.18.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=0.062047 σ=2.425930
    First 10: [-2.1774837970733643, -0.042265474796295166, 8.275694847106934, 1.1739144325256348, -9.493600845336914, -3.261657476425171, 0.8537642359733582, -0.01603122055530548, 0.9513674974441528, -0.4123399257659912]
    Last 10:  [-0.5237553715705872, 0.1617172360420227, 0.38433629274368286, 0.1967179924249649, -0.2654699385166168, -0.9831024408340454, -0.4114379286766052, -2.561054229736328, 0.35436972975730896, -0.37237581610679626]
  OUT[0]: [1, 3, 7, 256] | μ=-0.046454 σ=1.144631
    First 10: [-1.9474512338638306, -0.01537019107490778, -0.1596963107585907, 0.6601147651672363, 0.038346391171216965, -0.014301051385700703, 0.16802802681922913, -0.00372096779756248, 0.2638396620750427, -0.272217720746994]
    Last 10:  [-0.7556747198104858, 0.3389131724834442, 0.4232017397880554, 0.2777065932750702, -0.24795357882976532, -2.97719407081604, -0.3859609365463257, -4.463176727294922, 0.6152921915054321, -0.5298264026641846]
  WEIGHT: [256] | μ=0.388585

294_layers.18.self_attn.k_norm: layers.18.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.104629 σ=2.658833
    First 10: [0.162762850522995, 0.2684285640716553, -0.5371240377426147, -1.3025097846984863, -2.5659079551696777, -5.457845687866211, -2.5228047370910645, 3.0173192024230957, -7.311702728271484, -0.3233160972595215]
    Last 10:  [-2.0583090782165527, -5.3989667892456055, -3.754859447479248, -4.582265377044678, -2.5288443565368652, -1.9453688859939575, 2.989722728729248, -2.247180461883545, 4.377954959869385, -0.1701778918504715]
  OUT[0]: [1, 1, 7, 256] | μ=-0.007139 σ=1.435282
    First 10: [0.0668410211801529, 0.05782278627157211, -0.04486856237053871, -0.511626124382019, 0.003911871928721666, 0.05830930545926094, 0.11690755933523178, -0.03356814756989479, -0.12521857023239136, -0.12841273844242096]
    Last 10:  [-2.14074444770813, -3.6278793811798096, -5.295547962188721, -4.40044641494751, -4.79129695892334, -0.9543855786323547, 4.517821311950684, -2.6129047870635986, 3.6324167251586914, -0.18597762286663055]
  WEIGHT: [256] | μ=0.498036

295_layers.18.self_attn.o_proj: layers.18.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.091659 σ=1.014101
    First 10: [-2.6649892330169678, 1.796452283859253, -0.13894771039485931, 1.1040825843811035, 0.0843687355518341, -0.4004369080066681, -0.44738176465034485, -0.22352451086044312, 1.222933292388916, -0.6613889932632446]
    Last 10:  [-0.1822447031736374, -0.30132484436035156, -0.3175017833709717, -0.16374371945858002, -0.19287553429603577, -0.025285527110099792, 0.44553738832473755, 0.6794939041137695, 0.24065211415290833, -0.29227614402770996]
  OUT[0]: [1, 7, 768] | μ=0.014936 σ=0.467728
    First 10: [-0.028786268085241318, -0.24227291345596313, -0.17645567655563354, -0.32700619101524353, -0.0036256052553653717, 0.12427055835723877, -0.033314742147922516, 0.25487828254699707, 0.11698121577501297, -0.1492024064064026]
    Last 10:  [-0.04292595386505127, 0.09079144895076752, -0.17470766603946686, 0.20066092908382416, 0.05006881058216095, 0.008012007921934128, 0.0802340880036354, -0.02887076511979103, 0.027440868318080902, -0.033877477049827576]
  WEIGHT: [768, 768] | μ=-0.000015

296_layers.18.self_attn: layers.18.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.014936 σ=0.467728
    First 10: [-0.028786268085241318, -0.24227291345596313, -0.17645567655563354, -0.32700619101524353, -0.0036256052553653717, 0.12427055835723877, -0.033314742147922516, 0.25487828254699707, 0.11698121577501297, -0.1492024064064026]
    Last 10:  [-0.04292595386505127, 0.09079144895076752, -0.17470766603946686, 0.20066092908382416, 0.05006881058216095, 0.008012007921934128, 0.0802340880036354, -0.02887076511979103, 0.027440868318080902, -0.033877477049827576]

297_layers.18.post_attention_layernorm: layers.18.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.014936 σ=0.467728
    First 10: [-0.028786268085241318, -0.24227291345596313, -0.17645567655563354, -0.32700619101524353, -0.0036256052553653717, 0.12427055835723877, -0.033314742147922516, 0.25487828254699707, 0.11698121577501297, -0.1492024064064026]
    Last 10:  [-0.04292595386505127, 0.09079144895076752, -0.17470766603946686, 0.20066092908382416, 0.05006881058216095, 0.008012007921934128, 0.0802340880036354, -0.02887076511979103, 0.027440868318080902, -0.033877477049827576]
  OUT[0]: [1, 7, 768] | μ=0.408070 σ=74.197464
    First 10: [-2.061854362487793, -74.63522338867188, -21.957693099975586, -43.15880584716797, -0.6440495252609253, 28.67140769958496, -5.1889238357543945, 28.34436798095703, 28.34653663635254, -38.78664016723633]
    Last 10:  [-14.669159889221191, 20.427570343017578, -86.89913940429688, 121.09613800048828, 37.39701461791992, 9.15478515625, 68.94178771972656, -17.1794490814209, 16.96843910217285, -36.32876205444336]
  WEIGHT: [768] | μ=100.656677

298_layers.18.pre_feedforward_layernorm: layers.18.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=9.667328 σ=427.382690
    First 10: [257.6560363769531, -199.9566650390625, -171.45606994628906, -11.576305389404297, -29.712556838989258, 467.4134216308594, 222.13632202148438, 26.294757843017578, -235.74049377441406, -18.568222045898438]
    Last 10:  [6.734313011169434, 38.75648498535156, 106.05375671386719, 51.624061584472656, 334.3382568359375, -12.257030487060547, 179.72341918945312, -108.8668441772461, 50.45751953125, 129.87681579589844]
  OUT[0]: [1, 7, 768] | μ=0.012446 σ=1.019172
    First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
    Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
  WEIGHT: [768] | μ=1.649356

299_layers.18.mlp.gate_proj: layers.18.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.012446 σ=1.019172
    First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
    Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
  OUT[0]: [1, 7, 1152] | μ=-0.119476 σ=0.219135
    First 10: [-0.17988207936286926, -0.21000930666923523, -0.024091005325317383, -0.0394328236579895, -0.11351096630096436, -0.03969129920005798, 0.02730964682996273, -0.1018436923623085, 0.22572197020053864, -0.08108986914157867]
    Last 10:  [0.001233687624335289, -0.0050574736669659615, -0.03471614047884941, -0.10256095230579376, -0.05194105952978134, -0.10231079906225204, -0.05719830095767975, 0.03529198095202446, -0.0854916200041771, 0.00017721671611070633]
  WEIGHT: [1152, 768] | μ=-0.000025

300_layers.18.mlp.act_fn: layers.18.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.119476 σ=0.219135
    First 10: [-0.17988207936286926, -0.21000930666923523, -0.024091005325317383, -0.0394328236579895, -0.11351096630096436, -0.03969129920005798, 0.02730964682996273, -0.1018436923623085, 0.22572197020053864, -0.08108986914157867]
    Last 10:  [0.001233687624335289, -0.0050574736669659615, -0.03471614047884941, -0.10256095230579376, -0.05194105952978134, -0.10231079906225204, -0.05719830095767975, 0.03529198095202446, -0.0854916200041771, 0.00017721671611070633]
  OUT[0]: [1, 7, 1152] | μ=-0.035811 σ=0.092850
    First 10: [-0.07710185647010803, -0.08753884583711624, -0.011813987977802753, -0.019096238538622856, -0.051626287400722504, -0.019217321649193764, 0.013952323235571384, -0.046791139990091324, 0.13301514089107513, -0.037924546748399734]
    Last 10:  [0.0006174509762786329, -0.0025185327976942062, -0.01687735877931118, -0.04709148406982422, -0.024894719943404198, -0.04698678106069565, -0.027294667437672615, 0.018142778426408768, -0.03983357921242714, 8.862088725436479e-05]

301_layers.18.mlp.up_proj: layers.18.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.012446 σ=1.019172
    First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
    Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
  OUT[0]: [1, 7, 1152] | μ=-0.002900 σ=0.181142
    First 10: [-0.06145596504211426, -0.10385297983884811, -0.08923856914043427, 0.2193443775177002, 0.1481899917125702, -0.07554617524147034, -0.04965831711888313, -0.08212539553642273, 0.004987452179193497, -0.05415832996368408]
    Last 10:  [0.053890079259872437, 0.029755305498838425, 0.08888868987560272, 0.045460186898708344, 0.043922457844018936, -0.07866249978542328, -0.03991434723138809, 0.03006092458963394, -0.02783208154141903, 0.021822761744260788]
  WEIGHT: [1152, 768] | μ=0.000001

302_layers.18.mlp.down_proj: layers.18.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000024 σ=0.023587
    First 10: [0.004738369025290012, 0.009091169573366642, 0.0010542634408921003, -0.004188652615994215, -0.007650499232113361, 0.0014517951058223844, -0.000692848872859031, 0.003842740785330534, 0.0006634066812694073, 0.002053930191323161]
    Last 10:  [3.3274482120759785e-05, -7.493971497751772e-05, -0.0015002063009887934, -0.002140787662938237, -0.0010934373131021857, 0.0036960977595299482, 0.0010894488077610731, 0.000545388669706881, 0.0011086513986811042, 1.9339524897077354e-06]
  OUT[0]: [1, 7, 768] | μ=-0.000227 σ=0.007934
    First 10: [0.001970715122297406, 0.0019319071434438229, -0.002610577503219247, 0.0013772472739219666, 4.166521830484271e-05, 0.003911722917109728, 0.004739252384752035, -0.004501949530094862, 0.0033819079399108887, -0.0006725167040713131]
    Last 10:  [-0.0005120760179124773, -0.0003324755234643817, -0.0006768406601622701, 2.8345082682790235e-05, 0.0009595267474651337, -0.00018653649021871388, -0.0004320660373196006, 0.00013209789176471531, -0.0003018003480974585, -0.000598056532908231]
  WEIGHT: [768, 1152] | μ=0.000006

303_layers.18.mlp: layers.18.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.012446 σ=1.019172
    First 10: [2.495764970779419, -0.40583211183547974, -1.2048760652542114, -0.07598402351140976, -0.13423077762126923, 1.5435043573379517, 1.2629759311676025, 0.1980479657649994, -0.7980005145072937, -0.05286248400807381]
    Last 10:  [0.026964683085680008, 0.24109017848968506, 0.2918481230735779, 0.10320524126291275, 0.558355987071991, -0.013121549040079117, 0.24246187508106232, -0.39191192388534546, 0.11870010942220688, 0.1512594223022461]
  OUT[0]: [1, 7, 768] | μ=-0.000227 σ=0.007934
    First 10: [0.001970715122297406, 0.0019319071434438229, -0.002610577503219247, 0.0013772472739219666, 4.166521830484271e-05, 0.003911722917109728, 0.004739252384752035, -0.004501949530094862, 0.0033819079399108887, -0.0006725167040713131]
    Last 10:  [-0.0005120760179124773, -0.0003324755234643817, -0.0006768406601622701, 2.8345082682790235e-05, 0.0009595267474651337, -0.00018653649021871388, -0.0004320660373196006, 0.00013209789176471531, -0.0003018003480974585, -0.000598056532908231]

304_layers.18.post_feedforward_layernorm: layers.18.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000227 σ=0.007934
    First 10: [0.001970715122297406, 0.0019319071434438229, -0.002610577503219247, 0.0013772472739219666, 4.166521830484271e-05, 0.003911722917109728, 0.004739252384752035, -0.004501949530094862, 0.0033819079399108887, -0.0006725167040713131]
    Last 10:  [-0.0005120760179124773, -0.0003324755234643817, -0.0006768406601622701, 2.8345082682790235e-05, 0.0009595267474651337, -0.00018653649021871388, -0.0004320660373196006, 0.00013209789176471531, -0.0003018003480974585, -0.000598056532908231]
  OUT[0]: [1, 7, 768] | μ=8.218795 σ=174.462769
    First 10: [12.856961250305176, 60.41134262084961, -30.209253311157227, 18.07050132751465, 0.7325072288513184, 81.97917938232422, 71.00474548339844, -52.33843994140625, 73.60611724853516, -18.484697341918945]
    Last 10:  [-28.668489456176758, -11.386631965637207, -62.03402328491211, 3.54416561126709, 90.80278778076172, -32.65223693847656, -70.39073181152344, 13.29366397857666, -27.819137573242188, -104.61965942382812]
  WEIGHT: [768] | μ=152.509689

305_layers.19.input_layernorm: layers.19.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=17.886124 σ=549.190369
    First 10: [270.51300048828125, -139.54531860351562, -201.6653289794922, 6.494195938110352, -28.98004913330078, 549.392578125, 293.14105224609375, -26.043682098388672, -162.13436889648438, -37.05291748046875]
    Last 10:  [-21.93417739868164, 27.369853973388672, 44.01973342895508, 55.16822814941406, 425.14105224609375, -44.90926742553711, 109.33268737792969, -95.57318115234375, 22.638381958007812, 25.257156372070312]
  OUT[0]: [1, 7, 768] | μ=0.148822 σ=4.276307
    First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
    Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
  WEIGHT: [768] | μ=8.377877

306_layers.19.self_attn.q_proj: layers.19.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.148822 σ=4.276307
    First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
    Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
  OUT[0]: [1, 7, 768] | μ=-0.078969 σ=1.255975
    First 10: [0.9997197389602661, -0.6611632108688354, 1.151519775390625, 1.0701558589935303, 0.8845419883728027, -0.012620992958545685, -0.5445837378501892, 2.924321174621582, -1.1011874675750732, -0.08469951152801514]
    Last 10:  [-0.24868044257164001, 0.4550326466560364, -0.6265720129013062, -0.1513674557209015, 0.26094305515289307, -0.3760688900947571, 0.37938031554222107, -0.5787829160690308, -0.6251511573791504, -1.8353488445281982]
  WEIGHT: [768, 768] | μ=-0.000013

307_layers.19.self_attn.k_proj: layers.19.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.148822 σ=4.276307
    First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
    Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
  OUT[0]: [1, 7, 256] | μ=-0.117643 σ=1.734052
    First 10: [0.8714194297790527, -1.0026236772537231, -0.08344118297100067, -1.9501763582229614, -5.918198585510254, -2.1989688873291016, 2.344635009765625, 2.956681728363037, -0.41049450635910034, 0.4399896562099457]
    Last 10:  [-0.6533032059669495, 1.7090895175933838, -0.3604780435562134, -1.949053168296814, -1.2105743885040283, -1.5888001918792725, -2.3219118118286133, -1.1165657043457031, 0.8111847043037415, -3.1706151962280273]
  WEIGHT: [256, 768] | μ=0.000011

308_layers.19.self_attn.v_proj: layers.19.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.148822 σ=4.276307
    First 10: [8.734284400939941, -0.5718948245048523, -2.8434877395629883, 0.0822296217083931, -0.2926473319530487, 4.478161334991455, 3.2590107917785645, -0.3720315098762512, -1.1415328979492188, -0.2548315227031708]
    Last 10:  [-0.2428017556667328, 0.40256333351135254, 0.3094029724597931, 0.3491690754890442, 2.3056936264038086, -0.13707582652568817, 0.4327518343925476, -0.9795004725456238, 0.12985870242118835, 0.08612639456987381]
  OUT[0]: [1, 7, 256] | μ=0.003305 σ=0.768246
    First 10: [-0.09311835467815399, -1.0133436918258667, -0.5233939290046692, -0.34847012162208557, -0.3432435989379883, 1.136409044265747, -0.8997690081596375, 0.06556414067745209, -0.5830128192901611, -0.7777641415596008]
    Last 10:  [0.2082168161869049, 0.632858395576477, 0.10820508003234863, 0.806389570236206, -1.4193416833877563, -0.24411579966545105, 0.07685770094394684, 0.23310378193855286, 0.4236438274383545, -0.06579846143722534]
  WEIGHT: [256, 768] | μ=-0.000015

309_layers.19.self_attn.q_norm: layers.19.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.078969 σ=1.255975
    First 10: [0.9997197389602661, -0.6611632108688354, 1.151519775390625, 1.0701558589935303, 0.8845419883728027, -0.012620992958545685, -0.5445837378501892, 2.924321174621582, -1.1011874675750732, -0.08469951152801514]
    Last 10:  [-0.24868044257164001, 0.4550326466560364, -0.6265720129013062, -0.1513674557209015, 0.26094305515289307, -0.3760688900947571, 0.37938031554222107, -0.5787829160690308, -0.6251511573791504, -1.8353488445281982]
  OUT[0]: [1, 3, 7, 256] | μ=-0.049582 σ=1.112609
    First 10: [2.119532823562622, -0.6987621784210205, 1.46214759349823, -0.0036208159290254116, 0.47036099433898926, -0.017586015164852142, -0.5920274257659912, -1.2128721475601196, -4.498411178588867, -0.3093208074569702]
    Last 10:  [-0.3730458617210388, 0.8988171815872192, -1.0296274423599243, -0.2482423335313797, 0.44977715611457825, -0.5969147086143494, 0.5999048948287964, -0.8269142508506775, -0.8912956118583679, -1.792016863822937]
  WEIGHT: [256] | μ=0.183203

310_layers.19.self_attn.k_norm: layers.19.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.117643 σ=1.734052
    First 10: [0.8714194297790527, -1.0026236772537231, -0.08344118297100067, -1.9501763582229614, -5.918198585510254, -2.1989688873291016, 2.344635009765625, 2.956681728363037, -0.41049450635910034, 0.4399896562099457]
    Last 10:  [-0.6533032059669495, 1.7090895175933838, -0.3604780435562134, -1.949053168296814, -1.2105743885040283, -1.5888001918792725, -2.3219118118286133, -1.1165657043457031, 0.8111847043037415, -3.1706151962280273]
  OUT[0]: [1, 1, 7, 256] | μ=-0.119696 σ=1.295088
    First 10: [0.7442797422409058, -2.036738395690918, 0.01738479919731617, 0.0029593482613563538, -2.4216489791870117, -1.0225602388381958, 0.559409499168396, -0.692674458026886, -0.2392766773700714, 0.32603397965431213]
    Last 10:  [-0.7467968463897705, 2.080594062805176, -0.4687407612800598, -2.139889717102051, -1.4993035793304443, -2.262117385864258, -2.8749823570251465, -1.2592108249664307, 1.0839186906814575, -4.547543525695801]
  WEIGHT: [256] | μ=0.519761

311_layers.19.self_attn.o_proj: layers.19.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.010449 σ=0.546782
    First 10: [-0.09311835467815399, -1.0133436918258667, -0.5233939290046692, -0.34847012162208557, -0.3432435989379883, 1.136409044265747, -0.8997690081596375, 0.06556414067745209, -0.5830128192901611, -0.7777641415596008]
    Last 10:  [0.14888261258602142, 0.5811675786972046, 0.04036650061607361, 0.6124897003173828, -1.1038317680358887, -0.12090494483709335, -0.1123894602060318, 0.16309703886508942, 0.4210304021835327, -0.031128766015172005]
  OUT[0]: [1, 7, 768] | μ=-0.009816 σ=0.233819
    First 10: [-0.04161803424358368, 0.09904502332210541, 0.18690672516822815, 0.06329116225242615, 0.03062961995601654, -0.06561634689569473, 0.06879182904958725, 0.2753956913948059, 0.15538033843040466, 0.01525195874273777]
    Last 10:  [-0.0038687577471137047, 0.028554942458868027, -0.055815063416957855, -0.055135391652584076, 0.16534394025802612, -0.05187083035707474, 0.022894879803061485, -0.07421866804361343, 0.06020951271057129, 0.044333815574645996]
  WEIGHT: [768, 768] | μ=0.000008

312_layers.19.self_attn: layers.19.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.009816 σ=0.233819
    First 10: [-0.04161803424358368, 0.09904502332210541, 0.18690672516822815, 0.06329116225242615, 0.03062961995601654, -0.06561634689569473, 0.06879182904958725, 0.2753956913948059, 0.15538033843040466, 0.01525195874273777]
    Last 10:  [-0.0038687577471137047, 0.028554942458868027, -0.055815063416957855, -0.055135391652584076, 0.16534394025802612, -0.05187083035707474, 0.022894879803061485, -0.07421866804361343, 0.06020951271057129, 0.044333815574645996]

313_layers.19.post_attention_layernorm: layers.19.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.009816 σ=0.233819
    First 10: [-0.04161803424358368, 0.09904502332210541, 0.18690672516822815, 0.06329116225242615, 0.03062961995601654, -0.06561634689569473, 0.06879182904958725, 0.2753956913948059, 0.15538033843040466, 0.01525195874273777]
    Last 10:  [-0.0038687577471137047, 0.028554942458868027, -0.055815063416957855, -0.055135391652584076, 0.16534394025802612, -0.05187083035707474, 0.022894879803061485, -0.07421866804361343, 0.06020951271057129, 0.044333815574645996]
  OUT[0]: [1, 7, 768] | μ=-4.487651 σ=103.673340
    First 10: [-9.721266746520996, 121.05615234375, 114.63024139404297, 51.615543365478516, 18.99530601501465, -45.96036148071289, 51.86756134033203, 171.12130737304688, 135.06651306152344, 15.807371139526367]
    Last 10:  [-0.838489830493927, 2.820838212966919, -28.671588897705078, -20.468490600585938, 51.155792236328125, -30.456390380859375, 12.346565246582031, -12.817898750305176, 16.575565338134766, 24.549116134643555]
  WEIGHT: [768] | μ=104.723106

314_layers.19.pre_feedforward_layernorm: layers.19.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=13.398470 σ=495.212769
    First 10: [260.791748046875, -18.489166259765625, -87.03508758544922, 58.1097412109375, -9.984743118286133, 503.4322204589844, 345.00860595703125, 145.07762145996094, -27.067855834960938, -21.245546340942383]
    Last 10:  [-22.772666931152344, 30.190692901611328, 15.34814453125, 34.699737548828125, 476.2968444824219, -75.36566162109375, 121.67925262451172, -108.39108276367188, 39.21394729614258, 49.8062744140625]
  OUT[0]: [1, 7, 768] | μ=0.017846 σ=0.765819
    First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
    Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
  WEIGHT: [768] | μ=1.214840

315_layers.19.mlp.gate_proj: layers.19.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.017846 σ=0.765819
    First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
    Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
  OUT[0]: [1, 7, 1152] | μ=-0.040005 σ=0.147792
    First 10: [-0.02808528020977974, -0.08304241299629211, 0.2624969780445099, 0.1020033061504364, -0.1437465101480484, 0.07065102458000183, -0.114624984562397, 0.018533295020461082, 0.06318080425262451, 0.048162929713726044]
    Last 10:  [0.37262672185897827, -0.03964526578783989, -0.15938477218151093, 0.08839632570743561, -0.027503537014126778, -0.03254815936088562, -0.00853501632809639, 0.025330770760774612, -0.1033533588051796, -0.1038651391863823]
  WEIGHT: [1152, 768] | μ=-0.000021

316_layers.19.mlp.act_fn: layers.19.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.040005 σ=0.147792
    First 10: [-0.02808528020977974, -0.08304241299629211, 0.2624969780445099, 0.1020033061504364, -0.1437465101480484, 0.07065102458000183, -0.114624984562397, 0.018533295020461082, 0.06318080425262451, 0.048162929713726044]
    Last 10:  [0.37262672185897827, -0.03964526578783989, -0.15938477218151093, 0.08839632570743561, -0.027503537014126778, -0.03254815936088562, -0.00853501632809639, 0.025330770760774612, -0.1033533588051796, -0.1038651391863823]
  OUT[0]: [1, 7, 1152] | μ=-0.010804 σ=0.070061
    First 10: [-0.013728003017604351, -0.03877325728535652, 0.1584235280752182, 0.055145297199487686, -0.06365832686424255, 0.03731519356369972, -0.05208234861493111, 0.009403669275343418, 0.03318184241652489, 0.025006519630551338]
    Last 10:  [0.24044537544250488, -0.019195761531591415, -0.06960081309080124, 0.047311387956142426, -0.01345002930611372, -0.015851521864533424, -0.004238446708768606, 0.012921337969601154, -0.04742282256484032, -0.04763655737042427]

317_layers.19.mlp.up_proj: layers.19.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.017846 σ=0.765819
    First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
    Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
  OUT[0]: [1, 7, 1152] | μ=0.000643 σ=0.127050
    First 10: [-0.153435617685318, -0.017016377300024033, 0.01669328659772873, -0.08019869774580002, 0.02240096777677536, -0.1479894071817398, 0.15653537213802338, 0.17422373592853546, 0.15486571192741394, -0.0769917368888855]
    Last 10:  [0.1641092300415039, 0.012790899723768234, -0.011864956468343735, 0.03773633763194084, -0.04173664376139641, 0.041600435972213745, -0.043008893728256226, 0.039892394095659256, -0.03989381343126297, 0.020413141697645187]
  WEIGHT: [1152, 768] | μ=0.000003

318_layers.19.mlp.down_proj: layers.19.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000088 σ=0.012721
    First 10: [0.002106364583596587, 0.0006597804022021592, 0.0026446094270795584, -0.004422580823302269, -0.0014260081807151437, -0.005522253457456827, -0.008152729831635952, 0.0016383423935621977, 0.005138729698956013, -0.001925295335240662]
    Last 10:  [0.03945930674672127, -0.00024553106050007045, 0.0008258105954155326, 0.0017853585304692388, 0.0005613591056317091, -0.0006594302249141037, 0.00018229091074317694, 0.0005154631217010319, 0.001891877269372344, -0.0009724117699079216]
  OUT[0]: [1, 7, 768] | μ=0.000007 σ=0.003754
    First 10: [-0.0001366934011457488, -0.0006556336884386837, 0.0025630928575992584, 0.0008437503129243851, 0.0014984960434958339, 0.00017319759353995323, -1.9404746126383543e-05, -0.003034979570657015, -0.0011872879695147276, 0.0024240119382739067]
    Last 10:  [-0.0014284506905823946, -0.0007461392669938505, -0.0014848088612779975, 0.00029378122417256236, 0.0012645829701796174, -0.0005167420604266226, -0.0004040795029141009, 0.0010501946089789271, -9.315123315900564e-05, -0.0007154666818678379]
  WEIGHT: [768, 1152] | μ=-0.000004

319_layers.19.mlp: layers.19.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.017846 σ=0.765819
    First 10: [1.3964227437973022, -0.022452689707279205, -0.3471200168132782, 0.1922963410615921, -0.02512403205037117, 1.0386817455291748, 1.0669662952423096, 0.5477729439735413, -0.05264217033982277, -0.034996576607227325]
    Last 10:  [-0.06873448938131332, 0.1508382260799408, 0.028690870851278305, 0.05162292346358299, 0.6654092669487, -0.06688831746578217, 0.12760773301124573, -0.3073258101940155, 0.06806158274412155, 0.04664098471403122]
  OUT[0]: [1, 7, 768] | μ=0.000007 σ=0.003754
    First 10: [-0.0001366934011457488, -0.0006556336884386837, 0.0025630928575992584, 0.0008437503129243851, 0.0014984960434958339, 0.00017319759353995323, -1.9404746126383543e-05, -0.003034979570657015, -0.0011872879695147276, 0.0024240119382739067]
    Last 10:  [-0.0014284506905823946, -0.0007461392669938505, -0.0014848088612779975, 0.00029378122417256236, 0.0012645829701796174, -0.0005167420604266226, -0.0004040795029141009, 0.0010501946089789271, -9.315123315900564e-05, -0.0007154666818678379]

320_layers.19.post_feedforward_layernorm: layers.19.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000007 σ=0.003754
    First 10: [-0.0001366934011457488, -0.0006556336884386837, 0.0025630928575992584, 0.0008437503129243851, 0.0014984960434958339, 0.00017319759353995323, -1.9404746126383543e-05, -0.003034979570657015, -0.0011872879695147276, 0.0024240119382739067]
    Last 10:  [-0.0014284506905823946, -0.0007461392669938505, -0.0014848088612779975, 0.00029378122417256236, 0.0012645829701796174, -0.0005167420604266226, -0.0004040795029141009, 0.0010501946089789271, -9.315123315900564e-05, -0.0007154666818678379]
  OUT[0]: [1, 7, 768] | μ=3.678869 σ=142.907867
    First 10: [-2.207524538040161, -53.18722152709961, 69.3331527709961, 23.621549606323242, 70.34169006347656, 8.949487686157227, -0.6258789896965027, -77.27484893798828, -59.869083404541016, 177.43435668945312]
    Last 10:  [-88.21393585205078, -27.913347244262695, -141.93783569335938, 44.71241760253906, 136.95974731445312, -105.70487213134766, -77.20145416259766, 66.0838851928711, -9.757400512695312, -141.72918701171875]
  WEIGHT: [768] | μ=184.135437

321_layers.20.input_layernorm: layers.20.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=17.077339 σ=569.007141
    First 10: [258.584228515625, -71.6763916015625, -17.701934814453125, 81.73129272460938, 60.35694885253906, 512.3817138671875, 344.3827209472656, 67.80277252197266, -86.93693542480469, 156.18881225585938]
    Last 10:  [-110.98660278320312, 2.277345657348633, -126.58969116210938, 79.41215515136719, 613.256591796875, -181.07052612304688, 44.47779846191406, -42.30719757080078, 29.456546783447266, -91.92291259765625]
  OUT[0]: [1, 7, 768] | μ=0.187797 σ=6.553228
    First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
    Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
  WEIGHT: [768] | μ=15.578236

322_layers.20.self_attn.q_proj: layers.20.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.187797 σ=6.553228
    First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
    Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
  OUT[0]: [1, 7, 768] | μ=-0.024409 σ=2.357026
    First 10: [-1.3440251350402832, -0.3703478276729584, -1.1369025707244873, 0.513540506362915, -0.7575384378433228, 1.0102839469909668, -1.8490989208221436, 0.568389892578125, -0.6614009737968445, 0.28585365414619446]
    Last 10:  [-1.3447209596633911, 0.34324491024017334, -1.6670054197311401, -1.0905828475952148, 0.7890999913215637, -0.605061411857605, -0.4653666019439697, 0.7465041279792786, -0.9899506568908691, 1.2571016550064087]
  WEIGHT: [768, 768] | μ=0.000009

323_layers.20.self_attn.k_proj: layers.20.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.187797 σ=6.553228
    First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
    Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
  OUT[0]: [1, 7, 256] | μ=0.161733 σ=2.805400
    First 10: [-1.5511553287506104, 0.0686827301979065, 0.3431394398212433, -2.8122968673706055, -0.7340375781059265, 0.25276070833206177, -0.26014888286590576, -1.3399205207824707, 0.12287792563438416, -1.9904743432998657]
    Last 10:  [1.7680693864822388, 1.4631891250610352, 1.8920707702636719, -3.184497594833374, -5.011660575866699, 4.953741073608398, -3.9005789756774902, 4.9099273681640625, -4.502815246582031, 1.9667564630508423]
  WEIGHT: [256, 768] | μ=-0.000006

324_layers.20.self_attn.v_proj: layers.20.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.187797 σ=6.553228
    First 10: [10.70539379119873, -0.5089911818504333, -0.3466576635837555, 1.3253157138824463, 0.9044705629348755, 6.417768478393555, 5.3833537101745605, 1.3210264444351196, -1.0210013389587402, 1.5526450872421265]
    Last 10:  [-2.3550760746002197, 0.08581232279539108, -1.2562552690505981, 0.8015308976173401, 5.767246246337891, -1.0057835578918457, 0.31016501784324646, -0.7086113691329956, 0.34220263361930847, -0.5855534672737122]
  OUT[0]: [1, 7, 256] | μ=-0.080192 σ=1.302850
    First 10: [0.34779447317123413, 0.8539810180664062, -0.15037167072296143, -0.7638791799545288, 0.4911248981952667, 1.1574691534042358, 1.1371973752975464, -0.95177161693573, 0.12592613697052002, 0.5844687223434448]
    Last 10:  [-0.7123718857765198, 0.5391747951507568, -0.9238556027412415, -0.014662742614746094, 0.5158359408378601, 0.508171796798706, -0.9690453410148621, 0.09781811386346817, 1.1932687759399414, 0.17384730279445648]
  WEIGHT: [256, 768] | μ=0.000010

325_layers.20.self_attn.q_norm: layers.20.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.024409 σ=2.357026
    First 10: [-1.3440251350402832, -0.3703478276729584, -1.1369025707244873, 0.513540506362915, -0.7575384378433228, 1.0102839469909668, -1.8490989208221436, 0.568389892578125, -0.6614009737968445, 0.28585365414619446]
    Last 10:  [-1.3447209596633911, 0.34324491024017334, -1.6670054197311401, -1.0905828475952148, 0.7890999913215637, -0.605061411857605, -0.4653666019439697, 0.7465041279792786, -0.9899506568908691, 1.2571016550064087]
  OUT[0]: [1, 3, 7, 256] | μ=0.023178 σ=1.184326
    First 10: [-0.7103258371353149, -0.1769796758890152, -0.6651169657707214, 0.10792825371026993, -0.4096786379814148, 0.4286145269870758, -0.7430889010429382, 0.2477957010269165, -0.3093208074569702, 0.12394540756940842]
    Last 10:  [-0.564628541469574, 0.25831466913223267, -0.40617868304252625, -0.6505017280578613, 0.3764146566390991, -0.2677760720252991, -0.27225181460380554, 0.3438563048839569, -0.6194964647293091, 0.7517917156219482]
  WEIGHT: [256] | μ=0.431039

326_layers.20.self_attn.k_norm: layers.20.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.161733 σ=2.805400
    First 10: [-1.5511553287506104, 0.0686827301979065, 0.3431394398212433, -2.8122968673706055, -0.7340375781059265, 0.25276070833206177, -0.26014888286590576, -1.3399205207824707, 0.12287792563438416, -1.9904743432998657]
    Last 10:  [1.7680693864822388, 1.4631891250610352, 1.8920707702636719, -3.184497594833374, -5.011660575866699, 4.953741073608398, -3.9005789756774902, 4.9099273681640625, -4.502815246582031, 1.9667564630508423]
  OUT[0]: [1, 1, 7, 256] | μ=0.007829 σ=2.404580
    First 10: [-0.7965043187141418, 0.07909199595451355, 0.17118382453918457, -2.9248833656311035, -0.47024714946746826, 0.11251700669527054, -0.09325817972421646, -0.6520357131958008, 0.10392066091299057, -0.9211878776550293]
    Last 10:  [2.279050350189209, 0.9570527672767639, 3.578657627105713, -2.740859031677246, -5.231146335601807, 5.811042308807373, -3.209416627883911, 5.601173400878906, -3.5579376220703125, 1.7080662250518799]
  WEIGHT: [256] | μ=0.883833

327_layers.20.self_attn.o_proj: layers.20.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.081223 σ=0.925373
    First 10: [0.34779447317123413, 0.8539810180664062, -0.15037167072296143, -0.7638791799545288, 0.4911248981952667, 1.1574691534042358, 1.1371973752975464, -0.95177161693573, 0.12592613697052002, 0.5844687223434448]
    Last 10:  [-1.1329500675201416, -0.2988707423210144, -0.09596550464630127, 0.16949063539505005, 0.0933767557144165, -0.5033852458000183, -0.46598196029663086, 0.22006136178970337, 0.8598257303237915, 0.588088870048523]
  OUT[0]: [1, 7, 768] | μ=0.000344 σ=0.339814
    First 10: [-0.058488115668296814, 0.4968450665473938, 0.28777316212654114, 0.26345187425613403, -0.30926060676574707, -0.11739331483840942, -0.1300537884235382, -0.18562503159046173, 0.0504431277513504, 0.2471245676279068]
    Last 10:  [0.14162041246891022, -0.13119004666805267, 0.02552253007888794, -0.1741998940706253, 0.043956100940704346, 0.0424971878528595, 0.186425119638443, -0.19931669533252716, -0.04439568147063255, 0.127413809299469]
  WEIGHT: [768, 768] | μ=0.000007

328_layers.20.self_attn: layers.20.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.000344 σ=0.339814
    First 10: [-0.058488115668296814, 0.4968450665473938, 0.28777316212654114, 0.26345187425613403, -0.30926060676574707, -0.11739331483840942, -0.1300537884235382, -0.18562503159046173, 0.0504431277513504, 0.2471245676279068]
    Last 10:  [0.14162041246891022, -0.13119004666805267, 0.02552253007888794, -0.1741998940706253, 0.043956100940704346, 0.0424971878528595, 0.186425119638443, -0.19931669533252716, -0.04439568147063255, 0.127413809299469]

329_layers.20.post_attention_layernorm: layers.20.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000344 σ=0.339814
    First 10: [-0.058488115668296814, 0.4968450665473938, 0.28777316212654114, 0.26345187425613403, -0.30926060676574707, -0.11739331483840942, -0.1300537884235382, -0.18562503159046173, 0.0504431277513504, 0.2471245676279068]
    Last 10:  [0.14162041246891022, -0.13119004666805267, 0.02552253007888794, -0.1741998940706253, 0.043956100940704346, 0.0424971878528595, 0.186425119638443, -0.19931669533252716, -0.04439568147063255, 0.127413809299469]
  OUT[0]: [1, 7, 768] | μ=0.293801 σ=91.704613
    First 10: [-9.60929012298584, 448.73004150390625, 107.68287658691406, 99.04016876220703, -147.64407348632812, -62.59661865234375, -52.752201080322266, -67.20039367675781, 29.50484275817871, 185.05532836914062]
    Last 10:  [30.793262481689453, -19.613698959350586, 7.723239898681641, -70.47991180419922, 14.132282257080078, 23.94338607788086, 94.39569854736328, -28.745384216308594, -13.191473960876465, 67.77994537353516]
  WEIGHT: [768] | μ=121.437004

330_layers.20.pre_feedforward_layernorm: layers.20.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=17.371140 σ=586.346680
    First 10: [248.97494506835938, 377.05364990234375, 89.98094177246094, 180.77145385742188, -87.28712463378906, 449.78509521484375, 291.6305236816406, 0.6023788452148438, -57.432090759277344, 341.244140625]
    Last 10:  [-80.19334411621094, -17.336353302001953, -118.866455078125, 8.932243347167969, 627.3888549804688, -157.12713623046875, 138.87350463867188, -71.05258178710938, 16.265071868896484, -24.142967224121094]
  OUT[0]: [1, 7, 768] | μ=0.011086 σ=0.505234
    First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
    Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
  WEIGHT: [768] | μ=0.586642

331_layers.20.mlp.gate_proj: layers.20.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.011086 σ=0.505234
    First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
    Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
  OUT[0]: [1, 7, 1152] | μ=-0.016433 σ=0.093106
    First 10: [-0.02178696170449257, -0.0472281388938427, 0.03130030632019043, -0.02816949039697647, -0.05369313433766365, 0.13603079319000244, -0.22927212715148926, -0.10580705851316452, 0.001876235008239746, 0.02655385434627533]
    Last 10:  [-0.0902700126171112, 0.06619293987751007, -0.08180826902389526, -0.00012089498341083527, 0.026902345940470695, -0.07101458311080933, 0.03528192639350891, 0.09296828508377075, -0.08504308760166168, -0.05496104434132576]
  WEIGHT: [1152, 768] | μ=-0.000005

332_layers.20.mlp.act_fn: layers.20.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.016433 σ=0.093106
    First 10: [-0.02178696170449257, -0.0472281388938427, 0.03130030632019043, -0.02816949039697647, -0.05369313433766365, 0.13603079319000244, -0.22927212715148926, -0.10580705851316452, 0.001876235008239746, 0.02655385434627533]
    Last 10:  [-0.0902700126171112, 0.06619293987751007, -0.08180826902389526, -0.00012089498341083527, 0.026902345940470695, -0.07101458311080933, 0.03528192639350891, 0.09296828508377075, -0.08504308760166168, -0.05496104434132576]
  OUT[0]: [1, 7, 1152] | μ=-0.004676 σ=0.045887
    First 10: [-0.010704129002988338, -0.022724561393260956, 0.01604093611240387, -0.013768218457698822, -0.02569699101150036, 0.07537475973367691, -0.09384853392839432, -0.048445675522089005, 0.0009395218803547323, 0.013558191247284412]
    Last 10:  [-0.041888587176799774, 0.03484315797686577, -0.03823716565966606, -6.044166366336867e-05, 0.013739866204559803, -0.03349709510803223, 0.01813746988773346, 0.049927257001399994, -0.039639756083488464, -0.026276040822267532]

333_layers.20.mlp.up_proj: layers.20.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.011086 σ=0.505234
    First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
    Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
  OUT[0]: [1, 7, 1152] | μ=0.003907 σ=0.086509
    First 10: [0.06017717719078064, 0.05919542908668518, 0.03515588492155075, -0.007379017770290375, 0.03896184265613556, -0.10614454001188278, 0.1325536072254181, 0.018523387610912323, 0.0023583336733281612, -0.002930114045739174]
    Last 10:  [0.016781572252511978, 0.01196132879704237, 0.06597274541854858, -0.04236283153295517, 0.04420832544565201, 0.08220406621694565, 0.010258466005325317, 0.012672610580921173, 0.0204064529389143, 0.0111346784979105]
  WEIGHT: [1152, 768] | μ=0.000011

334_layers.20.mlp.down_proj: layers.20.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=-0.000079 σ=0.006150
    First 10: [-0.0006441442528739572, -0.0013451902195811272, 0.0005639332812279463, 0.00010159592784475535, -0.0010012021521106362, -0.008000618778169155, -0.012439961545169353, -0.0008973780204541981, 2.215705990238348e-06, -3.972704507759772e-05]
    Last 10:  [-0.00070295634213835, 0.00041677046101540327, -0.0025226108264178038, 2.560479970270535e-06, 0.0006074164994060993, -0.0027535974513739347, 0.00018606262165121734, 0.0006327086593955755, -0.0008089067996479571, -0.00029257527785375714]
  OUT[0]: [1, 7, 768] | μ=0.000030 σ=0.001813
    First 10: [0.00017601015861146152, 0.00041852964204736054, 0.00109209050424397, 0.0004689863126259297, -0.0011176781263202429, -0.000668035470880568, 0.0006481855525635183, -0.0011860872618854046, -0.00032616296084597707, 0.0007131723687052727]
    Last 10:  [0.00010153447510674596, -0.0003968976379837841, -0.001966560259461403, 0.0006268025608733296, 0.0012043251190334558, -0.0008723011123947799, -0.0008069015457294881, -0.00025963346706703305, -0.0002490523038432002, -0.0006480398587882519]
  WEIGHT: [768, 1152] | μ=-0.000007

335_layers.20.mlp: layers.20.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.011086 σ=0.505234
    First 10: [0.7595144510269165, 0.25533246994018555, 0.20136354863643646, 0.3627038598060608, -0.1229134052991867, 0.5091520547866821, 0.5220332741737366, 0.0013351005036383867, -0.061692070215940475, 0.3030652403831482]
    Last 10:  [-0.16651660203933716, -0.05567389354109764, -0.14964032173156738, 0.009337143041193485, 0.634450376033783, -0.09950122237205505, 0.1004299744963646, -0.14878182113170624, 0.018706252798438072, -0.016626451164484024]
  OUT[0]: [1, 7, 768] | μ=0.000030 σ=0.001813
    First 10: [0.00017601015861146152, 0.00041852964204736054, 0.00109209050424397, 0.0004689863126259297, -0.0011176781263202429, -0.000668035470880568, 0.0006481855525635183, -0.0011860872618854046, -0.00032616296084597707, 0.0007131723687052727]
    Last 10:  [0.00010153447510674596, -0.0003968976379837841, -0.001966560259461403, 0.0006268025608733296, 0.0012043251190334558, -0.0008723011123947799, -0.0008069015457294881, -0.00025963346706703305, -0.0002490523038432002, -0.0006480398587882519]

336_layers.20.post_feedforward_layernorm: layers.20.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000030 σ=0.001813
    First 10: [0.00017601015861146152, 0.00041852964204736054, 0.00109209050424397, 0.0004689863126259297, -0.0011176781263202429, -0.000668035470880568, 0.0006481855525635183, -0.0011860872618854046, -0.00032616296084597707, 0.0007131723687052727]
    Last 10:  [0.00010153447510674596, -0.0003968976379837841, -0.001966560259461403, 0.0006268025608733296, 0.0012043251190334558, -0.0008723011123947799, -0.0008069015457294881, -0.00025963346706703305, -0.0002490523038432002, -0.0006480398587882519]
  OUT[0]: [1, 7, 768] | μ=3.900361 σ=155.492065
    First 10: [5.777247428894043, 84.54557037353516, 58.293514251708984, 28.035646438598633, -113.77408599853516, -74.42931365966797, 44.6232795715332, -61.79989242553711, -39.28712463378906, 118.05073547363281]
    Last 10:  [4.037607669830322, -9.772262573242188, -120.04703521728516, 72.02775573730469, 86.53860473632812, -115.79740905761719, -107.16096496582031, -10.80485725402832, -16.19139862060547, -89.4576187133789]
  WEIGHT: [768] | μ=219.169250

337_layers.21.input_layernorm: layers.21.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=21.271503 σ=662.954468
    First 10: [254.752197265625, 461.5992126464844, 148.2744598388672, 208.80709838867188, -201.06121826171875, 375.35577392578125, 336.2538146972656, -61.197513580322266, -96.7192153930664, 459.29486083984375]
    Last 10:  [-76.1557388305664, -27.10861587524414, -238.91348266601562, 80.95999908447266, 713.927490234375, -272.924560546875, 31.712539672851562, -81.85743713378906, 0.07367324829101562, -113.6005859375]
  OUT[0]: [1, 7, 768] | μ=0.139903 σ=6.197062
    First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
    Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
  WEIGHT: [768] | μ=16.146418

338_layers.21.self_attn.q_proj: layers.21.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.139903 σ=6.197062
    First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
    Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
  OUT[0]: [1, 7, 768] | μ=-0.109239 σ=2.472522
    First 10: [-0.19218572974205017, -0.2559703588485718, -0.14413082599639893, -1.8379671573638916, 0.6077706217765808, -1.3140063285827637, 1.4457305669784546, 0.3771328032016754, 0.6528590321540833, -0.9798147678375244]
    Last 10:  [-0.3648371398448944, 3.6655635833740234, -0.7931320667266846, -0.9572938084602356, 0.04983040690422058, 0.45743250846862793, -0.02163083851337433, 0.17620426416397095, -4.172752857208252, -1.3119205236434937]
  WEIGHT: [768, 768] | μ=-0.000011

339_layers.21.self_attn.k_proj: layers.21.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.139903 σ=6.197062
    First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
    Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
  OUT[0]: [1, 7, 256] | μ=0.206281 σ=3.290427
    First 10: [-0.9187471866607666, -0.4273800849914551, -0.07798371464014053, 0.5687648057937622, -1.1755740642547607, 0.19697290658950806, -1.529198169708252, -0.3549632430076599, 0.24987700581550598, 1.3045965433120728]
    Last 10:  [-9.1122407913208, 0.23442280292510986, -3.68198823928833, 1.8998234272003174, -14.99787712097168, 0.7177560329437256, 1.5371174812316895, -0.7239113450050354, -5.350516319274902, -9.8025541305542]
  WEIGHT: [256, 768] | μ=0.000039

340_layers.21.self_attn.v_proj: layers.21.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.139903 σ=6.197062
    First 10: [9.764002799987793, 2.2557730674743652, 2.4215784072875977, 2.9736714363098145, -2.3844809532165527, 3.704371452331543, 4.702880859375, -1.0203813314437866, -0.9674139022827148, 3.390232563018799]
    Last 10:  [-1.6899062395095825, -0.8879852890968323, -2.942880630493164, 0.8398615121841431, 8.260110855102539, -1.7747811079025269, 0.23778462409973145, -1.9438344240188599, 0.000979680917225778, -0.8120612502098083]
  OUT[0]: [1, 7, 256] | μ=-0.011132 σ=1.331192
    First 10: [-0.1320808082818985, 0.08195514231920242, -0.5747569799423218, 0.391632080078125, 0.7524430155754089, -0.770601212978363, 0.7966300249099731, 0.004085659980773926, -0.59767085313797, 0.17842915654182434]
    Last 10:  [-1.9432055950164795, -0.340876042842865, -0.13599693775177002, -0.8425939083099365, -1.8811516761779785, -0.9611423015594482, -5.390427112579346, -0.20615625381469727, -1.243732213973999, -0.7150604724884033]
  WEIGHT: [256, 768] | μ=0.000023

341_layers.21.self_attn.q_norm: layers.21.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.109239 σ=2.472522
    First 10: [-0.19218572974205017, -0.2559703588485718, -0.14413082599639893, -1.8379671573638916, 0.6077706217765808, -1.3140063285827637, 1.4457305669784546, 0.3771328032016754, 0.6528590321540833, -0.9798147678375244]
    Last 10:  [-0.3648371398448944, 3.6655635833740234, -0.7931320667266846, -0.9572938084602356, 0.04983040690422058, 0.45743250846862793, -0.02163083851337433, 0.17620426416397095, -4.172752857208252, -1.3119205236434937]
  OUT[0]: [1, 3, 7, 256] | μ=-0.042108 σ=1.027172
    First 10: [-0.15371859073638916, -0.13253024220466614, -0.07927827537059784, -0.5358009934425354, 0.21853923797607422, -0.4262485206127167, 0.6792948246002197, 0.1280854344367981, 0.2800249457359314, -0.25661569833755493]
    Last 10:  [-0.21241535246372223, 2.3051040172576904, -0.2731737196445465, -0.5019936561584473, 0.03164730593562126, 0.12610414624214172, -0.001220033853314817, 0.07911889255046844, -1.0532164573669434, -0.376360148191452]
  WEIGHT: [256] | μ=0.197430

342_layers.21.self_attn.k_norm: layers.21.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.206281 σ=3.290427
    First 10: [-0.9187471866607666, -0.4273800849914551, -0.07798371464014053, 0.5687648057937622, -1.1755740642547607, 0.19697290658950806, -1.529198169708252, -0.3549632430076599, 0.24987700581550598, 1.3045965433120728]
    Last 10:  [-9.1122407913208, 0.23442280292510986, -3.68198823928833, 1.8998234272003174, -14.99787712097168, 0.7177560329437256, 1.5371174812316895, -0.7239113450050354, -5.350516319274902, -9.8025541305542]
  OUT[0]: [1, 1, 7, 256] | μ=0.027630 σ=1.070587
    First 10: [-0.33037132024765015, -0.09926631301641464, -0.015683896839618683, 0.18599826097488403, -0.291397362947464, 0.053973160684108734, -0.339073121547699, -0.09571564942598343, 0.05632392689585686, 0.35254767537117004]
    Last 10:  [-1.939253568649292, 0.08367564529180527, -1.451658010482788, 0.4529729187488556, -2.8118197917938232, 0.31843090057373047, 3.186762809753418, -0.2153470665216446, -3.5930094718933105, -3.9782094955444336]
  WEIGHT: [256] | μ=0.324199

343_layers.21.self_attn.o_proj: layers.21.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=-0.003022 σ=0.839146
    First 10: [-0.1320808082818985, 0.08195514231920242, -0.5747569799423218, 0.391632080078125, 0.7524430155754089, -0.770601212978363, 0.7966300249099731, 0.004085659980773926, -0.59767085313797, 0.17842915654182434]
    Last 10:  [-0.5243580937385559, -0.08183103799819946, -0.5590373873710632, -1.0080268383026123, 0.403024286031723, -0.5109790563583374, -0.5735402703285217, 0.8143228888511658, 0.349712073802948, -0.719255805015564]
  OUT[0]: [1, 7, 768] | μ=-0.028547 σ=0.551426
    First 10: [-0.03071139007806778, -0.04881244897842407, 0.017889641225337982, 0.08466877043247223, 0.21650660037994385, 0.14434614777565002, -0.1616826355457306, 0.02618226408958435, -0.12065969407558441, -0.008144095540046692]
    Last 10:  [0.007482957094907761, -0.0610712394118309, 0.1595326066017151, -0.14421889185905457, 0.002379700541496277, 0.07041843980550766, -0.1985519677400589, 0.20562228560447693, 0.18276390433311462, 0.15772560238838196]
  WEIGHT: [768, 768] | μ=0.000014

344_layers.21.self_attn: layers.21.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=-0.028547 σ=0.551426
    First 10: [-0.03071139007806778, -0.04881244897842407, 0.017889641225337982, 0.08466877043247223, 0.21650660037994385, 0.14434614777565002, -0.1616826355457306, 0.02618226408958435, -0.12065969407558441, -0.008144095540046692]
    Last 10:  [0.007482957094907761, -0.0610712394118309, 0.1595326066017151, -0.14421889185905457, 0.002379700541496277, 0.07041843980550766, -0.1985519677400589, 0.20562228560447693, 0.18276390433311462, 0.15772560238838196]

345_layers.21.post_attention_layernorm: layers.21.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.028547 σ=0.551426
    First 10: [-0.03071139007806778, -0.04881244897842407, 0.017889641225337982, 0.08466877043247223, 0.21650660037994385, 0.14434614777565002, -0.1616826355457306, 0.02618226408958435, -0.12065969407558441, -0.008144095540046692]
    Last 10:  [0.007482957094907761, -0.0610712394118309, 0.1595326066017151, -0.14421889185905457, 0.002379700541496277, 0.07041843980550766, -0.1985519677400589, 0.20562228560447693, 0.18276390433311462, 0.15772560238838196]
  OUT[0]: [1, 7, 768] | μ=0.006765 σ=70.276169
    First 10: [-5.2237653732299805, -36.63751220703125, 4.6811347007751465, 23.34031105041504, 93.01683807373047, 70.55953216552734, -54.95275115966797, 6.9258503913879395, -64.39913940429688, -5.358387470245361]
    Last 10:  [1.0138288736343384, -4.7995076179504395, 32.515220642089844, -48.0018424987793, 0.6005383729934692, 29.345741271972656, -84.22147369384766, 23.73798370361328, 42.91338348388672, 67.24455261230469]
  WEIGHT: [768] | μ=188.242004

346_layers.21.pre_feedforward_layernorm: layers.21.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=21.278267 σ=686.779907
    First 10: [249.52842712402344, 424.9617004394531, 152.95559692382812, 232.1474151611328, -108.04438018798828, 445.9153137207031, 281.3010559082031, -54.271663665771484, -161.11834716796875, 453.93646240234375]
    Last 10:  [-75.14190673828125, -31.908123016357422, -206.39825439453125, 32.95815658569336, 714.5280151367188, -243.57882690429688, -52.508934020996094, -58.11945343017578, 42.987056732177734, -46.35603332519531]
  OUT[0]: [1, 7, 768] | μ=0.006975 σ=0.463371
    First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
    Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
  WEIGHT: [768] | μ=0.539170

347_layers.21.mlp.gate_proj: layers.21.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.006975 σ=0.463371
    First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
    Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
  OUT[0]: [1, 7, 1152] | μ=-0.014042 σ=0.083661
    First 10: [-0.03226380795240402, -0.04939660429954529, -0.1958286315202713, 0.2221851646900177, 0.07295292615890503, 0.02665148675441742, -0.02239326760172844, 0.13844145834445953, -0.03876672312617302, -0.0346284843981266]
    Last 10:  [0.18315473198890686, 0.027935346588492393, -0.08284022659063339, 0.048996515572071075, 0.13530796766281128, -0.042232878506183624, 0.07718504965305328, 0.022640684619545937, 0.013000254519283772, 0.010271226987242699]
  WEIGHT: [1152, 768] | μ=-0.000016

348_layers.21.mlp.act_fn: layers.21.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.014042 σ=0.083661
    First 10: [-0.03226380795240402, -0.04939660429954529, -0.1958286315202713, 0.2221851646900177, 0.07295292615890503, 0.02665148675441742, -0.02239326760172844, 0.13844145834445953, -0.03876672312617302, -0.0346284843981266]
    Last 10:  [0.18315473198890686, 0.027935346588492393, -0.08284022659063339, 0.048996515572071075, 0.13530796766281128, -0.042232878506183624, 0.07718504965305328, 0.022640684619545937, 0.013000254519283772, 0.010271226987242699]
  OUT[0]: [1, 7, 1152] | μ=-0.004166 σ=0.041327
    First 10: [-0.01571669615805149, -0.023725271224975586, -0.08271303027868271, 0.13062524795532227, 0.03859779238700867, 0.013609078712761402, -0.010996597819030285, 0.07684239745140076, -0.01878395862877369, -0.016835954040288925]
    Last 10:  [0.10488533973693848, 0.014278961345553398, -0.03868551552295685, 0.025455597788095474, 0.07493558526039124, -0.02040509320795536, 0.04096686467528343, 0.011524822562932968, 0.006567548960447311, 0.005177700892090797]

349_layers.21.mlp.up_proj: layers.21.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.006975 σ=0.463371
    First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
    Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
  OUT[0]: [1, 7, 1152] | μ=-0.002499 σ=0.083128
    First 10: [0.038777295500040054, -0.059223420917987823, -0.07566986978054047, 0.023193221539258957, 0.005512133240699768, -0.035750798881053925, 0.08792135864496231, -0.020401477813720703, -0.033875707536935806, 0.04377712309360504]
    Last 10:  [0.19316941499710083, 0.017759615555405617, -0.016540395095944405, 0.04939170181751251, 0.16029660403728485, 0.03582299128174782, 0.06170757859945297, -0.03534972295165062, -0.05644694343209267, 0.09205536544322968]
  WEIGHT: [1152, 768] | μ=-0.000005

350_layers.21.mlp.down_proj: layers.21.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000150 σ=0.004593
    First 10: [-0.0006094509735703468, 0.0014050917234271765, 0.006258884444832802, 0.00302962027490139, 0.00021275617473293096, -0.00048653542762622237, -0.0009668358252383769, -0.0015676984330639243, 0.000636319862678647, -0.000737029651645571]
    Last 10:  [0.020260639488697052, 0.00025358886341564357, 0.0006398737314157188, 0.0012572952546179295, 0.012011920101940632, -0.0007309714565053582, 0.0025279659312218428, -0.00040739928954280913, -0.0003707180730998516, 0.0004766351485159248]
  OUT[0]: [1, 7, 768] | μ=0.000068 σ=0.001721
    First 10: [-0.0005158550338819623, -0.0004192159394733608, -0.0004108040011487901, 0.001043703523464501, -0.00043411084334366024, 3.03550623357296e-05, -0.0006948734517209232, 0.000522240181453526, 7.918966002762318e-05, -0.00033792047179304063]
    Last 10:  [0.00031575822504237294, -0.0016474274452775717, -0.0012615101877599955, 0.0014170357026159763, 0.0013975880574434996, -0.0007734567625448108, -0.002725002821534872, -0.0009682420641183853, 0.0014251329703256488, 0.0013294187374413013]
  WEIGHT: [768, 1152] | μ=0.000012

351_layers.21.mlp: layers.21.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.006975 σ=0.463371
    First 10: [0.6680500507354736, 0.2144639492034912, 0.2653672695159912, 0.358262836933136, -0.11393973976373672, 0.397667795419693, 0.38668984174728394, -0.09160667657852173, -0.14253225922584534, 0.31567084789276123]
    Last 10:  [-0.1502174735069275, -0.09504006057977676, -0.2949237525463104, 0.03175085037946701, 0.7084053754806519, -0.15706013143062592, -0.03775671124458313, -0.13790984451770782, 0.05038098990917206, -0.031093500554561615]
  OUT[0]: [1, 7, 768] | μ=0.000068 σ=0.001721
    First 10: [-0.0005158550338819623, -0.0004192159394733608, -0.0004108040011487901, 0.001043703523464501, -0.00043411084334366024, 3.03550623357296e-05, -0.0006948734517209232, 0.000522240181453526, 7.918966002762318e-05, -0.00033792047179304063]
    Last 10:  [0.00031575822504237294, -0.0016474274452775717, -0.0012615101877599955, 0.0014170357026159763, 0.0013975880574434996, -0.0007734567625448108, -0.002725002821534872, -0.0009682420641183853, 0.0014251329703256488, 0.0013294187374413013]

352_layers.21.post_feedforward_layernorm: layers.21.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000068 σ=0.001721
    First 10: [-0.0005158550338819623, -0.0004192159394733608, -0.0004108040011487901, 0.001043703523464501, -0.00043411084334366024, 3.03550623357296e-05, -0.0006948734517209232, 0.000522240181453526, 7.918966002762318e-05, -0.00033792047179304063]
    Last 10:  [0.00031575822504237294, -0.0016474274452775717, -0.0012615101877599955, 0.0014170357026159763, 0.0013975880574434996, -0.0007734567625448108, -0.002725002821534872, -0.0009682420641183853, 0.0014251329703256488, 0.0013294187374413013]
  OUT[0]: [1, 7, 768] | μ=8.731761 σ=180.165359
    First 10: [-26.966638565063477, -113.93172454833984, -29.287843704223633, 77.6457748413086, -60.865108489990234, 4.468834400177002, -60.76070785522461, 36.93429946899414, 12.962908744812012, -80.67521667480469]
    Last 10:  [10.876729011535645, -33.80330276489258, -66.55987548828125, 158.05856323242188, 88.21133422851562, -93.23436737060547, -331.0540771484375, -44.697052001953125, 87.8104019165039, 168.56503295898438]
  WEIGHT: [768] | μ=256.011139

353_layers.22.input_layernorm: layers.22.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=30.010027 σ=826.557312
    First 10: [222.56178283691406, 311.02996826171875, 123.66775512695312, 309.7931823730469, -168.90948486328125, 450.3841552734375, 220.54034423828125, -17.337364196777344, -148.1554412841797, 373.26123046875]
    Last 10:  [-64.26517486572266, -65.71142578125, -272.9581298828125, 191.0167236328125, 802.7393798828125, -336.8132019042969, -383.5630187988281, -102.8165054321289, 130.79745483398438, 122.20899963378906]
  OUT[0]: [1, 7, 768] | μ=0.119664 σ=5.098887
    First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
    Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
  WEIGHT: [768] | μ=16.440878

354_layers.22.self_attn.q_proj: layers.22.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.119664 σ=5.098887
    First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
    Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
  OUT[0]: [1, 7, 768] | μ=-0.085504 σ=2.071075
    First 10: [-0.3606719970703125, 0.25113391876220703, 1.154634714126587, -1.1956827640533447, 0.8577898740768433, -0.2992662191390991, 0.10739541053771973, 0.5160561203956604, 1.010702133178711, 0.13838011026382446]
    Last 10:  [-4.100765705108643, 1.8266681432724, 0.6036360263824463, 0.8861453533172607, -0.4781343936920166, -0.09689527750015259, 0.8772269487380981, 1.7120635509490967, -0.4919315576553345, -1.5381542444229126]
  WEIGHT: [768, 768] | μ=-0.000011

355_layers.22.self_attn.k_proj: layers.22.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.119664 σ=5.098887
    First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
    Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
  OUT[0]: [1, 7, 256] | μ=0.014008 σ=1.990108
    First 10: [0.9766206741333008, -0.5148115158081055, 0.6268669366836548, -1.2359373569488525, 1.1525217294692993, -0.6996595859527588, -0.9483623504638672, 1.3843380212783813, 0.42997777462005615, -0.4466647207736969]
    Last 10:  [-9.720972061157227, 3.4868927001953125, 0.6440816521644592, 2.1073660850524902, 2.507824182510376, 3.80507755279541, 4.631038188934326, 0.6810306310653687, -6.464661121368408, -0.8705835342407227]
  WEIGHT: [256, 768] | μ=0.000008

356_layers.22.self_attn.v_proj: layers.22.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.119664 σ=5.098887
    First 10: [6.723724365234375, 1.1632081270217896, 1.9014040231704712, 4.780550479888916, -1.3361886739730835, 3.454111099243164, 2.710125207901001, -0.2997994124889374, -0.9955587387084961, 1.81484055519104]
    Last 10:  [-1.2364739179611206, -1.87155020236969, -3.43204927444458, 1.304848551750183, 7.7312116622924805, -1.8186131715774536, -2.038466453552246, -1.9417072534561157, 1.2042346000671387, 0.6754948496818542]
  OUT[0]: [1, 7, 256] | μ=0.039747 σ=1.127255
    First 10: [1.0966882705688477, 0.7812347412109375, 0.23234941065311432, 0.19118180871009827, -0.6556218862533569, 0.7667942047119141, -0.4091002941131592, 0.22289711236953735, 0.17747120559215546, 0.04030734300613403]
    Last 10:  [-0.8188996315002441, 0.08696593344211578, 1.791534423828125, 0.2542421519756317, -0.3360554873943329, -0.36960694193840027, -0.14066553115844727, -0.49565476179122925, -0.8397150039672852, -0.5054383277893066]
  WEIGHT: [256, 768] | μ=0.000009

357_layers.22.self_attn.q_norm: layers.22.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.085504 σ=2.071075
    First 10: [-0.3606719970703125, 0.25113391876220703, 1.154634714126587, -1.1956827640533447, 0.8577898740768433, -0.2992662191390991, 0.10739541053771973, 0.5160561203956604, 1.010702133178711, 0.13838011026382446]
    Last 10:  [-4.100765705108643, 1.8266681432724, 0.6036360263824463, 0.8861453533172607, -0.4781343936920166, -0.09689527750015259, 0.8772269487380981, 1.7120635509490967, -0.4919315576553345, -1.5381542444229126]
  OUT[0]: [1, 3, 7, 256] | μ=0.003010 σ=0.907564
    First 10: [-0.06539787352085114, 0.19391512870788574, 0.7777132391929626, -0.8633933067321777, 0.2865588068962097, -0.16905853152275085, 0.06798228621482849, 0.3256538510322571, 0.4177933633327484, 0.07708168029785156]
    Last 10:  [-0.31349673867225647, 0.3238573968410492, 0.2545357048511505, 0.43479204177856445, -0.2915246784687042, -0.05743566155433655, 0.33197465538978577, 0.8465550541877747, -0.31335288286209106, -0.5584181547164917]
  WEIGHT: [256] | μ=0.094064

358_layers.22.self_attn.k_norm: layers.22.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=0.014008 σ=1.990108
    First 10: [0.9766206741333008, -0.5148115158081055, 0.6268669366836548, -1.2359373569488525, 1.1525217294692993, -0.6996595859527588, -0.9483623504638672, 1.3843380212783813, 0.42997777462005615, -0.4466647207736969]
    Last 10:  [-9.720972061157227, 3.4868927001953125, 0.6440816521644592, 2.1073660850524902, 2.507824182510376, 3.80507755279541, 4.631038188934326, 0.6810306310653687, -6.464661121368408, -0.8705835342407227]
  OUT[0]: [1, 1, 7, 256] | μ=-0.070471 σ=2.606749
    First 10: [0.6744826436042786, -0.3173788785934448, 0.4709046185016632, -0.520111620426178, 0.8953589200973511, -0.40938758850097656, -0.314823180437088, 0.6868636608123779, 0.25402072072029114, -0.18145418167114258]
    Last 10:  [-31.77065658569336, 4.397150039672852, 0.38686421513557434, 1.297036051750183, 1.2155823707580566, 1.6576658487319946, 3.1659507751464844, 0.35646507143974304, -2.803743839263916, -0.7436607480049133]
  WEIGHT: [256] | μ=0.524969

359_layers.22.self_attn.o_proj: layers.22.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.027073 σ=0.894376
    First 10: [1.0966882705688477, 0.7812347412109375, 0.23234941065311432, 0.19118180871009827, -0.6556218862533569, 0.7667942047119141, -0.4091002941131592, 0.22289711236953735, 0.17747120559215546, 0.04030734300613403]
    Last 10:  [-0.39939725399017334, 0.21678102016448975, 0.5563833117485046, -0.29007530212402344, 0.29163143038749695, -0.217654287815094, 0.11650477349758148, 0.16673356294631958, -0.7178808450698853, -0.7067828178405762]
  OUT[0]: [1, 7, 768] | μ=0.018907 σ=0.358094
    First 10: [-0.2199665904045105, 0.05313340574502945, -0.21738030016422272, 0.08784294128417969, -0.194219708442688, -0.04234836995601654, -0.06432276964187622, 0.02760402485728264, -0.1292407214641571, -0.08854381740093231]
    Last 10:  [-0.10702682286500931, 0.14953233301639557, 0.2191532850265503, 0.0015471316874027252, 0.03773049637675285, -0.19228309392929077, 0.11880626529455185, 0.007898246869444847, -0.007783878594636917, -0.05807621777057648]
  WEIGHT: [768, 768] | μ=-0.000001

360_layers.22.self_attn: layers.22.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.018907 σ=0.358094
    First 10: [-0.2199665904045105, 0.05313340574502945, -0.21738030016422272, 0.08784294128417969, -0.194219708442688, -0.04234836995601654, -0.06432276964187622, 0.02760402485728264, -0.1292407214641571, -0.08854381740093231]
    Last 10:  [-0.10702682286500931, 0.14953233301639557, 0.2191532850265503, 0.0015471316874027252, 0.03773049637675285, -0.19228309392929077, 0.11880626529455185, 0.007898246869444847, -0.007783878594636917, -0.05807621777057648]

361_layers.22.post_attention_layernorm: layers.22.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.018907 σ=0.358094
    First 10: [-0.2199665904045105, 0.05313340574502945, -0.21738030016422272, 0.08784294128417969, -0.194219708442688, -0.04234836995601654, -0.06432276964187622, 0.02760402485728264, -0.1292407214641571, -0.08854381740093231]
    Last 10:  [-0.10702682286500931, 0.14953233301639557, 0.2191532850265503, 0.0015471316874027252, 0.03773049637675285, -0.19228309392929077, 0.11880626529455185, 0.007898246869444847, -0.007783878594636917, -0.05807621777057648]
  OUT[0]: [1, 7, 768] | μ=2.420167 σ=88.506355
    First 10: [-38.79816436767578, 55.42149353027344, -98.62366485595703, 45.88089370727539, -103.36785125732422, -24.60865020751953, -35.644195556640625, 12.461679458618164, -80.68533325195312, -74.39836120605469]
    Last 10:  [-27.200626373291016, 20.855510711669922, 102.9354248046875, 0.7872195243835449, 13.462584495544434, -128.01654052734375, 76.5503158569336, 1.4986056089401245, -2.5646157264709473, -38.56374740600586]
  WEIGHT: [768] | μ=203.962051

362_layers.22.pre_feedforward_layernorm: layers.22.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=32.430195 σ=840.844421
    First 10: [183.76361083984375, 366.45147705078125, 25.044090270996094, 355.674072265625, -272.27734375, 425.7755126953125, 184.89614868164062, -4.87568473815918, -228.8407745361328, 298.86285400390625]
    Last 10:  [-91.46580505371094, -44.85591506958008, -170.022705078125, 191.80393981933594, 816.2019653320312, -464.8297424316406, -307.0126953125, -101.31790161132812, 128.2328338623047, 83.64524841308594]
  OUT[0]: [1, 7, 768] | μ=0.012731 σ=0.435994
    First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
    Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
  WEIGHT: [768] | μ=0.332127

363_layers.22.mlp.gate_proj: layers.22.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.012731 σ=0.435994
    First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
    Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
  OUT[0]: [1, 7, 1152] | μ=-0.005867 σ=0.083245
    First 10: [0.050328709185123444, 0.004280753433704376, 0.049845267087221146, 0.0332026481628418, 0.03385660797357559, -0.367888480424881, 0.013333476148545742, -0.12108683586120605, -0.006789416074752808, 0.06070050597190857]
    Last 10:  [-0.11343406140804291, -0.07796841859817505, 0.7547639012336731, -0.06256610155105591, 0.023868225514888763, -0.02085898444056511, 0.02691822126507759, 0.0031635360792279243, -0.040290504693984985, -0.0030505936592817307]
  WEIGHT: [1152, 768] | μ=-0.000016

364_layers.22.mlp.act_fn: layers.22.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.005867 σ=0.083245
    First 10: [0.050328709185123444, 0.004280753433704376, 0.049845267087221146, 0.0332026481628418, 0.03385660797357559, -0.367888480424881, 0.013333476148545742, -0.12108683586120605, -0.006789416074752808, 0.06070050597190857]
    Last 10:  [-0.11343406140804291, -0.07796841859817505, 0.7547639012336731, -0.06256610155105591, 0.023868225514888763, -0.02085898444056511, 0.02691822126507759, 0.0031635360792279243, -0.040290504693984985, -0.0030505936592817307]
  OUT[0]: [1, 7, 1152] | μ=-0.000187 σ=0.041290
    First 10: [0.026174437254667282, 0.002147687366232276, 0.025913415476679802, 0.01704104244709015, 0.017385512590408325, -0.13114970922470093, 0.006737660616636276, -0.05470845103263855, -0.003376318607479334, 0.03181926906108856]
    Last 10:  [-0.05159476771950722, -0.036561474204063416, 0.5847242474555969, -0.029722407460212708, 0.012161364778876305, -0.010255926288664341, 0.013748145662248135, 0.0015857606194913387, -0.019497815519571304, -0.0015215842286124825]

365_layers.22.mlp.up_proj: layers.22.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.012731 σ=0.435994
    First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
    Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
  OUT[0]: [1, 7, 1152] | μ=0.000125 σ=0.086457
    First 10: [-0.059474021196365356, 0.05188290774822235, -0.010762285441160202, -0.01627976819872856, -0.025735042989253998, -0.08914840221405029, 0.027703814208507538, 0.018703322857618332, 0.00683923065662384, 0.08297491073608398]
    Last 10:  [-0.22374555468559265, 0.07247208058834076, 0.23796246945858002, 0.020316364243626595, -0.024654977023601532, -0.09366852045059204, -0.01965862140059471, 0.16244667768478394, 0.044433265924453735, -0.03742983937263489]
  WEIGHT: [1152, 768] | μ=-0.000003

366_layers.22.mlp.down_proj: layers.22.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000042 σ=0.005932
    First 10: [-0.0015566990477964282, 0.00011142826406285167, -0.00027888757176697254, -0.00027742423117160797, -0.0004474169109016657, 0.011691787280142307, 0.0001866589009296149, -0.0010232297936454415, -2.3091421098797582e-05, 0.002640201011672616]
    Last 10:  [0.011544100008904934, -0.0026496860664337873, 0.13914242386817932, -0.0006038512801751494, -0.0002998381678480655, 0.0009606574312783778, -0.0002702695783227682, 0.00025760155403986573, -0.0008663516491651535, 5.695265281246975e-05]
  OUT[0]: [1, 7, 768] | μ=0.000013 σ=0.002551
    First 10: [-0.00041726240306161344, 0.00015297502977773547, -0.0002851833705790341, 0.0008279255125671625, -0.0003054695844184607, 0.0006038003484718502, -5.667538789566606e-05, -0.0003777878009714186, 0.00041177315870299935, 0.0004111839225515723]
    Last 10:  [0.0012045789044350386, -0.001689740689471364, 0.0012449956266209483, -0.00023999845143407583, -0.00020690337987616658, -0.00043740763794630766, -0.0001059499045368284, -0.001861112890765071, -0.0022947844117879868, -0.000678480020724237]
  WEIGHT: [768, 1152] | μ=0.000005

367_layers.22.mlp: layers.22.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.012731 σ=0.435994
    First 10: [0.5262330174446106, 0.14403127133846283, 0.027926908805966377, 0.3514578938484192, -0.22614671289920807, 0.28255483508110046, 0.17360283434391022, -0.005282275844365358, -0.1325574517250061, 0.15298496186733246]
    Last 10:  [-0.1193348616361618, -0.08345281332731247, -0.14297401905059814, 0.11381930112838745, 0.6250465512275696, -0.19583573937416077, -0.14475631713867188, -0.17708836495876312, 0.10604438930749893, 0.03917459771037102]
  OUT[0]: [1, 7, 768] | μ=0.000013 σ=0.002551
    First 10: [-0.00041726240306161344, 0.00015297502977773547, -0.0002851833705790341, 0.0008279255125671625, -0.0003054695844184607, 0.0006038003484718502, -5.667538789566606e-05, -0.0003777878009714186, 0.00041177315870299935, 0.0004111839225515723]
    Last 10:  [0.0012045789044350386, -0.001689740689471364, 0.0012449956266209483, -0.00023999845143407583, -0.00020690337987616658, -0.00043740763794630766, -0.0001059499045368284, -0.001861112890765071, -0.0022947844117879868, -0.000678480020724237]

368_layers.22.post_feedforward_layernorm: layers.22.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.000013 σ=0.002551
    First 10: [-0.00041726240306161344, 0.00015297502977773547, -0.0002851833705790341, 0.0008279255125671625, -0.0003054695844184607, 0.0006038003484718502, -5.667538789566606e-05, -0.0003777878009714186, 0.00041177315870299935, 0.0004111839225515723]
    Last 10:  [0.0012045789044350386, -0.001689740689471364, 0.0012449956266209483, -0.00023999845143407583, -0.00020690337987616658, -0.00043740763794630766, -0.0001059499045368284, -0.001861112890765071, -0.0022947844117879868, -0.000678480020724237]
  OUT[0]: [1, 7, 768] | μ=40.129307 σ=1295.566284
    First 10: [-28.188135147094727, 57.61558532714844, -28.908397674560547, 86.90762329101562, -63.00331497192383, 123.92156982421875, -6.685600280761719, -35.70066452026367, 93.79269409179688, 135.3519287109375]
    Last 10:  [23.96026611328125, -20.615041732788086, 38.43105697631836, -16.062400817871094, -7.503787994384766, -30.752761840820312, -7.0132155418396, -48.217960357666016, -80.36627960205078, -47.288516998291016]
  WEIGHT: [768] | μ=306.657318

369_layers.23.input_layernorm: layers.23.input_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=72.559509 σ=1928.775146
    First 10: [155.57546997070312, 424.06707763671875, -3.864307403564453, 442.5816955566406, -335.2806701660156, 549.6970825195312, 178.21054077148438, -40.57634735107422, -135.04808044433594, 434.21478271484375]
    Last 10:  [-67.50553894042969, -65.47095489501953, -131.59164428710938, 175.74154663085938, 808.6981811523438, -495.58251953125, -314.0259094238281, -149.53585815429688, 47.866554260253906, 36.35673141479492]
  OUT[0]: [1, 7, 768] | μ=0.016988 σ=1.770467
    First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
    Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
  WEIGHT: [768] | μ=6.491487

370_layers.23.self_attn.q_proj: layers.23.self_attn.q_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.016988 σ=1.770467
    First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
    Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
  OUT[0]: [1, 7, 768] | μ=-0.066113 σ=0.965892
    First 10: [-0.5019404888153076, 3.267324447631836, 0.9382902383804321, -4.378557205200195, -1.6263254880905151, 1.8315285444259644, -0.6986075639724731, 1.5401923656463623, 0.03232799470424652, -4.216312885284424]
    Last 10:  [-0.3292371332645416, 0.4730690121650696, 0.6639103293418884, -1.3571791648864746, -1.1953482627868652, -0.8623377680778503, 1.0080392360687256, -0.15944062173366547, 1.4105380773544312, 0.7137588262557983]
  WEIGHT: [768, 768] | μ=0.000017

371_layers.23.self_attn.k_proj: layers.23.self_attn.k_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.016988 σ=1.770467
    First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
    Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
  OUT[0]: [1, 7, 256] | μ=-0.014699 σ=0.683250
    First 10: [-0.035623274743556976, -0.5003649592399597, -0.6913220286369324, -0.5560872554779053, 0.5266618132591248, -0.674839198589325, -0.22738128900527954, -0.5199233889579773, -0.5867617130279541, 0.21602745354175568]
    Last 10:  [2.399643898010254, 3.239105463027954, 2.177467107772827, -0.5970985889434814, 1.1158716678619385, -0.3703809976577759, 5.396165370941162, 0.2536398470401764, 3.2775368690490723, -0.33081382513046265]
  WEIGHT: [256, 768] | μ=0.000012

372_layers.23.self_attn.v_proj: layers.23.self_attn.v_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.016988 σ=1.770467
    First 10: [1.4559245109558105, 0.7395883798599243, -0.015464695170521736, 1.2770875692367554, -0.9538198709487915, 1.4470045566558838, 0.6014631390571594, -0.14018279314041138, -0.29424208402633667, 0.7059279680252075]
    Last 10:  [-0.4822034537792206, -0.5538904070854187, -0.44842129945755005, 0.39549773931503296, 2.996586561203003, -1.0359150171279907, -0.6578942537307739, -1.0287410020828247, 0.16991205513477325, 0.06812917441129684]
  OUT[0]: [1, 7, 256] | μ=-0.002767 σ=0.433900
    First 10: [0.18057888746261597, 0.10078537464141846, 0.5773279666900635, 0.39569172263145447, -0.06049492955207825, 0.3637787401676178, 0.2827119529247284, 0.6494826078414917, -0.15422837436199188, -0.2906862497329712]
    Last 10:  [-0.3941286504268646, 0.44312334060668945, 0.08729101717472076, 0.33791521191596985, -1.408284306526184, 0.387949675321579, -0.6129022836685181, 0.7450695037841797, 0.5986040830612183, 0.78910231590271]
  WEIGHT: [256, 768] | μ=0.000024

373_layers.23.self_attn.q_norm: layers.23.self_attn.q_norm (Gemma3RMSNorm)
  IN[0]:  [1, 3, 7, 256] | μ=-0.066113 σ=0.965892
    First 10: [-0.5019404888153076, 3.267324447631836, 0.9382902383804321, -4.378557205200195, -1.6263254880905151, 1.8315285444259644, -0.6986075639724731, 1.5401923656463623, 0.03232799470424652, -4.216312885284424]
    Last 10:  [-0.3292371332645416, 0.4730690121650696, 0.6639103293418884, -1.3571791648864746, -1.1953482627868652, -0.8623377680778503, 1.0080392360687256, -0.15944062173366547, 1.4105380773544312, 0.7137588262557983]
  OUT[0]: [1, 3, 7, 256] | μ=-0.025536 σ=0.878382
    First 10: [-0.2403334230184555, -0.0022922917269170284, -1.032644510269165, -2.5529251098632812, 0.01627814583480358, -1.5146085023880005, 0.7634945511817932, 1.4874383211135864, -0.01454649493098259, 0.022197827696800232]
    Last 10:  [-0.050226546823978424, 0.19520524144172668, 0.22679750621318817, -0.45152172446250916, -0.22718971967697144, -0.23443470895290375, 0.12096568197011948, -0.026906533166766167, 0.394452303647995, 0.27729979157447815]
  WEIGHT: [256] | μ=0.469170

374_layers.23.self_attn.k_norm: layers.23.self_attn.k_norm (Gemma3RMSNorm)
  IN[0]:  [1, 1, 7, 256] | μ=-0.014699 σ=0.683250
    First 10: [-0.035623274743556976, -0.5003649592399597, -0.6913220286369324, -0.5560872554779053, 0.5266618132591248, -0.674839198589325, -0.22738128900527954, -0.5199233889579773, -0.5867617130279541, 0.21602745354175568]
    Last 10:  [2.399643898010254, 3.239105463027954, 2.177467107772827, -0.5970985889434814, 1.1158716678619385, -0.3703809976577759, 5.396165370941162, 0.2536398470401764, 3.2775368690490723, -0.33081382513046265]
  OUT[0]: [1, 1, 7, 256] | μ=-0.040708 σ=3.154028
    First 10: [-0.00044170464389026165, -0.012608443386852741, 1.7572158575057983, 0.6053315997123718, -0.07268968969583511, 1.3084105253219604, -0.21574939787387848, -0.998650312423706, -0.014400137588381767, -0.017188720405101776]
    Last 10:  [9.812729835510254, 4.772675037384033, 4.241828441619873, -1.528754472732544, 5.684643745422363, -1.2181940078735352, 27.801761627197266, 1.267327904701233, 7.393815040588379, -0.7430755496025085]
  WEIGHT: [256] | μ=0.754886

375_layers.23.self_attn.o_proj: layers.23.self_attn.o_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.001016 σ=0.225265
    First 10: [0.18057888746261597, 0.10078537464141846, 0.5773279666900635, 0.39569172263145447, -0.06049492955207825, 0.3637787401676178, 0.2827119529247284, 0.6494826078414917, -0.15422837436199188, -0.2906862497329712]
    Last 10:  [-0.04445837065577507, -0.106530100107193, -0.03558943420648575, -0.04302895814180374, -0.0926256775856018, 0.1158161386847496, -0.05509444698691368, 0.07242661714553833, -0.03410325199365616, 0.22681641578674316]
  OUT[0]: [1, 7, 768] | μ=0.002948 σ=0.135374
    First 10: [-0.08060356229543686, -0.03412829339504242, -0.03302070498466492, -0.029198644682765007, 0.0558071993291378, -0.08552975207567215, 0.00853467732667923, -0.028378888964653015, 0.03082314506173134, -0.015844620764255524]
    Last 10:  [0.042154934257268906, 0.03602764010429382, -0.00597868487238884, 0.02808588370680809, -0.0717778354883194, 0.03321591764688492, -0.013857553713023663, 0.0379830077290535, -0.029481563717126846, 0.0010167928412556648]
  WEIGHT: [768, 768] | μ=0.000002

376_layers.23.self_attn: layers.23.self_attn (Gemma3Attention)
  OUT[0]: [1, 7, 768] | μ=0.002948 σ=0.135374
    First 10: [-0.08060356229543686, -0.03412829339504242, -0.03302070498466492, -0.029198644682765007, 0.0558071993291378, -0.08552975207567215, 0.00853467732667923, -0.028378888964653015, 0.03082314506173134, -0.015844620764255524]
    Last 10:  [0.042154934257268906, 0.03602764010429382, -0.00597868487238884, 0.02808588370680809, -0.0717778354883194, 0.03321591764688492, -0.013857553713023663, 0.0379830077290535, -0.029481563717126846, 0.0010167928412556648]

377_layers.23.post_attention_layernorm: layers.23.post_attention_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=0.002948 σ=0.135374
    First 10: [-0.08060356229543686, -0.03412829339504242, -0.03302070498466492, -0.029198644682765007, 0.0558071993291378, -0.08552975207567215, 0.00853467732667923, -0.028378888964653015, 0.03082314506173134, -0.015844620764255524]
    Last 10:  [0.042154934257268906, 0.03602764010429382, -0.00597868487238884, 0.02808588370680809, -0.0717778354883194, 0.03321591764688492, -0.013857553713023663, 0.0379830077290535, -0.029481563717126846, 0.0010167928412556648]
  OUT[0]: [1, 7, 768] | μ=13.232907 σ=331.626190
    First 10: [-33.60166931152344, -85.44408416748047, -19.16473388671875, -18.60396957397461, 71.15177154541016, -122.20758056640625, 6.340312480926514, -15.008856773376465, 45.54396438598633, -33.05653381347656]
    Last 10:  [22.34293556213379, 10.73908519744873, -4.434736728668213, 43.20695495605469, -74.09333038330078, 69.53937530517578, -23.06243896484375, 21.458480834960938, -28.96901512145996, 1.8043187856674194]
  WEIGHT: [768] | μ=243.108200

378_layers.23.pre_feedforward_layernorm: layers.23.pre_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=85.792412 σ=2236.355713
    First 10: [121.97380065917969, 338.62298583984375, -23.029041290283203, 423.97772216796875, -264.12890625, 427.489501953125, 184.5508575439453, -55.585205078125, -89.50411987304688, 401.15826416015625]
    Last 10:  [-45.16260528564453, -54.731868743896484, -136.02638244628906, 218.94850158691406, 734.6048583984375, -426.04315185546875, -337.0883483886719, -128.07737731933594, 18.897539138793945, 38.161048889160156]
  OUT[0]: [1, 7, 768] | μ=0.012118 σ=0.588893
    First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
    Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
  WEIGHT: [768] | μ=2.299745

379_layers.23.mlp.gate_proj: layers.23.mlp.gate_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.012118 σ=0.588893
    First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
    Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
  OUT[0]: [1, 7, 1152] | μ=-0.009133 σ=0.127814
    First 10: [0.013385389000177383, -0.03814718499779701, -0.19594824314117432, -0.20470348000526428, 0.013659888878464699, 0.07857532054185867, 0.43904343247413635, -0.023601919412612915, -0.17886635661125183, -0.020931705832481384]
    Last 10:  [-0.5184257626533508, 0.09926365315914154, 0.26727116107940674, -0.714452862739563, -0.01524563878774643, 0.026633061468601227, -0.0894288420677185, 0.5458469390869141, -0.2703744173049927, -0.11396177858114243]
  WEIGHT: [1152, 768] | μ=0.000005

380_layers.23.mlp.act_fn: layers.23.mlp.act_fn (PytorchGELUTanh)
  IN[0]:  [1, 7, 1152] | μ=-0.009133 σ=0.127814
    First 10: [0.013385389000177383, -0.03814718499779701, -0.19594824314117432, -0.20470348000526428, 0.013659888878464699, 0.07857532054185867, 0.43904343247413635, -0.023601919412612915, -0.17886635661125183, -0.020931705832481384]
    Last 10:  [-0.5184257626533508, 0.09926365315914154, 0.26727116107940674, -0.714452862739563, -0.01524563878774643, 0.026633061468601227, -0.0894288420677185, 0.5458469390869141, -0.2703744173049927, -0.11396177858114243]
  OUT[0]: [1, 7, 1152] | μ=0.001662 σ=0.060468
    First 10: [0.006764170713722706, -0.01849319040775299, -0.08275438100099564, -0.0857512354850769, 0.0069043817929923534, 0.04174821451306343, 0.29401013255119324, -0.011578749865293503, -0.07673780620098114, -0.010291074402630329]
    Last 10:  [-0.15662600100040436, 0.05355623736977577, 0.16179630160331726, -0.1697227656841278, -0.007530097384005785, 0.013599475845694542, -0.04152814298868179, 0.3861163854598999, -0.10637672245502472, -0.05181095749139786]

381_layers.23.mlp.up_proj: layers.23.mlp.up_proj (Linear)
  IN[0]:  [1, 7, 768] | μ=0.012118 σ=0.588893
    First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
    Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
  OUT[0]: [1, 7, 1152] | μ=-0.000164 σ=0.145596
    First 10: [0.01934933476150036, 0.03202500566840172, -0.048482246696949005, 0.171466663479805, -0.08870480954647064, 0.2702706456184387, -0.08358319848775864, 0.31863975524902344, -0.25187334418296814, -0.0422697439789772]
    Last 10:  [-0.3087368607521057, -0.055336885154247284, 0.6487718820571899, 2.1040916442871094, 0.2937208116054535, -0.10384551435709, -0.6375556588172913, 0.04321000725030899, 0.029359988868236542, -0.07044504582881927]
  WEIGHT: [1152, 768] | μ=0.000002

382_layers.23.mlp.down_proj: layers.23.mlp.down_proj (Linear)
  IN[0]:  [1, 7, 1152] | μ=0.000295 σ=0.028018
    First 10: [0.00013088221021462232, -0.0005922445561736822, 0.0040121180936694145, -0.014703478664159775, -0.0006124518695287406, 0.011283316649496555, -0.02457430772483349, -0.003689449978992343, 0.01932820864021778, 0.0004350010713096708]
    Last 10:  [0.04835622012615204, -0.0029636353719979525, 0.10496889054775238, -0.35711225867271423, -0.0022117462940514088, -0.001412244513630867, 0.026476502418518066, 0.016684092581272125, -0.003123219357803464, 0.003649825230240822]
  OUT[0]: [1, 7, 768] | μ=-0.000003 σ=0.007013
    First 10: [0.0012564724311232567, -0.00041205191519111395, -0.003087694989517331, -0.0004482174990698695, -0.0008019140223041177, -0.0013704855227842927, -0.002324463566765189, 0.0021277498453855515, -7.806951180100441e-05, 0.00023313546262215823]
    Last 10:  [0.01264757476747036, -0.0054664406925439835, -0.00577447609975934, 0.007187287788838148, -0.01551779080182314, -0.009138539433479309, -0.0025247656740248203, 0.005036311224102974, -0.015160895884037018, -0.007592188194394112]
  WEIGHT: [768, 1152] | μ=-0.000004

383_layers.23.mlp: layers.23.mlp (Gemma3MLP)
  IN[0]:  [1, 7, 768] | μ=0.012118 σ=0.588893
    First 10: [0.5724362134933472, 0.18382179737091064, -0.039059124886989594, 0.6380001306533813, -0.30752769112586975, 0.4224797189235687, 0.25983867049217224, -0.09699634462594986, -0.0745527520775795, 0.2763983905315399]
    Last 10:  [-0.10416929423809052, -0.16681945323944092, -0.20903778076171875, 0.23161587119102478, 0.9579293131828308, -0.30938223004341125, -0.29352453351020813, -0.6420341730117798, 0.027220435440540314, 0.030856870114803314]
  OUT[0]: [1, 7, 768] | μ=-0.000003 σ=0.007013
    First 10: [0.0012564724311232567, -0.00041205191519111395, -0.003087694989517331, -0.0004482174990698695, -0.0008019140223041177, -0.0013704855227842927, -0.002324463566765189, 0.0021277498453855515, -7.806951180100441e-05, 0.00023313546262215823]
    Last 10:  [0.01264757476747036, -0.0054664406925439835, -0.00577447609975934, 0.007187287788838148, -0.01551779080182314, -0.009138539433479309, -0.0025247656740248203, 0.005036311224102974, -0.015160895884037018, -0.007592188194394112]

384_layers.23.post_feedforward_layernorm: layers.23.post_feedforward_layernorm (Gemma3RMSNorm)
  IN[0]:  [1, 7, 768] | μ=-0.000003 σ=0.007013
    First 10: [0.0012564724311232567, -0.00041205191519111395, -0.003087694989517331, -0.0004482174990698695, -0.0008019140223041177, -0.0013704855227842927, -0.002324463566765189, 0.0021277498453855515, -7.806951180100441e-05, 0.00023313546262215823]
    Last 10:  [0.01264757476747036, -0.0054664406925439835, -0.00577447609975934, 0.007187287788838148, -0.01551779080182314, -0.009138539433479309, -0.0025247656740248203, 0.005036311224102974, -0.015160895884037018, -0.007592188194394112]
  OUT[0]: [1, 7, 768] | μ=15.959156 σ=765.469299
    First 10: [28.176244735717773, -33.85921859741211, -101.64606475830078, -18.55021095275879, -35.45656967163086, -84.20851135253906, -92.92117309570312, 75.3086929321289, -4.63818883895874, 18.471643447875977]
    Last 10:  [83.44525909423828, -19.312490463256836, -84.33599853515625, 122.01461791992188, -192.36846923828125, -196.8218536376953, -45.513999938964844, 63.81926345825195, -167.50921630859375, -159.90078735351562]
  WEIGHT: [768] | μ=282.086700
Debug data exported to hf_model_debug_operations.json and hf_model_debug_tensors.pkl
